{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from fetchData import fetchdata, cv_events\n",
    "import __MLP\n",
    "# from __MLP import getSamplers, convert_df_to_unsqueezed_tensor, train_sequential, clf_report\n",
    "import random\n",
    "\n",
    "import __Preprocessing\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.backends.cudnn.deterministic=True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def _init_fn(worker_id):\n",
    "    np.random.seed(int(seed))\n",
    "\n",
    "def test_data_process(X_test, y_test):\n",
    "    tensor_x1 = torch.Tensor(X_test.values).unsqueeze(1)\n",
    "    tensor_y1 = torch.Tensor(y_test.values).unsqueeze(1)\n",
    "    test_dataset = TensorDataset(tensor_x1,tensor_y1)\n",
    "\n",
    "    batch_size = 8\n",
    "\n",
    "    # train_sampler, test_sampler = __MLP.getSamplers(pheme_y, tensor_x2)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "    data = next(iter(test_dataloader))\n",
    "    print(\"mean: %s, std: %s\" %(data[0].mean(), data[0].std()))\n",
    "\n",
    "    test_size = int(tensor_y1.size(0))\n",
    "\n",
    "    print(\"Test Size\",test_size)\n",
    "\n",
    "    # predict_batch\n",
    "    return test_dataloader, test_size\n",
    "\n",
    "\n",
    "def test_data_process(X_test, y_test):\n",
    "\n",
    "    tensor_x1 = torch.Tensor(X_test.values).unsqueeze(1)\n",
    "    tensor_y1 = torch.Tensor(y_test.values).unsqueeze(1)\n",
    "    test_dataset = TensorDataset(tensor_x1,tensor_y1)\n",
    "\n",
    "    batch_size = 8\n",
    "\n",
    "    # train_sampler, test_sampler = __MLP.getSamplers(pheme_y, tensor_x2)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "    data = next(iter(test_dataloader))\n",
    "    print(\"mean: %s, std: %s\" %(data[0].mean(), data[0].std()))\n",
    "\n",
    "    test_size = int(tensor_y1.size(0))\n",
    "\n",
    "    print(\"Test Size\",test_size)\n",
    "\n",
    "    # predict_batch\n",
    "    return test_dataloader, test_size\n",
    "\n",
    "def predict(model, criterion, val_dataloader, val_size):\n",
    "    model.eval()\n",
    "    val_label_list = []\n",
    "    # val_preds_list = []\n",
    "    running_val_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "        f1_running = 0\n",
    "        for j, val in enumerate(val_dataloader, 0):\n",
    "            val_x, val_label = val\n",
    "            val_x, val_label = val_x.float(), val_label.float()\n",
    "            val_outputs = model(val_x)\n",
    "            val_preds = val_outputs.squeeze(1) > 0.0\n",
    "            f1_running += (f1_score(val_label, val_preds,zero_division=True) * val_x.size(0))\n",
    "            v_loss = criterion(val_outputs, val_label.unsqueeze(1))\n",
    "            val_loss += (v_loss.item() * val_x.size(0))\n",
    "            val_corrects += torch.sum(val_preds == val_label)\n",
    "            val_label_list.append(val_label)\n",
    "            running_val_preds.append(val_preds)\n",
    "\n",
    "    running_val_preds = torch.cat(running_val_preds, 0)\n",
    "    val_label_list = torch.cat(val_label_list, 0)\n",
    "    val_corrects = val_corrects\n",
    "    val_loss = val_loss/val_size\n",
    "    val_acc = val_corrects.double().numpy() / val_size\n",
    "    f1_running /= val_size\n",
    "    print(\"accuracy_score:\\t\\t%.4f\" % val_acc)\n",
    "    print('Precision Score:\\t%.4f' % precision_score(val_label_list,running_val_preds))\n",
    "    print('Recall Score:\\t\\t%.4f' % recall_score(val_label_list,running_val_preds))\n",
    "    print(\"f1_score:\\t\\t%.4f\" % f1_running)\n",
    "    print(\"Test_loss:\\t\\t%.4f\" % val_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final\n",
    "pheme_sparse_final = pd.read_csv('./data/_PHEME_sparse.csv')\n",
    "pheme_y = pd.read_csv('./data/_PHEME_target.csv').target\n",
    "pheme_pos_final = pd.read_csv('./data/_PHEME_postags.csv')\n",
    "pheme_thread_final_avg = pd.read_csv('./data/_PHEME_thread_avg.csv')\n",
    "pheme_thread_final_std = pd.read_csv('./data/_PHEME_thread_std.csv')\n",
    "\n",
    "ext_pos_final = pd.read_csv('./data/_PHEMEext_postags.csv')\n",
    "ext_sparse_final = pd.read_csv('./data/_PHEMEext_sparse.csv')\n",
    "ext_y = pd.read_csv('./data/_PHEMEext_text.csv').target\n",
    "ext_thread_final_avg = pd.read_csv('./data/_PHEMEext_thread_avg.csv')\n",
    "ext_thread_final_std = pd.read_csv('./data/_PHEMEext_thread_std.csv')\n",
    "\n",
    "pheme_bert_simple_normal = pd.read_csv('./data/_PHEME_Bert_final_simple_nrmzd.csv')\n",
    "ext_bert_simple_normal = pd.read_csv('./data/_PHEMEext_Bert_final_simple_nrmzd.csv')\n",
    "\n",
    "pheme_bert_brackets_normal = pd.read_csv('./data/_PHEME_Bert_final_brackets_nrmzd.csv')\n",
    "ext_bert_brackets_normal = pd.read_csv('./data/_PHEMEext_Bert_final_brackets_nrmzd.csv')\n",
    "\n",
    "pheme_event = pd.read_csv('./data/_PHEME_text.csv')['Event']\n",
    "ext_event = pd.read_csv('./data/_PHEMEext_text.csv').Event\n",
    "pheme_AVGw2v = pd.read_csv('./data/_PHEME_text_AVGw2v.csv').drop(['token'],axis=1)\n",
    "ext_AVGw2v = pd.read_csv('./data/_PHEMEext_text_AVGw2v.csv').drop(['token'],axis=1)\n",
    "\n",
    "pheme_root = pd.concat([pheme_sparse_final, pheme_pos_final],axis=1)\n",
    "ext_root = pd.concat([ext_sparse_final, ext_pos_final],axis=1)\n",
    "\n",
    "pheme_root_thread = pd.concat([pheme_root, pheme_thread_final_avg],axis=1)\n",
    "ext_root_thread = pd.concat([ext_root, ext_thread_final_avg],axis=1)\n",
    "\n",
    "pheme_total= pd.concat([pheme_root_thread, pheme_bert_simple_normal],axis=1)\n",
    "ext_total = pd.concat([ext_root_thread, ext_bert_simple_normal],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_event = pd.concat([pheme_event,ext_event],axis=0, ignore_index=True)\n",
    "all_y = pd.concat([pheme_y,ext_y],axis=0, ignore_index=True)\n",
    "\n",
    "all_root = pd.concat([pheme_root, ext_root],axis=0, ignore_index=True)\n",
    "all_thread = pd.concat([pheme_thread_final_avg, ext_thread_final_avg],axis=0, ignore_index=True)\n",
    "all_bert_simple = pd.concat([pheme_bert_simple_normal,ext_bert_simple_normal],axis=0,ignore_index=True)\n",
    "all_root_thread = pd.concat([pheme_root_thread,ext_root_thread],axis=0,ignore_index=True)\n",
    "all_total = pd.concat([pheme_total,ext_total],axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pheme_sparse_final (5802, 28)\n",
      "Index(['emoji_count', 'URLcount', 'has_media', 'Skepticism', 'MentionCount',\n",
      "       'FirstPersonPronoun', 'SecondPersonPronoun', 'ThirdPersonPronoun',\n",
      "       'test_auxiliary', 'test_tentat', 'test_certain', 'Numeral',\n",
      "       'char_count', 'word_count', 'HashTag', 'has_question', 'has_exclaim',\n",
      "       'has_period', 'capital_ratio', 'retweet_count', 'tweet_count',\n",
      "       'listed_count', 'friends_count', 'follower_count', 'followers/friend',\n",
      "       'favourites_count', 'account_age_days', 'verified'],\n",
      "      dtype='object') \n",
      "\n",
      "pheme_pos_final (5802, 21)\n",
      "{('n', 'pre/postposition/subordinating conjunction'), ('o', 'adverb'), ('#', 'Hashtag'), ('&', 'coordinating conjunction'), ('p', 'nominal + possessive'), ('d', 'nominal + verbal'), ('v', 'proper noun + possessive'), ('s', 'URL or email'), ('x', 'discourse marker'), (',', 'punctuation'), ('l', 'pronoun'), ('a', 'adjectivedeterminerother'), ('g', 'common noun'), ('t', 'verb incl. copula, auxiliaries'), ('^', 'proper noun'), ('r', 'verb particle'), ('u', 'existential there, predeterminers'), ('@', 'at-mention'), ('!', 'Interjection')} \n",
      "\n",
      "pheme_thread_final (5802, 52)\n",
      "Index(['depth', 'SUM FriendsCount', 'AVG FriendsCount', 'AVG WordCount',\n",
      "       'SUM WordCount', 'AVG CharCount', 'AVG HashTag', 'SUM HashTag',\n",
      "       'Ratio HashTag', 'SUM Url', 'AVG Url', 'RATIO Url', 'SUM Mention',\n",
      "       'AVG Mention', 'Ratio Mention', 'AVG Statues', 'AVG Listed',\n",
      "       'AVG Follower', 'AVG followers/friend', 'AVG favorite', 'Tweets Count',\n",
      "       'Ratio Verified', 'SUM Verified', 'SUM RT', 'AVG RT', 'AVG AccAge',\n",
      "       'thread_time', 'AVG Emoji', 'RATIO Emoji', 'Ratio Media',\n",
      "       'RATIO Question', 'RATIO Exclaim', 'RATIO Period', 'AVG FPP', 'AVG SPP',\n",
      "       'AVG TPP', 'AVG Skepticism', 'Ratio Skepticism', 'test_auxiliary',\n",
      "       'test_tentat', 'test_certain', 'root_user_ratio', 'unique_user_ratio',\n",
      "       'unique_user_sum', 'NodeThreadCount_0', 'NodeThreadCount_25',\n",
      "       'NodeThreadCount_5', 'NodeThreadCount_75', 'NodeThreadRatio_0',\n",
      "       'NodeThreadRatio_25', 'NodeThreadRatio_5', 'NodeThreadRatio_75'],\n",
      "      dtype='object') \n",
      "\n",
      "pheme_bert_simple_normal (5802, 768)\n",
      "Index(['BERTEmbed_0', 'BERTEmbed_1', 'BERTEmbed_2', 'BERTEmbed_3',\n",
      "       'BERTEmbed_4', 'BERTEmbed_5', 'BERTEmbed_6', 'BERTEmbed_7',\n",
      "       'BERTEmbed_8', 'BERTEmbed_9',\n",
      "       ...\n",
      "       'BERTEmbed_758', 'BERTEmbed_759', 'BERTEmbed_760', 'BERTEmbed_761',\n",
      "       'BERTEmbed_762', 'BERTEmbed_763', 'BERTEmbed_764', 'BERTEmbed_765',\n",
      "       'BERTEmbed_766', 'BERTEmbed_767'],\n",
      "      dtype='object', length=768) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"pheme_sparse_final\", pheme_sparse_final.shape)\n",
    "print(pheme_sparse_final.columns, \"\\n\")\n",
    "print(\"pheme_pos_final\", pheme_pos_final.shape)\n",
    "x = zip(pheme_pos_final.columns.values, ['Interjection', 'Hashtag', 'coordinating conjunction', 'punctuation', 'at-mention', 'proper noun', 'adjective' 'determiner' 'other', 'nominal + verbal',\n",
    "    'common noun', 'pronoun', 'pre/postposition/subordinating conjunction', 'adverb', 'nominal + possessive', 'verb particle', 'URL or email', 'verb incl. copula, auxiliaries',\n",
    " 'existential there, predeterminers', 'proper noun + possessive', 'discourse marker'])\n",
    "print(set(x), \"\\n\")\n",
    "print(\"pheme_thread_final\", pheme_thread_final_avg.shape)\n",
    "print(pheme_thread_final_avg.columns, \"\\n\")\n",
    "print(\"pheme_bert_simple_normal\", pheme_bert_simple_normal.shape)\n",
    "print(pheme_bert_simple_normal.columns, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pheme_sparse_final (623, 28)\n",
      "Index(['emoji_count', 'URLcount', 'has_media', 'Skepticism', 'MentionCount',\n",
      "       'FirstPersonPronoun', 'SecondPersonPronoun', 'ThirdPersonPronoun',\n",
      "       'test_auxiliary', 'test_tentat', 'test_certain', 'Numeral',\n",
      "       'char_count', 'word_count', 'HashTag', 'has_question', 'has_exclaim',\n",
      "       'has_period', 'capital_ratio', 'retweet_count', 'tweet_count',\n",
      "       'listed_count', 'friends_count', 'follower_count', 'followers/friend',\n",
      "       'favourites_count', 'account_age_days', 'verified'],\n",
      "      dtype='object') \n",
      "\n",
      "pheme_pos_final (623, 21)\n",
      "{('n', 'pre/postposition/subordinating conjunction'), ('o', 'adverb'), ('#', 'Hashtag'), ('&', 'coordinating conjunction'), ('p', 'nominal + possessive'), ('d', 'nominal + verbal'), ('v', 'proper noun + possessive'), ('s', 'URL or email'), ('x', 'discourse marker'), (',', 'punctuation'), ('l', 'pronoun'), ('a', 'adjectivedeterminerother'), ('g', 'common noun'), ('t', 'verb incl. copula, auxiliaries'), ('^', 'proper noun'), ('r', 'verb particle'), ('u', 'existential there, predeterminers'), ('@', 'at-mention'), ('!', 'Interjection')} \n",
      "\n",
      "pheme_thread_final (623, 52)\n",
      "Index(['depth', 'SUM FriendsCount', 'AVG FriendsCount', 'AVG WordCount',\n",
      "       'SUM WordCount', 'AVG CharCount', 'AVG HashTag', 'SUM HashTag',\n",
      "       'Ratio HashTag', 'SUM Url', 'AVG Url', 'RATIO Url', 'SUM Mention',\n",
      "       'AVG Mention', 'Ratio Mention', 'AVG Statues', 'AVG Listed',\n",
      "       'AVG Follower', 'AVG followers/friend', 'AVG favorite', 'Tweets Count',\n",
      "       'Ratio Verified', 'SUM Verified', 'SUM RT', 'AVG RT', 'AVG AccAge',\n",
      "       'thread_time', 'AVG Emoji', 'RATIO Emoji', 'Ratio Media',\n",
      "       'RATIO Question', 'RATIO Exclaim', 'RATIO Period', 'AVG FPP', 'AVG SPP',\n",
      "       'AVG TPP', 'AVG Skepticism', 'Ratio Skepticism', 'test_auxiliary',\n",
      "       'test_tentat', 'test_certain', 'root_user_ratio', 'unique_user_ratio',\n",
      "       'unique_user_sum', 'NodeThreadCount_0', 'NodeThreadCount_25',\n",
      "       'NodeThreadCount_5', 'NodeThreadCount_75', 'NodeThreadRatio_0',\n",
      "       'NodeThreadRatio_25', 'NodeThreadRatio_5', 'NodeThreadRatio_75'],\n",
      "      dtype='object') \n",
      "\n",
      "pheme_bert_simple_normal (623, 768)\n",
      "Index(['BERTEmbed_0', 'BERTEmbed_1', 'BERTEmbed_2', 'BERTEmbed_3',\n",
      "       'BERTEmbed_4', 'BERTEmbed_5', 'BERTEmbed_6', 'BERTEmbed_7',\n",
      "       'BERTEmbed_8', 'BERTEmbed_9',\n",
      "       ...\n",
      "       'BERTEmbed_758', 'BERTEmbed_759', 'BERTEmbed_760', 'BERTEmbed_761',\n",
      "       'BERTEmbed_762', 'BERTEmbed_763', 'BERTEmbed_764', 'BERTEmbed_765',\n",
      "       'BERTEmbed_766', 'BERTEmbed_767'],\n",
      "      dtype='object', length=768) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"pheme_sparse_final\", ext_sparse_final.shape)\n",
    "print(ext_sparse_final.columns, \"\\n\")\n",
    "print(\"pheme_pos_final\", ext_pos_final.shape)\n",
    "x = zip(pheme_pos_final.columns.values, ['Interjection', 'Hashtag', 'coordinating conjunction', 'punctuation', 'at-mention', 'proper noun', 'adjective' 'determiner' 'other', 'nominal + verbal',\n",
    "    'common noun', 'pronoun', 'pre/postposition/subordinating conjunction', 'adverb', 'nominal + possessive', 'verb particle', 'URL or email', 'verb incl. copula, auxiliaries',\n",
    " 'existential there, predeterminers', 'proper noun + possessive', 'discourse marker'])\n",
    "print(set(x), \"\\n\")\n",
    "print(\"pheme_thread_final\", ext_thread_final_avg.shape)\n",
    "print(ext_thread_final_avg.columns, \"\\n\")\n",
    "print(\"pheme_bert_simple_normal\", ext_bert_simple_normal.shape)\n",
    "print(ext_bert_simple_normal.columns, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed_value=42):\n",
    "    \"\"\"Set seed for reproducibility.\n",
    "    \"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.backends.cudnn.deterministic=True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed = 42\n",
    "\n",
    "def _init_fn(worker_id):\n",
    "    np.random.seed(int(seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataSize(tensor_x1, tensor_y1, tensor_x2, tensor_y2):\n",
    "    train_size = int(tensor_y1.size(0))\n",
    "    test_size = int(tensor_y2.size(0))\n",
    "\n",
    "    # print(\"Variables)\\n\\tTrain:%s\\n\\tTest: %s\"%(tensor_x1.size(),tensor_x2.size()))\n",
    "    # print(\"\\tTargets:%s \\ %s\"%(tensor_y1.size()[0],tensor_y2.size()[0]))\n",
    "    # print(\"Train Size\",train_size,\"Test Size\",test_size)\n",
    "    # print()\n",
    "    return train_size, test_size\n",
    "\n",
    "def reset_weights(m):\n",
    "  '''\n",
    "    Try resetting model weights to avoid\n",
    "    weight leakage.\n",
    "  '''\n",
    "  for layer in m.children():\n",
    "   if hasattr(layer, 'reset_parameters'):\n",
    "    # print(f'Reset trainable parameters of layer = {layer}')\n",
    "    print(\"Parameter Resetted\")\n",
    "    layer.reset_parameters()\n",
    "\n",
    "class writeLog():\n",
    "  def write(self, fileName, text):\n",
    "    print(text)\n",
    "    f=open(fileName,'a')\n",
    "    f.write(text)\n",
    "    f.write(\"\\n\")\n",
    "    f.close()\n",
    "  def writeWithoutCR(self, fileName, text):\n",
    "    f=open(fileName,'a')\n",
    "    f.write(text)\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_process(dataset, criterion, modelClass, target, epochs, events, verbose=True, scaling=False):\n",
    "\n",
    "    # cv_pd_list[?][0]은 Training cv_pd_list[?][1] Testing\n",
    "    cv_pd_list = []\n",
    "    data = pd.concat([dataset, events, target], axis=1)\n",
    "    NUM_EVENT = data.Event.unique().shape[0]\n",
    "    EVENTS = data.Event.unique()\n",
    "    results = {}\n",
    "    # modelClass.__class__\n",
    "\n",
    "    for i, d in enumerate(EVENTS):\n",
    "        df1, df2 = [x for _, x in data.groupby(data['Event'] != d)]\n",
    "        df1.reset_index(inplace=True, drop=True)\n",
    "        df2.reset_index(inplace=True, drop=True)\n",
    "        cv_pd_list.append([df2, df1])\n",
    "    \n",
    "    # for train, test in cv_pd_list:\n",
    "    #     print(\"Train: %s \\ Test: %s\" % (train.shape, test.shape))\n",
    "\n",
    "    log = writeLog()\n",
    "    modelname = modelClass.__name__\n",
    "    PREFIX = \"./Model/\"+modelname+\"_\"\n",
    "    log.write(PREFIX+\"log.txt\",f\"\\nSTARTING TEST of {epochs} EPOCH\\n\")\n",
    "\n",
    "    for index, fold in enumerate(cv_pd_list):\n",
    "\n",
    "        # DATA PREPARATION\n",
    "        train, test = fold\n",
    "        log.writeWithoutCR(PREFIX+\"log.txt\",f\"\\n----------------------------------------------------------------------------\\n> FOLD {int(index)+1}\\n----------------------------------------------------------------------------\")\n",
    "        print(f'> FOLD {int(index)+1}')\n",
    "        train_target = train.pop('target')\n",
    "        train.pop('Event').values\n",
    "        test_target = test.pop('target')\n",
    "        test.pop('Event')\n",
    "\n",
    "        if scaling==True:\n",
    "            scaler = StandardScaler()\n",
    "            train = pd.DataFrame(scaler.fit_transform(train))\n",
    "            test = pd.DataFrame(scaler.transform(test))\n",
    "\n",
    "        tensor_x1, tensor_y1, tensor_x2, tensor_y2 = __MLP.convert_df_to_unsqueezed_tensor(\n",
    "            train.values, train_target, test.values, test_target.values)\n",
    "        train_dataset = TensorDataset(tensor_x1, tensor_y1)\n",
    "        test_dataset = TensorDataset(tensor_x2, tensor_y2)\n",
    "\n",
    "        batch_size = 16\n",
    "\n",
    "        # train_sampler, test_sampler = __MLP.getSamplers(train_target, tensor_x2)\n",
    "        counts = np.bincount(train_target.values)\n",
    "        labels_weights = 1. / counts\n",
    "        weights = labels_weights[train_target.values]\n",
    "        train_sampler = WeightedRandomSampler(weights, len(weights))\n",
    "        test_sampler = SequentialSampler(tensor_x2)\n",
    "\n",
    "\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                    sampler=train_sampler, pin_memory=True, num_workers=0, worker_init_fn=_init_fn)\n",
    "        test_dataloader = DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                    shuffle=False, pin_memory=True, num_workers=0, worker_init_fn=_init_fn)\n",
    "\n",
    "        data = next(iter(train_dataloader))\n",
    "\n",
    "        train_size, test_size = getDataSize(tensor_x1, tensor_y1, tensor_x2, tensor_y2)\n",
    "        results\n",
    "\n",
    "        if verbose==True:\n",
    "            print(\"mean: %s, std: %s\" % (data[0].mean(), data[0].std()))\n",
    "            print(\"Train Size\",train_size,\"Test Size\",test_size)\n",
    "        log.writeWithoutCR(PREFIX+\"log.txt\", f\"\\nmean: {data[0].mean()}, std: {data[0].std()}\")\n",
    "        log.writeWithoutCR(PREFIX+\"log.txt\", f\"\\nTrain Size: {train_size}, Test Size: {test_size}\\n\")\n",
    "        \n",
    "\n",
    "        model = modelClass()\n",
    "        model.apply(reset_weights)\n",
    "        # for layer in model.children():\n",
    "        #     if hasattr(layer, 'reset_parameters'):\n",
    "        #         print(f'Reset trainable parameters of layer = {layer}')\n",
    "        #         layer.reset_parameters()\n",
    "\n",
    "\n",
    "        # model_sparse = sparse_model()\n",
    "        # criterion = nn.BCEWithLogitsLoss()\n",
    "        # optimizer = optim.SGD(model_sparse.parameters(), lr=0.01, momentum=0.9)\n",
    "        # optimizer = optim.Adam(model_sparse.parameters(), lr=5e-5, eps=1e-8, weight_decay=1e-7)\n",
    "        optimizer = AdamW(model.parameters(),\n",
    "                        # lr=5e-5,    # Default learning rate\n",
    "                        lr=8e-5,    # Default learning rate\n",
    "                        eps=1e-8,    # Default epsilon value\n",
    "                        weight_decay=1e-6\n",
    "                        )\n",
    "\n",
    "\n",
    "        total_steps = len(train_dataloader) * epochs\n",
    "        # print(f'length of tloader: {len(train_dataloader)}')\n",
    "        # print(f'total step: {total_steps}')\n",
    "        log.writeWithoutCR(PREFIX+\"log.txt\", f'total step: {total_steps}\\n')\n",
    "        \n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                    num_warmup_steps=0,  # Default value\n",
    "                                                    num_training_steps=total_steps)\n",
    "\n",
    "        # print(f'Model: {modelname}')\n",
    "        PATH = \"./Model/\"+modelname+\"_\"+str(index+1)+\".pt\"\n",
    "        # print(f'PATH: {PATH}')\n",
    "        log.writeWithoutCR(PREFIX+\"log.txt\", f'PATH: {PATH}')\n",
    "\n",
    "        training_acc = []\n",
    "        training_loss = []\n",
    "        # train_acc, train_loss, val_acc, val_loss_list = __MLP.train_sequential(model=model, num_epochs=epochs, patience=patience, criterion=criterion, optimizer=optimizer, scheduler=scheduler, train_loader=train_dataloader, train_size=train_size, test_loader=test_dataloader, test_size=test_size, PATH=PATH)\n",
    "\n",
    "        # Run the training loop for defined number of epochs\n",
    "        for epoch in range(0, epochs):\n",
    "\n",
    "            # Print epoch\n",
    "            if (verbose!=False):\n",
    "                # pass\n",
    "                print(f'Starting epoch {epoch+1}')\n",
    "            elif (verbose!=True):\n",
    "                if epoch%50 == 49:\n",
    "                    print(f'Starting epoch {epoch+1}')\n",
    "            # Set current loss value\n",
    "            current_loss = 0.0\n",
    "            running_corrects = 0.0\n",
    "            running_loss = 0.0\n",
    "\n",
    "            # Iterate over the DataLoader for training data\n",
    "            for i, data in enumerate(train_dataloader, 0):\n",
    "\n",
    "                # Get inputs\n",
    "                inputs, targets = data\n",
    "\n",
    "                # Zero the gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Perform forward pass\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                outputs = outputs.view(outputs.size(0), -1)\n",
    "\n",
    "                # Compute Prediction Outputs\n",
    "                # preds = outputs.squeeze(1) > 0.0\n",
    "                preds = outputs > 0.0\n",
    "\n",
    "                # Compute loss\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == targets.data).data\n",
    "\n",
    "                # Perform backward pass\n",
    "                loss.backward()\n",
    "\n",
    "                # Perform optimization and Scheduler\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "\n",
    "                # Print statistics\n",
    "                # current_loss += loss.item() # 원본\n",
    "                # if i % len(train_dataloader) == len(train_dataloader)-1:\n",
    "                #     print('Loss after mini-batch %5d: %.3f' %\n",
    "                #           (i + 1, current_loss / i+1))\n",
    "\n",
    "                current_loss += loss.item() * inputs.size(0)\n",
    "                if verbose == True:\n",
    "                    if i % len(train_dataloader) == len(train_dataloader)-1:\n",
    "                        print(\"Loss/ACC after mini-batch %5d: %.3f / %.4f\" %\n",
    "                            (i + 1, current_loss / train_size, running_corrects/train_size))\n",
    "\n",
    "            # epoch_acc = running_corrects.double() / train_size\n",
    "            epoch_acc = running_corrects / train_size\n",
    "            epoch_loss = running_loss / train_size\n",
    "            training_acc.append(epoch_acc)\n",
    "            training_loss.append(epoch_loss)\n",
    "            # print('Epoch {}/{}\\tTrain) Acc: {:.4f}, Loss: {:.4f}'.format(epoch+1,\n",
    "                                                                        #  epochs, epoch_acc, epoch_loss))\n",
    "            \n",
    "        # Process is complete.\n",
    "        if verbose==True:\n",
    "            print('>> Training process has finished. Saving trained model and starting Testing')\n",
    "\n",
    "        # Print about testing\n",
    "\n",
    "        # Saving the model\n",
    "        torch.save(model.state_dict(), PATH)\n",
    "\n",
    "        # Evaluation for this fold\n",
    "        correct, total = 0, 0\n",
    "        val_corrects=0\n",
    "        f1_batch_epoch = 0\n",
    "        val_label_list = []\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # Iterate over the test data and generate predictions\n",
    "            for i, data in enumerate(test_dataloader, 0):\n",
    "\n",
    "                # Get inputs\n",
    "                inputs, targets = data\n",
    "\n",
    "                # Generate outputs\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                # Set total and correct\n",
    "                outputs = outputs.view(outputs.size(0), -1).float()\n",
    "                predicted = (outputs > 0.0).float()\n",
    "                correct += (predicted == targets).float().sum().item()\n",
    "\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                #!\n",
    "                preds = (outputs > 0.0).float()\n",
    "                # running_loss += loss.item() * inputs.size(0)\n",
    "                val_corrects += torch.sum(preds == targets.data).data\n",
    "                # f1_batch = f1_score(targets.cpu(), outputs.sigmoid().cpu() > 0.5, average='macro')\n",
    "                f1_batch = f1_score(targets.cpu(), preds, average='macro')\n",
    "                f1_batch_epoch += f1_batch * inputs.size(0)\n",
    "                # f1_running += (f1_score(targets, preds, average='macro') * inputs.size(0))\n",
    "                total += targets.size(0)\n",
    "            \n",
    "            if verbose==True:\n",
    "                # Print accuracy\n",
    "                print('Accuracy for fold %d: %f %%' % (index, 100.0 * correct / total))\n",
    "                # print('Accuracy-2 for fold %d: %f %%' % (index, 100.0 * val_corrects / total))\n",
    "                # print('F1 Score-2 for fold %d: %f ->  %%' %(index, f1_score(targets, preds, zero_division=False)))\n",
    "                # print('F1 Score-3 for fold %d: %f %%' %(index, f1_score(targets, predicted, zero_division=False)))\n",
    "                print('F1 Score for fold %d: %f %%' %(index, f1_batch_epoch / total))\n",
    "                print('Loss for fold %d: %f %%' %(index, val_loss / total))\n",
    "                # print('F1 Score-5 for fold %d: %f %%' %(index, f1_batch_epoch / test_size))\n",
    "                # print('F1 Score-6 for fold %d: %f %%' %(index, f1_running / test_size))\n",
    "            \n",
    "            results[index] = [100.0 * (correct / total), 100.0 * f1_batch_epoch / total, val_loss / total]\n",
    "            log.writeWithoutCR(PREFIX+\"log.txt\", f'\\nAccuracy for fold {index+1}: {100.0 * correct / total:.3f}')\n",
    "            log.writeWithoutCR(PREFIX+\"log.txt\", f'\\nF1 Score for fold {index+1}: {f1_batch_epoch / total:.3f}')\n",
    "            log.writeWithoutCR(PREFIX+\"log.txt\", f'\\nLoss for fold {index+1}: {val_loss / total:.3f}')\n",
    "\n",
    "    # ---------------------------- Print fold results ---------------------------- #\n",
    "    # log.write(PREFIX+\"log.txt\",f\"FOLD {int(index)+1}\\n----------------------------------------------------------------------------\")\n",
    "\n",
    "    # print(f'K-FOLD CROSS VALIDATION RESULTS FOR {NUM_EVENT} FOLDS')\n",
    "    log.write(PREFIX+\"log.txt\", f'\\n\\n----------------------------------------------------------------------------\\n>>>K-FOLD CROSS VALIDATION RESULTS FOR {NUM_EVENT} FOLDS\\n----------------------------------------------------------------------------')\n",
    "\n",
    "    # print('----------------------------------------------------------------------------')\n",
    "    acc_sum = 0.0\n",
    "    f1_sum = 0.0\n",
    "    loss_sum = 0.0\n",
    "    for key, value in results.items():\n",
    "        # print(f'Fold {key}: Acc {value[0]}, F1 {value[1]} %')\n",
    "        log.write(PREFIX+\"log.txt\", f'Fold {key}: Acc {value[0]}, F1 {value[1]}')\n",
    "        acc_sum += value[0]\n",
    "        f1_sum += value[1]\n",
    "        loss_sum += value[2]\n",
    "    # print(f'Average: {acc_sum/len(results.items())} %')\n",
    "    # print(f'F1: {f1_sum/len(results.items())} %')\n",
    "    log.write(PREFIX+\"log.txt\", f'Average: {acc_sum/len(results.items()):.3f}%')\n",
    "    log.write(PREFIX+\"log.txt\", f'F1: {f1_sum/len(results.items()):.3f}%')\n",
    "    log.write(PREFIX+\"log.txt\", f'Loss: {loss_sum/len(results.items()):.3f}\\n')\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epochs_diff(testing_results):\n",
    "    string = \"\"\n",
    "    print('----------------------------------------------------------------------------')\n",
    "    for loop in testing_results:\n",
    "        acc_sum = 0.0\n",
    "        f1_sum = 0.0\n",
    "        loss=0.0\n",
    "        for key, value in loop.items():\n",
    "            print(f'Fold {key}: Acc {value[0]:.2f}%, F1 {value[1]:.2f}%, Loss {value[2]:.2f}')\n",
    "            acc_sum += value[0]\n",
    "            f1_sum += value[1]\n",
    "            loss += value[2]\n",
    "        string+=f'Average: {acc_sum/len(loop.items()):.2f}%\\n'\n",
    "        string+=f'F1: {f1_sum/len(loop.items()):.2f}%\\n'\n",
    "        string+=f'Loss: {loss/len(loop.items()):.2f}\\n'\n",
    "        # print(f'Average: {acc_sum/len(loop.items()):.2f} %')\n",
    "        # print(f'F1: {f1_sum/len(loop.items()):.2f} %')\n",
    "        print(\"-----------------------------\")\n",
    "        return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class root_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(root_model, self).__init__()  # 1*20\n",
    "        self.layers = nn.Sequential(\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(49, 16),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(16, 5),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(5, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "# model = sparse_model()\n",
    "dataset = all_root\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# testing_epochs = [3]\n",
    "testing_results = []\n",
    "\n",
    "writeLog().write(\"./Model/\"+root_model.__name__+\"_\"+\"log.txt\",f\"\\n\\n************************************************************\\nSTARTING A CROSS-VALIDATION ... {testing_epochs} epochs\\n************************************************************\")\n",
    "writeLog().write(\"./Model/\"+root_model.__name__+\"_\"+\"log.txt\",f\"TIME: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\")\n",
    "writeLog().write(\"./Model/\"+root_model.__name__+\"_\"+\"log.txt\",f\"LAYER: {[layer for layer in root_model().children()]}\")\n",
    "\n",
    "for epoch in testing_epochs:\n",
    "    result = cv_process(dataset, criterion, modelClass=root_model, events=all_event, target=all_y, epochs=epoch, verbose=False, scaling=False)\n",
    "    testing_results.append(result)\n",
    "\n",
    "# writeLog().writeWithoutCR(\"./Model/\"+root_model.__name__+\"_\"+\"log.txt\",f\"RESULT:\\n{epochs_diff(testing_results)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 FOLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num event: 5\n",
      "Events: ['charliehebdo' 'ferguson' 'germanwings-crash' 'ottawashooting'\n",
      " 'sydneysiege']\n",
      "cv_pd_list: 5\n",
      "cv_pd_list[0]: 2\n",
      "\n",
      "Epochs: 5\n",
      "FOLD 1\n",
      "----------------------------------------------------------------------------\n",
      "length of tloader: 233\n",
      "total step: 1165\n",
      "PATH: ./Model/sparse_model_1.pt\n",
      "Num event: 5\n",
      "Events: ['charliehebdo' 'ferguson' 'germanwings-crash' 'ottawashooting'\n",
      " 'sydneysiege']\n",
      "cv_pd_list: 5\n",
      "cv_pd_list[0]: 2\n",
      "\n",
      "Epochs: 10\n",
      "FOLD 1\n",
      "----------------------------------------------------------------------------\n",
      "length of tloader: 233\n",
      "total step: 2330\n",
      "PATH: ./Model/sparse_model_1.pt\n",
      "Num event: 5\n",
      "Events: ['charliehebdo' 'ferguson' 'germanwings-crash' 'ottawashooting'\n",
      " 'sydneysiege']\n",
      "cv_pd_list: 5\n",
      "cv_pd_list[0]: 2\n",
      "\n",
      "Epochs: 25\n",
      "FOLD 1\n",
      "----------------------------------------------------------------------------\n",
      "length of tloader: 233\n",
      "total step: 5825\n",
      "PATH: ./Model/sparse_model_1.pt\n"
     ]
    }
   ],
   "source": [
    "class sparse_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(sparse_model, self).__init__()  # 1*20\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(28, 10),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(10, 4),\n",
    "            nn.ELU(),\n",
    "            # nn.Linear(12, 8),\n",
    "            # nn.ELU(),\n",
    "            nn.Linear(4, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "model = sparse_model()\n",
    "dataset = pheme_sparse_final\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "testing_epochs = [5, 10, 25]\n",
    "testing_results = []\n",
    "\n",
    "for epoch in testing_epochs:\n",
    "    result = cv_process(dataset, criterion, modelClass=sparse_model, events=pheme_event, target=pheme_y, epochs=epoch, verbose=False, scaling=True)\n",
    "    testing_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sparse_model()\n",
    "dataset = pheme_sparse_final\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "testing_epochs = [5, 10, 25]\n",
    "testing_results = []\n",
    "\n",
    "for epoch in testing_epochs:\n",
    "    result = cv_process(dataset, criterion, modelClass=sparse_model, events=pheme_event, target=pheme_y, epochs=epoch, verbose=False, scaling=True)\n",
    "    testing_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_diff(testing_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epochs: 5\n",
      "FOLD 1\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(0.0065), std: tensor(1.1613)\n",
      "Train Size 3723 Test Size 2079\n",
      "PATH: ./Model/pos_model_1.pt\n",
      "\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 2\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(0.0023), std: tensor(0.9391)\n",
      "Train Size 4659 Test Size 1143\n",
      "PATH: ./Model/pos_model_2.pt\n",
      "\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 3\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.1089), std: tensor(0.8013)\n",
      "Train Size 5333 Test Size 469\n",
      "PATH: ./Model/pos_model_3.pt\n",
      "\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 4\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.0209), std: tensor(0.8833)\n",
      "Train Size 4912 Test Size 890\n",
      "PATH: ./Model/pos_model_4.pt\n",
      "\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 5\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.0034), std: tensor(1.0404)\n",
      "Train Size 4581 Test Size 1221\n",
      "PATH: ./Model/pos_model_5.pt\n",
      "\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 39.53823953823954, F1 26.86820737672125 %\n",
      "Fold 1: Acc 71.47856517935259, F1 46.104740907800505 %\n",
      "Fold 2: Acc 53.94456289978679, F1 33.5764348649522 %\n",
      "Fold 3: Acc 46.62921348314607, F1 41.35887256678678 %\n",
      "Fold 4: Acc 51.433251433251435, F1 32.72608439603775 %\n",
      "Average: 52.60476650675529 %\n",
      "F1: 36.126868022459696 %\n",
      "\n",
      "Epochs: 10\n",
      "FOLD 1\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.0985), std: tensor(0.8399)\n",
      "Train Size 3723 Test Size 2079\n",
      "PATH: ./Model/pos_model_1.pt\n",
      "\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 2\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(0.0456), std: tensor(1.0386)\n",
      "Train Size 4659 Test Size 1143\n",
      "PATH: ./Model/pos_model_2.pt\n",
      "\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 3\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.0704), std: tensor(0.8518)\n",
      "Train Size 5333 Test Size 469\n",
      "PATH: ./Model/pos_model_3.pt\n",
      "\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 4\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.0226), std: tensor(1.2086)\n",
      "Train Size 4912 Test Size 890\n",
      "PATH: ./Model/pos_model_4.pt\n",
      "\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 5\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.0250), std: tensor(1.0153)\n",
      "Train Size 4581 Test Size 1221\n",
      "PATH: ./Model/pos_model_5.pt\n",
      "\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 47.52284752284752, F1 31.821332223257276 %\n",
      "Fold 1: Acc 46.63167104111986, F1 31.17782263993101 %\n",
      "Fold 2: Acc 49.68017057569296, F1 32.006905031474176 %\n",
      "Fold 3: Acc 50.337078651685395, F1 33.32335035823068 %\n",
      "Fold 4: Acc 45.7002457002457, F1 40.396591823736536 %\n",
      "Average: 47.974402698318286 %\n",
      "F1: 33.74520041532593 %\n",
      "\n",
      "Epochs: 50\n",
      "FOLD 1\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.0109), std: tensor(0.9370)\n",
      "Train Size 3723 Test Size 2079\n",
      "PATH: ./Model/pos_model_1.pt\n",
      "\n",
      "Starting epoch 50\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 2\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.0012), std: tensor(1.0711)\n",
      "Train Size 4659 Test Size 1143\n",
      "PATH: ./Model/pos_model_2.pt\n",
      "\n",
      "Starting epoch 50\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 3\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.0178), std: tensor(0.8974)\n",
      "Train Size 5333 Test Size 469\n",
      "PATH: ./Model/pos_model_3.pt\n",
      "\n",
      "Starting epoch 50\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 4\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(0.0356), std: tensor(1.0480)\n",
      "Train Size 4912 Test Size 890\n",
      "PATH: ./Model/pos_model_4.pt\n",
      "\n",
      "Starting epoch 50\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 5\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(0.0470), std: tensor(1.1285)\n",
      "Train Size 4581 Test Size 1221\n",
      "PATH: ./Model/pos_model_5.pt\n",
      "\n",
      "Starting epoch 50\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 62.86676286676287, F1 38.379059029112426 %\n",
      "Fold 1: Acc 65.61679790026247, F1 38.808553058297846 %\n",
      "Fold 2: Acc 61.62046908315565, F1 37.9602938386346 %\n",
      "Fold 3: Acc 61.68539325842697, F1 39.27056336955693 %\n",
      "Fold 4: Acc 56.92055692055692, F1 35.53090098481438 %\n",
      "Average: 61.74199600583297 %\n",
      "F1: 37.98987405608324 %\n",
      "\n",
      "Epochs: 100\n",
      "FOLD 1\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(0.0135), std: tensor(0.8967)\n",
      "Train Size 3723 Test Size 2079\n",
      "PATH: ./Model/pos_model_1.pt\n",
      "\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 2\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.1009), std: tensor(0.8081)\n",
      "Train Size 4659 Test Size 1143\n",
      "PATH: ./Model/pos_model_2.pt\n",
      "\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 3\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.0177), std: tensor(1.0858)\n",
      "Train Size 5333 Test Size 469\n",
      "PATH: ./Model/pos_model_3.pt\n",
      "\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 4\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.0111), std: tensor(1.0682)\n",
      "Train Size 4912 Test Size 890\n",
      "PATH: ./Model/pos_model_4.pt\n",
      "\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 5\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(0.0233), std: tensor(1.1368)\n",
      "Train Size 4581 Test Size 1221\n",
      "PATH: ./Model/pos_model_5.pt\n",
      "\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 60.17316017316018, F1 37.37296865875964 %\n",
      "Fold 1: Acc 56.78040244969379, F1 35.46118187773473 %\n",
      "Fold 2: Acc 60.76759061833689, F1 37.56796363114952 %\n",
      "Fold 3: Acc 65.95505617977528, F1 40.15891076747383 %\n",
      "Fold 4: Acc 62.24406224406225, F1 38.20486488835205 %\n",
      "Average: 61.184054333005676 %\n",
      "F1: 37.753177964693954 %\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 39.54, F1 26.87 %\n",
      "Fold 1: Acc 71.48, F1 46.10 %\n",
      "Fold 2: Acc 53.94, F1 33.58 %\n",
      "Fold 3: Acc 46.63, F1 41.36 %\n",
      "Fold 4: Acc 51.43, F1 32.73 %\n",
      "Average: 52.60 %\n",
      "F1: 36.13 %\n",
      "-----------------------------\n",
      "Fold 0: Acc 47.52, F1 31.82 %\n",
      "Fold 1: Acc 46.63, F1 31.18 %\n",
      "Fold 2: Acc 49.68, F1 32.01 %\n",
      "Fold 3: Acc 50.34, F1 33.32 %\n",
      "Fold 4: Acc 45.70, F1 40.40 %\n",
      "Average: 47.97 %\n",
      "F1: 33.75 %\n",
      "-----------------------------\n",
      "Fold 0: Acc 62.87, F1 38.38 %\n",
      "Fold 1: Acc 65.62, F1 38.81 %\n",
      "Fold 2: Acc 61.62, F1 37.96 %\n",
      "Fold 3: Acc 61.69, F1 39.27 %\n",
      "Fold 4: Acc 56.92, F1 35.53 %\n",
      "Average: 61.74 %\n",
      "F1: 37.99 %\n",
      "-----------------------------\n",
      "Fold 0: Acc 60.17, F1 37.37 %\n",
      "Fold 1: Acc 56.78, F1 35.46 %\n",
      "Fold 2: Acc 60.77, F1 37.57 %\n",
      "Fold 3: Acc 65.96, F1 40.16 %\n",
      "Fold 4: Acc 62.24, F1 38.20 %\n",
      "Average: 61.18 %\n",
      "F1: 37.75 %\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "class pos_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(pos_model, self).__init__() # 1*20\n",
    "        self.layers = nn.Sequential(\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(21, 4, bias=True),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "        \n",
    "model = pos_model()\n",
    "dataset = pheme_pos_final\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# epochs = 10\n",
    "\n",
    "testing_epochs = [5,10,50,100]\n",
    "testing_results = []\n",
    "\n",
    "for epoch in testing_epochs:\n",
    "    result = cv_process(dataset, criterion,scaling=True, modelClass=pos_model, events=pheme_event, target=pheme_y, epochs=epoch, verbose=False)\n",
    "    testing_results.append(result)\n",
    "\n",
    "epochs_diff(testing_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epochs: 5\n",
      "FOLD 1\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.0044), std: tensor(1.0529)\n",
      "Train Size 3723 Test Size 2079\n",
      "PATH: ./Model/pos_model_1.pt\n",
      "\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 2\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.0009), std: tensor(1.1191)\n",
      "Train Size 4659 Test Size 1143\n",
      "PATH: ./Model/pos_model_2.pt\n",
      "\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 3\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.0236), std: tensor(0.9941)\n",
      "Train Size 5333 Test Size 469\n",
      "PATH: ./Model/pos_model_3.pt\n",
      "\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 4\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.1289), std: tensor(0.8273)\n",
      "Train Size 4912 Test Size 890\n",
      "PATH: ./Model/pos_model_4.pt\n",
      "\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 5\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(0.0653), std: tensor(1.3192)\n",
      "Train Size 4581 Test Size 1221\n",
      "PATH: ./Model/pos_model_5.pt\n",
      "\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 67.003367003367, F1 39.907398831915046 %\n",
      "Fold 1: Acc 65.26684164479441, F1 38.52599515232862 %\n",
      "Fold 2: Acc 50.53304904051173, F1 47.592452484123164 %\n",
      "Fold 3: Acc 53.25842696629214, F1 45.822148741535564 %\n",
      "Fold 4: Acc 56.838656838656846, F1 54.18129406399201 %\n",
      "Average: 58.58006829872443 %\n",
      "F1: 45.20585785477888 %\n",
      "\n",
      "Epochs: 10\n",
      "FOLD 1\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(0.0629), std: tensor(1.0356)\n",
      "Train Size 3723 Test Size 2079\n",
      "PATH: ./Model/pos_model_1.pt\n",
      "\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 2\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.0918), std: tensor(0.9120)\n",
      "Train Size 4659 Test Size 1143\n",
      "PATH: ./Model/pos_model_2.pt\n",
      "\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 3\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.0531), std: tensor(0.9712)\n",
      "Train Size 5333 Test Size 469\n",
      "PATH: ./Model/pos_model_3.pt\n",
      "\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 4\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.0959), std: tensor(0.8026)\n",
      "Train Size 4912 Test Size 890\n",
      "PATH: ./Model/pos_model_4.pt\n",
      "\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 5\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.0276), std: tensor(1.0595)\n",
      "Train Size 4581 Test Size 1221\n",
      "PATH: ./Model/pos_model_5.pt\n",
      "\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 24.38672438672439, F1 20.468201745430235 %\n",
      "Fold 1: Acc 62.117235345581804, F1 36.936805929350754 %\n",
      "Fold 2: Acc 54.15778251599147, F1 49.189671053785005 %\n",
      "Fold 3: Acc 54.044943820224724, F1 48.14237409133258 %\n",
      "Fold 4: Acc 43.980343980343974, F1 38.895702871734024 %\n",
      "Average: 47.73740600977327 %\n",
      "F1: 38.72655113832651 %\n",
      "\n",
      "Epochs: 50\n",
      "FOLD 1\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.1560), std: tensor(0.7305)\n",
      "Train Size 3723 Test Size 2079\n",
      "PATH: ./Model/pos_model_1.pt\n",
      "\n",
      "Starting epoch 50\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 2\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.0107), std: tensor(0.8342)\n",
      "Train Size 4659 Test Size 1143\n",
      "PATH: ./Model/pos_model_2.pt\n",
      "\n",
      "Starting epoch 50\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 3\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.0212), std: tensor(1.0188)\n",
      "Train Size 5333 Test Size 469\n",
      "PATH: ./Model/pos_model_3.pt\n",
      "\n",
      "Starting epoch 50\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 4\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(0.0420), std: tensor(1.2470)\n",
      "Train Size 4912 Test Size 890\n",
      "PATH: ./Model/pos_model_4.pt\n",
      "\n",
      "Starting epoch 50\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 5\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(0.0394), std: tensor(1.1382)\n",
      "Train Size 4581 Test Size 1221\n",
      "PATH: ./Model/pos_model_5.pt\n",
      "\n",
      "Starting epoch 50\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 52.76575276575276, F1 33.93599354421541 %\n",
      "Fold 1: Acc 61.679790026246714, F1 36.9684801361494 %\n",
      "Fold 2: Acc 63.965884861407254, F1 41.184679491128186 %\n",
      "Fold 3: Acc 66.51685393258427, F1 40.368519812647115 %\n",
      "Fold 4: Acc 60.60606060606061, F1 37.15688485841448 %\n",
      "Average: 61.106868438410324 %\n",
      "F1: 37.92291156851092 %\n",
      "\n",
      "Epochs: 100\n",
      "FOLD 1\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(0.0393), std: tensor(1.0845)\n",
      "Train Size 3723 Test Size 2079\n",
      "PATH: ./Model/pos_model_1.pt\n",
      "\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 2\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(0.0416), std: tensor(1.0064)\n",
      "Train Size 4659 Test Size 1143\n",
      "PATH: ./Model/pos_model_2.pt\n",
      "\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 3\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(0.0904), std: tensor(0.9498)\n",
      "Train Size 5333 Test Size 469\n",
      "PATH: ./Model/pos_model_3.pt\n",
      "\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 4\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.1189), std: tensor(0.7992)\n",
      "Train Size 4912 Test Size 890\n",
      "PATH: ./Model/pos_model_4.pt\n",
      "\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 5\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.0017), std: tensor(1.4327)\n",
      "Train Size 4581 Test Size 1221\n",
      "PATH: ./Model/pos_model_5.pt\n",
      "\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 59.59595959595959, F1 37.16138324241472 %\n",
      "Fold 1: Acc 60.54243219597551, F1 36.90208472076462 %\n",
      "Fold 2: Acc 62.89978678038379, F1 38.3027695543917 %\n",
      "Fold 3: Acc 68.76404494382022, F1 40.66505194954207 %\n",
      "Fold 4: Acc 62.48976248976249, F1 38.37117148077574 %\n",
      "Average: 62.858397201180324 %\n",
      "F1: 38.28049218957777 %\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 67.00, F1 39.91 %\n",
      "Fold 1: Acc 65.27, F1 38.53 %\n",
      "Fold 2: Acc 50.53, F1 47.59 %\n",
      "Fold 3: Acc 53.26, F1 45.82 %\n",
      "Fold 4: Acc 56.84, F1 54.18 %\n",
      "Average: 58.58 %\n",
      "F1: 45.21 %\n",
      "-----------------------------\n",
      "Fold 0: Acc 24.39, F1 20.47 %\n",
      "Fold 1: Acc 62.12, F1 36.94 %\n",
      "Fold 2: Acc 54.16, F1 49.19 %\n",
      "Fold 3: Acc 54.04, F1 48.14 %\n",
      "Fold 4: Acc 43.98, F1 38.90 %\n",
      "Average: 47.74 %\n",
      "F1: 38.73 %\n",
      "-----------------------------\n",
      "Fold 0: Acc 52.77, F1 33.94 %\n",
      "Fold 1: Acc 61.68, F1 36.97 %\n",
      "Fold 2: Acc 63.97, F1 41.18 %\n",
      "Fold 3: Acc 66.52, F1 40.37 %\n",
      "Fold 4: Acc 60.61, F1 37.16 %\n",
      "Average: 61.11 %\n",
      "F1: 37.92 %\n",
      "-----------------------------\n",
      "Fold 0: Acc 59.60, F1 37.16 %\n",
      "Fold 1: Acc 60.54, F1 36.90 %\n",
      "Fold 2: Acc 62.90, F1 38.30 %\n",
      "Fold 3: Acc 68.76, F1 40.67 %\n",
      "Fold 4: Acc 62.49, F1 38.37 %\n",
      "Average: 62.86 %\n",
      "F1: 38.28 %\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "class pos_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(pos_model, self).__init__() # 1*20\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(21, 8, bias=True),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(8, 3, bias=True),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(3, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = pos_model()\n",
    "dataset = pheme_pos_final\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# epochs = 10\n",
    "\n",
    "testing_epochs = [5,10,50,100]\n",
    "testing_results = []\n",
    "\n",
    "for epoch in testing_epochs:\n",
    "    result = cv_process(dataset, criterion,scaling=True, modelClass=pos_model, events=pheme_event, target=pheme_y, epochs=epoch, verbose=False)\n",
    "    testing_results.append(result)\n",
    "\n",
    "epochs_diff(testing_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epochs: 5\n",
      "FOLD 1\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.0002), std: tensor(0.7655)\n",
      "Train Size 3723 Test Size 2079\n",
      "PATH: ./Model/thread_model_1.pt\n",
      "\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 2\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.0363), std: tensor(0.9062)\n",
      "Train Size 4659 Test Size 1143\n",
      "PATH: ./Model/thread_model_2.pt\n",
      "\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 3\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.0468), std: tensor(0.7949)\n",
      "Train Size 5333 Test Size 469\n",
      "PATH: ./Model/thread_model_3.pt\n",
      "\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 4\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.0074), std: tensor(0.8713)\n",
      "Train Size 4912 Test Size 890\n",
      "PATH: ./Model/thread_model_4.pt\n",
      "\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 5\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(0.0179), std: tensor(0.8346)\n",
      "Train Size 4581 Test Size 1221\n",
      "PATH: ./Model/thread_model_5.pt\n",
      "\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 36.988936988936985, F1 25.38188213787148 %\n",
      "Fold 1: Acc 39.37007874015748, F1 26.630708272585085 %\n",
      "Fold 2: Acc 53.73134328358209, F1 34.779954598996035 %\n",
      "Fold 3: Acc 50.674157303370784, F1 32.76653063885132 %\n",
      "Fold 4: Acc 48.56674856674857, F1 32.04769304366099 %\n",
      "Average: 45.86625297655918 %\n",
      "F1: 30.32135373839298 %\n",
      "\n",
      "Epochs: 10\n",
      "FOLD 1\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(0.0576), std: tensor(1.1579)\n",
      "Train Size 3723 Test Size 2079\n",
      "PATH: ./Model/thread_model_1.pt\n",
      "\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 2\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(0.0167), std: tensor(1.1809)\n",
      "Train Size 4659 Test Size 1143\n",
      "PATH: ./Model/thread_model_2.pt\n",
      "\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 3\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(0.0028), std: tensor(0.7622)\n",
      "Train Size 5333 Test Size 469\n",
      "PATH: ./Model/thread_model_3.pt\n",
      "\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 4\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(0.1118), std: tensor(1.2979)\n",
      "Train Size 4912 Test Size 890\n",
      "PATH: ./Model/thread_model_4.pt\n",
      "\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 5\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(0.0057), std: tensor(1.0343)\n",
      "Train Size 4581 Test Size 1221\n",
      "PATH: ./Model/thread_model_5.pt\n",
      "\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 32.323232323232325, F1 22.242902487922322 %\n",
      "Fold 1: Acc 44.794400699912515, F1 30.573811832457135 %\n",
      "Fold 2: Acc 48.61407249466951, F1 31.895784136397687 %\n",
      "Fold 3: Acc 54.9438202247191, F1 36.21446142477745 %\n",
      "Fold 4: Acc 55.11875511875511, F1 34.258110875578126 %\n",
      "Average: 47.15885617225771 %\n",
      "F1: 31.037014151426547 %\n",
      "\n",
      "Epochs: 25\n",
      "FOLD 1\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.0523), std: tensor(0.8635)\n",
      "Train Size 3723 Test Size 2079\n",
      "PATH: ./Model/thread_model_1.pt\n",
      "\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 2\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.0238), std: tensor(0.8793)\n",
      "Train Size 4659 Test Size 1143\n",
      "PATH: ./Model/thread_model_2.pt\n",
      "\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 3\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(0.1464), std: tensor(1.2488)\n",
      "Train Size 5333 Test Size 469\n",
      "PATH: ./Model/thread_model_3.pt\n",
      "\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 4\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.0276), std: tensor(1.0209)\n",
      "Train Size 4912 Test Size 890\n",
      "PATH: ./Model/thread_model_4.pt\n",
      "\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 5\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.0076), std: tensor(0.8709)\n",
      "Train Size 4581 Test Size 1221\n",
      "PATH: ./Model/thread_model_5.pt\n",
      "\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 53.72775372775372, F1 34.75305777011101 %\n",
      "Fold 1: Acc 53.71828521434821, F1 34.493338736058085 %\n",
      "Fold 2: Acc 50.10660980810234, F1 33.00027953773203 %\n",
      "Fold 3: Acc 54.831460674157306, F1 34.835161091219575 %\n",
      "Fold 4: Acc 51.92465192465192, F1 33.547998822782006 %\n",
      "Average: 52.86175226980269 %\n",
      "F1: 34.12596719158054 %\n",
      "\n",
      "Epochs: 50\n",
      "FOLD 1\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.0476), std: tensor(0.7602)\n",
      "Train Size 3723 Test Size 2079\n",
      "PATH: ./Model/thread_model_1.pt\n",
      "\n",
      "Starting epoch 50\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 2\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(0.0780), std: tensor(0.9558)\n",
      "Train Size 4659 Test Size 1143\n",
      "PATH: ./Model/thread_model_2.pt\n",
      "\n",
      "Starting epoch 50\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 3\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(0.0555), std: tensor(1.1709)\n",
      "Train Size 5333 Test Size 469\n",
      "PATH: ./Model/thread_model_3.pt\n",
      "\n",
      "Starting epoch 50\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 4\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(0.0114), std: tensor(0.8682)\n",
      "Train Size 4912 Test Size 890\n",
      "PATH: ./Model/thread_model_4.pt\n",
      "\n",
      "Starting epoch 50\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 5\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.0517), std: tensor(0.9281)\n",
      "Train Size 4581 Test Size 1221\n",
      "PATH: ./Model/thread_model_5.pt\n",
      "\n",
      "Starting epoch 50\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 47.33044733044733, F1 31.052141433331983 %\n",
      "Fold 1: Acc 58.180227471566056, F1 36.77936562411126 %\n",
      "Fold 2: Acc 54.15778251599147, F1 33.53674425499533 %\n",
      "Fold 3: Acc 58.651685393258425, F1 36.611619402400336 %\n",
      "Fold 4: Acc 56.67485667485668, F1 36.19358553652769 %\n",
      "Average: 54.998999877223994 %\n",
      "F1: 34.834691250273316 %\n",
      "\n",
      "Epochs: 100\n",
      "FOLD 1\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(0.0610), std: tensor(1.6003)\n",
      "Train Size 3723 Test Size 2079\n",
      "PATH: ./Model/thread_model_1.pt\n",
      "\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 2\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.0908), std: tensor(0.8764)\n",
      "Train Size 4659 Test Size 1143\n",
      "PATH: ./Model/thread_model_2.pt\n",
      "\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 3\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.0259), std: tensor(1.3755)\n",
      "Train Size 5333 Test Size 469\n",
      "PATH: ./Model/thread_model_3.pt\n",
      "\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 4\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(0.0156), std: tensor(1.4117)\n",
      "Train Size 4912 Test Size 890\n",
      "PATH: ./Model/thread_model_4.pt\n",
      "\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 5\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.0128), std: tensor(0.9107)\n",
      "Train Size 4581 Test Size 1221\n",
      "PATH: ./Model/thread_model_5.pt\n",
      "\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 54.44925444925445, F1 34.694488136466994 %\n",
      "Fold 1: Acc 54.505686789151355, F1 34.96203977466757 %\n",
      "Fold 2: Acc 54.15778251599147, F1 34.93773844395762 %\n",
      "Fold 3: Acc 60.67415730337079, F1 37.499274072944004 %\n",
      "Fold 4: Acc 60.1965601965602, F1 37.66439168447254 %\n",
      "Average: 56.79668825086566 %\n",
      "F1: 35.95158642250175 %\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 36.99, F1 25.38 %\n",
      "Fold 1: Acc 39.37, F1 26.63 %\n",
      "Fold 2: Acc 53.73, F1 34.78 %\n",
      "Fold 3: Acc 50.67, F1 32.77 %\n",
      "Fold 4: Acc 48.57, F1 32.05 %\n",
      "Average: 45.87 %\n",
      "F1: 30.32 %\n",
      "-----------------------------\n",
      "Fold 0: Acc 32.32, F1 22.24 %\n",
      "Fold 1: Acc 44.79, F1 30.57 %\n",
      "Fold 2: Acc 48.61, F1 31.90 %\n",
      "Fold 3: Acc 54.94, F1 36.21 %\n",
      "Fold 4: Acc 55.12, F1 34.26 %\n",
      "Average: 47.16 %\n",
      "F1: 31.04 %\n",
      "-----------------------------\n",
      "Fold 0: Acc 53.73, F1 34.75 %\n",
      "Fold 1: Acc 53.72, F1 34.49 %\n",
      "Fold 2: Acc 50.11, F1 33.00 %\n",
      "Fold 3: Acc 54.83, F1 34.84 %\n",
      "Fold 4: Acc 51.92, F1 33.55 %\n",
      "Average: 52.86 %\n",
      "F1: 34.13 %\n",
      "-----------------------------\n",
      "Fold 0: Acc 47.33, F1 31.05 %\n",
      "Fold 1: Acc 58.18, F1 36.78 %\n",
      "Fold 2: Acc 54.16, F1 33.54 %\n",
      "Fold 3: Acc 58.65, F1 36.61 %\n",
      "Fold 4: Acc 56.67, F1 36.19 %\n",
      "Average: 55.00 %\n",
      "F1: 34.83 %\n",
      "-----------------------------\n",
      "Fold 0: Acc 54.45, F1 34.69 %\n",
      "Fold 1: Acc 54.51, F1 34.96 %\n",
      "Fold 2: Acc 54.16, F1 34.94 %\n",
      "Fold 3: Acc 60.67, F1 37.50 %\n",
      "Fold 4: Acc 60.20, F1 37.66 %\n",
      "Average: 56.80 %\n",
      "F1: 35.95 %\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "class thread_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(thread_model, self).__init__() # 1*20\n",
    "        self.layers = nn.Sequential(\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(52, 12, bias=True),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(12, 8, bias=True),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(8, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = thread_model()\n",
    "dataset = pheme_thread_final_avg\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# epochs = 10\n",
    "\n",
    "testing_epochs = [5,10,25,50,100]\n",
    "testing_results = []\n",
    "\n",
    "for epoch in testing_epochs:\n",
    "    result = cv_process(dataset, criterion, modelClass=thread_model, events=pheme_event, target=pheme_y, epochs=epoch, verbose=False, scaling=True)\n",
    "    testing_results.append(result)\n",
    "\n",
    "epochs_diff(testing_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class thread_model2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(thread_model, self).__init__() # 1*20\n",
    "        self.layers = nn.Sequential(\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(52, 8, bias=True),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(8, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "    \n",
    "model = thread_model()\n",
    "dataset = pheme_thread_final_avg\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# epochs = 10\n",
    "\n",
    "testing_epochs = [5,10,25,50,100]\n",
    "testing_results = []\n",
    "\n",
    "for epoch in testing_epochs:\n",
    "    result = cv_process(dataset, criterion, modelClass=thread_model, events=pheme_event, target=pheme_y, epochs=epoch, verbose=False, scaling=True)\n",
    "    testing_results.append(result)\n",
    "\n",
    "epochs_diff(testing_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPARSE + POS + Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class all_sparse_model(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(all_sparse_model, self).__init__() # 1*20\n",
    "#         self.layers = nn.Sequential(\n",
    "#             nn.Dropout(0.3),\n",
    "#             nn.Linear(52, 8),\n",
    "#             nn.ELU(),\n",
    "#             nn.Dropout(0.3),\n",
    "#             nn.Linear(8, 1)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.layers(x)\n",
    "#         return x\n",
    "\n",
    "class all_sparse_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(all_sparse_model, self).__init__() # 1*20\n",
    "        self.layers = nn.Sequential(\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(101, 32),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(32, 10),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(10, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FOLD 1\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(17072.7910), std: tensor(317982.8125)\n",
      "Variables)\n",
      "\tTrain:torch.Size([3723, 1, 101])\n",
      "\tTest: torch.Size([2079, 1, 101])\n",
      "Train Size 3723 Test Size 2079\n",
      "\n",
      "Model: all_sparse_model\n",
      "Epochs: 50\n",
      "PATH: ./Model/all_sparse_model_1.pt\n",
      "\n",
      "Starting epoch 25\n",
      "Starting epoch 50\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 2\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(24228.5430), std: tensor(385957.3750)\n",
      "Variables)\n",
      "\tTrain:torch.Size([4659, 1, 101])\n",
      "\tTest: torch.Size([1143, 1, 101])\n",
      "Train Size 4659 Test Size 1143\n",
      "\n",
      "Model: all_sparse_model\n",
      "Epochs: 50\n",
      "PATH: ./Model/all_sparse_model_2.pt\n",
      "\n",
      "Starting epoch 25\n",
      "Starting epoch 50\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 3\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(29769.6191), std: tensor(536090.5625)\n",
      "Variables)\n",
      "\tTrain:torch.Size([5333, 1, 101])\n",
      "\tTest: torch.Size([469, 1, 101])\n",
      "Train Size 5333 Test Size 469\n",
      "\n",
      "Model: all_sparse_model\n",
      "Epochs: 50\n",
      "PATH: ./Model/all_sparse_model_3.pt\n",
      "\n",
      "Starting epoch 25\n",
      "Starting epoch 50\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 4\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(5097.3018), std: tensor(68551.0312)\n",
      "Variables)\n",
      "\tTrain:torch.Size([4912, 1, 101])\n",
      "\tTest: torch.Size([890, 1, 101])\n",
      "Train Size 4912 Test Size 890\n",
      "\n",
      "Model: all_sparse_model\n",
      "Epochs: 50\n",
      "PATH: ./Model/all_sparse_model_4.pt\n",
      "\n",
      "Starting epoch 25\n",
      "Starting epoch 50\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 5\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(8906.4893), std: tensor(151588.9531)\n",
      "Variables)\n",
      "\tTrain:torch.Size([4581, 1, 101])\n",
      "\tTest: torch.Size([1221, 1, 101])\n",
      "Train Size 4581 Test Size 1221\n",
      "\n",
      "Model: all_sparse_model\n",
      "Epochs: 50\n",
      "PATH: ./Model/all_sparse_model_5.pt\n",
      "\n",
      "Starting epoch 25\n",
      "Starting epoch 50\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "----------------------------------------------------------------------------\"\n",
      "Fold 0: Acc 39.05723905723906, F1 26.4128939535082 %\n",
      "Fold 1: Acc 68.76640419947506, F1 41.459138407056436 %\n",
      "Fold 2: Acc 46.908315565031984, F1 28.639343528710832 %\n",
      "Fold 3: Acc 49.325842696629216, F1 35.073662392986954 %\n",
      "Fold 4: Acc 56.75675675675676, F1 43.708553007567744 %\n",
      "Average: 52.16291165502641 %\n",
      "F1: 35.05871825796603 %\n",
      "\n",
      "FOLD 1\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(9545.6904), std: tensor(184576.2031)\n",
      "Variables)\n",
      "\tTrain:torch.Size([3723, 1, 101])\n",
      "\tTest: torch.Size([2079, 1, 101])\n",
      "Train Size 3723 Test Size 2079\n",
      "\n",
      "Model: all_sparse_model\n",
      "Epochs: 100\n",
      "PATH: ./Model/all_sparse_model_1.pt\n",
      "\n",
      "Starting epoch 25\n",
      "Starting epoch 50\n",
      "Starting epoch 75\n",
      "Starting epoch 100\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 2\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(26170.6816), std: tensor(394063.1875)\n",
      "Variables)\n",
      "\tTrain:torch.Size([4659, 1, 101])\n",
      "\tTest: torch.Size([1143, 1, 101])\n",
      "Train Size 4659 Test Size 1143\n",
      "\n",
      "Model: all_sparse_model\n",
      "Epochs: 100\n",
      "PATH: ./Model/all_sparse_model_2.pt\n",
      "\n",
      "Starting epoch 25\n",
      "Starting epoch 50\n",
      "Starting epoch 75\n",
      "Starting epoch 100\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 3\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(19657.9434), std: tensor(358120.6875)\n",
      "Variables)\n",
      "\tTrain:torch.Size([5333, 1, 101])\n",
      "\tTest: torch.Size([469, 1, 101])\n",
      "Train Size 5333 Test Size 469\n",
      "\n",
      "Model: all_sparse_model\n",
      "Epochs: 100\n",
      "PATH: ./Model/all_sparse_model_3.pt\n",
      "\n",
      "Starting epoch 25\n",
      "Starting epoch 50\n",
      "Starting epoch 75\n",
      "Starting epoch 100\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 4\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(11433.3564), std: tensor(137543.0938)\n",
      "Variables)\n",
      "\tTrain:torch.Size([4912, 1, 101])\n",
      "\tTest: torch.Size([890, 1, 101])\n",
      "Train Size 4912 Test Size 890\n",
      "\n",
      "Model: all_sparse_model\n",
      "Epochs: 100\n",
      "PATH: ./Model/all_sparse_model_4.pt\n",
      "\n",
      "Starting epoch 25\n",
      "Starting epoch 50\n",
      "Starting epoch 75\n",
      "Starting epoch 100\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 5\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(16683.5918), std: tensor(271039.1562)\n",
      "Variables)\n",
      "\tTrain:torch.Size([4581, 1, 101])\n",
      "\tTest: torch.Size([1221, 1, 101])\n",
      "Train Size 4581 Test Size 1221\n",
      "\n",
      "Model: all_sparse_model\n",
      "Epochs: 100\n",
      "PATH: ./Model/all_sparse_model_5.pt\n",
      "\n",
      "Starting epoch 25\n",
      "Starting epoch 50\n",
      "Starting epoch 75\n",
      "Starting epoch 100\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "----------------------------------------------------------------------------\"\n",
      "Fold 0: Acc 76.76767676767676, F1 61.705682185135544 %\n",
      "Fold 1: Acc 35.43307086614173, F1 24.33364579280107 %\n",
      "Fold 2: Acc 45.62899786780384, F1 29.10781513741769 %\n",
      "Fold 3: Acc 58.42696629213483, F1 34.96229365874696 %\n",
      "Fold 4: Acc 56.01965601965602, F1 34.57303363713342 %\n",
      "Average: 54.455273562682635 %\n",
      "F1: 36.93649408224694 %\n"
     ]
    }
   ],
   "source": [
    "model = all_sparse_model()\n",
    "dataset = pd.concat([pheme_sparse_final, pheme_pos_final, pheme_thread_final_avg],axis=1)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# epochs = 10\n",
    "\n",
    "testing_epochs = [50,100]\n",
    "testing_results = []\n",
    "\n",
    "for epoch in testing_epochs:\n",
    "    result = cv_process(dataset, criterion, events=pheme_event, target=pheme_y, epochs=epoch, verbose=False)\n",
    "    testing_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: Acc 39.06, F1 26.41 %\n",
      "Fold 1: Acc 68.77, F1 41.46 %\n",
      "Fold 2: Acc 46.91, F1 28.64 %\n",
      "Fold 3: Acc 49.33, F1 35.07 %\n",
      "Fold 4: Acc 56.76, F1 43.71 %\n",
      "Average: 52.16 %\n",
      "F1: 35.06 %\n",
      "-----------------------------\n",
      "Fold 0: Acc 76.77, F1 61.71 %\n",
      "Fold 1: Acc 35.43, F1 24.33 %\n",
      "Fold 2: Acc 45.63, F1 29.11 %\n",
      "Fold 3: Acc 58.43, F1 34.96 %\n",
      "Fold 4: Acc 56.02, F1 34.57 %\n",
      "Average: 54.46 %\n",
      "F1: 36.94 %\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "epochs_diff(testing_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class all_sparse_model(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(all_sparse_model, self).__init__() # 1*20\n",
    "#         self.layers = nn.Sequential(\n",
    "#             nn.Dropout(0.3),\n",
    "#             nn.Linear(52, 8),\n",
    "#             nn.ELU(),\n",
    "#             nn.Dropout(0.3),\n",
    "#             nn.Linear(8, 1)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.layers(x)\n",
    "#         return x\n",
    "\n",
    "class all_sparse_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(all_sparse_model, self).__init__() # 1*20\n",
    "        self.layers = nn.Sequential(\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(101, 50),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(50, 25),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(25, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FOLD 1\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(2469.1448), std: tensor(24742.1504)\n",
      "Variables)\n",
      "\tTrain:torch.Size([3723, 1, 101])\n",
      "\tTest: torch.Size([2079, 1, 101])\n",
      "Train Size 3723 Test Size 2079\n",
      "\n",
      "Model: all_sparse_model\n",
      "Epochs: 100\n",
      "PATH: ./Model/all_sparse_model_1.pt\n",
      "\n",
      "Starting epoch 25\n",
      "Starting epoch 50\n",
      "Starting epoch 75\n",
      "Starting epoch 100\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 2\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(16121.2100), std: tensor(338595.2188)\n",
      "Variables)\n",
      "\tTrain:torch.Size([4659, 1, 101])\n",
      "\tTest: torch.Size([1143, 1, 101])\n",
      "Train Size 4659 Test Size 1143\n",
      "\n",
      "Model: all_sparse_model\n",
      "Epochs: 100\n",
      "PATH: ./Model/all_sparse_model_2.pt\n",
      "\n",
      "Starting epoch 25\n",
      "Starting epoch 50\n",
      "Starting epoch 75\n",
      "Starting epoch 100\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 3\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(23605.2148), std: tensor(437834.4062)\n",
      "Variables)\n",
      "\tTrain:torch.Size([5333, 1, 101])\n",
      "\tTest: torch.Size([469, 1, 101])\n",
      "Train Size 5333 Test Size 469\n",
      "\n",
      "Model: all_sparse_model\n",
      "Epochs: 100\n",
      "PATH: ./Model/all_sparse_model_3.pt\n",
      "\n",
      "Starting epoch 25\n",
      "Starting epoch 50\n",
      "Starting epoch 75\n",
      "Starting epoch 100\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 4\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(29522.2871), std: tensor(417365.5938)\n",
      "Variables)\n",
      "\tTrain:torch.Size([4912, 1, 101])\n",
      "\tTest: torch.Size([890, 1, 101])\n",
      "Train Size 4912 Test Size 890\n",
      "\n",
      "Model: all_sparse_model\n",
      "Epochs: 100\n",
      "PATH: ./Model/all_sparse_model_4.pt\n",
      "\n",
      "Starting epoch 25\n",
      "Starting epoch 50\n",
      "Starting epoch 75\n",
      "Starting epoch 100\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 5\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(8530.1680), std: tensor(101227.5547)\n",
      "Variables)\n",
      "\tTrain:torch.Size([4581, 1, 101])\n",
      "\tTest: torch.Size([1221, 1, 101])\n",
      "Train Size 4581 Test Size 1221\n",
      "\n",
      "Model: all_sparse_model\n",
      "Epochs: 100\n",
      "PATH: ./Model/all_sparse_model_5.pt\n",
      "\n",
      "Starting epoch 25\n",
      "Starting epoch 50\n",
      "Starting epoch 75\n",
      "Starting epoch 100\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "----------------------------------------------------------------------------\"\n",
      "Fold 0: Acc 49.2063492063492, F1 32.42209492718736 %\n",
      "Fold 1: Acc 66.49168853893264, F1 39.1211548160054 %\n",
      "Fold 2: Acc 46.05543710021322, F1 31.361124809905753 %\n",
      "Fold 3: Acc 56.067415730337075, F1 34.48041883001717 %\n",
      "Fold 4: Acc 57.98525798525799, F1 36.403507724574446 %\n",
      "Average: 55.16122971221803 %\n",
      "F1: 34.75766022153802 %\n",
      "\n",
      "FOLD 1\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(7891.3657), std: tensor(109087.1875)\n",
      "Variables)\n",
      "\tTrain:torch.Size([3723, 1, 101])\n",
      "\tTest: torch.Size([2079, 1, 101])\n",
      "Train Size 3723 Test Size 2079\n",
      "\n",
      "Model: all_sparse_model\n",
      "Epochs: 200\n",
      "PATH: ./Model/all_sparse_model_1.pt\n",
      "\n",
      "Starting epoch 25\n",
      "Starting epoch 50\n",
      "Starting epoch 75\n",
      "Starting epoch 100\n",
      "Starting epoch 125\n",
      "Starting epoch 150\n",
      "Starting epoch 175\n",
      "Starting epoch 200\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 2\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(17690.9941), std: tensor(375247.8750)\n",
      "Variables)\n",
      "\tTrain:torch.Size([4659, 1, 101])\n",
      "\tTest: torch.Size([1143, 1, 101])\n",
      "Train Size 4659 Test Size 1143\n",
      "\n",
      "Model: all_sparse_model\n",
      "Epochs: 200\n",
      "PATH: ./Model/all_sparse_model_2.pt\n",
      "\n",
      "Starting epoch 25\n",
      "Starting epoch 50\n",
      "Starting epoch 75\n",
      "Starting epoch 100\n",
      "Starting epoch 125\n",
      "Starting epoch 150\n",
      "Starting epoch 175\n",
      "Starting epoch 200\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 3\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(32302.1367), std: tensor(482222.)\n",
      "Variables)\n",
      "\tTrain:torch.Size([5333, 1, 101])\n",
      "\tTest: torch.Size([469, 1, 101])\n",
      "Train Size 5333 Test Size 469\n",
      "\n",
      "Model: all_sparse_model\n",
      "Epochs: 200\n",
      "PATH: ./Model/all_sparse_model_3.pt\n",
      "\n",
      "Starting epoch 25\n",
      "Starting epoch 50\n",
      "Starting epoch 75\n",
      "Starting epoch 100\n",
      "Starting epoch 125\n",
      "Starting epoch 150\n",
      "Starting epoch 175\n",
      "Starting epoch 200\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 4\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(7491.3950), std: tensor(125358.2031)\n",
      "Variables)\n",
      "\tTrain:torch.Size([4912, 1, 101])\n",
      "\tTest: torch.Size([890, 1, 101])\n",
      "Train Size 4912 Test Size 890\n",
      "\n",
      "Model: all_sparse_model\n",
      "Epochs: 200\n",
      "PATH: ./Model/all_sparse_model_4.pt\n",
      "\n",
      "Starting epoch 25\n",
      "Starting epoch 50\n",
      "Starting epoch 75\n",
      "Starting epoch 100\n",
      "Starting epoch 125\n",
      "Starting epoch 150\n",
      "Starting epoch 175\n",
      "Starting epoch 200\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 5\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(9058.3760), std: tensor(179827.0312)\n",
      "Variables)\n",
      "\tTrain:torch.Size([4581, 1, 101])\n",
      "\tTest: torch.Size([1221, 1, 101])\n",
      "Train Size 4581 Test Size 1221\n",
      "\n",
      "Model: all_sparse_model\n",
      "Epochs: 200\n",
      "PATH: ./Model/all_sparse_model_5.pt\n",
      "\n",
      "Starting epoch 25\n",
      "Starting epoch 50\n",
      "Starting epoch 75\n",
      "Starting epoch 100\n",
      "Starting epoch 125\n",
      "Starting epoch 150\n",
      "Starting epoch 175\n",
      "Starting epoch 200\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "----------------------------------------------------------------------------\"\n",
      "Fold 0: Acc 57.527657527657524, F1 36.29203052083241 %\n",
      "Fold 1: Acc 58.70516185476815, F1 36.35981173672334 %\n",
      "Fold 2: Acc 50.31982942430704, F1 32.48032527225317 %\n",
      "Fold 3: Acc 59.662921348314605, F1 36.23716352125175 %\n",
      "Fold 4: Acc 60.85176085176085, F1 37.87707671599813 %\n",
      "Average: 57.41346620136163 %\n",
      "F1: 35.84928155341176 %\n"
     ]
    }
   ],
   "source": [
    "model = all_sparse_model()\n",
    "dataset = pd.concat([pheme_sparse_final, pheme_pos_final, pheme_thread_final_avg],axis=1)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# epochs = 10\n",
    "\n",
    "testing_epochs = [100,200]\n",
    "testing_results = []\n",
    "\n",
    "for epoch in testing_epochs:\n",
    "    result = cv_process(dataset, criterion, events=pheme_event, target=pheme_y, epochs=epoch, verbose=False)\n",
    "    testing_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: Acc 49.21, F1 32.42 %\n",
      "Fold 1: Acc 66.49, F1 39.12 %\n",
      "Fold 2: Acc 46.06, F1 31.36 %\n",
      "Fold 3: Acc 56.07, F1 34.48 %\n",
      "Fold 4: Acc 57.99, F1 36.40 %\n",
      "Average: 55.16 %\n",
      "F1: 34.76 %\n",
      "-----------------------------\n",
      "Fold 0: Acc 57.53, F1 36.29 %\n",
      "Fold 1: Acc 58.71, F1 36.36 %\n",
      "Fold 2: Acc 50.32, F1 32.48 %\n",
      "Fold 3: Acc 59.66, F1 36.24 %\n",
      "Fold 4: Acc 60.85, F1 37.88 %\n",
      "Average: 57.41 %\n",
      "F1: 35.85 %\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "epochs_diff(testing_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPARSE + POS + Thread Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "class all_sparse_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(all_sparse_model, self).__init__() # 1*20\n",
    "        self.layers = nn.Sequential(\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(101, 20),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(20, 6),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(6, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FOLD 1\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.0077), std: tensor(0.8630)\n",
      "Variables)\n",
      "\tTrain:torch.Size([3723, 1, 101])\n",
      "\tTest: torch.Size([2079, 1, 101])\n",
      "Train Size 3723 Test Size 2079\n",
      "\n",
      "Model: all_sparse_model\n",
      "Epochs: 5\n",
      "PATH: ./Model/all_sparse_model_1.pt\n",
      "\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 2\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.0158), std: tensor(0.8134)\n",
      "Variables)\n",
      "\tTrain:torch.Size([4659, 1, 101])\n",
      "\tTest: torch.Size([1143, 1, 101])\n",
      "Train Size 4659 Test Size 1143\n",
      "\n",
      "Model: all_sparse_model\n",
      "Epochs: 5\n",
      "PATH: ./Model/all_sparse_model_2.pt\n",
      "\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 3\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(0.0249), std: tensor(0.9493)\n",
      "Variables)\n",
      "\tTrain:torch.Size([5333, 1, 101])\n",
      "\tTest: torch.Size([469, 1, 101])\n",
      "Train Size 5333 Test Size 469\n",
      "\n",
      "Model: all_sparse_model\n",
      "Epochs: 5\n",
      "PATH: ./Model/all_sparse_model_3.pt\n",
      "\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 4\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(0.0092), std: tensor(0.9185)\n",
      "Variables)\n",
      "\tTrain:torch.Size([4912, 1, 101])\n",
      "\tTest: torch.Size([890, 1, 101])\n",
      "Train Size 4912 Test Size 890\n",
      "\n",
      "Model: all_sparse_model\n",
      "Epochs: 5\n",
      "PATH: ./Model/all_sparse_model_4.pt\n",
      "\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 5\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.0355), std: tensor(0.9679)\n",
      "Variables)\n",
      "\tTrain:torch.Size([4581, 1, 101])\n",
      "\tTest: torch.Size([1221, 1, 101])\n",
      "Train Size 4581 Test Size 1221\n",
      "\n",
      "Model: all_sparse_model\n",
      "Epochs: 5\n",
      "PATH: ./Model/all_sparse_model_5.pt\n",
      "\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "----------------------------------------------------------------------------\"\n",
      "Fold 0: Acc 52.23665223665223, F1 33.62999482784151 %\n",
      "Fold 1: Acc 62.904636920384945, F1 37.00682109454008 %\n",
      "Fold 2: Acc 57.995735607675904, F1 37.08026404554385 %\n",
      "Fold 3: Acc 67.97752808988764, F1 40.162444689445074 %\n",
      "Fold 4: Acc 68.38656838656838, F1 41.957686017134264 %\n",
      "Average: 61.900224248233826 %\n",
      "F1: 37.967442134900956 %\n",
      "\n",
      "FOLD 1\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(0.0345), std: tensor(1.0960)\n",
      "Variables)\n",
      "\tTrain:torch.Size([3723, 1, 101])\n",
      "\tTest: torch.Size([2079, 1, 101])\n",
      "Train Size 3723 Test Size 2079\n",
      "\n",
      "Model: all_sparse_model\n",
      "Epochs: 10\n",
      "PATH: ./Model/all_sparse_model_1.pt\n",
      "\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 2\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.0457), std: tensor(0.9302)\n",
      "Variables)\n",
      "\tTrain:torch.Size([4659, 1, 101])\n",
      "\tTest: torch.Size([1143, 1, 101])\n",
      "Train Size 4659 Test Size 1143\n",
      "\n",
      "Model: all_sparse_model\n",
      "Epochs: 10\n",
      "PATH: ./Model/all_sparse_model_2.pt\n",
      "\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 3\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.0091), std: tensor(0.8579)\n",
      "Variables)\n",
      "\tTrain:torch.Size([5333, 1, 101])\n",
      "\tTest: torch.Size([469, 1, 101])\n",
      "Train Size 5333 Test Size 469\n",
      "\n",
      "Model: all_sparse_model\n",
      "Epochs: 10\n",
      "PATH: ./Model/all_sparse_model_3.pt\n",
      "\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 4\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(0.0352), std: tensor(1.0227)\n",
      "Variables)\n",
      "\tTrain:torch.Size([4912, 1, 101])\n",
      "\tTest: torch.Size([890, 1, 101])\n",
      "Train Size 4912 Test Size 890\n",
      "\n",
      "Model: all_sparse_model\n",
      "Epochs: 10\n",
      "PATH: ./Model/all_sparse_model_4.pt\n",
      "\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 5\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.0408), std: tensor(0.9565)\n",
      "Variables)\n",
      "\tTrain:torch.Size([4581, 1, 101])\n",
      "\tTest: torch.Size([1221, 1, 101])\n",
      "Train Size 4581 Test Size 1221\n",
      "\n",
      "Model: all_sparse_model\n",
      "Epochs: 10\n",
      "PATH: ./Model/all_sparse_model_5.pt\n",
      "\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "----------------------------------------------------------------------------\"\n",
      "Fold 0: Acc 65.27176527176528, F1 39.284890936855206 %\n",
      "Fold 1: Acc 70.07874015748031, F1 42.55490361594885 %\n",
      "Fold 2: Acc 64.60554371002132, F1 39.970917090343065 %\n",
      "Fold 3: Acc 73.82022471910112, F1 42.61212365015915 %\n",
      "Fold 4: Acc 69.04176904176904, F1 40.913317353508525 %\n",
      "Average: 68.56360858002742 %\n",
      "F1: 41.06723052936296 %\n",
      "\n",
      "FOLD 1\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.0851), std: tensor(0.8830)\n",
      "Variables)\n",
      "\tTrain:torch.Size([3723, 1, 101])\n",
      "\tTest: torch.Size([2079, 1, 101])\n",
      "Train Size 3723 Test Size 2079\n",
      "\n",
      "Model: all_sparse_model\n",
      "Epochs: 25\n",
      "PATH: ./Model/all_sparse_model_1.pt\n",
      "\n",
      "Starting epoch 25\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 2\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.0170), std: tensor(0.8779)\n",
      "Variables)\n",
      "\tTrain:torch.Size([4659, 1, 101])\n",
      "\tTest: torch.Size([1143, 1, 101])\n",
      "Train Size 4659 Test Size 1143\n",
      "\n",
      "Model: all_sparse_model\n",
      "Epochs: 25\n",
      "PATH: ./Model/all_sparse_model_2.pt\n",
      "\n",
      "Starting epoch 25\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 3\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.0402), std: tensor(0.8895)\n",
      "Variables)\n",
      "\tTrain:torch.Size([5333, 1, 101])\n",
      "\tTest: torch.Size([469, 1, 101])\n",
      "Train Size 5333 Test Size 469\n",
      "\n",
      "Model: all_sparse_model\n",
      "Epochs: 25\n",
      "PATH: ./Model/all_sparse_model_3.pt\n",
      "\n",
      "Starting epoch 25\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 4\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(0.0217), std: tensor(1.0018)\n",
      "Variables)\n",
      "\tTrain:torch.Size([4912, 1, 101])\n",
      "\tTest: torch.Size([890, 1, 101])\n",
      "Train Size 4912 Test Size 890\n",
      "\n",
      "Model: all_sparse_model\n",
      "Epochs: 25\n",
      "PATH: ./Model/all_sparse_model_4.pt\n",
      "\n",
      "Starting epoch 25\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 5\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.0024), std: tensor(0.8813)\n",
      "Variables)\n",
      "\tTrain:torch.Size([4581, 1, 101])\n",
      "\tTest: torch.Size([1221, 1, 101])\n",
      "Train Size 4581 Test Size 1221\n",
      "\n",
      "Model: all_sparse_model\n",
      "Epochs: 25\n",
      "PATH: ./Model/all_sparse_model_5.pt\n",
      "\n",
      "Starting epoch 25\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "----------------------------------------------------------------------------\"\n",
      "Fold 0: Acc 66.04136604136605, F1 39.64121343113071 %\n",
      "Fold 1: Acc 70.86614173228347, F1 42.1267687993346 %\n",
      "Fold 2: Acc 68.01705756929638, F1 42.75881210020675 %\n",
      "Fold 3: Acc 73.82022471910112, F1 42.509794781117456 %\n",
      "Fold 4: Acc 70.43407043407043, F1 41.36069605446351 %\n",
      "Average: 69.83577209922348 %\n",
      "F1: 41.67945703325061 %\n",
      "\n",
      "FOLD 1\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(0.0348), std: tensor(0.8758)\n",
      "Variables)\n",
      "\tTrain:torch.Size([3723, 1, 101])\n",
      "\tTest: torch.Size([2079, 1, 101])\n",
      "Train Size 3723 Test Size 2079\n",
      "\n",
      "Model: all_sparse_model\n",
      "Epochs: 50\n",
      "PATH: ./Model/all_sparse_model_1.pt\n",
      "\n",
      "Starting epoch 25\n",
      "Starting epoch 50\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 2\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(0.0172), std: tensor(1.1312)\n",
      "Variables)\n",
      "\tTrain:torch.Size([4659, 1, 101])\n",
      "\tTest: torch.Size([1143, 1, 101])\n",
      "Train Size 4659 Test Size 1143\n",
      "\n",
      "Model: all_sparse_model\n",
      "Epochs: 50\n",
      "PATH: ./Model/all_sparse_model_2.pt\n",
      "\n",
      "Starting epoch 25\n",
      "Starting epoch 50\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 3\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(0.0735), std: tensor(1.1132)\n",
      "Variables)\n",
      "\tTrain:torch.Size([5333, 1, 101])\n",
      "\tTest: torch.Size([469, 1, 101])\n",
      "Train Size 5333 Test Size 469\n",
      "\n",
      "Model: all_sparse_model\n",
      "Epochs: 50\n",
      "PATH: ./Model/all_sparse_model_3.pt\n",
      "\n",
      "Starting epoch 25\n",
      "Starting epoch 50\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 4\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(0.0095), std: tensor(1.0017)\n",
      "Variables)\n",
      "\tTrain:torch.Size([4912, 1, 101])\n",
      "\tTest: torch.Size([890, 1, 101])\n",
      "Train Size 4912 Test Size 890\n",
      "\n",
      "Model: all_sparse_model\n",
      "Epochs: 50\n",
      "PATH: ./Model/all_sparse_model_4.pt\n",
      "\n",
      "Starting epoch 25\n",
      "Starting epoch 50\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 5\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.0236), std: tensor(0.9620)\n",
      "Variables)\n",
      "\tTrain:torch.Size([4581, 1, 101])\n",
      "\tTest: torch.Size([1221, 1, 101])\n",
      "Train Size 4581 Test Size 1221\n",
      "\n",
      "Model: all_sparse_model\n",
      "Epochs: 50\n",
      "PATH: ./Model/all_sparse_model_5.pt\n",
      "\n",
      "Starting epoch 25\n",
      "Starting epoch 50\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "----------------------------------------------------------------------------\"\n",
      "Fold 0: Acc 65.75276575276575, F1 39.88518881293433 %\n",
      "Fold 1: Acc 69.81627296587926, F1 40.91527104869028 %\n",
      "Fold 2: Acc 66.73773987206823, F1 41.71520403925311 %\n",
      "Fold 3: Acc 73.37078651685394, F1 42.36403959657011 %\n",
      "Fold 4: Acc 71.66257166257166, F1 42.43082963802366 %\n",
      "Average: 69.46802735402777 %\n",
      "F1: 41.46210662709429 %\n",
      "\n",
      "FOLD 1\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.0481), std: tensor(0.8478)\n",
      "Variables)\n",
      "\tTrain:torch.Size([3723, 1, 101])\n",
      "\tTest: torch.Size([2079, 1, 101])\n",
      "Train Size 3723 Test Size 2079\n",
      "\n",
      "Model: all_sparse_model\n",
      "Epochs: 100\n",
      "PATH: ./Model/all_sparse_model_1.pt\n",
      "\n",
      "Starting epoch 25\n",
      "Starting epoch 50\n",
      "Starting epoch 75\n",
      "Starting epoch 100\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 2\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.0196), std: tensor(0.9507)\n",
      "Variables)\n",
      "\tTrain:torch.Size([4659, 1, 101])\n",
      "\tTest: torch.Size([1143, 1, 101])\n",
      "Train Size 4659 Test Size 1143\n",
      "\n",
      "Model: all_sparse_model\n",
      "Epochs: 100\n",
      "PATH: ./Model/all_sparse_model_2.pt\n",
      "\n",
      "Starting epoch 25\n",
      "Starting epoch 50\n",
      "Starting epoch 75\n",
      "Starting epoch 100\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 3\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(0.0225), std: tensor(1.5156)\n",
      "Variables)\n",
      "\tTrain:torch.Size([5333, 1, 101])\n",
      "\tTest: torch.Size([469, 1, 101])\n",
      "Train Size 5333 Test Size 469\n",
      "\n",
      "Model: all_sparse_model\n",
      "Epochs: 100\n",
      "PATH: ./Model/all_sparse_model_3.pt\n",
      "\n",
      "Starting epoch 25\n",
      "Starting epoch 50\n",
      "Starting epoch 75\n",
      "Starting epoch 100\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 4\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(-0.0087), std: tensor(0.8116)\n",
      "Variables)\n",
      "\tTrain:torch.Size([4912, 1, 101])\n",
      "\tTest: torch.Size([890, 1, 101])\n",
      "Train Size 4912 Test Size 890\n",
      "\n",
      "Model: all_sparse_model\n",
      "Epochs: 100\n",
      "PATH: ./Model/all_sparse_model_4.pt\n",
      "\n",
      "Starting epoch 25\n",
      "Starting epoch 50\n",
      "Starting epoch 75\n",
      "Starting epoch 100\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 5\n",
      "----------------------------------------------------------------------------\n",
      "mean: tensor(0.0091), std: tensor(0.9926)\n",
      "Variables)\n",
      "\tTrain:torch.Size([4581, 1, 101])\n",
      "\tTest: torch.Size([1221, 1, 101])\n",
      "Train Size 4581 Test Size 1221\n",
      "\n",
      "Model: all_sparse_model\n",
      "Epochs: 100\n",
      "PATH: ./Model/all_sparse_model_5.pt\n",
      "\n",
      "Starting epoch 25\n",
      "Starting epoch 50\n",
      "Starting epoch 75\n",
      "Starting epoch 100\n",
      "Training process has finished. Saving trained model.\n",
      "<Starting TESTING>\n",
      "----------------------------------------------------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "----------------------------------------------------------------------------\"\n",
      "Fold 0: Acc 66.23376623376623, F1 40.0358726305513 %\n",
      "Fold 1: Acc 70.16622922134734, F1 42.478584186948325 %\n",
      "Fold 2: Acc 64.81876332622602, F1 39.81190889695411 %\n",
      "Fold 3: Acc 72.35955056179775, F1 41.86839200788155 %\n",
      "Fold 4: Acc 72.07207207207207, F1 42.542198465738124 %\n",
      "Average: 69.13007628304187 %\n",
      "F1: 41.34739123761468 %\n"
     ]
    }
   ],
   "source": [
    "model = all_sparse_model()\n",
    "dataset = pd.concat([pheme_sparse_final, pheme_pos_final, pheme_thread_final_avg],axis=1)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# epochs = 10\n",
    "\n",
    "testing_epochs = [5,10,25,50,100]\n",
    "testing_results = []\n",
    "\n",
    "for epoch in testing_epochs:\n",
    "    result = cv_process(dataset, criterion, events=pheme_event, target=pheme_y, epochs=epoch, verbose=False, scaling=True)\n",
    "    testing_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/x.notebook.stdout": "Fold 0: Acc 39.06, F1 26.41 %\nFold 1: Acc 68.77, F1 41.46 %\nFold 2: Acc 46.91, F1 28.64 %\nFold 3: Acc 49.33, F1 35.07 %\nFold 4: Acc 56.76, F1 43.71 %\nAverage: 52.16 %\nF1: 35.06 %\n-----------------------------\nFold 0: Acc 76.77, F1 61.71 %\nFold 1: Acc 35.43, F1 24.33 %\nFold 2: Acc 45.63, F1 29.11 %\nFold 3: Acc 58.43, F1 34.96 %\nFold 4: Acc 56.02, F1 34.57 %\nAverage: 54.46 %\nF1: 36.94 %\n-----------------------------\n"
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "epochs_diff(testing_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class all_sparse_model(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(all_sparse_model, self).__init__() # 1*20\n",
    "#         self.layers = nn.Sequential(\n",
    "#             nn.Dropout(0.3),\n",
    "#             nn.Linear(52, 8),\n",
    "#             nn.ELU(),\n",
    "#             nn.Dropout(0.3),\n",
    "#             nn.Linear(8, 1)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.layers(x)\n",
    "#         return x\n",
    "\n",
    "class all_sparse_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(all_sparse_model, self).__init__() # 1*20\n",
    "        self.layers = nn.Sequential(\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(101, 50),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(50, 25),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(25, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/x.notebook.stdout": "\nFOLD 1\n----------------------------------------------------------------------------\nmean: tensor(2469.1448), std: tensor(24742.1504)\nVariables)\n\tTrain:torch.Size([3723, 1, 101])\n\tTest: torch.Size([2079, 1, 101])\nTrain Size 3723 Test Size 2079\n\nModel: all_sparse_model\nEpochs: 100\nPATH: ./Model/all_sparse_model_1.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 2\n----------------------------------------------------------------------------\nmean: tensor(16121.2100), std: tensor(338595.2188)\nVariables)\n\tTrain:torch.Size([4659, 1, 101])\n\tTest: torch.Size([1143, 1, 101])\nTrain Size 4659 Test Size 1143\n\nModel: all_sparse_model\nEpochs: 100\nPATH: ./Model/all_sparse_model_2.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 3\n----------------------------------------------------------------------------\nmean: tensor(23605.2148), std: tensor(437834.4062)\nVariables)\n\tTrain:torch.Size([5333, 1, 101])\n\tTest: torch.Size([469, 1, 101])\nTrain Size 5333 Test Size 469\n\nModel: all_sparse_model\nEpochs: 100\nPATH: ./Model/all_sparse_model_3.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 4\n----------------------------------------------------------------------------\nmean: tensor(29522.2871), std: tensor(417365.5938)\nVariables)\n\tTrain:torch.Size([4912, 1, 101])\n\tTest: torch.Size([890, 1, 101])\nTrain Size 4912 Test Size 890\n\nModel: all_sparse_model\nEpochs: 100\nPATH: ./Model/all_sparse_model_4.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 5\n----------------------------------------------------------------------------\nmean: tensor(8530.1680), std: tensor(101227.5547)\nVariables)\n\tTrain:torch.Size([4581, 1, 101])\n\tTest: torch.Size([1221, 1, 101])\nTrain Size 4581 Test Size 1221\n\nModel: all_sparse_model\nEpochs: 100\nPATH: ./Model/all_sparse_model_5.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nK-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n----------------------------------------------------------------------------\"\nFold 0: Acc 49.2063492063492, F1 32.42209492718736 %\nFold 1: Acc 66.49168853893264, F1 39.1211548160054 %\nFold 2: Acc 46.05543710021322, F1 31.361124809905753 %\nFold 3: Acc 56.067415730337075, F1 34.48041883001717 %\nFold 4: Acc 57.98525798525799, F1 36.403507724574446 %\nAverage: 55.16122971221803 %\nF1: 34.75766022153802 %\n\nFOLD 1\n----------------------------------------------------------------------------\nmean: tensor(7891.3657), std: tensor(109087.1875)\nVariables)\n\tTrain:torch.Size([3723, 1, 101])\n\tTest: torch.Size([2079, 1, 101])\nTrain Size 3723 Test Size 2079\n\nModel: all_sparse_model\nEpochs: 200\nPATH: ./Model/all_sparse_model_1.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nStarting epoch 125\nStarting epoch 150\nStarting epoch 175\nStarting epoch 200\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 2\n----------------------------------------------------------------------------\nmean: tensor(17690.9941), std: tensor(375247.8750)\nVariables)\n\tTrain:torch.Size([4659, 1, 101])\n\tTest: torch.Size([1143, 1, 101])\nTrain Size 4659 Test Size 1143\n\nModel: all_sparse_model\nEpochs: 200\nPATH: ./Model/all_sparse_model_2.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nStarting epoch 125\nStarting epoch 150\nStarting epoch 175\nStarting epoch 200\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 3\n----------------------------------------------------------------------------\nmean: tensor(32302.1367), std: tensor(482222.)\nVariables)\n\tTrain:torch.Size([5333, 1, 101])\n\tTest: torch.Size([469, 1, 101])\nTrain Size 5333 Test Size 469\n\nModel: all_sparse_model\nEpochs: 200\nPATH: ./Model/all_sparse_model_3.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nStarting epoch 125\nStarting epoch 150\nStarting epoch 175\nStarting epoch 200\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 4\n----------------------------------------------------------------------------\nmean: tensor(7491.3950), std: tensor(125358.2031)\nVariables)\n\tTrain:torch.Size([4912, 1, 101])\n\tTest: torch.Size([890, 1, 101])\nTrain Size 4912 Test Size 890\n\nModel: all_sparse_model\nEpochs: 200\nPATH: ./Model/all_sparse_model_4.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nStarting epoch 125\nStarting epoch 150\nStarting epoch 175\nStarting epoch 200\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 5\n----------------------------------------------------------------------------\nmean: tensor(9058.3760), std: tensor(179827.0312)\nVariables)\n\tTrain:torch.Size([4581, 1, 101])\n\tTest: torch.Size([1221, 1, 101])\nTrain Size 4581 Test Size 1221\n\nModel: all_sparse_model\nEpochs: 200\nPATH: ./Model/all_sparse_model_5.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nStarting epoch 125\nStarting epoch 150\nStarting epoch 175\nStarting epoch 200\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nK-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n----------------------------------------------------------------------------\"\nFold 0: Acc 57.527657527657524, F1 36.29203052083241 %\nFold 1: Acc 58.70516185476815, F1 36.35981173672334 %\nFold 2: Acc 50.31982942430704, F1 32.48032527225317 %\nFold 3: Acc 59.662921348314605, F1 36.23716352125175 %\nFold 4: Acc 60.85176085176085, F1 37.87707671599813 %\nAverage: 57.41346620136163 %\nF1: 35.84928155341176 %\n"
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "model = all_sparse_model()\n",
    "dataset = pd.concat([pheme_sparse_final, pheme_pos_final, pheme_thread_final_avg],axis=1)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# epochs = 10\n",
    "\n",
    "testing_epochs = [100,200]\n",
    "testing_results = []\n",
    "\n",
    "for epoch in testing_epochs:\n",
    "    result = cv_process(dataset, criterion, events=pheme_event, target=pheme_y, epochs=epoch, verbose=False)\n",
    "    testing_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/x.notebook.stdout": "Fold 0: Acc 49.21, F1 32.42 %\nFold 1: Acc 66.49, F1 39.12 %\nFold 2: Acc 46.06, F1 31.36 %\nFold 3: Acc 56.07, F1 34.48 %\nFold 4: Acc 57.99, F1 36.40 %\nAverage: 55.16 %\nF1: 34.76 %\n-----------------------------\nFold 0: Acc 57.53, F1 36.29 %\nFold 1: Acc 58.71, F1 36.36 %\nFold 2: Acc 50.32, F1 32.48 %\nFold 3: Acc 59.66, F1 36.24 %\nFold 4: Acc 60.85, F1 37.88 %\nAverage: 57.41 %\nF1: 35.85 %\n-----------------------------\n"
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "epochs_diff(testing_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epochs: 2\n",
      "FOLD 1\n",
      "----------------------------------------------------------------------------\n",
      "PATH: ./Model/bert_model_1.pt\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 2\n",
      "----------------------------------------------------------------------------\n",
      "PATH: ./Model/bert_model_2.pt\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 3\n",
      "----------------------------------------------------------------------------\n",
      "PATH: ./Model/bert_model_3.pt\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 4\n",
      "----------------------------------------------------------------------------\n",
      "PATH: ./Model/bert_model_4.pt\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 5\n",
      "----------------------------------------------------------------------------\n",
      "PATH: ./Model/bert_model_5.pt\n",
      "----------------------------------------------------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 77.44107744107744, F1 44.86421789495889 %\n",
      "Fold 1: Acc 69.9912510936133, F1 41.27409149821182 %\n",
      "Fold 2: Acc 74.84008528784648, F1 43.768720852062536 %\n",
      "Fold 3: Acc 77.75280898876404, F1 44.79981126323252 %\n",
      "Fold 4: Acc 58.88615888615889, F1 40.424085801265505 %\n",
      "Average: 71.78227633949203 %\n",
      "F1: 43.026185461946255 %\n",
      "\n",
      "Epochs: 3\n",
      "FOLD 1\n",
      "----------------------------------------------------------------------------\n",
      "PATH: ./Model/bert_model_1.pt\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 2\n",
      "----------------------------------------------------------------------------\n",
      "PATH: ./Model/bert_model_2.pt\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 3\n",
      "----------------------------------------------------------------------------\n",
      "PATH: ./Model/bert_model_3.pt\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 4\n",
      "----------------------------------------------------------------------------\n",
      "PATH: ./Model/bert_model_4.pt\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 5\n",
      "----------------------------------------------------------------------------\n",
      "PATH: ./Model/bert_model_5.pt\n",
      "----------------------------------------------------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 77.97017797017797, F1 44.1907652927596 %\n",
      "Fold 1: Acc 72.35345581802275, F1 42.05566645770738 %\n",
      "Fold 2: Acc 73.98720682302772, F1 43.509472151884296 %\n",
      "Fold 3: Acc 77.86516853932585, F1 44.851310375301516 %\n",
      "Fold 4: Acc 72.31777231777232, F1 41.96329447929071 %\n",
      "Average: 74.89875629366531 %\n",
      "F1: 43.314101751388705 %\n",
      "\n",
      "Epochs: 4\n",
      "FOLD 1\n",
      "----------------------------------------------------------------------------\n",
      "PATH: ./Model/bert_model_1.pt\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 2\n",
      "----------------------------------------------------------------------------\n",
      "PATH: ./Model/bert_model_2.pt\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 3\n",
      "----------------------------------------------------------------------------\n",
      "PATH: ./Model/bert_model_3.pt\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 4\n",
      "----------------------------------------------------------------------------\n",
      "PATH: ./Model/bert_model_4.pt\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 5\n",
      "----------------------------------------------------------------------------\n",
      "PATH: ./Model/bert_model_5.pt\n",
      "----------------------------------------------------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 80.47138047138047, F1 45.037494869906865 %\n",
      "Fold 1: Acc 74.62817147856518, F1 42.83518141884326 %\n",
      "Fold 2: Acc 71.85501066098081, F1 44.365741576958115 %\n",
      "Fold 3: Acc 78.53932584269663, F1 46.76763177954207 %\n",
      "Fold 4: Acc 69.28746928746928, F1 41.02884338121555 %\n",
      "Average: 74.95627154821847 %\n",
      "F1: 44.00697860529317 %\n",
      "\n",
      "Epochs: 5\n",
      "FOLD 1\n",
      "----------------------------------------------------------------------------\n",
      "PATH: ./Model/bert_model_1.pt\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 2\n",
      "----------------------------------------------------------------------------\n",
      "PATH: ./Model/bert_model_2.pt\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 3\n",
      "----------------------------------------------------------------------------\n",
      "PATH: ./Model/bert_model_3.pt\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 4\n",
      "----------------------------------------------------------------------------\n",
      "PATH: ./Model/bert_model_4.pt\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 5\n",
      "----------------------------------------------------------------------------\n",
      "PATH: ./Model/bert_model_5.pt\n",
      "----------------------------------------------------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 78.40307840307841, F1 44.788426693157604 %\n",
      "Fold 1: Acc 74.1907261592301, F1 42.72224706273536 %\n",
      "Fold 2: Acc 70.57569296375267, F1 47.09941091471284 %\n",
      "Fold 3: Acc 77.52808988764045, F1 46.412980613249715 %\n",
      "Fold 4: Acc 71.74447174447175, F1 41.907438063295594 %\n",
      "Average: 74.48841183163468 %\n",
      "F1: 44.58610066943022 %\n",
      "\n",
      "Epochs: 10\n",
      "FOLD 1\n",
      "----------------------------------------------------------------------------\n",
      "PATH: ./Model/bert_model_1.pt\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 2\n",
      "----------------------------------------------------------------------------\n",
      "PATH: ./Model/bert_model_2.pt\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 3\n",
      "----------------------------------------------------------------------------\n",
      "PATH: ./Model/bert_model_3.pt\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 4\n",
      "----------------------------------------------------------------------------\n",
      "PATH: ./Model/bert_model_4.pt\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 5\n",
      "----------------------------------------------------------------------------\n",
      "PATH: ./Model/bert_model_5.pt\n",
      "----------------------------------------------------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 81.38528138528139, F1 45.74264796437585 %\n",
      "Fold 1: Acc 73.31583552055993, F1 42.505707691662316 %\n",
      "Fold 2: Acc 72.06823027718549, F1 46.10725762798754 %\n",
      "Fold 3: Acc 78.53932584269663, F1 45.84314919727173 %\n",
      "Fold 4: Acc 70.92547092547092, F1 42.966870698553215 %\n",
      "Average: 75.24682879023888 %\n",
      "F1: 44.63312663597013 %\n",
      "\n",
      "Epochs: 25\n",
      "FOLD 1\n",
      "----------------------------------------------------------------------------\n",
      "PATH: ./Model/bert_model_1.pt\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 2\n",
      "----------------------------------------------------------------------------\n",
      "PATH: ./Model/bert_model_2.pt\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 3\n",
      "----------------------------------------------------------------------------\n",
      "PATH: ./Model/bert_model_3.pt\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 4\n",
      "----------------------------------------------------------------------------\n",
      "PATH: ./Model/bert_model_4.pt\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 5\n",
      "----------------------------------------------------------------------------\n",
      "PATH: ./Model/bert_model_5.pt\n",
      "----------------------------------------------------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 82.58778258778258, F1 46.83069327494912 %\n",
      "Fold 1: Acc 74.01574803149606, F1 43.15037910535412 %\n",
      "Fold 2: Acc 72.06823027718549, F1 42.86578941963969 %\n",
      "Fold 3: Acc 77.07865168539327, F1 46.999270627477635 %\n",
      "Fold 4: Acc 72.3996723996724, F1 43.525300305684276 %\n",
      "Average: 75.63001699630595 %\n",
      "F1: 44.67428654662097 %\n",
      "\n",
      "Epochs: 50\n",
      "FOLD 1\n",
      "----------------------------------------------------------------------------\n",
      "PATH: ./Model/bert_model_1.pt\n",
      "Starting epoch 50\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 2\n",
      "----------------------------------------------------------------------------\n",
      "PATH: ./Model/bert_model_2.pt\n",
      "Starting epoch 50\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 3\n",
      "----------------------------------------------------------------------------\n",
      "PATH: ./Model/bert_model_3.pt\n",
      "Starting epoch 50\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 4\n",
      "----------------------------------------------------------------------------\n",
      "PATH: ./Model/bert_model_4.pt\n",
      "Starting epoch 50\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 5\n",
      "----------------------------------------------------------------------------\n",
      "PATH: ./Model/bert_model_5.pt\n",
      "Starting epoch 50\n",
      "----------------------------------------------------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 82.01058201058201, F1 47.064669857826324 %\n",
      "Fold 1: Acc 75.06561679790026, F1 45.31561461525346 %\n",
      "Fold 2: Acc 69.9360341151386, F1 42.217902620865324 %\n",
      "Fold 3: Acc 77.19101123595506, F1 45.271295058726224 %\n",
      "Fold 4: Acc 72.80917280917281, F1 42.336744219265746 %\n",
      "Average: 75.40248339374975 %\n",
      "F1: 44.44124527438741 %\n",
      "\n",
      "Epochs: 100\n",
      "FOLD 1\n",
      "----------------------------------------------------------------------------\n",
      "PATH: ./Model/bert_model_1.pt\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 2\n",
      "----------------------------------------------------------------------------\n",
      "PATH: ./Model/bert_model_2.pt\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 3\n",
      "----------------------------------------------------------------------------\n",
      "PATH: ./Model/bert_model_3.pt\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 4\n",
      "----------------------------------------------------------------------------\n",
      "PATH: ./Model/bert_model_4.pt\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 5\n",
      "----------------------------------------------------------------------------\n",
      "PATH: ./Model/bert_model_5.pt\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "----------------------------------------------------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 81.33718133718133, F1 46.84987021025894 %\n",
      "Fold 1: Acc 76.64041994750657, F1 51.977115946758204 %\n",
      "Fold 2: Acc 67.590618336887, F1 41.177543295351455 %\n",
      "Fold 3: Acc 75.1685393258427, F1 43.684598945400566 %\n",
      "Fold 4: Acc 73.21867321867322, F1 42.485723929373975 %\n",
      "Average: 74.79108643321817 %\n",
      "F1: 45.23497046542864 %\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 77.44, F1 44.86 %\n",
      "Fold 1: Acc 69.99, F1 41.27 %\n",
      "Fold 2: Acc 74.84, F1 43.77 %\n",
      "Fold 3: Acc 77.75, F1 44.80 %\n",
      "Fold 4: Acc 58.89, F1 40.42 %\n",
      "Average: 71.78 %\n",
      "F1: 43.03 %\n",
      "-----------------------------\n",
      "Fold 0: Acc 77.97, F1 44.19 %\n",
      "Fold 1: Acc 72.35, F1 42.06 %\n",
      "Fold 2: Acc 73.99, F1 43.51 %\n",
      "Fold 3: Acc 77.87, F1 44.85 %\n",
      "Fold 4: Acc 72.32, F1 41.96 %\n",
      "Average: 74.90 %\n",
      "F1: 43.31 %\n",
      "-----------------------------\n",
      "Fold 0: Acc 80.47, F1 45.04 %\n",
      "Fold 1: Acc 74.63, F1 42.84 %\n",
      "Fold 2: Acc 71.86, F1 44.37 %\n",
      "Fold 3: Acc 78.54, F1 46.77 %\n",
      "Fold 4: Acc 69.29, F1 41.03 %\n",
      "Average: 74.96 %\n",
      "F1: 44.01 %\n",
      "-----------------------------\n",
      "Fold 0: Acc 78.40, F1 44.79 %\n",
      "Fold 1: Acc 74.19, F1 42.72 %\n",
      "Fold 2: Acc 70.58, F1 47.10 %\n",
      "Fold 3: Acc 77.53, F1 46.41 %\n",
      "Fold 4: Acc 71.74, F1 41.91 %\n",
      "Average: 74.49 %\n",
      "F1: 44.59 %\n",
      "-----------------------------\n",
      "Fold 0: Acc 81.39, F1 45.74 %\n",
      "Fold 1: Acc 73.32, F1 42.51 %\n",
      "Fold 2: Acc 72.07, F1 46.11 %\n",
      "Fold 3: Acc 78.54, F1 45.84 %\n",
      "Fold 4: Acc 70.93, F1 42.97 %\n",
      "Average: 75.25 %\n",
      "F1: 44.63 %\n",
      "-----------------------------\n",
      "Fold 0: Acc 82.59, F1 46.83 %\n",
      "Fold 1: Acc 74.02, F1 43.15 %\n",
      "Fold 2: Acc 72.07, F1 42.87 %\n",
      "Fold 3: Acc 77.08, F1 47.00 %\n",
      "Fold 4: Acc 72.40, F1 43.53 %\n",
      "Average: 75.63 %\n",
      "F1: 44.67 %\n",
      "-----------------------------\n",
      "Fold 0: Acc 82.01, F1 47.06 %\n",
      "Fold 1: Acc 75.07, F1 45.32 %\n",
      "Fold 2: Acc 69.94, F1 42.22 %\n",
      "Fold 3: Acc 77.19, F1 45.27 %\n",
      "Fold 4: Acc 72.81, F1 42.34 %\n",
      "Average: 75.40 %\n",
      "F1: 44.44 %\n",
      "-----------------------------\n",
      "Fold 0: Acc 81.34, F1 46.85 %\n",
      "Fold 1: Acc 76.64, F1 51.98 %\n",
      "Fold 2: Acc 67.59, F1 41.18 %\n",
      "Fold 3: Acc 75.17, F1 43.68 %\n",
      "Fold 4: Acc 73.22, F1 42.49 %\n",
      "Average: 74.79 %\n",
      "F1: 45.23 %\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "class bert_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(bert_model, self).__init__() # 1*20\n",
    "        self.layers = nn.Sequential(\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(768, 50, bias=True),\n",
    "            nn.ELU(),\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(50, 8, bias=True),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(8, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = bert_model()\n",
    "dataset = pheme_bert_brackets_normal\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# epochs = 10\n",
    "\n",
    "testing_epochs = [2,3,4,5,10,25,50,100]\n",
    "testing_results = []\n",
    "\n",
    "for epoch in testing_epochs:\n",
    "    result = cv_process(dataset, criterion, modelClass=bert_model, events=pheme_event, target=pheme_y, epochs=epoch, verbose=False)\n",
    "    testing_results.append(result)\n",
    "\n",
    "epochs_diff(testing_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bert_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(bert_model, self).__init__() # 1*20\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(768, 50, bias=True),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(50, 8, bias=True),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(8, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "dataset = pheme_bert_brackets_normal\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# epochs = 10\n",
    "\n",
    "testing_epochs = [2,3,4,5,10,25,50,100]\n",
    "testing_results = []\n",
    "\n",
    "for epoch in testing_epochs:\n",
    "    result = cv_process(dataset, criterion, modelClass=bert_model, events=pheme_event, target=pheme_y, epochs=epoch, verbose=False, )\n",
    "    testing_results.append(result)\n",
    "\n",
    "epochs_diff(testing_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT + ALL SPARSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epochs: 10\n",
      "FOLD 1\n",
      "----------------------------------------------------------------------------\n",
      "PATH: ./Model/bert_sparse_model_1.pt\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 2\n",
      "----------------------------------------------------------------------------\n",
      "PATH: ./Model/bert_sparse_model_2.pt\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 3\n",
      "----------------------------------------------------------------------------\n",
      "PATH: ./Model/bert_sparse_model_3.pt\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 4\n",
      "----------------------------------------------------------------------------\n",
      "PATH: ./Model/bert_sparse_model_4.pt\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 5\n",
      "----------------------------------------------------------------------------\n",
      "PATH: ./Model/bert_sparse_model_5.pt\n",
      "----------------------------------------------------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 46.7051467051467, F1 34.91870697938969 %\n",
      "Fold 1: Acc 47.41907261592301, F1 31.612784066704457 %\n",
      "Fold 2: Acc 70.36247334754798, F1 43.33114209014762 %\n",
      "Fold 3: Acc 61.46067415730337, F1 47.15918245146596 %\n",
      "Fold 4: Acc 69.2055692055692, F1 40.845026049971935 %\n",
      "Average: 59.03058720629806 %\n",
      "F1: 39.57336832753593 %\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 46.71, F1 34.92 %\n",
      "Fold 1: Acc 47.42, F1 31.61 %\n",
      "Fold 2: Acc 70.36, F1 43.33 %\n",
      "Fold 3: Acc 61.46, F1 47.16 %\n",
      "Fold 4: Acc 69.21, F1 40.85 %\n",
      "Average: 59.03 %\n",
      "F1: 39.57 %\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "class bert_sparse_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(bert_sparse_model, self).__init__() # 1*20\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(869, 50, bias=True),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(50, 8, bias=True),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(8, 3, bias=True),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(3, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# dataset = pd.concat([pheme_sparse_final, pheme_pos_final, pheme_thread_final_avg, pheme_bert_brackets_normal],axis=1)\n",
    "dataset = pd.concat([pheme_sparse_final, pheme_pos_final, pheme_thread_final_avg, pheme_bert_simple_normal],axis=1)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# epochs = 10\n",
    "\n",
    "testing_epochs = [25]\n",
    "testing_results = []\n",
    "\n",
    "for epoch in testing_epochs:\n",
    "    result = cv_process(dataset, criterion, modelClass=bert_sparse_model, events=pheme_event, target=pheme_y, epochs=epoch, verbose=False, scaling=True)\n",
    "    testing_results.append(result)\n",
    "\n",
    "epochs_diff(testing_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT + ALL SPARSE (STD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epochs: 10\n",
      "FOLD 1\n",
      "----------------------------------------------------------------------------\n",
      "PATH: ./Model/bert_sparse_model_1.pt\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 2\n",
      "----------------------------------------------------------------------------\n",
      "PATH: ./Model/bert_sparse_model_2.pt\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 3\n",
      "----------------------------------------------------------------------------\n",
      "PATH: ./Model/bert_sparse_model_3.pt\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 4\n",
      "----------------------------------------------------------------------------\n",
      "PATH: ./Model/bert_sparse_model_4.pt\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 5\n",
      "----------------------------------------------------------------------------\n",
      "PATH: ./Model/bert_sparse_model_5.pt\n",
      "----------------------------------------------------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 34.48773448773449, F1 23.704120406014766 %\n",
      "Fold 1: Acc 67.8915135608049, F1 39.48187633838347 %\n",
      "Fold 2: Acc 50.53304904051173, F1 39.53168249198337 %\n",
      "Fold 3: Acc 51.79775280898876, F1 33.93450128050548 %\n",
      "Fold 4: Acc 42.75184275184275, F1 42.43684243684244 %\n",
      "Average: 49.49237852997653 %\n",
      "F1: 35.8178045907459 %\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 34.49, F1 23.70 %\n",
      "Fold 1: Acc 67.89, F1 39.48 %\n",
      "Fold 2: Acc 50.53, F1 39.53 %\n",
      "Fold 3: Acc 51.80, F1 33.93 %\n",
      "Fold 4: Acc 42.75, F1 42.44 %\n",
      "Average: 49.49 %\n",
      "F1: 35.82 %\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "class bert_sparse_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(bert_sparse_model, self).__init__() # 1*20\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(869, 50, bias=True),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(50, 8, bias=True),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(8, 3, bias=True),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(3, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# dataset = pd.concat([pheme_sparse_final, pheme_pos_final, pheme_thread_final_avg, pheme_bert_simple_normal],axis=1)\n",
    "dataset = pd.concat([pheme_sparse_final, pheme_pos_final, pheme_thread_final_avg, pheme_bert_brackets_normal],axis=1)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# epochs = 10\n",
    "\n",
    "testing_epochs = [10]\n",
    "testing_results = []\n",
    "\n",
    "for epoch in testing_epochs:\n",
    "    result = cv_process(dataset, criterion, modelClass=bert_sparse_model, events=pheme_event, target=pheme_y, epochs=epoch, verbose=False, scaling=False)\n",
    "    testing_results.append(result)\n",
    "\n",
    "epochs_diff(testing_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['charliehebdo' 'ferguson' 'germanwings-crash' 'ottawashooting'\n",
      " 'sydneysiege']\n",
      "['ebola-essien' 'prince-toronto' 'putinmissing']\n"
     ]
    }
   ],
   "source": [
    "print(pheme_event.unique())\n",
    "print(ext_event.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>!</th>\n      <th>#</th>\n      <th>&amp;</th>\n      <th>,</th>\n      <th>@</th>\n      <th>^</th>\n      <th>a</th>\n      <th>d</th>\n      <th>g</th>\n      <th>l</th>\n      <th>n</th>\n      <th>o</th>\n      <th>p</th>\n      <th>r</th>\n      <th>s</th>\n      <th>t</th>\n      <th>u</th>\n      <th>v</th>\n      <th>x</th>\n      <th>z</th>\n      <th>~</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>5</td>\n      <td>2</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>480</th>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>481</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>482</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>483</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>484</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>485 rows × 21 columns</p>\n</div>",
      "text/plain": "     !  #  &  ,  @  ^  a  d  g  l  n  o  p  r  s  t  u  v  x  z  ~\n0    0  0  0  0  0  3  0  1  0  0  1  0  1  0  0  0  1  1  0  0  0\n1    0  1  2  2  0  1  2  1  0  1  5  2  3  3  0  0  0  6  0  0  0\n2    0  0  1  1  0  3  1  4  0  0  4  0  3  0  0  0  0  4  0  0  0\n3    0  0  0  2  0  3  2  2  0  0  3  0  1  0  0  0  2  3  0  0  0\n4    0  0  0  1  1  3  1  1  0  0  1  0  2  1  0  0  1  4  0  0  0\n..  .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. ..\n480  0  3  0  0  0  4  0  0  0  0  3  0  3  0  0  0  2  1  0  0  0\n481  0  1  0  1  0  2  0  0  0  0  2  0  2  0  0  1  0  2  0  0  0\n482  0  1  0  1  0  0  0  1  0  0  2  0  0  0  0  0  1  0  0  0  0\n483  0  0  0  2  0  1  2  1  0  0  5  1  2  1  0  0  0  3  0  0  0\n484  0  0  0  0  0  2  1  1  0  0  2  0  2  0  0  0  1  1  0  0  0\n\n[485 rows x 21 columns]"
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ext_pos_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5802, 28)\n",
      "(5802, 21)\n"
     ]
    }
   ],
   "source": [
    "print(pheme_sparse_final.shape)\n",
    "print(pheme_pos_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(623, 28)\n",
      "(623, 21)\n",
      "(623, 768)\n",
      "(623, 768)\n"
     ]
    }
   ],
   "source": [
    "print(ext_sparse_final.shape)\n",
    "print(ext_pos_final.shape)\n",
    "print(ext_bert_simple_normal.shape)\n",
    "print(ext_bert_brackets_normal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Final\n",
    "pheme_sparse_final = pd.read_csv('./data/_PHEME_sparse.csv')\n",
    "pheme_y = pd.read_csv('./data/_PHEME_target.csv').target\n",
    "pheme_pos_final = pd.read_csv('./data/_PHEME_postags.csv')\n",
    "pheme_thread_final_avg = pd.read_csv('./data/_PHEME_thread_avg.csv')\n",
    "pheme_thread_final_std = pd.read_csv('./data/_PHEME_thread_std.csv')\n",
    "\n",
    "ext_pos_final = pd.read_csv('./data/_PHEMEext_postags.csv')\n",
    "ext_sparse_final = pd.read_csv('./data/_PHEMEext_sparse.csv')\n",
    "ext_y = pd.read_csv('./data/_PHEMEext_text.csv').target\n",
    "ext_thread_final_avg = pd.read_csv('./data/_PHEMEext_thread_avg.csv')\n",
    "ext_thread_final_std = pd.read_csv('./data/_PHEMEext_thread_std.csv')\n",
    "\n",
    "pheme_bert_simple_normal = pd.read_csv('./data/_PHEME_Bert_final_simple_nrmzd.csv')\n",
    "ext_bert_simple_normal = pd.read_csv('./data/_PHEMEext_Bert_final_simple_nrmzd.csv')\n",
    "\n",
    "pheme_bert_brackets_normal = pd.read_csv('./data/_PHEME_Bert_final_brackets_nrmzd.csv')\n",
    "ext_bert_brackets_normal = pd.read_csv('./data/_PHEMEext_Bert_final_brackets_nrmzd.csv')\n",
    "\n",
    "pheme_event = pd.read_csv('./data/_PHEME_text.csv')['Event']\n",
    "ext_event = pd.read_csv('./data/_PHEMEext_text.csv').Event\n",
    "pheme_AVGw2v = pd.read_csv('./data/_PHEME_text_AVGw2v.csv').drop(['token'],axis=1)\n",
    "ext_AVGw2v = pd.read_csv('./data/_PHEMEext_text_AVGw2v.csv').drop(['token'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_event = pd.concat([pheme_event,ext_event],axis=0, ignore_index=True)\n",
    "all_y = pd.concat([pheme_y,ext_y],axis=0, ignore_index=True)\n",
    "all_sparse = pd.concat([pheme_sparse_final, ext_sparse_final],axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "************************************************************\n",
      "STARTING A CROSS-VALIDATION ... [10, 100] epochs\n",
      "************************************************************\n",
      "\n",
      "STARTING TEST of 10 EPOCH\n",
      "\n",
      "> FOLD 1\n",
      "> FOLD 2\n",
      "> FOLD 3\n",
      "> FOLD 4\n",
      "> FOLD 5\n",
      "> FOLD 6\n",
      "> FOLD 7\n",
      "> FOLD 8\n",
      "> FOLD 9\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      ">>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 63.44396344396345, F1 38.68452196113811\n",
      "Fold 1: Acc 61.76727909011374, F1 37.803648325060465\n",
      "Fold 2: Acc 65.88486140724946, F1 39.87612714301961\n",
      "Fold 3: Acc 59.88764044943821, F1 37.247254896172656\n",
      "Fold 4: Acc 61.83456183456183, F1 38.40176099773573\n",
      "Fold 5: Acc 42.857142857142854, F1 30.0\n",
      "Fold 6: Acc 66.09442060085837, F1 40.40443858006322\n",
      "Fold 7: Acc 60.924369747899156, F1 39.31815520708469\n",
      "Fold 8: Acc 49.275362318840585, F1 32.28237248527103\n",
      "Average: 59.108%\n",
      "F1: 37.113%\n",
      "Loss: 0.678%\n",
      "\n",
      "\n",
      "STARTING TEST of 100 EPOCH\n",
      "\n",
      "> FOLD 1\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 2\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 3\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 4\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 5\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 6\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 7\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 8\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 9\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      ">>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 61.56806156806157, F1 37.891281655392774\n",
      "Fold 1: Acc 61.76727909011374, F1 37.721098499206555\n",
      "Fold 2: Acc 60.3411513859275, F1 38.25054283628374\n",
      "Fold 3: Acc 60.67415730337079, F1 37.523167054127406\n",
      "Fold 4: Acc 62.08026208026208, F1 38.306226841187936\n",
      "Fold 5: Acc 21.428571428571427, F1 17.647058823529413\n",
      "Fold 6: Acc 60.94420600858369, F1 38.522915329782286\n",
      "Fold 7: Acc 64.28571428571429, F1 40.12408383741206\n",
      "Fold 8: Acc 53.62318840579711, F1 35.93737821841162\n",
      "Average: 56.301%\n",
      "F1: 35.769%\n",
      "Loss: 0.702%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class sparse_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(sparse_model, self).__init__()  # 1*20\n",
    "        self.layers = nn.Sequential(\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(28, 10),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(10, 4),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            # nn.Linear(12, 8),\n",
    "            # nn.ELU(),\n",
    "            nn.Linear(4, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "# model = sparse_model()\n",
    "dataset = all_sparse\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "testing_epochs = [10, 100]\n",
    "testing_results = []\n",
    "\n",
    "writeLog().write(\"./Model/\"+sparse_model.__name__+\"_\"+\"log.txt\",f\"\\n\\n************************************************************\\nSTARTING A CROSS-VALIDATION ... {testing_epochs} epochs\\n************************************************************\")\n",
    "\n",
    "for epoch in testing_epochs:\n",
    "    result = cv_process(dataset, criterion, modelClass=sparse_model, events=all_event, target=all_y, epochs=epoch, verbose=False, scaling=True)\n",
    "    testing_results.append(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pos_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(pos_model, self).__init__() # 1*20\n",
    "        self.layers = nn.Sequential(\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(21, 4),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/x.notebook.stdout": "\nFOLD 1\n----------------------------------------------------------------------------\nmean: tensor(0.8542), std: tensor(1.3381)\nVariables)\n\tTrain:torch.Size([3723, 1, 21])\n\tTest: torch.Size([2079, 1, 21])\nTrain Size 3723 Test Size 2079\n\nModel: pos_model\nEpochs: 200\nPATH: ./Model/pos_model_1.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nStarting epoch 125\nStarting epoch 150\nStarting epoch 175\nStarting epoch 200\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 2\n----------------------------------------------------------------------------\nmean: tensor(0.8214), std: tensor(1.3263)\nVariables)\n\tTrain:torch.Size([4659, 1, 21])\n\tTest: torch.Size([1143, 1, 21])\nTrain Size 4659 Test Size 1143\n\nModel: pos_model\nEpochs: 200\nPATH: ./Model/pos_model_2.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nStarting epoch 125\nStarting epoch 150\nStarting epoch 175\nStarting epoch 200\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 3\n----------------------------------------------------------------------------\nmean: tensor(0.7649), std: tensor(1.2865)\nVariables)\n\tTrain:torch.Size([5333, 1, 21])\n\tTest: torch.Size([469, 1, 21])\nTrain Size 5333 Test Size 469\n\nModel: pos_model\nEpochs: 200\nPATH: ./Model/pos_model_3.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nStarting epoch 125\nStarting epoch 150\nStarting epoch 175\nStarting epoch 200\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 4\n----------------------------------------------------------------------------\nmean: tensor(0.8571), std: tensor(1.4091)\nVariables)\n\tTrain:torch.Size([4912, 1, 21])\n\tTest: torch.Size([890, 1, 21])\nTrain Size 4912 Test Size 890\n\nModel: pos_model\nEpochs: 200\nPATH: ./Model/pos_model_4.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nStarting epoch 125\nStarting epoch 150\nStarting epoch 175\nStarting epoch 200\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 5\n----------------------------------------------------------------------------\nmean: tensor(0.8393), std: tensor(1.3196)\nVariables)\n\tTrain:torch.Size([4581, 1, 21])\n\tTest: torch.Size([1221, 1, 21])\nTrain Size 4581 Test Size 1221\n\nModel: pos_model\nEpochs: 200\nPATH: ./Model/pos_model_5.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nStarting epoch 125\nStarting epoch 150\nStarting epoch 175\nStarting epoch 200\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nK-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n----------------------------------------------------------------------------\"\nFold 0: Acc 50.12025012025012, F1 32.85822203643859 %\nFold 1: Acc 51.70603674540683, F1 33.56656709742465 %\nFold 2: Acc 56.28997867803838, F1 35.57152537859402 %\nFold 3: Acc 60.1123595505618, F1 37.11830558599607 %\nFold 4: Acc 55.528255528255535, F1 35.465322883404035 %\nAverage: 54.75137612450253 %\nF1: 34.91598859637147 %\n"
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "model = pos_model()\n",
    "dataset = pheme_pos_final\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# epochs = 10\n",
    "\n",
    "testing_epochs = [200]\n",
    "testing_results = []\n",
    "\n",
    "for epoch in testing_epochs:\n",
    "    result = cv_process(dataset, criterion, events=pheme_event, target=pheme_y, epochs=epoch, verbose=False)\n",
    "    testing_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/x.notebook.stdout": "Fold 0: Acc 50.12, F1 32.86 %\nFold 1: Acc 51.71, F1 33.57 %\nFold 2: Acc 56.29, F1 35.57 %\nFold 3: Acc 60.11, F1 37.12 %\nFold 4: Acc 55.53, F1 35.47 %\nAverage: 54.75 %\nF1: 34.92 %\n-----------------------------\n"
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "epochs_diff(testing_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pos_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(pos_model, self).__init__() # 1*20\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(21, 8),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(8, 3),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(8, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/x.notebook.stdout": "\nFOLD 1\n----------------------------------------------------------------------------\nmean: tensor(0.8304), std: tensor(1.3487)\nVariables)\n\tTrain:torch.Size([3723, 1, 21])\n\tTest: torch.Size([2079, 1, 21])\nTrain Size 3723 Test Size 2079\n\nModel: pos_model\nEpochs: 100\nPATH: ./Model/pos_model_1.pt\n\n"
     },
     "output_type": "unknown"
    },
    {
     "data": {
      "application/x.notebook.error-traceback": {
       "ename": "RuntimeError",
       "evalue": "mat1 and mat2 shapes cannot be multiplied (16x3 and 8x1)",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
        "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-121-b40e175f282a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtesting_epochs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpheme_event\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpheme_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mtesting_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-93-f2f6947dc6ae>\u001b[0m in \u001b[0;36mcv_process\u001b[0;34m(dataset, criterion, events, target, epochs, verbose)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0;31m# Perform forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-120-ee50768f6fa9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (16x3 and 8x1)"
       ]
      }
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "model = pos_model()\n",
    "dataset = pheme_pos_final\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# epochs = 10\n",
    "\n",
    "testing_epochs = [100,200]\n",
    "testing_results = []\n",
    "\n",
    "for epoch in testing_epochs:\n",
    "    result = cv_process(dataset, criterion, events=pheme_event, target=pheme_y, epochs=epoch, verbose=False)\n",
    "    testing_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/x.notebook.stdout": "Fold 0: Acc 54.59, F1 35.04 %\nFold 1: Acc 49.61, F1 32.81 %\nFold 2: Acc 49.04, F1 32.19 %\nFold 3: Acc 51.69, F1 33.74 %\nFold 4: Acc 56.27, F1 35.43 %\nAverage: 52.24 %\nF1: 33.84 %\n-----------------------------\nFold 0: Acc 63.06, F1 38.17 %\nFold 1: Acc 68.94, F1 40.89 %\nFold 2: Acc 47.12, F1 27.20 %\nFold 3: Acc 47.64, F1 39.98 %\nFold 4: Acc 56.51, F1 41.42 %\nAverage: 56.65 %\nF1: 37.53 %\n-----------------------------\nFold 0: Acc 77.78, F1 67.65 %\nFold 1: Acc 75.07, F1 73.08 %\nFold 2: Acc 46.27, F1 30.93 %\nFold 3: Acc 54.16, F1 34.49 %\nFold 4: Acc 46.93, F1 31.20 %\nAverage: 60.04 %\nF1: 47.47 %\n-----------------------------\nFold 0: Acc 48.10, F1 31.88 %\nFold 1: Acc 43.13, F1 29.30 %\nFold 2: Acc 51.60, F1 33.53 %\nFold 3: Acc 55.96, F1 35.15 %\nFold 4: Acc 50.94, F1 33.16 %\nAverage: 49.95 %\nF1: 32.61 %\n-----------------------------\n"
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "epochs_diff(testing_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class thread_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(thread_model, self).__init__() # 1*20\n",
    "        self.layers = nn.Sequential(\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(52, 8),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(8, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/x.notebook.stdout": "\nFOLD 1\n----------------------------------------------------------------------------\nmean: tensor(2963.2720), std: tensor(24845.1055)\nVariables)\n\tTrain:torch.Size([3723, 1, 52])\n\tTest: torch.Size([2079, 1, 52])\nTrain Size 3723 Test Size 2079\n\nModel: thread_model\nEpochs: 200\nPATH: ./Model/thread_model_1.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nStarting epoch 125\nStarting epoch 150\nStarting epoch 175\nStarting epoch 200\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 2\n----------------------------------------------------------------------------\nmean: tensor(3497.9487), std: tensor(27849.6016)\nVariables)\n\tTrain:torch.Size([4659, 1, 52])\n\tTest: torch.Size([1143, 1, 52])\nTrain Size 4659 Test Size 1143\n\nModel: thread_model\nEpochs: 200\nPATH: ./Model/thread_model_2.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nStarting epoch 125\nStarting epoch 150\nStarting epoch 175\nStarting epoch 200\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 3\n----------------------------------------------------------------------------\nmean: tensor(3168.0876), std: tensor(21924.1816)\nVariables)\n\tTrain:torch.Size([5333, 1, 52])\n\tTest: torch.Size([469, 1, 52])\nTrain Size 5333 Test Size 469\n\nModel: thread_model\nEpochs: 200\nPATH: ./Model/thread_model_3.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nStarting epoch 125\nStarting epoch 150\nStarting epoch 175\nStarting epoch 200\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 4\n----------------------------------------------------------------------------\nmean: tensor(2852.2446), std: tensor(25351.4004)\nVariables)\n\tTrain:torch.Size([4912, 1, 52])\n\tTest: torch.Size([890, 1, 52])\nTrain Size 4912 Test Size 890\n\nModel: thread_model\nEpochs: 200\nPATH: ./Model/thread_model_4.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nStarting epoch 125\nStarting epoch 150\nStarting epoch 175\nStarting epoch 200\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 5\n----------------------------------------------------------------------------\nmean: tensor(8398.1855), std: tensor(108311.9219)\nVariables)\n\tTrain:torch.Size([4581, 1, 52])\n\tTest: torch.Size([1221, 1, 52])\nTrain Size 4581 Test Size 1221\n\nModel: thread_model\nEpochs: 200\nPATH: ./Model/thread_model_5.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nStarting epoch 125\nStarting epoch 150\nStarting epoch 175\nStarting epoch 200\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nK-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n----------------------------------------------------------------------------\"\nFold 0: Acc 64.06926406926407, F1 37.88078353895472 %\nFold 1: Acc 51.70603674540683, F1 33.80851064551472 %\nFold 2: Acc 51.812366737739865, F1 33.848900499498455 %\nFold 3: Acc 51.01123595505618, F1 33.24992845183369 %\nFold 4: Acc 48.239148239148236, F1 31.579850404801086 %\nAverage: 53.36761034932304 %\nF1: 34.07359470812053 %\n"
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "model = thread_model()\n",
    "dataset = pheme_thread_final_avg\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# epochs = 10\n",
    "\n",
    "testing_epochs = [200]\n",
    "testing_results = []\n",
    "\n",
    "for epoch in testing_epochs:\n",
    "    result = cv_process(dataset, criterion, events=pheme_event, target=pheme_y, epochs=epoch, verbose=False)\n",
    "    testing_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/x.notebook.stdout": "Fold 0: Acc 64.07, F1 37.88 %\nFold 1: Acc 51.71, F1 33.81 %\nFold 2: Acc 51.81, F1 33.85 %\nFold 3: Acc 51.01, F1 33.25 %\nFold 4: Acc 48.24, F1 31.58 %\nAverage: 53.37 %\nF1: 34.07 %\n-----------------------------\n"
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "epochs_diff(testing_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class thread_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(thread_model, self).__init__() # 1*20\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(52, 12),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(12, 8),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(8, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/x.notebook.stdout": "\nFOLD 1\n----------------------------------------------------------------------------\nmean: tensor(3277.9453), std: tensor(27177.8438)\nVariables)\n\tTrain:torch.Size([3723, 1, 52])\n\tTest: torch.Size([2079, 1, 52])\nTrain Size 3723 Test Size 2079\n\nModel: thread_model\nEpochs: 200\nPATH: ./Model/thread_model_1.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nStarting epoch 125\nStarting epoch 150\nStarting epoch 175\nStarting epoch 200\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 2\n----------------------------------------------------------------------------\nmean: tensor(6453.4585), std: tensor(69573.0312)\nVariables)\n\tTrain:torch.Size([4659, 1, 52])\n\tTest: torch.Size([1143, 1, 52])\nTrain Size 4659 Test Size 1143\n\nModel: thread_model\nEpochs: 200\nPATH: ./Model/thread_model_2.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nStarting epoch 125\nStarting epoch 150\nStarting epoch 175\nStarting epoch 200\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 3\n----------------------------------------------------------------------------\nmean: tensor(2897.2771), std: tensor(21537.5762)\nVariables)\n\tTrain:torch.Size([5333, 1, 52])\n\tTest: torch.Size([469, 1, 52])\nTrain Size 5333 Test Size 469\n\nModel: thread_model\nEpochs: 200\nPATH: ./Model/thread_model_3.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nStarting epoch 125\nStarting epoch 150\nStarting epoch 175\nStarting epoch 200\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 4\n----------------------------------------------------------------------------\nmean: tensor(4545.2944), std: tensor(64156.3711)\nVariables)\n\tTrain:torch.Size([4912, 1, 52])\n\tTest: torch.Size([890, 1, 52])\nTrain Size 4912 Test Size 890\n\nModel: thread_model\nEpochs: 200\nPATH: ./Model/thread_model_4.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nStarting epoch 125\nStarting epoch 150\nStarting epoch 175\nStarting epoch 200\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 5\n----------------------------------------------------------------------------\nmean: tensor(5839.2158), std: tensor(98214.8594)\nVariables)\n\tTrain:torch.Size([4581, 1, 52])\n\tTest: torch.Size([1221, 1, 52])\nTrain Size 4581 Test Size 1221\n\nModel: thread_model\nEpochs: 200\nPATH: ./Model/thread_model_5.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nStarting epoch 125\nStarting epoch 150\nStarting epoch 175\nStarting epoch 200\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nK-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n----------------------------------------------------------------------------\"\nFold 0: Acc 58.778258778258774, F1 36.54151319467047 %\nFold 1: Acc 50.568678915135614, F1 33.101949776104334 %\nFold 2: Acc 52.02558635394456, F1 34.15840493433894 %\nFold 3: Acc 51.573033707865164, F1 33.70705915996299 %\nFold 4: Acc 54.791154791154796, F1 35.04936380142794 %\nAverage: 53.54734250927178 %\nF1: 34.51165817330094 %\n"
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "model = thread_model()\n",
    "dataset = pheme_thread_final_avg\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# epochs = 10\n",
    "\n",
    "testing_epochs = [200]\n",
    "testing_results = []\n",
    "\n",
    "for epoch in testing_epochs:\n",
    "    result = cv_process(dataset, criterion, events=pheme_event, target=pheme_y, epochs=epoch, verbose=False)\n",
    "    testing_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/x.notebook.stdout": "Fold 0: Acc 58.78, F1 36.54 %\nFold 1: Acc 50.57, F1 33.10 %\nFold 2: Acc 52.03, F1 34.16 %\nFold 3: Acc 51.57, F1 33.71 %\nFold 4: Acc 54.79, F1 35.05 %\nAverage: 53.55 %\nF1: 34.51 %\n-----------------------------\n"
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "epochs_diff(testing_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPARSE + POS + Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class all_sparse_model(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(all_sparse_model, self).__init__() # 1*20\n",
    "#         self.layers = nn.Sequential(\n",
    "#             nn.Dropout(0.3),\n",
    "#             nn.Linear(52, 8),\n",
    "#             nn.ELU(),\n",
    "#             nn.Dropout(0.3),\n",
    "#             nn.Linear(8, 1)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.layers(x)\n",
    "#         return x\n",
    "\n",
    "class all_sparse_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(all_sparse_model, self).__init__() # 1*20\n",
    "        self.layers = nn.Sequential(\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(101, 32),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(32, 10),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(10, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/x.notebook.stdout": "\nFOLD 1\n----------------------------------------------------------------------------\nmean: tensor(17072.7910), std: tensor(317982.8125)\nVariables)\n\tTrain:torch.Size([3723, 1, 101])\n\tTest: torch.Size([2079, 1, 101])\nTrain Size 3723 Test Size 2079\n\nModel: all_sparse_model\nEpochs: 50\nPATH: ./Model/all_sparse_model_1.pt\n\nStarting epoch 25\nStarting epoch 50\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 2\n----------------------------------------------------------------------------\nmean: tensor(24228.5430), std: tensor(385957.3750)\nVariables)\n\tTrain:torch.Size([4659, 1, 101])\n\tTest: torch.Size([1143, 1, 101])\nTrain Size 4659 Test Size 1143\n\nModel: all_sparse_model\nEpochs: 50\nPATH: ./Model/all_sparse_model_2.pt\n\nStarting epoch 25\nStarting epoch 50\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 3\n----------------------------------------------------------------------------\nmean: tensor(29769.6191), std: tensor(536090.5625)\nVariables)\n\tTrain:torch.Size([5333, 1, 101])\n\tTest: torch.Size([469, 1, 101])\nTrain Size 5333 Test Size 469\n\nModel: all_sparse_model\nEpochs: 50\nPATH: ./Model/all_sparse_model_3.pt\n\nStarting epoch 25\nStarting epoch 50\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 4\n----------------------------------------------------------------------------\nmean: tensor(5097.3018), std: tensor(68551.0312)\nVariables)\n\tTrain:torch.Size([4912, 1, 101])\n\tTest: torch.Size([890, 1, 101])\nTrain Size 4912 Test Size 890\n\nModel: all_sparse_model\nEpochs: 50\nPATH: ./Model/all_sparse_model_4.pt\n\nStarting epoch 25\nStarting epoch 50\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 5\n----------------------------------------------------------------------------\nmean: tensor(8906.4893), std: tensor(151588.9531)\nVariables)\n\tTrain:torch.Size([4581, 1, 101])\n\tTest: torch.Size([1221, 1, 101])\nTrain Size 4581 Test Size 1221\n\nModel: all_sparse_model\nEpochs: 50\nPATH: ./Model/all_sparse_model_5.pt\n\nStarting epoch 25\nStarting epoch 50\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nK-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n----------------------------------------------------------------------------\"\nFold 0: Acc 39.05723905723906, F1 26.4128939535082 %\nFold 1: Acc 68.76640419947506, F1 41.459138407056436 %\nFold 2: Acc 46.908315565031984, F1 28.639343528710832 %\nFold 3: Acc 49.325842696629216, F1 35.073662392986954 %\nFold 4: Acc 56.75675675675676, F1 43.708553007567744 %\nAverage: 52.16291165502641 %\nF1: 35.05871825796603 %\n\nFOLD 1\n----------------------------------------------------------------------------\nmean: tensor(9545.6904), std: tensor(184576.2031)\nVariables)\n\tTrain:torch.Size([3723, 1, 101])\n\tTest: torch.Size([2079, 1, 101])\nTrain Size 3723 Test Size 2079\n\nModel: all_sparse_model\nEpochs: 100\nPATH: ./Model/all_sparse_model_1.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 2\n----------------------------------------------------------------------------\nmean: tensor(26170.6816), std: tensor(394063.1875)\nVariables)\n\tTrain:torch.Size([4659, 1, 101])\n\tTest: torch.Size([1143, 1, 101])\nTrain Size 4659 Test Size 1143\n\nModel: all_sparse_model\nEpochs: 100\nPATH: ./Model/all_sparse_model_2.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 3\n----------------------------------------------------------------------------\nmean: tensor(19657.9434), std: tensor(358120.6875)\nVariables)\n\tTrain:torch.Size([5333, 1, 101])\n\tTest: torch.Size([469, 1, 101])\nTrain Size 5333 Test Size 469\n\nModel: all_sparse_model\nEpochs: 100\nPATH: ./Model/all_sparse_model_3.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 4\n----------------------------------------------------------------------------\nmean: tensor(11433.3564), std: tensor(137543.0938)\nVariables)\n\tTrain:torch.Size([4912, 1, 101])\n\tTest: torch.Size([890, 1, 101])\nTrain Size 4912 Test Size 890\n\nModel: all_sparse_model\nEpochs: 100\nPATH: ./Model/all_sparse_model_4.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 5\n----------------------------------------------------------------------------\nmean: tensor(16683.5918), std: tensor(271039.1562)\nVariables)\n\tTrain:torch.Size([4581, 1, 101])\n\tTest: torch.Size([1221, 1, 101])\nTrain Size 4581 Test Size 1221\n\nModel: all_sparse_model\nEpochs: 100\nPATH: ./Model/all_sparse_model_5.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nK-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n----------------------------------------------------------------------------\"\nFold 0: Acc 76.76767676767676, F1 61.705682185135544 %\nFold 1: Acc 35.43307086614173, F1 24.33364579280107 %\nFold 2: Acc 45.62899786780384, F1 29.10781513741769 %\nFold 3: Acc 58.42696629213483, F1 34.96229365874696 %\nFold 4: Acc 56.01965601965602, F1 34.57303363713342 %\nAverage: 54.455273562682635 %\nF1: 36.93649408224694 %\n"
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "model = all_sparse_model()\n",
    "dataset = pd.concat([pheme_sparse_final, pheme_pos_final, pheme_thread_final_avg],axis=1)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# epochs = 10\n",
    "\n",
    "testing_epochs = [50,100]\n",
    "testing_results = []\n",
    "\n",
    "for epoch in testing_epochs:\n",
    "    result = cv_process(dataset, criterion, events=pheme_event, target=pheme_y, epochs=epoch, verbose=False)\n",
    "    testing_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/x.notebook.stdout": "Fold 0: Acc 39.06, F1 26.41 %\nFold 1: Acc 68.77, F1 41.46 %\nFold 2: Acc 46.91, F1 28.64 %\nFold 3: Acc 49.33, F1 35.07 %\nFold 4: Acc 56.76, F1 43.71 %\nAverage: 52.16 %\nF1: 35.06 %\n-----------------------------\nFold 0: Acc 76.77, F1 61.71 %\nFold 1: Acc 35.43, F1 24.33 %\nFold 2: Acc 45.63, F1 29.11 %\nFold 3: Acc 58.43, F1 34.96 %\nFold 4: Acc 56.02, F1 34.57 %\nAverage: 54.46 %\nF1: 36.94 %\n-----------------------------\n"
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "epochs_diff(testing_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class all_sparse_model(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(all_sparse_model, self).__init__() # 1*20\n",
    "#         self.layers = nn.Sequential(\n",
    "#             nn.Dropout(0.3),\n",
    "#             nn.Linear(52, 8),\n",
    "#             nn.ELU(),\n",
    "#             nn.Dropout(0.3),\n",
    "#             nn.Linear(8, 1)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.layers(x)\n",
    "#         return x\n",
    "\n",
    "class all_sparse_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(all_sparse_model, self).__init__() # 1*20\n",
    "        self.layers = nn.Sequential(\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(101, 50),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(50, 25),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(25, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/x.notebook.stdout": "\nFOLD 1\n----------------------------------------------------------------------------\nmean: tensor(2469.1448), std: tensor(24742.1504)\nVariables)\n\tTrain:torch.Size([3723, 1, 101])\n\tTest: torch.Size([2079, 1, 101])\nTrain Size 3723 Test Size 2079\n\nModel: all_sparse_model\nEpochs: 100\nPATH: ./Model/all_sparse_model_1.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 2\n----------------------------------------------------------------------------\nmean: tensor(16121.2100), std: tensor(338595.2188)\nVariables)\n\tTrain:torch.Size([4659, 1, 101])\n\tTest: torch.Size([1143, 1, 101])\nTrain Size 4659 Test Size 1143\n\nModel: all_sparse_model\nEpochs: 100\nPATH: ./Model/all_sparse_model_2.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 3\n----------------------------------------------------------------------------\nmean: tensor(23605.2148), std: tensor(437834.4062)\nVariables)\n\tTrain:torch.Size([5333, 1, 101])\n\tTest: torch.Size([469, 1, 101])\nTrain Size 5333 Test Size 469\n\nModel: all_sparse_model\nEpochs: 100\nPATH: ./Model/all_sparse_model_3.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 4\n----------------------------------------------------------------------------\nmean: tensor(29522.2871), std: tensor(417365.5938)\nVariables)\n\tTrain:torch.Size([4912, 1, 101])\n\tTest: torch.Size([890, 1, 101])\nTrain Size 4912 Test Size 890\n\nModel: all_sparse_model\nEpochs: 100\nPATH: ./Model/all_sparse_model_4.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 5\n----------------------------------------------------------------------------\nmean: tensor(8530.1680), std: tensor(101227.5547)\nVariables)\n\tTrain:torch.Size([4581, 1, 101])\n\tTest: torch.Size([1221, 1, 101])\nTrain Size 4581 Test Size 1221\n\nModel: all_sparse_model\nEpochs: 100\nPATH: ./Model/all_sparse_model_5.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nK-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n----------------------------------------------------------------------------\"\nFold 0: Acc 49.2063492063492, F1 32.42209492718736 %\nFold 1: Acc 66.49168853893264, F1 39.1211548160054 %\nFold 2: Acc 46.05543710021322, F1 31.361124809905753 %\nFold 3: Acc 56.067415730337075, F1 34.48041883001717 %\nFold 4: Acc 57.98525798525799, F1 36.403507724574446 %\nAverage: 55.16122971221803 %\nF1: 34.75766022153802 %\n\nFOLD 1\n----------------------------------------------------------------------------\nmean: tensor(7891.3657), std: tensor(109087.1875)\nVariables)\n\tTrain:torch.Size([3723, 1, 101])\n\tTest: torch.Size([2079, 1, 101])\nTrain Size 3723 Test Size 2079\n\nModel: all_sparse_model\nEpochs: 200\nPATH: ./Model/all_sparse_model_1.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nStarting epoch 125\nStarting epoch 150\nStarting epoch 175\nStarting epoch 200\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 2\n----------------------------------------------------------------------------\nmean: tensor(17690.9941), std: tensor(375247.8750)\nVariables)\n\tTrain:torch.Size([4659, 1, 101])\n\tTest: torch.Size([1143, 1, 101])\nTrain Size 4659 Test Size 1143\n\nModel: all_sparse_model\nEpochs: 200\nPATH: ./Model/all_sparse_model_2.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nStarting epoch 125\nStarting epoch 150\nStarting epoch 175\nStarting epoch 200\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 3\n----------------------------------------------------------------------------\nmean: tensor(32302.1367), std: tensor(482222.)\nVariables)\n\tTrain:torch.Size([5333, 1, 101])\n\tTest: torch.Size([469, 1, 101])\nTrain Size 5333 Test Size 469\n\nModel: all_sparse_model\nEpochs: 200\nPATH: ./Model/all_sparse_model_3.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nStarting epoch 125\nStarting epoch 150\nStarting epoch 175\nStarting epoch 200\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 4\n----------------------------------------------------------------------------\nmean: tensor(7491.3950), std: tensor(125358.2031)\nVariables)\n\tTrain:torch.Size([4912, 1, 101])\n\tTest: torch.Size([890, 1, 101])\nTrain Size 4912 Test Size 890\n\nModel: all_sparse_model\nEpochs: 200\nPATH: ./Model/all_sparse_model_4.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nStarting epoch 125\nStarting epoch 150\nStarting epoch 175\nStarting epoch 200\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 5\n----------------------------------------------------------------------------\nmean: tensor(9058.3760), std: tensor(179827.0312)\nVariables)\n\tTrain:torch.Size([4581, 1, 101])\n\tTest: torch.Size([1221, 1, 101])\nTrain Size 4581 Test Size 1221\n\nModel: all_sparse_model\nEpochs: 200\nPATH: ./Model/all_sparse_model_5.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nStarting epoch 125\nStarting epoch 150\nStarting epoch 175\nStarting epoch 200\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nK-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n----------------------------------------------------------------------------\"\nFold 0: Acc 57.527657527657524, F1 36.29203052083241 %\nFold 1: Acc 58.70516185476815, F1 36.35981173672334 %\nFold 2: Acc 50.31982942430704, F1 32.48032527225317 %\nFold 3: Acc 59.662921348314605, F1 36.23716352125175 %\nFold 4: Acc 60.85176085176085, F1 37.87707671599813 %\nAverage: 57.41346620136163 %\nF1: 35.84928155341176 %\n"
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "model = all_sparse_model()\n",
    "dataset = pd.concat([pheme_sparse_final, pheme_pos_final, pheme_thread_final_avg],axis=1)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# epochs = 10\n",
    "\n",
    "testing_epochs = [100,200]\n",
    "testing_results = []\n",
    "\n",
    "for epoch in testing_epochs:\n",
    "    result = cv_process(dataset, criterion, events=pheme_event, target=pheme_y, epochs=epoch, verbose=False)\n",
    "    testing_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/x.notebook.stdout": "Fold 0: Acc 49.21, F1 32.42 %\nFold 1: Acc 66.49, F1 39.12 %\nFold 2: Acc 46.06, F1 31.36 %\nFold 3: Acc 56.07, F1 34.48 %\nFold 4: Acc 57.99, F1 36.40 %\nAverage: 55.16 %\nF1: 34.76 %\n-----------------------------\nFold 0: Acc 57.53, F1 36.29 %\nFold 1: Acc 58.71, F1 36.36 %\nFold 2: Acc 50.32, F1 32.48 %\nFold 3: Acc 59.66, F1 36.24 %\nFold 4: Acc 60.85, F1 37.88 %\nAverage: 57.41 %\nF1: 35.85 %\n-----------------------------\n"
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "epochs_diff(testing_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPARSE + POS + Thread Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class all_sparse_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(all_sparse_model, self).__init__() # 1*20\n",
    "        self.layers = nn.Sequential(\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(101, 20),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(20, 6),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(6, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/x.notebook.stdout": "\nFOLD 1\n----------------------------------------------------------------------------\nmean: tensor(-0.0077), std: tensor(0.8630)\nVariables)\n\tTrain:torch.Size([3723, 1, 101])\n\tTest: torch.Size([2079, 1, 101])\nTrain Size 3723 Test Size 2079\n\nModel: all_sparse_model\nEpochs: 5\nPATH: ./Model/all_sparse_model_1.pt\n\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 2\n----------------------------------------------------------------------------\nmean: tensor(-0.0158), std: tensor(0.8134)\nVariables)\n\tTrain:torch.Size([4659, 1, 101])\n\tTest: torch.Size([1143, 1, 101])\nTrain Size 4659 Test Size 1143\n\nModel: all_sparse_model\nEpochs: 5\nPATH: ./Model/all_sparse_model_2.pt\n\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 3\n----------------------------------------------------------------------------\nmean: tensor(0.0249), std: tensor(0.9493)\nVariables)\n\tTrain:torch.Size([5333, 1, 101])\n\tTest: torch.Size([469, 1, 101])\nTrain Size 5333 Test Size 469\n\nModel: all_sparse_model\nEpochs: 5\nPATH: ./Model/all_sparse_model_3.pt\n\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 4\n----------------------------------------------------------------------------\nmean: tensor(0.0092), std: tensor(0.9185)\nVariables)\n\tTrain:torch.Size([4912, 1, 101])\n\tTest: torch.Size([890, 1, 101])\nTrain Size 4912 Test Size 890\n\nModel: all_sparse_model\nEpochs: 5\nPATH: ./Model/all_sparse_model_4.pt\n\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 5\n----------------------------------------------------------------------------\nmean: tensor(-0.0355), std: tensor(0.9679)\nVariables)\n\tTrain:torch.Size([4581, 1, 101])\n\tTest: torch.Size([1221, 1, 101])\nTrain Size 4581 Test Size 1221\n\nModel: all_sparse_model\nEpochs: 5\nPATH: ./Model/all_sparse_model_5.pt\n\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nK-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n----------------------------------------------------------------------------\"\nFold 0: Acc 52.23665223665223, F1 33.62999482784151 %\nFold 1: Acc 62.904636920384945, F1 37.00682109454008 %\nFold 2: Acc 57.995735607675904, F1 37.08026404554385 %\nFold 3: Acc 67.97752808988764, F1 40.162444689445074 %\nFold 4: Acc 68.38656838656838, F1 41.957686017134264 %\nAverage: 61.900224248233826 %\nF1: 37.967442134900956 %\n\nFOLD 1\n----------------------------------------------------------------------------\nmean: tensor(0.0345), std: tensor(1.0960)\nVariables)\n\tTrain:torch.Size([3723, 1, 101])\n\tTest: torch.Size([2079, 1, 101])\nTrain Size 3723 Test Size 2079\n\nModel: all_sparse_model\nEpochs: 10\nPATH: ./Model/all_sparse_model_1.pt\n\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 2\n----------------------------------------------------------------------------\nmean: tensor(-0.0457), std: tensor(0.9302)\nVariables)\n\tTrain:torch.Size([4659, 1, 101])\n\tTest: torch.Size([1143, 1, 101])\nTrain Size 4659 Test Size 1143\n\nModel: all_sparse_model\nEpochs: 10\nPATH: ./Model/all_sparse_model_2.pt\n\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 3\n----------------------------------------------------------------------------\nmean: tensor(-0.0091), std: tensor(0.8579)\nVariables)\n\tTrain:torch.Size([5333, 1, 101])\n\tTest: torch.Size([469, 1, 101])\nTrain Size 5333 Test Size 469\n\nModel: all_sparse_model\nEpochs: 10\nPATH: ./Model/all_sparse_model_3.pt\n\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 4\n----------------------------------------------------------------------------\nmean: tensor(0.0352), std: tensor(1.0227)\nVariables)\n\tTrain:torch.Size([4912, 1, 101])\n\tTest: torch.Size([890, 1, 101])\nTrain Size 4912 Test Size 890\n\nModel: all_sparse_model\nEpochs: 10\nPATH: ./Model/all_sparse_model_4.pt\n\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 5\n----------------------------------------------------------------------------\nmean: tensor(-0.0408), std: tensor(0.9565)\nVariables)\n\tTrain:torch.Size([4581, 1, 101])\n\tTest: torch.Size([1221, 1, 101])\nTrain Size 4581 Test Size 1221\n\nModel: all_sparse_model\nEpochs: 10\nPATH: ./Model/all_sparse_model_5.pt\n\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nK-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n----------------------------------------------------------------------------\"\nFold 0: Acc 65.27176527176528, F1 39.284890936855206 %\nFold 1: Acc 70.07874015748031, F1 42.55490361594885 %\nFold 2: Acc 64.60554371002132, F1 39.970917090343065 %\nFold 3: Acc 73.82022471910112, F1 42.61212365015915 %\nFold 4: Acc 69.04176904176904, F1 40.913317353508525 %\nAverage: 68.56360858002742 %\nF1: 41.06723052936296 %\n\nFOLD 1\n----------------------------------------------------------------------------\nmean: tensor(-0.0851), std: tensor(0.8830)\nVariables)\n\tTrain:torch.Size([3723, 1, 101])\n\tTest: torch.Size([2079, 1, 101])\nTrain Size 3723 Test Size 2079\n\nModel: all_sparse_model\nEpochs: 25\nPATH: ./Model/all_sparse_model_1.pt\n\nStarting epoch 25\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 2\n----------------------------------------------------------------------------\nmean: tensor(-0.0170), std: tensor(0.8779)\nVariables)\n\tTrain:torch.Size([4659, 1, 101])\n\tTest: torch.Size([1143, 1, 101])\nTrain Size 4659 Test Size 1143\n\nModel: all_sparse_model\nEpochs: 25\nPATH: ./Model/all_sparse_model_2.pt\n\nStarting epoch 25\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 3\n----------------------------------------------------------------------------\nmean: tensor(-0.0402), std: tensor(0.8895)\nVariables)\n\tTrain:torch.Size([5333, 1, 101])\n\tTest: torch.Size([469, 1, 101])\nTrain Size 5333 Test Size 469\n\nModel: all_sparse_model\nEpochs: 25\nPATH: ./Model/all_sparse_model_3.pt\n\nStarting epoch 25\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 4\n----------------------------------------------------------------------------\nmean: tensor(0.0217), std: tensor(1.0018)\nVariables)\n\tTrain:torch.Size([4912, 1, 101])\n\tTest: torch.Size([890, 1, 101])\nTrain Size 4912 Test Size 890\n\nModel: all_sparse_model\nEpochs: 25\nPATH: ./Model/all_sparse_model_4.pt\n\nStarting epoch 25\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 5\n----------------------------------------------------------------------------\nmean: tensor(-0.0024), std: tensor(0.8813)\nVariables)\n\tTrain:torch.Size([4581, 1, 101])\n\tTest: torch.Size([1221, 1, 101])\nTrain Size 4581 Test Size 1221\n\nModel: all_sparse_model\nEpochs: 25\nPATH: ./Model/all_sparse_model_5.pt\n\nStarting epoch 25\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nK-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n----------------------------------------------------------------------------\"\nFold 0: Acc 66.04136604136605, F1 39.64121343113071 %\nFold 1: Acc 70.86614173228347, F1 42.1267687993346 %\nFold 2: Acc 68.01705756929638, F1 42.75881210020675 %\nFold 3: Acc 73.82022471910112, F1 42.509794781117456 %\nFold 4: Acc 70.43407043407043, F1 41.36069605446351 %\nAverage: 69.83577209922348 %\nF1: 41.67945703325061 %\n\nFOLD 1\n----------------------------------------------------------------------------\nmean: tensor(0.0348), std: tensor(0.8758)\nVariables)\n\tTrain:torch.Size([3723, 1, 101])\n\tTest: torch.Size([2079, 1, 101])\nTrain Size 3723 Test Size 2079\n\nModel: all_sparse_model\nEpochs: 50\nPATH: ./Model/all_sparse_model_1.pt\n\nStarting epoch 25\nStarting epoch 50\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 2\n----------------------------------------------------------------------------\nmean: tensor(0.0172), std: tensor(1.1312)\nVariables)\n\tTrain:torch.Size([4659, 1, 101])\n\tTest: torch.Size([1143, 1, 101])\nTrain Size 4659 Test Size 1143\n\nModel: all_sparse_model\nEpochs: 50\nPATH: ./Model/all_sparse_model_2.pt\n\nStarting epoch 25\nStarting epoch 50\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 3\n----------------------------------------------------------------------------\nmean: tensor(0.0735), std: tensor(1.1132)\nVariables)\n\tTrain:torch.Size([5333, 1, 101])\n\tTest: torch.Size([469, 1, 101])\nTrain Size 5333 Test Size 469\n\nModel: all_sparse_model\nEpochs: 50\nPATH: ./Model/all_sparse_model_3.pt\n\nStarting epoch 25\nStarting epoch 50\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 4\n----------------------------------------------------------------------------\nmean: tensor(0.0095), std: tensor(1.0017)\nVariables)\n\tTrain:torch.Size([4912, 1, 101])\n\tTest: torch.Size([890, 1, 101])\nTrain Size 4912 Test Size 890\n\nModel: all_sparse_model\nEpochs: 50\nPATH: ./Model/all_sparse_model_4.pt\n\nStarting epoch 25\nStarting epoch 50\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 5\n----------------------------------------------------------------------------\nmean: tensor(-0.0236), std: tensor(0.9620)\nVariables)\n\tTrain:torch.Size([4581, 1, 101])\n\tTest: torch.Size([1221, 1, 101])\nTrain Size 4581 Test Size 1221\n\nModel: all_sparse_model\nEpochs: 50\nPATH: ./Model/all_sparse_model_5.pt\n\nStarting epoch 25\nStarting epoch 50\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nK-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n----------------------------------------------------------------------------\"\nFold 0: Acc 65.75276575276575, F1 39.88518881293433 %\nFold 1: Acc 69.81627296587926, F1 40.91527104869028 %\nFold 2: Acc 66.73773987206823, F1 41.71520403925311 %\nFold 3: Acc 73.37078651685394, F1 42.36403959657011 %\nFold 4: Acc 71.66257166257166, F1 42.43082963802366 %\nAverage: 69.46802735402777 %\nF1: 41.46210662709429 %\n\nFOLD 1\n----------------------------------------------------------------------------\nmean: tensor(-0.0481), std: tensor(0.8478)\nVariables)\n\tTrain:torch.Size([3723, 1, 101])\n\tTest: torch.Size([2079, 1, 101])\nTrain Size 3723 Test Size 2079\n\nModel: all_sparse_model\nEpochs: 100\nPATH: ./Model/all_sparse_model_1.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 2\n----------------------------------------------------------------------------\nmean: tensor(-0.0196), std: tensor(0.9507)\nVariables)\n\tTrain:torch.Size([4659, 1, 101])\n\tTest: torch.Size([1143, 1, 101])\nTrain Size 4659 Test Size 1143\n\nModel: all_sparse_model\nEpochs: 100\nPATH: ./Model/all_sparse_model_2.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 3\n----------------------------------------------------------------------------\nmean: tensor(0.0225), std: tensor(1.5156)\nVariables)\n\tTrain:torch.Size([5333, 1, 101])\n\tTest: torch.Size([469, 1, 101])\nTrain Size 5333 Test Size 469\n\nModel: all_sparse_model\nEpochs: 100\nPATH: ./Model/all_sparse_model_3.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 4\n----------------------------------------------------------------------------\nmean: tensor(-0.0087), std: tensor(0.8116)\nVariables)\n\tTrain:torch.Size([4912, 1, 101])\n\tTest: torch.Size([890, 1, 101])\nTrain Size 4912 Test Size 890\n\nModel: all_sparse_model\nEpochs: 100\nPATH: ./Model/all_sparse_model_4.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 5\n----------------------------------------------------------------------------\nmean: tensor(0.0091), std: tensor(0.9926)\nVariables)\n\tTrain:torch.Size([4581, 1, 101])\n\tTest: torch.Size([1221, 1, 101])\nTrain Size 4581 Test Size 1221\n\nModel: all_sparse_model\nEpochs: 100\nPATH: ./Model/all_sparse_model_5.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nK-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n----------------------------------------------------------------------------\"\nFold 0: Acc 66.23376623376623, F1 40.0358726305513 %\nFold 1: Acc 70.16622922134734, F1 42.478584186948325 %\nFold 2: Acc 64.81876332622602, F1 39.81190889695411 %\nFold 3: Acc 72.35955056179775, F1 41.86839200788155 %\nFold 4: Acc 72.07207207207207, F1 42.542198465738124 %\nAverage: 69.13007628304187 %\nF1: 41.34739123761468 %\n"
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "model = all_sparse_model()\n",
    "dataset = pd.concat([pheme_sparse_final, pheme_pos_final, pheme_thread_final_avg],axis=1)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# epochs = 10\n",
    "\n",
    "testing_epochs = [5,10,25,50,100]\n",
    "testing_results = []\n",
    "\n",
    "for epoch in testing_epochs:\n",
    "    result = cv_process(dataset, criterion, events=pheme_event, target=pheme_y, epochs=epoch, verbose=False, scaling=True)\n",
    "    testing_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/x.notebook.stdout": "Fold 0: Acc 39.06, F1 26.41 %\nFold 1: Acc 68.77, F1 41.46 %\nFold 2: Acc 46.91, F1 28.64 %\nFold 3: Acc 49.33, F1 35.07 %\nFold 4: Acc 56.76, F1 43.71 %\nAverage: 52.16 %\nF1: 35.06 %\n-----------------------------\nFold 0: Acc 76.77, F1 61.71 %\nFold 1: Acc 35.43, F1 24.33 %\nFold 2: Acc 45.63, F1 29.11 %\nFold 3: Acc 58.43, F1 34.96 %\nFold 4: Acc 56.02, F1 34.57 %\nAverage: 54.46 %\nF1: 36.94 %\n-----------------------------\n"
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "epochs_diff(testing_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class all_sparse_model(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(all_sparse_model, self).__init__() # 1*20\n",
    "#         self.layers = nn.Sequential(\n",
    "#             nn.Dropout(0.3),\n",
    "#             nn.Linear(52, 8),\n",
    "#             nn.ELU(),\n",
    "#             nn.Dropout(0.3),\n",
    "#             nn.Linear(8, 1)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.layers(x)\n",
    "#         return x\n",
    "\n",
    "class all_sparse_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(all_sparse_model, self).__init__() # 1*20\n",
    "        self.layers = nn.Sequential(\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(101, 50),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(50, 25),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(25, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/x.notebook.stdout": "\nFOLD 1\n----------------------------------------------------------------------------\nmean: tensor(2469.1448), std: tensor(24742.1504)\nVariables)\n\tTrain:torch.Size([3723, 1, 101])\n\tTest: torch.Size([2079, 1, 101])\nTrain Size 3723 Test Size 2079\n\nModel: all_sparse_model\nEpochs: 100\nPATH: ./Model/all_sparse_model_1.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 2\n----------------------------------------------------------------------------\nmean: tensor(16121.2100), std: tensor(338595.2188)\nVariables)\n\tTrain:torch.Size([4659, 1, 101])\n\tTest: torch.Size([1143, 1, 101])\nTrain Size 4659 Test Size 1143\n\nModel: all_sparse_model\nEpochs: 100\nPATH: ./Model/all_sparse_model_2.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 3\n----------------------------------------------------------------------------\nmean: tensor(23605.2148), std: tensor(437834.4062)\nVariables)\n\tTrain:torch.Size([5333, 1, 101])\n\tTest: torch.Size([469, 1, 101])\nTrain Size 5333 Test Size 469\n\nModel: all_sparse_model\nEpochs: 100\nPATH: ./Model/all_sparse_model_3.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 4\n----------------------------------------------------------------------------\nmean: tensor(29522.2871), std: tensor(417365.5938)\nVariables)\n\tTrain:torch.Size([4912, 1, 101])\n\tTest: torch.Size([890, 1, 101])\nTrain Size 4912 Test Size 890\n\nModel: all_sparse_model\nEpochs: 100\nPATH: ./Model/all_sparse_model_4.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 5\n----------------------------------------------------------------------------\nmean: tensor(8530.1680), std: tensor(101227.5547)\nVariables)\n\tTrain:torch.Size([4581, 1, 101])\n\tTest: torch.Size([1221, 1, 101])\nTrain Size 4581 Test Size 1221\n\nModel: all_sparse_model\nEpochs: 100\nPATH: ./Model/all_sparse_model_5.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nK-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n----------------------------------------------------------------------------\"\nFold 0: Acc 49.2063492063492, F1 32.42209492718736 %\nFold 1: Acc 66.49168853893264, F1 39.1211548160054 %\nFold 2: Acc 46.05543710021322, F1 31.361124809905753 %\nFold 3: Acc 56.067415730337075, F1 34.48041883001717 %\nFold 4: Acc 57.98525798525799, F1 36.403507724574446 %\nAverage: 55.16122971221803 %\nF1: 34.75766022153802 %\n\nFOLD 1\n----------------------------------------------------------------------------\nmean: tensor(7891.3657), std: tensor(109087.1875)\nVariables)\n\tTrain:torch.Size([3723, 1, 101])\n\tTest: torch.Size([2079, 1, 101])\nTrain Size 3723 Test Size 2079\n\nModel: all_sparse_model\nEpochs: 200\nPATH: ./Model/all_sparse_model_1.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nStarting epoch 125\nStarting epoch 150\nStarting epoch 175\nStarting epoch 200\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 2\n----------------------------------------------------------------------------\nmean: tensor(17690.9941), std: tensor(375247.8750)\nVariables)\n\tTrain:torch.Size([4659, 1, 101])\n\tTest: torch.Size([1143, 1, 101])\nTrain Size 4659 Test Size 1143\n\nModel: all_sparse_model\nEpochs: 200\nPATH: ./Model/all_sparse_model_2.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nStarting epoch 125\nStarting epoch 150\nStarting epoch 175\nStarting epoch 200\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 3\n----------------------------------------------------------------------------\nmean: tensor(32302.1367), std: tensor(482222.)\nVariables)\n\tTrain:torch.Size([5333, 1, 101])\n\tTest: torch.Size([469, 1, 101])\nTrain Size 5333 Test Size 469\n\nModel: all_sparse_model\nEpochs: 200\nPATH: ./Model/all_sparse_model_3.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nStarting epoch 125\nStarting epoch 150\nStarting epoch 175\nStarting epoch 200\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 4\n----------------------------------------------------------------------------\nmean: tensor(7491.3950), std: tensor(125358.2031)\nVariables)\n\tTrain:torch.Size([4912, 1, 101])\n\tTest: torch.Size([890, 1, 101])\nTrain Size 4912 Test Size 890\n\nModel: all_sparse_model\nEpochs: 200\nPATH: ./Model/all_sparse_model_4.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nStarting epoch 125\nStarting epoch 150\nStarting epoch 175\nStarting epoch 200\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 5\n----------------------------------------------------------------------------\nmean: tensor(9058.3760), std: tensor(179827.0312)\nVariables)\n\tTrain:torch.Size([4581, 1, 101])\n\tTest: torch.Size([1221, 1, 101])\nTrain Size 4581 Test Size 1221\n\nModel: all_sparse_model\nEpochs: 200\nPATH: ./Model/all_sparse_model_5.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nStarting epoch 125\nStarting epoch 150\nStarting epoch 175\nStarting epoch 200\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nK-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n----------------------------------------------------------------------------\"\nFold 0: Acc 57.527657527657524, F1 36.29203052083241 %\nFold 1: Acc 58.70516185476815, F1 36.35981173672334 %\nFold 2: Acc 50.31982942430704, F1 32.48032527225317 %\nFold 3: Acc 59.662921348314605, F1 36.23716352125175 %\nFold 4: Acc 60.85176085176085, F1 37.87707671599813 %\nAverage: 57.41346620136163 %\nF1: 35.84928155341176 %\n"
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "model = all_sparse_model()\n",
    "dataset = pd.concat([pheme_sparse_final, pheme_pos_final, pheme_thread_final_avg],axis=1)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# epochs = 10\n",
    "\n",
    "testing_epochs = [100,200]\n",
    "testing_results = []\n",
    "\n",
    "for epoch in testing_epochs:\n",
    "    result = cv_process(dataset, criterion, events=pheme_event, target=pheme_y, epochs=epoch, verbose=False)\n",
    "    testing_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/x.notebook.stdout": "Fold 0: Acc 49.21, F1 32.42 %\nFold 1: Acc 66.49, F1 39.12 %\nFold 2: Acc 46.06, F1 31.36 %\nFold 3: Acc 56.07, F1 34.48 %\nFold 4: Acc 57.99, F1 36.40 %\nAverage: 55.16 %\nF1: 34.76 %\n-----------------------------\nFold 0: Acc 57.53, F1 36.29 %\nFold 1: Acc 58.71, F1 36.36 %\nFold 2: Acc 50.32, F1 32.48 %\nFold 3: Acc 59.66, F1 36.24 %\nFold 4: Acc 60.85, F1 37.88 %\nAverage: 57.41 %\nF1: 35.85 %\n-----------------------------\n"
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "epochs_diff(testing_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "************************************************************\n",
      "STARTING A CROSS-VALIDATION ... [2, 3, 4, 5, 10, 25, 50, 100] epochs\n",
      "************************************************************\n",
      "\n",
      "STARTING TEST of 2 EPOCH\n",
      "\n",
      "> FOLD 1\n",
      "> FOLD 2\n",
      "> FOLD 3\n",
      "> FOLD 4\n",
      "> FOLD 5\n",
      "> FOLD 6\n",
      "> FOLD 7\n",
      "> FOLD 8\n",
      "> FOLD 9\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      ">>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 65.31986531986533, F1 38.917415269719854\n",
      "Fold 1: Acc 75.67804024496938, F1 52.860823533214806\n",
      "Fold 2: Acc 66.52452025586354, F1 40.75424995038963\n",
      "Fold 3: Acc 77.30337078651685, F1 43.649535368374\n",
      "Fold 4: Acc 73.54627354627354, F1 43.34452112732069\n",
      "Fold 5: Acc 50.0, F1 33.33333333333333\n",
      "Fold 6: Acc 60.94420600858369, F1 38.906737067044254\n",
      "Fold 7: Acc 62.18487394957983, F1 38.41633103862764\n",
      "Fold 8: Acc 56.52173913043478, F1 36.61520676630513\n",
      "Average: 65.336%\n",
      "F1: 40.755%\n",
      "Loss: 0.657%\n",
      "\n",
      "\n",
      "STARTING TEST of 3 EPOCH\n",
      "\n",
      "> FOLD 1\n",
      "> FOLD 2\n",
      "> FOLD 3\n",
      "> FOLD 4\n",
      "> FOLD 5\n",
      "> FOLD 6\n",
      "> FOLD 7\n",
      "> FOLD 8\n",
      "> FOLD 9\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      ">>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 83.64598364598365, F1 48.63482080379723\n",
      "Fold 1: Acc 75.94050743657043, F1 44.62943477195098\n",
      "Fold 2: Acc 75.47974413646055, F1 45.460744316987565\n",
      "Fold 3: Acc 78.31460674157303, F1 50.11696747265191\n",
      "Fold 4: Acc 77.96887796887798, F1 45.571274373647356\n",
      "Fold 5: Acc 85.71428571428571, F1 46.153846153846146\n",
      "Fold 6: Acc 90.12875536480686, F1 56.12803198685462\n",
      "Fold 7: Acc 68.0672268907563, F1 40.193244059817694\n",
      "Fold 8: Acc 57.971014492753625, F1 35.30401750691606\n",
      "Average: 77.026%\n",
      "F1: 45.799%\n",
      "Loss: 0.524%\n",
      "\n",
      "\n",
      "STARTING TEST of 4 EPOCH\n",
      "\n",
      "> FOLD 1\n",
      "> FOLD 2\n",
      "> FOLD 3\n",
      "> FOLD 4\n",
      "> FOLD 5\n",
      "> FOLD 6\n",
      "> FOLD 7\n",
      "> FOLD 8\n",
      "> FOLD 9\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      ">>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 84.12698412698413, F1 50.30625807427677\n",
      "Fold 1: Acc 79.26509186351706, F1 45.84999811873257\n",
      "Fold 2: Acc 75.90618336886993, F1 46.27785968656809\n",
      "Fold 3: Acc 78.98876404494382, F1 51.9126348581707\n",
      "Fold 4: Acc 78.70597870597871, F1 46.97156247511272\n",
      "Fold 5: Acc 85.71428571428571, F1 46.153846153846146\n",
      "Fold 6: Acc 93.56223175965665, F1 67.04341592452847\n",
      "Fold 7: Acc 68.90756302521008, F1 41.42960517808388\n",
      "Fold 8: Acc 59.42028985507246, F1 36.30062065461757\n",
      "Average: 78.289%\n",
      "F1: 48.027%\n",
      "Loss: 0.504%\n",
      "\n",
      "\n",
      "STARTING TEST of 5 EPOCH\n",
      "\n",
      "> FOLD 1\n",
      "> FOLD 2\n",
      "> FOLD 3\n",
      "> FOLD 4\n",
      "> FOLD 5\n",
      "> FOLD 6\n",
      "> FOLD 7\n",
      "> FOLD 8\n",
      "> FOLD 9\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      ">>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 85.18518518518519, F1 49.51034956599607\n",
      "Fold 1: Acc 80.13998250218722, F1 46.75489984681786\n",
      "Fold 2: Acc 75.90618336886993, F1 46.56487836833107\n",
      "Fold 3: Acc 78.76404494382022, F1 54.5647939560137\n",
      "Fold 4: Acc 79.85257985257985, F1 46.12104809670539\n",
      "Fold 5: Acc 85.71428571428571, F1 46.153846153846146\n",
      "Fold 6: Acc 95.27896995708154, F1 73.98026896838167\n",
      "Fold 7: Acc 71.00840336134453, F1 42.25905796991115\n",
      "Fold 8: Acc 56.52173913043478, F1 35.30388023141646\n",
      "Average: 78.708%\n",
      "F1: 49.024%\n",
      "Loss: 0.475%\n",
      "\n",
      "\n",
      "STARTING TEST of 10 EPOCH\n",
      "\n",
      "> FOLD 1\n",
      "> FOLD 2\n",
      "> FOLD 3\n",
      "> FOLD 4\n",
      "> FOLD 5\n",
      "> FOLD 6\n",
      "> FOLD 7\n",
      "> FOLD 8\n",
      "> FOLD 9\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      ">>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 84.65608465608466, F1 49.01852031341591\n",
      "Fold 1: Acc 82.41469816272966, F1 51.632436172302874\n",
      "Fold 2: Acc 75.47974413646055, F1 48.0831777824246\n",
      "Fold 3: Acc 80.89887640449437, F1 53.60819626521306\n",
      "Fold 4: Acc 79.44307944307944, F1 46.67615353859326\n",
      "Fold 5: Acc 92.85714285714286, F1 48.14814814814815\n",
      "Fold 6: Acc 95.27896995708154, F1 73.98026896838167\n",
      "Fold 7: Acc 73.10924369747899, F1 43.322034512237735\n",
      "Fold 8: Acc 58.69565217391305, F1 35.934005543200946\n",
      "Average: 80.315%\n",
      "F1: 50.045%\n",
      "Loss: 0.456%\n",
      "\n",
      "\n",
      "STARTING TEST of 25 EPOCH\n",
      "\n",
      "> FOLD 1\n",
      "> FOLD 2\n",
      "> FOLD 3\n",
      "> FOLD 4\n",
      "> FOLD 5\n",
      "> FOLD 6\n",
      "> FOLD 7\n",
      "> FOLD 8\n",
      "> FOLD 9\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      ">>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 84.46368446368446, F1 48.91095725065866\n",
      "Fold 1: Acc 82.50218722659667, F1 55.52648985617169\n",
      "Fold 2: Acc 76.33262260127933, F1 45.290383278709555\n",
      "Fold 3: Acc 81.01123595505618, F1 52.805953097688146\n",
      "Fold 4: Acc 78.21457821457821, F1 45.60874431410129\n",
      "Fold 5: Acc 92.85714285714286, F1 48.14814814814815\n",
      "Fold 6: Acc 96.56652360515021, F1 78.16497683865815\n",
      "Fold 7: Acc 75.63025210084034, F1 47.43360856887558\n",
      "Fold 8: Acc 57.2463768115942, F1 35.36909988301684\n",
      "Average: 80.536%\n",
      "F1: 50.806%\n",
      "Loss: 0.451%\n",
      "\n",
      "\n",
      "STARTING TEST of 50 EPOCH\n",
      "\n",
      "> FOLD 1\n",
      "Starting epoch 50\n",
      "> FOLD 2\n",
      "Starting epoch 50\n",
      "> FOLD 3\n",
      "Starting epoch 50\n",
      "> FOLD 4\n",
      "Starting epoch 50\n",
      "> FOLD 5\n",
      "Starting epoch 50\n",
      "> FOLD 6\n",
      "Starting epoch 50\n",
      "> FOLD 7\n",
      "Starting epoch 50\n",
      "> FOLD 8\n",
      "Starting epoch 50\n",
      "> FOLD 9\n",
      "Starting epoch 50\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      ">>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 83.21308321308322, F1 47.416548748127944\n",
      "Fold 1: Acc 81.01487314085739, F1 56.11279052062497\n",
      "Fold 2: Acc 75.26652452025586, F1 44.50548842217387\n",
      "Fold 3: Acc 80.78651685393258, F1 51.83598913595236\n",
      "Fold 4: Acc 78.95167895167894, F1 45.849805309946184\n",
      "Fold 5: Acc 85.71428571428571, F1 46.153846153846146\n",
      "Fold 6: Acc 96.56652360515021, F1 71.64613041672436\n",
      "Fold 7: Acc 74.78991596638656, F1 46.7625604235169\n",
      "Fold 8: Acc 58.69565217391305, F1 37.41397168191485\n",
      "Average: 79.444%\n",
      "F1: 49.744%\n",
      "Loss: 0.459%\n",
      "\n",
      "\n",
      "STARTING TEST of 100 EPOCH\n",
      "\n",
      "> FOLD 1\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 2\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 3\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 4\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 5\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 6\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 7\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 8\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 9\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      ">>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 82.82828282828282, F1 48.047117406428775\n",
      "Fold 1: Acc 80.40244969378828, F1 55.068897942309775\n",
      "Fold 2: Acc 75.05330490405117, F1 45.36833342035996\n",
      "Fold 3: Acc 80.89887640449437, F1 51.00215764632298\n",
      "Fold 4: Acc 77.39557739557739, F1 45.284567708001134\n",
      "Fold 5: Acc 71.42857142857143, F1 41.666666666666664\n",
      "Fold 6: Acc 95.27896995708154, F1 67.86561447228762\n",
      "Fold 7: Acc 73.52941176470588, F1 43.373775670389094\n",
      "Fold 8: Acc 58.69565217391305, F1 37.79304550261463\n",
      "Average: 77.279%\n",
      "F1: 48.386%\n",
      "Loss: 0.478%\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 65.32, F1 38.92 %\n",
      "Fold 1: Acc 75.68, F1 52.86 %\n",
      "Fold 2: Acc 66.52, F1 40.75 %\n",
      "Fold 3: Acc 77.30, F1 43.65 %\n",
      "Fold 4: Acc 73.55, F1 43.34 %\n",
      "Fold 5: Acc 50.00, F1 33.33 %\n",
      "Fold 6: Acc 60.94, F1 38.91 %\n",
      "Fold 7: Acc 62.18, F1 38.42 %\n",
      "Fold 8: Acc 56.52, F1 36.62 %\n",
      "Average: 65.34 %\n",
      "F1: 40.76 %\n",
      "-----------------------------\n",
      "Fold 0: Acc 83.65, F1 48.63 %\n",
      "Fold 1: Acc 75.94, F1 44.63 %\n",
      "Fold 2: Acc 75.48, F1 45.46 %\n",
      "Fold 3: Acc 78.31, F1 50.12 %\n",
      "Fold 4: Acc 77.97, F1 45.57 %\n",
      "Fold 5: Acc 85.71, F1 46.15 %\n",
      "Fold 6: Acc 90.13, F1 56.13 %\n",
      "Fold 7: Acc 68.07, F1 40.19 %\n",
      "Fold 8: Acc 57.97, F1 35.30 %\n",
      "Average: 77.03 %\n",
      "F1: 45.80 %\n",
      "-----------------------------\n",
      "Fold 0: Acc 84.13, F1 50.31 %\n",
      "Fold 1: Acc 79.27, F1 45.85 %\n",
      "Fold 2: Acc 75.91, F1 46.28 %\n",
      "Fold 3: Acc 78.99, F1 51.91 %\n",
      "Fold 4: Acc 78.71, F1 46.97 %\n",
      "Fold 5: Acc 85.71, F1 46.15 %\n",
      "Fold 6: Acc 93.56, F1 67.04 %\n",
      "Fold 7: Acc 68.91, F1 41.43 %\n",
      "Fold 8: Acc 59.42, F1 36.30 %\n",
      "Average: 78.29 %\n",
      "F1: 48.03 %\n",
      "-----------------------------\n",
      "Fold 0: Acc 85.19, F1 49.51 %\n",
      "Fold 1: Acc 80.14, F1 46.75 %\n",
      "Fold 2: Acc 75.91, F1 46.56 %\n",
      "Fold 3: Acc 78.76, F1 54.56 %\n",
      "Fold 4: Acc 79.85, F1 46.12 %\n",
      "Fold 5: Acc 85.71, F1 46.15 %\n",
      "Fold 6: Acc 95.28, F1 73.98 %\n",
      "Fold 7: Acc 71.01, F1 42.26 %\n",
      "Fold 8: Acc 56.52, F1 35.30 %\n",
      "Average: 78.71 %\n",
      "F1: 49.02 %\n",
      "-----------------------------\n",
      "Fold 0: Acc 84.66, F1 49.02 %\n",
      "Fold 1: Acc 82.41, F1 51.63 %\n",
      "Fold 2: Acc 75.48, F1 48.08 %\n",
      "Fold 3: Acc 80.90, F1 53.61 %\n",
      "Fold 4: Acc 79.44, F1 46.68 %\n",
      "Fold 5: Acc 92.86, F1 48.15 %\n",
      "Fold 6: Acc 95.28, F1 73.98 %\n",
      "Fold 7: Acc 73.11, F1 43.32 %\n",
      "Fold 8: Acc 58.70, F1 35.93 %\n",
      "Average: 80.31 %\n",
      "F1: 50.04 %\n",
      "-----------------------------\n",
      "Fold 0: Acc 84.46, F1 48.91 %\n",
      "Fold 1: Acc 82.50, F1 55.53 %\n",
      "Fold 2: Acc 76.33, F1 45.29 %\n",
      "Fold 3: Acc 81.01, F1 52.81 %\n",
      "Fold 4: Acc 78.21, F1 45.61 %\n",
      "Fold 5: Acc 92.86, F1 48.15 %\n",
      "Fold 6: Acc 96.57, F1 78.16 %\n",
      "Fold 7: Acc 75.63, F1 47.43 %\n",
      "Fold 8: Acc 57.25, F1 35.37 %\n",
      "Average: 80.54 %\n",
      "F1: 50.81 %\n",
      "-----------------------------\n",
      "Fold 0: Acc 83.21, F1 47.42 %\n",
      "Fold 1: Acc 81.01, F1 56.11 %\n",
      "Fold 2: Acc 75.27, F1 44.51 %\n",
      "Fold 3: Acc 80.79, F1 51.84 %\n",
      "Fold 4: Acc 78.95, F1 45.85 %\n",
      "Fold 5: Acc 85.71, F1 46.15 %\n",
      "Fold 6: Acc 96.57, F1 71.65 %\n",
      "Fold 7: Acc 74.79, F1 46.76 %\n",
      "Fold 8: Acc 58.70, F1 37.41 %\n",
      "Average: 79.44 %\n",
      "F1: 49.74 %\n",
      "-----------------------------\n",
      "Fold 0: Acc 82.83, F1 48.05 %\n",
      "Fold 1: Acc 80.40, F1 55.07 %\n",
      "Fold 2: Acc 75.05, F1 45.37 %\n",
      "Fold 3: Acc 80.90, F1 51.00 %\n",
      "Fold 4: Acc 77.40, F1 45.28 %\n",
      "Fold 5: Acc 71.43, F1 41.67 %\n",
      "Fold 6: Acc 95.28, F1 67.87 %\n",
      "Fold 7: Acc 73.53, F1 43.37 %\n",
      "Fold 8: Acc 58.70, F1 37.79 %\n",
      "Average: 77.28 %\n",
      "F1: 48.39 %\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "class bert_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(bert_model, self).__init__() # 1*20\n",
    "        self.layers = nn.Sequential(\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(768, 50, bias=True),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(50, 8, bias=True),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(8, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = bert_model()\n",
    "dataset = pd.concat([pheme_bert_simple_normal,ext_bert_simple_normal],axis=0,ignore_index=True)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# epochs = 10\n",
    "\n",
    "testing_epochs = [2,3,4,5,10,25,50,100]\n",
    "testing_results = []\n",
    "\n",
    "writeLog().write(\"./Model/\"+bert_model.__name__+\"_\"+\"log.txt\",f\"\\n\\n************************************************************\\nSTARTING A CROSS-VALIDATION ... {testing_epochs} epochs\\n************************************************************\")\n",
    "\n",
    "\n",
    "for epoch in testing_epochs:\n",
    "    result = cv_process(dataset, criterion, modelClass=bert_model, events=all_event, target=all_y, epochs=epoch, verbose=False)\n",
    "    testing_results.append(result)\n",
    "\n",
    "epochs_diff(testing_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "************************************************************\n",
      "STARTING A CROSS-VALIDATION ... [2, 3, 4, 5, 10, 25, 50, 100] epochs\n",
      "************************************************************\n",
      "\n",
      "STARTING TEST of 2 EPOCH\n",
      "\n",
      "> FOLD 1\n",
      "> FOLD 2\n",
      "> FOLD 3\n",
      "> FOLD 4\n",
      "> FOLD 5\n",
      "> FOLD 6\n",
      "> FOLD 7\n",
      "> FOLD 8\n",
      "> FOLD 9\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      ">>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 80.13468013468014, F1 45.372089880119\n",
      "Fold 1: Acc 72.17847769028872, F1 42.34933598612385\n",
      "Fold 2: Acc 75.47974413646055, F1 45.66179898243038\n",
      "Fold 3: Acc 77.64044943820225, F1 48.89709070482427\n",
      "Fold 4: Acc 74.36527436527437, F1 44.78585585646129\n",
      "Fold 5: Acc 85.71428571428571, F1 46.153846153846146\n",
      "Fold 6: Acc 79.39914163090128, F1 49.4352435911727\n",
      "Fold 7: Acc 65.54621848739495, F1 39.36211791191444\n",
      "Fold 8: Acc 58.69565217391305, F1 36.56052336946673\n",
      "Average: 74.350%\n",
      "F1: 44.286%\n",
      "Loss: 0.606%\n",
      "\n",
      "\n",
      "STARTING TEST of 3 EPOCH\n",
      "\n",
      "> FOLD 1\n",
      "> FOLD 2\n",
      "> FOLD 3\n",
      "> FOLD 4\n",
      "> FOLD 5\n",
      "> FOLD 6\n",
      "> FOLD 7\n",
      "> FOLD 8\n",
      "> FOLD 9\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      ">>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 84.07888407888407, F1 49.87041208700788\n",
      "Fold 1: Acc 79.35258092738408, F1 47.712966900937545\n",
      "Fold 2: Acc 76.33262260127933, F1 44.433059604171625\n",
      "Fold 3: Acc 79.10112359550561, F1 50.19007675414114\n",
      "Fold 4: Acc 78.54217854217855, F1 46.23469628438108\n",
      "Fold 5: Acc 85.71428571428571, F1 46.153846153846146\n",
      "Fold 6: Acc 93.13304721030042, F1 66.90810650995311\n",
      "Fold 7: Acc 68.0672268907563, F1 40.20354178082307\n",
      "Fold 8: Acc 60.86956521739131, F1 37.42680796353959\n",
      "Average: 78.355%\n",
      "F1: 47.682%\n",
      "Loss: 0.479%\n",
      "\n",
      "\n",
      "STARTING TEST of 4 EPOCH\n",
      "\n",
      "> FOLD 1\n",
      "> FOLD 2\n",
      "> FOLD 3\n",
      "> FOLD 4\n",
      "> FOLD 5\n",
      "> FOLD 6\n",
      "> FOLD 7\n",
      "> FOLD 8\n",
      "> FOLD 9\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      ">>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 84.75228475228475, F1 50.148758209501054\n",
      "Fold 1: Acc 82.50218722659667, F1 53.55711334110573\n",
      "Fold 2: Acc 77.61194029850746, F1 46.62529594358034\n",
      "Fold 3: Acc 79.21348314606742, F1 51.1543261016117\n",
      "Fold 4: Acc 79.19737919737919, F1 47.81555371268323\n",
      "Fold 5: Acc 85.71428571428571, F1 46.153846153846146\n",
      "Fold 6: Acc 95.70815450643777, F1 77.52450266629113\n",
      "Fold 7: Acc 71.84873949579831, F1 42.577793509408764\n",
      "Fold 8: Acc 60.86956521739131, F1 37.57272035532905\n",
      "Average: 79.713%\n",
      "F1: 50.348%\n",
      "Loss: 0.440%\n",
      "\n",
      "\n",
      "STARTING TEST of 5 EPOCH\n",
      "\n",
      "> FOLD 1\n",
      "> FOLD 2\n",
      "> FOLD 3\n",
      "> FOLD 4\n",
      "> FOLD 5\n",
      "> FOLD 6\n",
      "> FOLD 7\n",
      "> FOLD 8\n",
      "> FOLD 9\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      ">>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 85.04088504088504, F1 50.1770347328544\n",
      "Fold 1: Acc 83.55205599300088, F1 56.7371700992673\n",
      "Fold 2: Acc 77.39872068230277, F1 47.21012596772206\n",
      "Fold 3: Acc 79.88764044943821, F1 52.306893935933836\n",
      "Fold 4: Acc 79.03357903357903, F1 47.12298949027104\n",
      "Fold 5: Acc 92.85714285714286, F1 48.14814814814815\n",
      "Fold 6: Acc 95.70815450643777, F1 77.52450266629113\n",
      "Fold 7: Acc 72.68907563025209, F1 46.229773424443515\n",
      "Fold 8: Acc 60.86956521739131, F1 37.191105930736114\n",
      "Average: 80.782%\n",
      "F1: 51.405%\n",
      "Loss: 0.419%\n",
      "\n",
      "\n",
      "STARTING TEST of 10 EPOCH\n",
      "\n",
      "> FOLD 1\n",
      "> FOLD 2\n",
      "> FOLD 3\n",
      "> FOLD 4\n",
      "> FOLD 5\n",
      "> FOLD 6\n",
      "> FOLD 7\n",
      "> FOLD 8\n",
      "> FOLD 9\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      ">>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 84.992784992785, F1 50.579921706935\n",
      "Fold 1: Acc 83.63954505686789, F1 57.384537969114874\n",
      "Fold 2: Acc 77.18550106609808, F1 48.73190829973893\n",
      "Fold 3: Acc 80.2247191011236, F1 53.34559324321424\n",
      "Fold 4: Acc 79.52497952497953, F1 45.98318873905018\n",
      "Fold 5: Acc 92.85714285714286, F1 48.14814814814815\n",
      "Fold 6: Acc 96.13733905579399, F1 78.03868805172117\n",
      "Fold 7: Acc 74.36974789915966, F1 47.001812154465426\n",
      "Fold 8: Acc 58.69565217391305, F1 36.14433249832941\n",
      "Average: 80.847%\n",
      "F1: 51.706%\n",
      "Loss: 0.411%\n",
      "\n",
      "\n",
      "STARTING TEST of 25 EPOCH\n",
      "\n",
      "> FOLD 1\n",
      "> FOLD 2\n",
      "> FOLD 3\n",
      "> FOLD 4\n",
      "> FOLD 5\n",
      "> FOLD 6\n",
      "> FOLD 7\n",
      "> FOLD 8\n",
      "> FOLD 9\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      ">>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 83.98268398268398, F1 49.16137504051661\n",
      "Fold 1: Acc 81.97725284339458, F1 59.138516881776276\n",
      "Fold 2: Acc 76.97228144989339, F1 45.38770170550567\n",
      "Fold 3: Acc 80.89887640449437, F1 52.70026824710052\n",
      "Fold 4: Acc 79.19737919737919, F1 45.9603566996967\n",
      "Fold 5: Acc 92.85714285714286, F1 48.14814814814815\n",
      "Fold 6: Acc 95.27896995708154, F1 70.95022065590223\n",
      "Fold 7: Acc 75.63025210084034, F1 43.79282941607093\n",
      "Fold 8: Acc 59.42028985507246, F1 37.96340446232892\n",
      "Average: 80.691%\n",
      "F1: 50.356%\n",
      "Loss: 0.419%\n",
      "\n",
      "\n",
      "STARTING TEST of 50 EPOCH\n",
      "\n",
      "> FOLD 1\n",
      "Starting epoch 50\n",
      "> FOLD 2\n",
      "Starting epoch 50\n",
      "> FOLD 3\n",
      "Starting epoch 50\n",
      "> FOLD 4\n",
      "Starting epoch 50\n",
      "> FOLD 5\n",
      "Starting epoch 50\n",
      "> FOLD 6\n",
      "Starting epoch 50\n",
      "> FOLD 7\n",
      "Starting epoch 50\n",
      "> FOLD 8\n",
      "Starting epoch 50\n",
      "> FOLD 9\n",
      "Starting epoch 50\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      ">>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 84.46368446368446, F1 49.28543083804961\n",
      "Fold 1: Acc 81.97725284339458, F1 61.92045735435381\n",
      "Fold 2: Acc 77.82515991471215, F1 47.45499425358354\n",
      "Fold 3: Acc 80.78651685393258, F1 51.858602998251186\n",
      "Fold 4: Acc 78.95167895167894, F1 47.12139425092623\n",
      "Fold 5: Acc 85.71428571428571, F1 46.153846153846146\n",
      "Fold 6: Acc 95.27896995708154, F1 67.53227574492978\n",
      "Fold 7: Acc 76.05042016806722, F1 44.04804261246059\n",
      "Fold 8: Acc 62.31884057971014, F1 41.11842302364434\n",
      "Average: 80.374%\n",
      "F1: 50.721%\n",
      "Loss: 0.405%\n",
      "\n",
      "\n",
      "STARTING TEST of 100 EPOCH\n",
      "\n",
      "> FOLD 1\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 2\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 3\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 4\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 5\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 6\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 7\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 8\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 9\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      ">>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 84.992784992785, F1 50.964012390941825\n",
      "Fold 1: Acc 86.43919510061242, F1 58.62487150722842\n",
      "Fold 2: Acc 81.02345415778251, F1 50.23199698909029\n",
      "Fold 3: Acc 85.73033707865169, F1 55.36901326047315\n",
      "Fold 4: Acc 82.80098280098281, F1 48.58396607302798\n",
      "Fold 5: Acc 100.0, F1 100.0\n",
      "Fold 6: Acc 93.13304721030042, F1 63.507329890292375\n",
      "Fold 7: Acc 81.5126050420168, F1 49.01037649974378\n",
      "Fold 8: Acc 84.78260869565217, F1 50.68613534161404\n",
      "Average: 86.713%\n",
      "F1: 58.553%\n",
      "Loss: 0.308%\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 80.13, F1 45.37 %\n",
      "Fold 1: Acc 72.18, F1 42.35 %\n",
      "Fold 2: Acc 75.48, F1 45.66 %\n",
      "Fold 3: Acc 77.64, F1 48.90 %\n",
      "Fold 4: Acc 74.37, F1 44.79 %\n",
      "Fold 5: Acc 85.71, F1 46.15 %\n",
      "Fold 6: Acc 79.40, F1 49.44 %\n",
      "Fold 7: Acc 65.55, F1 39.36 %\n",
      "Fold 8: Acc 58.70, F1 36.56 %\n",
      "Average: 74.35 %\n",
      "F1: 44.29 %\n",
      "-----------------------------\n",
      "Fold 0: Acc 84.08, F1 49.87 %\n",
      "Fold 1: Acc 79.35, F1 47.71 %\n",
      "Fold 2: Acc 76.33, F1 44.43 %\n",
      "Fold 3: Acc 79.10, F1 50.19 %\n",
      "Fold 4: Acc 78.54, F1 46.23 %\n",
      "Fold 5: Acc 85.71, F1 46.15 %\n",
      "Fold 6: Acc 93.13, F1 66.91 %\n",
      "Fold 7: Acc 68.07, F1 40.20 %\n",
      "Fold 8: Acc 60.87, F1 37.43 %\n",
      "Average: 78.35 %\n",
      "F1: 47.68 %\n",
      "-----------------------------\n",
      "Fold 0: Acc 84.75, F1 50.15 %\n",
      "Fold 1: Acc 82.50, F1 53.56 %\n",
      "Fold 2: Acc 77.61, F1 46.63 %\n",
      "Fold 3: Acc 79.21, F1 51.15 %\n",
      "Fold 4: Acc 79.20, F1 47.82 %\n",
      "Fold 5: Acc 85.71, F1 46.15 %\n",
      "Fold 6: Acc 95.71, F1 77.52 %\n",
      "Fold 7: Acc 71.85, F1 42.58 %\n",
      "Fold 8: Acc 60.87, F1 37.57 %\n",
      "Average: 79.71 %\n",
      "F1: 50.35 %\n",
      "-----------------------------\n",
      "Fold 0: Acc 85.04, F1 50.18 %\n",
      "Fold 1: Acc 83.55, F1 56.74 %\n",
      "Fold 2: Acc 77.40, F1 47.21 %\n",
      "Fold 3: Acc 79.89, F1 52.31 %\n",
      "Fold 4: Acc 79.03, F1 47.12 %\n",
      "Fold 5: Acc 92.86, F1 48.15 %\n",
      "Fold 6: Acc 95.71, F1 77.52 %\n",
      "Fold 7: Acc 72.69, F1 46.23 %\n",
      "Fold 8: Acc 60.87, F1 37.19 %\n",
      "Average: 80.78 %\n",
      "F1: 51.41 %\n",
      "-----------------------------\n",
      "Fold 0: Acc 84.99, F1 50.58 %\n",
      "Fold 1: Acc 83.64, F1 57.38 %\n",
      "Fold 2: Acc 77.19, F1 48.73 %\n",
      "Fold 3: Acc 80.22, F1 53.35 %\n",
      "Fold 4: Acc 79.52, F1 45.98 %\n",
      "Fold 5: Acc 92.86, F1 48.15 %\n",
      "Fold 6: Acc 96.14, F1 78.04 %\n",
      "Fold 7: Acc 74.37, F1 47.00 %\n",
      "Fold 8: Acc 58.70, F1 36.14 %\n",
      "Average: 80.85 %\n",
      "F1: 51.71 %\n",
      "-----------------------------\n",
      "Fold 0: Acc 83.98, F1 49.16 %\n",
      "Fold 1: Acc 81.98, F1 59.14 %\n",
      "Fold 2: Acc 76.97, F1 45.39 %\n",
      "Fold 3: Acc 80.90, F1 52.70 %\n",
      "Fold 4: Acc 79.20, F1 45.96 %\n",
      "Fold 5: Acc 92.86, F1 48.15 %\n",
      "Fold 6: Acc 95.28, F1 70.95 %\n",
      "Fold 7: Acc 75.63, F1 43.79 %\n",
      "Fold 8: Acc 59.42, F1 37.96 %\n",
      "Average: 80.69 %\n",
      "F1: 50.36 %\n",
      "-----------------------------\n",
      "Fold 0: Acc 84.46, F1 49.29 %\n",
      "Fold 1: Acc 81.98, F1 61.92 %\n",
      "Fold 2: Acc 77.83, F1 47.45 %\n",
      "Fold 3: Acc 80.79, F1 51.86 %\n",
      "Fold 4: Acc 78.95, F1 47.12 %\n",
      "Fold 5: Acc 85.71, F1 46.15 %\n",
      "Fold 6: Acc 95.28, F1 67.53 %\n",
      "Fold 7: Acc 76.05, F1 44.05 %\n",
      "Fold 8: Acc 62.32, F1 41.12 %\n",
      "Average: 80.37 %\n",
      "F1: 50.72 %\n",
      "-----------------------------\n",
      "Fold 0: Acc 84.99, F1 50.96 %\n",
      "Fold 1: Acc 86.44, F1 58.62 %\n",
      "Fold 2: Acc 81.02, F1 50.23 %\n",
      "Fold 3: Acc 85.73, F1 55.37 %\n",
      "Fold 4: Acc 82.80, F1 48.58 %\n",
      "Fold 5: Acc 100.00, F1 100.00 %\n",
      "Fold 6: Acc 93.13, F1 63.51 %\n",
      "Fold 7: Acc 81.51, F1 49.01 %\n",
      "Fold 8: Acc 84.78, F1 50.69 %\n",
      "Average: 86.71 %\n",
      "F1: 58.55 %\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "class bert_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(bert_model, self).__init__() # 1*20\n",
    "        self.layers = nn.Sequential(\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(768, 50, bias=True),\n",
    "            nn.ELU(),\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(50, 8, bias=True),\n",
    "            nn.ELU(),\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(8, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = bert_model()\n",
    "dataset = pd.concat([pheme_bert_simple_normal,ext_bert_simple_normal],axis=0,ignore_index=True)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# epochs = 10\n",
    "\n",
    "testing_epochs = [2,3,4,5,10,25,50,100]\n",
    "testing_results = []\n",
    "\n",
    "writeLog().write(\"./Model/\"+bert_model.__name__+\"_\"+\"log.txt\",f\"\\n\\n************************************************************\\nSTARTING A CROSS-VALIDATION ... {testing_epochs} epochs\\n************************************************************\")\n",
    "\n",
    "\n",
    "for epoch in testing_epochs:\n",
    "    result = cv_process(dataset, criterion, modelClass=bert_model, events=all_event, target=all_y, epochs=epoch, verbose=False)\n",
    "    testing_results.append(result)\n",
    "\n",
    "epochs_diff(testing_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT + ALL SPARSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_simple_all = pd.concat([pheme_bert_simple_normal,ext_bert_simple_normal],axis=0,ignore_index=True)\n",
    "sparse_all = pd.concat([pheme_sparse_final, ext_sparse_final],axis=0,ignore_index=True)\n",
    "thread_avg_all = pd.concat([pheme_thread_final_avg, ext_thread_final_avg],axis=0,ignore_index=True)\n",
    "pos_all = pd.concat([pheme_pos_final, ext_pos_final],axis=0,ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "((6425, 768), (6425, 28), (6425, 52), (6425, 21), (6425, 869))"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_simple_all.shape, sparse_all.shape, thread_avg_all.shape, pos_all.shape, dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "************************************************************\n",
      "STARTING A CROSS-VALIDATION ... [2, 3, 4, 5, 10, 25, 50, 100] epochs\n",
      "************************************************************\n",
      "\n",
      "STARTING TEST of 2 EPOCH\n",
      "\n",
      "> FOLD 1\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "> FOLD 2\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "> FOLD 3\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "> FOLD 4\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "> FOLD 5\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "> FOLD 6\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "> FOLD 7\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "> FOLD 8\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "> FOLD 9\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      ">>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 53.96825396825397, F1 34.601724126999834\n",
      "Fold 1: Acc 60.10498687664042, F1 36.98149550850507\n",
      "Fold 2: Acc 49.68017057569296, F1 32.446973991992294\n",
      "Fold 3: Acc 46.853932584269664, F1 30.363768711542207\n",
      "Fold 4: Acc 52.416052416052416, F1 33.67409036155636\n",
      "Fold 5: Acc 78.57142857142857, F1 44.0\n",
      "Fold 6: Acc 15.450643776824036, F1 13.241133212565202\n",
      "Fold 7: Acc 55.88235294117647, F1 36.03811368063696\n",
      "Fold 8: Acc 49.275362318840585, F1 33.59751949758602\n",
      "Average: 51.356%\n",
      "F1: 32.772%\n",
      "Loss: 375.492%\n",
      "\n",
      "\n",
      "STARTING TEST of 3 EPOCH\n",
      "\n",
      "> FOLD 1\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "> FOLD 2\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "> FOLD 3\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "> FOLD 4\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "> FOLD 5\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "> FOLD 6\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "> FOLD 7\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "> FOLD 8\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "> FOLD 9\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      ">>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 47.234247234247235, F1 31.651457859681674\n",
      "Fold 1: Acc 53.805774278215225, F1 34.58945042120513\n",
      "Fold 2: Acc 50.10660980810234, F1 33.75766509497724\n",
      "Fold 3: Acc 48.87640449438202, F1 32.26803277504431\n",
      "Fold 4: Acc 49.221949221949224, F1 32.51830940895498\n",
      "Fold 5: Acc 50.0, F1 33.33333333333333\n",
      "Fold 6: Acc 39.48497854077253, F1 28.473287613052495\n",
      "Fold 7: Acc 47.05882352941176, F1 29.77241315263709\n",
      "Fold 8: Acc 45.65217391304348, F1 30.83580843279941\n",
      "Average: 47.938%\n",
      "F1: 31.911%\n",
      "Loss: 126.459%\n",
      "\n",
      "\n",
      "STARTING TEST of 4 EPOCH\n",
      "\n",
      "> FOLD 1\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "> FOLD 2\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "> FOLD 3\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "> FOLD 4\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "> FOLD 5\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "> FOLD 6\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "> FOLD 7\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "> FOLD 8\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "> FOLD 9\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      ">>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 38.62433862433862, F1 26.697025742486648\n",
      "Fold 1: Acc 36.39545056867892, F1 24.633937956652243\n",
      "Fold 2: Acc 50.31982942430704, F1 33.41233417464865\n",
      "Fold 3: Acc 52.359550561797754, F1 34.4839282150267\n",
      "Fold 4: Acc 51.02375102375102, F1 33.80136890156999\n",
      "Fold 5: Acc 50.0, F1 33.33333333333333\n",
      "Fold 6: Acc 63.0901287553648, F1 38.174676010948865\n",
      "Fold 7: Acc 47.89915966386555, F1 32.5530340695235\n",
      "Fold 8: Acc 60.86956521739131, F1 38.687551980161835\n",
      "Average: 50.065%\n",
      "F1: 32.864%\n",
      "Loss: 230.090%\n",
      "\n",
      "\n",
      "STARTING TEST of 5 EPOCH\n",
      "\n",
      "> FOLD 1\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "> FOLD 2\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "> FOLD 3\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "> FOLD 4\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "> FOLD 5\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "> FOLD 6\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "> FOLD 7\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "> FOLD 8\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "> FOLD 9\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      ">>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 58.48965848965849, F1 36.2302430077649\n",
      "Fold 1: Acc 37.70778652668417, F1 26.153483470416123\n",
      "Fold 2: Acc 53.09168443496801, F1 33.9624297171968\n",
      "Fold 3: Acc 47.19101123595505, F1 30.637765686649633\n",
      "Fold 4: Acc 56.838656838656846, F1 37.03710190174573\n",
      "Fold 5: Acc 21.428571428571427, F1 17.647058823529413\n",
      "Fold 6: Acc 87.1244635193133, F1 56.51367177509721\n",
      "Fold 7: Acc 49.159663865546214, F1 28.990635667132693\n",
      "Fold 8: Acc 52.89855072463768, F1 34.95337161846298\n",
      "Average: 51.548%\n",
      "F1: 33.570%\n",
      "Loss: 133.668%\n",
      "\n",
      "\n",
      "STARTING TEST of 10 EPOCH\n",
      "\n",
      "> FOLD 1\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "> FOLD 2\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "> FOLD 3\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "> FOLD 4\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "> FOLD 5\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "> FOLD 6\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "> FOLD 7\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "> FOLD 8\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "> FOLD 9\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      ">>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 42.66474266474267, F1 29.45245234146356\n",
      "Fold 1: Acc 54.330708661417326, F1 34.681848180139134\n",
      "Fold 2: Acc 52.66524520255863, F1 34.55073802862808\n",
      "Fold 3: Acc 47.86516853932584, F1 30.075995301542896\n",
      "Fold 4: Acc 56.42915642915642, F1 35.57143494819916\n",
      "Fold 5: Acc 14.285714285714285, F1 12.5\n",
      "Fold 6: Acc 74.2489270386266, F1 42.541146825592584\n",
      "Fold 7: Acc 47.89915966386555, F1 34.16411547962236\n",
      "Fold 8: Acc 51.449275362318836, F1 33.10650828127384\n",
      "Average: 49.093%\n",
      "F1: 31.849%\n",
      "Loss: 44.252%\n",
      "\n",
      "\n",
      "STARTING TEST of 25 EPOCH\n",
      "\n",
      "> FOLD 1\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "> FOLD 2\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "> FOLD 3\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "> FOLD 4\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "> FOLD 5\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "> FOLD 6\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "> FOLD 7\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "> FOLD 8\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "> FOLD 9\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      ">>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 46.464646464646464, F1 31.332196421029916\n",
      "Fold 1: Acc 45.66929133858268, F1 30.70765565871639\n",
      "Fold 2: Acc 51.812366737739865, F1 33.90150848090963\n",
      "Fold 3: Acc 53.70786516853933, F1 32.33706486282848\n",
      "Fold 4: Acc 44.88124488124488, F1 28.969019831679127\n",
      "Fold 5: Acc 78.57142857142857, F1 44.0\n",
      "Fold 6: Acc 61.37339055793991, F1 38.248447891587695\n",
      "Fold 7: Acc 50.0, F1 32.755471973594005\n",
      "Fold 8: Acc 55.79710144927537, F1 32.8750222218279\n",
      "Average: 54.253%\n",
      "F1: 33.903%\n",
      "Loss: 5.597%\n",
      "\n",
      "\n",
      "STARTING TEST of 50 EPOCH\n",
      "\n",
      "> FOLD 1\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "Starting epoch 50\n",
      "> FOLD 2\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "Starting epoch 50\n",
      "> FOLD 3\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "Starting epoch 50\n",
      "> FOLD 4\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "Starting epoch 50\n",
      "> FOLD 5\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "Starting epoch 50\n",
      "> FOLD 6\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "Starting epoch 50\n",
      "> FOLD 7\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "Starting epoch 50\n",
      "> FOLD 8\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "Starting epoch 50\n",
      "> FOLD 9\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "Starting epoch 50\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      ">>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 59.45165945165945, F1 36.69921563703778\n",
      "Fold 1: Acc 57.48031496062992, F1 36.24794286691667\n",
      "Fold 2: Acc 52.02558635394456, F1 33.961921701755415\n",
      "Fold 3: Acc 46.741573033707866, F1 31.408544032409523\n",
      "Fold 4: Acc 52.98935298935299, F1 34.326799172183954\n",
      "Fold 5: Acc 21.428571428571427, F1 17.647058823529413\n",
      "Fold 6: Acc 56.22317596566524, F1 35.723320603428824\n",
      "Fold 7: Acc 54.20168067226891, F1 35.99181152941646\n",
      "Fold 8: Acc 44.927536231884055, F1 30.895845968309736\n",
      "Average: 49.497%\n",
      "F1: 32.545%\n",
      "Loss: 0.946%\n",
      "\n",
      "\n",
      "STARTING TEST of 100 EPOCH\n",
      "\n",
      "> FOLD 1\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 2\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 3\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 4\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 5\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 6\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 7\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 8\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 9\n",
      "Reset trainable parameters of layer = Linear(in_features=869, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=8, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=3, out_features=1, bias=True)\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      ">>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 55.41125541125541, F1 35.18538389009141\n",
      "Fold 1: Acc 52.66841644794401, F1 34.43179769822746\n",
      "Fold 2: Acc 50.53304904051173, F1 33.421290915643944\n",
      "Fold 3: Acc 48.426966292134836, F1 32.12985596378982\n",
      "Fold 4: Acc 52.825552825552826, F1 34.2208762634913\n",
      "Fold 5: Acc 35.714285714285715, F1 26.315789473684212\n",
      "Fold 6: Acc 44.20600858369099, F1 31.176555732629627\n",
      "Fold 7: Acc 55.88235294117647, F1 36.09216194163216\n",
      "Fold 8: Acc 56.52173913043478, F1 35.88763173185204\n",
      "Average: 50.243%\n",
      "F1: 33.207%\n",
      "Loss: 1.671%\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 53.97, F1 34.60 %\n",
      "Fold 1: Acc 60.10, F1 36.98 %\n",
      "Fold 2: Acc 49.68, F1 32.45 %\n",
      "Fold 3: Acc 46.85, F1 30.36 %\n",
      "Fold 4: Acc 52.42, F1 33.67 %\n",
      "Fold 5: Acc 78.57, F1 44.00 %\n",
      "Fold 6: Acc 15.45, F1 13.24 %\n",
      "Fold 7: Acc 55.88, F1 36.04 %\n",
      "Fold 8: Acc 49.28, F1 33.60 %\n",
      "Average: 51.36 %\n",
      "F1: 32.77 %\n",
      "-----------------------------\n",
      "Fold 0: Acc 47.23, F1 31.65 %\n",
      "Fold 1: Acc 53.81, F1 34.59 %\n",
      "Fold 2: Acc 50.11, F1 33.76 %\n",
      "Fold 3: Acc 48.88, F1 32.27 %\n",
      "Fold 4: Acc 49.22, F1 32.52 %\n",
      "Fold 5: Acc 50.00, F1 33.33 %\n",
      "Fold 6: Acc 39.48, F1 28.47 %\n",
      "Fold 7: Acc 47.06, F1 29.77 %\n",
      "Fold 8: Acc 45.65, F1 30.84 %\n",
      "Average: 47.94 %\n",
      "F1: 31.91 %\n",
      "-----------------------------\n",
      "Fold 0: Acc 38.62, F1 26.70 %\n",
      "Fold 1: Acc 36.40, F1 24.63 %\n",
      "Fold 2: Acc 50.32, F1 33.41 %\n",
      "Fold 3: Acc 52.36, F1 34.48 %\n",
      "Fold 4: Acc 51.02, F1 33.80 %\n",
      "Fold 5: Acc 50.00, F1 33.33 %\n",
      "Fold 6: Acc 63.09, F1 38.17 %\n",
      "Fold 7: Acc 47.90, F1 32.55 %\n",
      "Fold 8: Acc 60.87, F1 38.69 %\n",
      "Average: 50.06 %\n",
      "F1: 32.86 %\n",
      "-----------------------------\n",
      "Fold 0: Acc 58.49, F1 36.23 %\n",
      "Fold 1: Acc 37.71, F1 26.15 %\n",
      "Fold 2: Acc 53.09, F1 33.96 %\n",
      "Fold 3: Acc 47.19, F1 30.64 %\n",
      "Fold 4: Acc 56.84, F1 37.04 %\n",
      "Fold 5: Acc 21.43, F1 17.65 %\n",
      "Fold 6: Acc 87.12, F1 56.51 %\n",
      "Fold 7: Acc 49.16, F1 28.99 %\n",
      "Fold 8: Acc 52.90, F1 34.95 %\n",
      "Average: 51.55 %\n",
      "F1: 33.57 %\n",
      "-----------------------------\n",
      "Fold 0: Acc 42.66, F1 29.45 %\n",
      "Fold 1: Acc 54.33, F1 34.68 %\n",
      "Fold 2: Acc 52.67, F1 34.55 %\n",
      "Fold 3: Acc 47.87, F1 30.08 %\n",
      "Fold 4: Acc 56.43, F1 35.57 %\n",
      "Fold 5: Acc 14.29, F1 12.50 %\n",
      "Fold 6: Acc 74.25, F1 42.54 %\n",
      "Fold 7: Acc 47.90, F1 34.16 %\n",
      "Fold 8: Acc 51.45, F1 33.11 %\n",
      "Average: 49.09 %\n",
      "F1: 31.85 %\n",
      "-----------------------------\n",
      "Fold 0: Acc 46.46, F1 31.33 %\n",
      "Fold 1: Acc 45.67, F1 30.71 %\n",
      "Fold 2: Acc 51.81, F1 33.90 %\n",
      "Fold 3: Acc 53.71, F1 32.34 %\n",
      "Fold 4: Acc 44.88, F1 28.97 %\n",
      "Fold 5: Acc 78.57, F1 44.00 %\n",
      "Fold 6: Acc 61.37, F1 38.25 %\n",
      "Fold 7: Acc 50.00, F1 32.76 %\n",
      "Fold 8: Acc 55.80, F1 32.88 %\n",
      "Average: 54.25 %\n",
      "F1: 33.90 %\n",
      "-----------------------------\n",
      "Fold 0: Acc 59.45, F1 36.70 %\n",
      "Fold 1: Acc 57.48, F1 36.25 %\n",
      "Fold 2: Acc 52.03, F1 33.96 %\n",
      "Fold 3: Acc 46.74, F1 31.41 %\n",
      "Fold 4: Acc 52.99, F1 34.33 %\n",
      "Fold 5: Acc 21.43, F1 17.65 %\n",
      "Fold 6: Acc 56.22, F1 35.72 %\n",
      "Fold 7: Acc 54.20, F1 35.99 %\n",
      "Fold 8: Acc 44.93, F1 30.90 %\n",
      "Average: 49.50 %\n",
      "F1: 32.54 %\n",
      "-----------------------------\n",
      "Fold 0: Acc 55.41, F1 35.19 %\n",
      "Fold 1: Acc 52.67, F1 34.43 %\n",
      "Fold 2: Acc 50.53, F1 33.42 %\n",
      "Fold 3: Acc 48.43, F1 32.13 %\n",
      "Fold 4: Acc 52.83, F1 34.22 %\n",
      "Fold 5: Acc 35.71, F1 26.32 %\n",
      "Fold 6: Acc 44.21, F1 31.18 %\n",
      "Fold 7: Acc 55.88, F1 36.09 %\n",
      "Fold 8: Acc 56.52, F1 35.89 %\n",
      "Average: 50.24 %\n",
      "F1: 33.21 %\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "class bert_sparse_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(bert_sparse_model, self).__init__() # 1*20\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(869, 50, bias=True),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(50, 8, bias=True),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(8, 3, bias=True),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(3, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# model = bert_sparse_model()\n",
    "# dataset = pd.concat([pheme_bert_simple_normal,ext_bert_simple_normal],axis=0,ignore_index=True)\n",
    "dataset = pd.concat([bert_simple_all, sparse_all, thread_avg_all, pos_all],axis=1)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# epochs = 10\n",
    "\n",
    "testing_epochs = [2,3,4,5,10,25,50,100]\n",
    "testing_results = []\n",
    "\n",
    "writeLog().write(\"./Model/\"+bert_sparse_model.__name__+\"_\"+\"log.txt\",f\"\\n\\n************************************************************\\nSTARTING A CROSS-VALIDATION ... {testing_epochs} epochs\\n************************************************************\")\n",
    "\n",
    "\n",
    "for epoch in testing_epochs:\n",
    "    result = cv_process(dataset, criterion, modelClass=bert_sparse_model, events=all_event, target=all_y, epochs=epoch, verbose=False)\n",
    "    testing_results.append(result)\n",
    "\n",
    "epochs_diff(testing_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bert_sparse_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(bert_sparse_model, self).__init__() # 1*20\n",
    "        self.layers = nn.Sequential(\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(869, 72, bias=True),\n",
    "            nn.ELU(),\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(72, 10, bias = True),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(10, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/x.notebook.stdout": "\nFOLD 1\n----------------------------------------------------------------------------\nmean: tensor(-0.0112), std: tensor(0.9256)\nVariables)\n\tTrain:torch.Size([3723, 1, 869])\n\tTest: torch.Size([2079, 1, 869])\nTrain Size 3723 Test Size 2079\n\nModel: bert_sparse_model\nEpochs: 5\nPATH: ./Model/bert_sparse_model_1.pt\n\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 2\n----------------------------------------------------------------------------\nmean: tensor(-0.0030), std: tensor(1.0567)\nVariables)\n\tTrain:torch.Size([4659, 1, 869])\n\tTest: torch.Size([1143, 1, 869])\nTrain Size 4659 Test Size 1143\n\nModel: bert_sparse_model\nEpochs: 5\nPATH: ./Model/bert_sparse_model_2.pt\n\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 3\n----------------------------------------------------------------------------\nmean: tensor(0.0007), std: tensor(0.9938)\nVariables)\n\tTrain:torch.Size([5333, 1, 869])\n\tTest: torch.Size([469, 1, 869])\nTrain Size 5333 Test Size 469\n\nModel: bert_sparse_model\nEpochs: 5\nPATH: ./Model/bert_sparse_model_3.pt\n\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 4\n----------------------------------------------------------------------------\nmean: tensor(0.0097), std: tensor(1.1174)\nVariables)\n\tTrain:torch.Size([4912, 1, 869])\n\tTest: torch.Size([890, 1, 869])\nTrain Size 4912 Test Size 890\n\nModel: bert_sparse_model\nEpochs: 5\nPATH: ./Model/bert_sparse_model_4.pt\n\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 5\n----------------------------------------------------------------------------\nmean: tensor(-0.0012), std: tensor(1.0192)\nVariables)\n\tTrain:torch.Size([4581, 1, 869])\n\tTest: torch.Size([1221, 1, 869])\nTrain Size 4581 Test Size 1221\n\nModel: bert_sparse_model\nEpochs: 5\nPATH: ./Model/bert_sparse_model_5.pt\n\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nK-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n----------------------------------------------------------------------------\"\nFold 0: Acc 80.27898027898028, F1 45.421171656076496 %\nFold 1: Acc 79.35258092738408, F1 49.15792882129025 %\nFold 2: Acc 74.20042643923242, F1 49.26026874944086 %\nFold 3: Acc 82.58426966292134, F1 56.81194526839246 %\nFold 4: Acc 80.83538083538083, F1 48.34346119188924 %\nAverage: 79.45032762877979 %\nF1: 49.79895513741786 %\n\nFOLD 1\n----------------------------------------------------------------------------\nmean: tensor(-0.0084), std: tensor(0.9621)\nVariables)\n\tTrain:torch.Size([3723, 1, 869])\n\tTest: torch.Size([2079, 1, 869])\nTrain Size 3723 Test Size 2079\n\nModel: bert_sparse_model\nEpochs: 10\nPATH: ./Model/bert_sparse_model_1.pt\n\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 2\n----------------------------------------------------------------------------\nmean: tensor(-0.0046), std: tensor(0.9946)\nVariables)\n\tTrain:torch.Size([4659, 1, 869])\n\tTest: torch.Size([1143, 1, 869])\nTrain Size 4659 Test Size 1143\n\nModel: bert_sparse_model\nEpochs: 10\nPATH: ./Model/bert_sparse_model_2.pt\n\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 3\n----------------------------------------------------------------------------\nmean: tensor(-0.0032), std: tensor(0.9369)\nVariables)\n\tTrain:torch.Size([5333, 1, 869])\n\tTest: torch.Size([469, 1, 869])\nTrain Size 5333 Test Size 469\n\nModel: bert_sparse_model\nEpochs: 10\nPATH: ./Model/bert_sparse_model_3.pt\n\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 4\n----------------------------------------------------------------------------\nmean: tensor(-0.0047), std: tensor(0.9816)\nVariables)\n\tTrain:torch.Size([4912, 1, 869])\n\tTest: torch.Size([890, 1, 869])\nTrain Size 4912 Test Size 890\n\nModel: bert_sparse_model\nEpochs: 10\nPATH: ./Model/bert_sparse_model_4.pt\n\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 5\n----------------------------------------------------------------------------\nmean: tensor(-0.0010), std: tensor(1.0140)\nVariables)\n\tTrain:torch.Size([4581, 1, 869])\n\tTest: torch.Size([1221, 1, 869])\nTrain Size 4581 Test Size 1221\n\nModel: bert_sparse_model\nEpochs: 10\nPATH: ./Model/bert_sparse_model_5.pt\n\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nK-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n----------------------------------------------------------------------------\"\nFold 0: Acc 85.32948532948534, F1 50.7635387459103 %\nFold 1: Acc 84.95188101487314, F1 58.59458720538894 %\nFold 2: Acc 84.86140724946695, F1 56.125158161630814 %\nFold 3: Acc 88.87640449438202, F1 59.09218564358907 %\nFold 4: Acc 88.28828828828829, F1 54.63372733673067 %\nAverage: 86.46149327529915 %\nF1: 55.841839418649954 %\n\nFOLD 1\n----------------------------------------------------------------------------\nmean: tensor(-0.0074), std: tensor(0.9809)\nVariables)\n\tTrain:torch.Size([3723, 1, 869])\n\tTest: torch.Size([2079, 1, 869])\nTrain Size 3723 Test Size 2079\n\nModel: bert_sparse_model\nEpochs: 50\nPATH: ./Model/bert_sparse_model_1.pt\n\nStarting epoch 25\nStarting epoch 50\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 2\n----------------------------------------------------------------------------\nmean: tensor(0.0094), std: tensor(1.2248)\nVariables)\n\tTrain:torch.Size([4659, 1, 869])\n\tTest: torch.Size([1143, 1, 869])\nTrain Size 4659 Test Size 1143\n\nModel: bert_sparse_model\nEpochs: 50\nPATH: ./Model/bert_sparse_model_2.pt\n\nStarting epoch 25\nStarting epoch 50\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 3\n----------------------------------------------------------------------------\nmean: tensor(-0.0011), std: tensor(0.9948)\nVariables)\n\tTrain:torch.Size([5333, 1, 869])\n\tTest: torch.Size([469, 1, 869])\nTrain Size 5333 Test Size 469\n\nModel: bert_sparse_model\nEpochs: 50\nPATH: ./Model/bert_sparse_model_3.pt\n\nStarting epoch 25\nStarting epoch 50\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 4\n----------------------------------------------------------------------------\nmean: tensor(-0.0087), std: tensor(1.0074)\nVariables)\n\tTrain:torch.Size([4912, 1, 869])\n\tTest: torch.Size([890, 1, 869])\nTrain Size 4912 Test Size 890\n\nModel: bert_sparse_model\nEpochs: 50\nPATH: ./Model/bert_sparse_model_4.pt\n\nStarting epoch 25\nStarting epoch 50\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 5\n----------------------------------------------------------------------------\nmean: tensor(-0.0029), std: tensor(1.0190)\nVariables)\n\tTrain:torch.Size([4581, 1, 869])\n\tTest: torch.Size([1221, 1, 869])\nTrain Size 4581 Test Size 1221\n\nModel: bert_sparse_model\nEpochs: 50\nPATH: ./Model/bert_sparse_model_5.pt\n\nStarting epoch 25\nStarting epoch 50\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nK-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n----------------------------------------------------------------------------\"\nFold 0: Acc 88.60028860028861, F1 57.04500359419085 %\nFold 1: Acc 92.56342957130359, F1 79.32223202975523 %\nFold 2: Acc 97.44136460554371, F1 83.97284197161342 %\nFold 3: Acc 99.7752808988764, F1 98.14425516491482 %\nFold 4: Acc 99.91809991809993, F1 99.32366383979287 %\nAverage: 95.65969271882246 %\nF1: 83.56159932005343 %\n\nFOLD 1\n----------------------------------------------------------------------------\nmean: tensor(0.0022), std: tensor(0.9659)\nVariables)\n\tTrain:torch.Size([3723, 1, 869])\n\tTest: torch.Size([2079, 1, 869])\nTrain Size 3723 Test Size 2079\n\nModel: bert_sparse_model\nEpochs: 100\nPATH: ./Model/bert_sparse_model_1.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 2\n----------------------------------------------------------------------------\nmean: tensor(0.0022), std: tensor(0.9752)\nVariables)\n\tTrain:torch.Size([4659, 1, 869])\n\tTest: torch.Size([1143, 1, 869])\nTrain Size 4659 Test Size 1143\n\nModel: bert_sparse_model\nEpochs: 100\nPATH: ./Model/bert_sparse_model_2.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 3\n----------------------------------------------------------------------------\nmean: tensor(-0.0074), std: tensor(0.9135)\nVariables)\n\tTrain:torch.Size([5333, 1, 869])\n\tTest: torch.Size([469, 1, 869])\nTrain Size 5333 Test Size 469\n\nModel: bert_sparse_model\nEpochs: 100\nPATH: ./Model/bert_sparse_model_3.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 4\n----------------------------------------------------------------------------\nmean: tensor(-0.0089), std: tensor(0.9715)\nVariables)\n\tTrain:torch.Size([4912, 1, 869])\n\tTest: torch.Size([890, 1, 869])\nTrain Size 4912 Test Size 890\n\nModel: bert_sparse_model\nEpochs: 100\nPATH: ./Model/bert_sparse_model_4.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nFOLD 5\n----------------------------------------------------------------------------\nmean: tensor(-0.0020), std: tensor(0.9402)\nVariables)\n\tTrain:torch.Size([4581, 1, 869])\n\tTest: torch.Size([1221, 1, 869])\nTrain Size 4581 Test Size 1221\n\nModel: bert_sparse_model\nEpochs: 100\nPATH: ./Model/bert_sparse_model_5.pt\n\nStarting epoch 25\nStarting epoch 50\nStarting epoch 75\nStarting epoch 100\nTraining process has finished. Saving trained model.\n<Starting TESTING>\n----------------------------------------------------------------------------\nK-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n----------------------------------------------------------------------------\"\nFold 0: Acc 100.0, F1 100.0 %\nFold 1: Acc 100.0, F1 100.0 %\nFold 2: Acc 100.0, F1 100.0 %\nFold 3: Acc 100.0, F1 100.0 %\nFold 4: Acc 100.0, F1 100.0 %\nAverage: 100.0 %\nF1: 100.0 %\n"
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "model = bert_sparse_model()\n",
    "dataset = pd.concat([pheme_sparse_final, pheme_pos_final, pheme_thread_final_avg, pheme_bert_brackets_normal],axis=1)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# epochs = 10\n",
    "\n",
    "testing_epochs = [5,10,50,100]\n",
    "testing_results = []\n",
    "\n",
    "for epoch in testing_epochs:\n",
    "    result = cv_process(dataset, criterion, events=pheme_event, target=pheme_y, epochs=epoch, verbose=False,scaling=True)\n",
    "    testing_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/x.notebook.stdout": "Fold 0: Acc 80.28, F1 45.42 %\nFold 1: Acc 79.35, F1 49.16 %\nFold 2: Acc 74.20, F1 49.26 %\nFold 3: Acc 82.58, F1 56.81 %\nFold 4: Acc 80.84, F1 48.34 %\nAverage: 79.45 %\nF1: 49.80 %\n-----------------------------\nFold 0: Acc 85.33, F1 50.76 %\nFold 1: Acc 84.95, F1 58.59 %\nFold 2: Acc 84.86, F1 56.13 %\nFold 3: Acc 88.88, F1 59.09 %\nFold 4: Acc 88.29, F1 54.63 %\nAverage: 86.46 %\nF1: 55.84 %\n-----------------------------\nFold 0: Acc 88.60, F1 57.05 %\nFold 1: Acc 92.56, F1 79.32 %\nFold 2: Acc 97.44, F1 83.97 %\nFold 3: Acc 99.78, F1 98.14 %\nFold 4: Acc 99.92, F1 99.32 %\nAverage: 95.66 %\nF1: 83.56 %\n-----------------------------\nFold 0: Acc 100.00, F1 100.00 %\nFold 1: Acc 100.00, F1 100.00 %\nFold 2: Acc 100.00, F1 100.00 %\nFold 3: Acc 100.00, F1 100.00 %\nFold 4: Acc 100.00, F1 100.00 %\nAverage: 100.00 %\nF1: 100.00 %\n-----------------------------\n"
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "epochs_diff(testing_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT + ALL SPARSE (STD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9 Folds Batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "************************************************************\n",
      "STARTING A CROSS-VALIDATION ... [100] epochs\n",
      "************************************************************\n",
      "TIME: 31/03/2021 21:34:10\n",
      "LAYER: [Sequential(\n",
      "  (0): Linear(in_features=49, out_features=16, bias=True)\n",
      "  (1): ELU(alpha=1.0)\n",
      "  (2): Dropout(p=0.5, inplace=False)\n",
      "  (3): Linear(in_features=16, out_features=5, bias=True)\n",
      "  (4): ELU(alpha=1.0)\n",
      "  (5): Dropout(p=0.5, inplace=False)\n",
      "  (6): Linear(in_features=5, out_features=1, bias=True)\n",
      ")]\n",
      "\n",
      "STARTING TEST of 100 EPOCH\n",
      "\n",
      "> FOLD 1\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 2\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-59020d0f4360>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtesting_epochs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelClass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mroot_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_event\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mtesting_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-106-12b23e8528e6>\u001b[0m in \u001b[0;36mcv_process\u001b[0;34m(dataset, criterion, modelClass, target, epochs, events, verbose, scaling)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;31m# Iterate over the DataLoader for training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0;31m# Get inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class root_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(root_model, self).__init__()  # 1*20\n",
    "        self.layers = nn.Sequential(\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(49, 16),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(16, 5),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(5, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "# model = sparse_model()\n",
    "dataset = all_root\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "testing_epochs = [100]\n",
    "testing_results = []\n",
    "\n",
    "writeLog().write(\"./Model/\"+root_model.__name__+\"_\"+\"log.txt\",f\"\\n\\n************************************************************\\nSTARTING A CROSS-VALIDATION ... {testing_epochs} epochs\\n************************************************************\")\n",
    "writeLog().write(\"./Model/\"+root_model.__name__+\"_\"+\"log.txt\",f\"TIME: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\")\n",
    "writeLog().write(\"./Model/\"+root_model.__name__+\"_\"+\"log.txt\",f\"LAYER: {[layer for layer in root_model().children()]}\")\n",
    "\n",
    "for epoch in testing_epochs:\n",
    "    result = cv_process(dataset, criterion, modelClass=root_model, events=all_event, target=all_y, epochs=epoch, verbose=False, scaling=False)\n",
    "    testing_results.append(result)\n",
    "\n",
    "writeLog().writeWithoutCR(\"./Model/\"+root_model.__name__+\"_\"+\"log.txt\",f\"RESULT:\\n{epochs_diff(testing_results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "************************************************************\n",
      "STARTING A CROSS-VALIDATION ... [50, 100] epochs\n",
      "************************************************************\n",
      "TIME: 31/03/2021 17:25:36\n",
      "LAYER: [Sequential(\n",
      "  (0): Linear(in_features=49, out_features=12, bias=True)\n",
      "  (1): ELU(alpha=1.0)\n",
      "  (2): Dropout(p=0.5, inplace=False)\n",
      "  (3): Linear(in_features=12, out_features=4, bias=True)\n",
      "  (4): ELU(alpha=1.0)\n",
      "  (5): Dropout(p=0.5, inplace=False)\n",
      "  (6): Linear(in_features=4, out_features=1, bias=True)\n",
      ")]\n",
      "\n",
      "STARTING TEST of 50 EPOCH\n",
      "\n",
      "> FOLD 1\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "> FOLD 2\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "> FOLD 3\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "> FOLD 4\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "> FOLD 5\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "> FOLD 6\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "> FOLD 7\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "> FOLD 8\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "> FOLD 9\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      ">>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 73.78547378547378, F1 49.294405363446195\n",
      "Fold 1: Acc 61.15485564304461, F1 37.3151144511986\n",
      "Fold 2: Acc 53.09168443496801, F1 33.74488664436882\n",
      "Fold 3: Acc 54.157303370786515, F1 35.227680370111\n",
      "Fold 4: Acc 54.217854217854224, F1 34.159599099712\n",
      "Fold 5: Acc 14.285714285714285, F1 12.5\n",
      "Fold 6: Acc 74.67811158798283, F1 45.99774339747701\n",
      "Fold 7: Acc 45.79831932773109, F1 31.223268754141976\n",
      "Fold 8: Acc 57.2463768115942, F1 42.19624954547816\n",
      "Average: 54.268%\n",
      "F1: 35.740%\n",
      "Loss: 86.885\n",
      "\n",
      "\n",
      "STARTING TEST of 100 EPOCH\n",
      "\n",
      "> FOLD 1\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 2\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 3\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 4\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 5\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 6\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 7\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 8\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 9\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      ">>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 23.56902356902357, F1 20.97733601242531\n",
      "Fold 1: Acc 61.76727909011374, F1 37.72010715829083\n",
      "Fold 2: Acc 48.8272921108742, F1 38.500431213055464\n",
      "Fold 3: Acc 54.606741573033716, F1 34.48935521289566\n",
      "Fold 4: Acc 51.35135135135135, F1 32.00788066845551\n",
      "Fold 5: Acc 57.14285714285714, F1 36.36363636363636\n",
      "Fold 6: Acc 50.21459227467812, F1 33.75091457028386\n",
      "Fold 7: Acc 49.57983193277311, F1 32.69319692337595\n",
      "Fold 8: Acc 44.927536231884055, F1 31.54263508353336\n",
      "Average: 49.110%\n",
      "F1: 33.116%\n",
      "Loss: 7.862\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 73.79%, F1 49.29%, Loss 359.59\n",
      "Fold 1: Acc 61.15%, F1 37.32%, Loss 4.50\n",
      "Fold 2: Acc 53.09%, F1 33.74%, Loss 4.42\n",
      "Fold 3: Acc 54.16%, F1 35.23%, Loss 65.91\n",
      "Fold 4: Acc 54.22%, F1 34.16%, Loss 338.18\n",
      "Fold 5: Acc 14.29%, F1 12.50%, Loss 0.89\n",
      "Fold 6: Acc 74.68%, F1 46.00%, Loss 5.04\n",
      "Fold 7: Acc 45.80%, F1 31.22%, Loss 2.59\n",
      "Fold 8: Acc 57.25%, F1 42.20%, Loss 0.85\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "class root_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(root_model, self).__init__()  # 1*20\n",
    "        self.layers = nn.Sequential(\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(49, 12),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(12, 4),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "# model = sparse_model()\n",
    "dataset = all_root\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "testing_epochs = [50, 100]\n",
    "testing_results = []\n",
    "\n",
    "writeLog().write(\"./Model/\"+root_model.__name__+\"_\"+\"log.txt\",f\"\\n\\n************************************************************\\nSTARTING A CROSS-VALIDATION ... {testing_epochs} epochs\\n************************************************************\")\n",
    "writeLog().write(\"./Model/\"+root_model.__name__+\"_\"+\"log.txt\",f\"TIME: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\")\n",
    "writeLog().write(\"./Model/\"+root_model.__name__+\"_\"+\"log.txt\",f\"LAYER: {[layer for layer in root_model().children()]}\")\n",
    "\n",
    "for epoch in testing_epochs:\n",
    "    result = cv_process(dataset, criterion, modelClass=root_model, events=all_event, target=all_y, epochs=epoch, verbose=False, scaling=False)\n",
    "    testing_results.append(result)\n",
    "\n",
    "writeLog().writeWithoutCR(\"./Model/\"+root_model.__name__+\"_\"+\"log.txt\",f\"RESULT:\\n{epochs_diff(testing_results)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "************************************************************\n",
      "STARTING A CROSS-VALIDATION ... [50, 100] epochs\n",
      "************************************************************\n",
      "TIME: 31/03/2021 17:30:37\n",
      "LAYER: [Sequential(\n",
      "  (0): Linear(in_features=49, out_features=8, bias=True)\n",
      "  (1): ELU(alpha=1.0)\n",
      "  (2): Dropout(p=0.5, inplace=False)\n",
      "  (3): Linear(in_features=8, out_features=3, bias=True)\n",
      "  (4): ELU(alpha=1.0)\n",
      "  (5): Dropout(p=0.5, inplace=False)\n",
      "  (6): Linear(in_features=3, out_features=1, bias=True)\n",
      ")]\n",
      "\n",
      "STARTING TEST of 50 EPOCH\n",
      "\n",
      "> FOLD 1\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "> FOLD 2\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "> FOLD 3\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "> FOLD 4\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "> FOLD 5\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "> FOLD 6\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "> FOLD 7\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "> FOLD 8\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "> FOLD 9\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      ">>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 54.97835497835498, F1 35.23458110574113\n",
      "Fold 1: Acc 44.70691163604549, F1 30.3485136693663\n",
      "Fold 2: Acc 49.25373134328358, F1 34.492233367378645\n",
      "Fold 3: Acc 49.21348314606742, F1 32.297152042094005\n",
      "Fold 4: Acc 51.269451269451274, F1 32.62862890971249\n",
      "Fold 5: Acc 64.28571428571429, F1 39.130434782608695\n",
      "Fold 6: Acc 12.446351931330472, F1 10.656407280930596\n",
      "Fold 7: Acc 50.42016806722689, F1 34.963672749139874\n",
      "Fold 8: Acc 51.449275362318836, F1 33.66582368691841\n",
      "Average: 47.558%\n",
      "F1: 31.491%\n",
      "Loss: 121.558\n",
      "\n",
      "\n",
      "STARTING TEST of 100 EPOCH\n",
      "\n",
      "> FOLD 1\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 2\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 3\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 4\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 5\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 6\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 7\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 8\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 9\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      ">>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 40.83694083694084, F1 28.042188897053016\n",
      "Fold 1: Acc 50.04374453193351, F1 33.05969730110105\n",
      "Fold 2: Acc 47.54797441364605, F1 30.727148246778064\n",
      "Fold 3: Acc 49.10112359550562, F1 32.800408540752926\n",
      "Fold 4: Acc 57.65765765765766, F1 51.590395419962434\n",
      "Fold 5: Acc 57.14285714285714, F1 36.36363636363636\n",
      "Fold 6: Acc 69.09871244635193, F1 43.80193686314937\n",
      "Fold 7: Acc 49.159663865546214, F1 32.813235497446016\n",
      "Fold 8: Acc 48.55072463768116, F1 32.665882762061216\n",
      "Average: 52.127%\n",
      "F1: 35.763%\n",
      "Loss: 0.847\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 54.98%, F1 35.23%, Loss 57.42\n",
      "Fold 1: Acc 44.71%, F1 30.35%, Loss 5.12\n",
      "Fold 2: Acc 49.25%, F1 34.49%, Loss 359.95\n",
      "Fold 3: Acc 49.21%, F1 32.30%, Loss 1.15\n",
      "Fold 4: Acc 51.27%, F1 32.63%, Loss 456.36\n",
      "Fold 5: Acc 64.29%, F1 39.13%, Loss 0.71\n",
      "Fold 6: Acc 12.45%, F1 10.66%, Loss 0.87\n",
      "Fold 7: Acc 50.42%, F1 34.96%, Loss 0.74\n",
      "Fold 8: Acc 51.45%, F1 33.67%, Loss 211.70\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "class root_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(root_model, self).__init__()  # 1*20\n",
    "        self.layers = nn.Sequential(\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(49, 8),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(8, 3),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(3, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "# model = sparse_model()\n",
    "dataset = all_root\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "testing_epochs = [50, 100]\n",
    "testing_results = []\n",
    "\n",
    "writeLog().write(\"./Model/\"+root_model.__name__+\"_\"+\"log.txt\",f\"\\n\\n************************************************************\\nSTARTING A CROSS-VALIDATION ... {testing_epochs} epochs\\n************************************************************\")\n",
    "writeLog().write(\"./Model/\"+root_model.__name__+\"_\"+\"log.txt\",f\"TIME: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\")\n",
    "writeLog().write(\"./Model/\"+root_model.__name__+\"_\"+\"log.txt\",f\"LAYER: {[layer for layer in root_model().children()]}\")\n",
    "\n",
    "for epoch in testing_epochs:\n",
    "    result = cv_process(dataset, criterion, modelClass=root_model, events=all_event, target=all_y, epochs=epoch, verbose=False, scaling=False)\n",
    "    testing_results.append(result)\n",
    "\n",
    "writeLog().writeWithoutCR(\"./Model/\"+root_model.__name__+\"_\"+\"log.txt\",f\"RESULT:\\n{epochs_diff(testing_results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "************************************************************\n",
      "STARTING A CROSS-VALIDATION ... [100] epochs\n",
      "************************************************************\n",
      "TIME: 31/03/2021 22:21:44\n",
      "LAYER: [Sequential(\n",
      "  (0): Linear(in_features=52, out_features=12, bias=True)\n",
      "  (1): ELU(alpha=1.0)\n",
      "  (2): Dropout(p=0.5, inplace=False)\n",
      "  (3): Linear(in_features=12, out_features=1, bias=True)\n",
      ")]\n",
      "\n",
      "STARTING TEST of 100 EPOCH\n",
      "\n",
      "> FOLD 1\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 2\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 3\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 4\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 5\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 6\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 7\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 8\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 9\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      ">>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 53.775853775853776, F1 34.449838549715246\n",
      "Fold 1: Acc 48.90638670166229, F1 32.82115447360467\n",
      "Fold 2: Acc 50.53304904051173, F1 33.530573241707\n",
      "Fold 3: Acc 50.89887640449439, F1 33.58396452639668\n",
      "Fold 4: Acc 50.696150696150696, F1 33.384228294568565\n",
      "Fold 5: Acc 35.714285714285715, F1 26.315789473684212\n",
      "Fold 6: Acc 66.95278969957081, F1 41.24797778260853\n",
      "Fold 7: Acc 47.47899159663865, F1 31.764306705407577\n",
      "Fold 8: Acc 55.072463768115945, F1 35.74230385824589\n",
      "Average: 51.114%\n",
      "F1: 33.649%\n",
      "Loss: 1.232\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 53.78%, F1 34.45%, Loss 0.84\n",
      "Fold 1: Acc 48.91%, F1 32.82%, Loss 4.36\n",
      "Fold 2: Acc 50.53%, F1 33.53%, Loss 0.71\n",
      "Fold 3: Acc 50.90%, F1 33.58%, Loss 0.71\n",
      "Fold 4: Acc 50.70%, F1 33.38%, Loss 0.73\n",
      "Fold 5: Acc 35.71%, F1 26.32%, Loss 0.75\n",
      "Fold 6: Acc 66.95%, F1 41.25%, Loss 1.38\n",
      "Fold 7: Acc 47.48%, F1 31.76%, Loss 0.82\n",
      "Fold 8: Acc 55.07%, F1 35.74%, Loss 0.78\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "class thread_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(thread_model, self).__init__() # 1*20\n",
    "        self.layers = nn.Sequential(\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(52, 12),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(12, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "# model = thread_model()\n",
    "dataset = all_thread\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# epochs = 10\n",
    "\n",
    "testing_epochs = [100]\n",
    "testing_results = []\n",
    "\n",
    "writeLog().write(\"./Model/\"+thread_model.__name__+\"_\"+\"log.txt\",f\"\\n\\n************************************************************\\nSTARTING A CROSS-VALIDATION ... {testing_epochs} epochs\\n************************************************************\")\n",
    "writeLog().write(\"./Model/\"+thread_model.__name__+\"_\"+\"log.txt\",f\"TIME: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\")\n",
    "writeLog().write(\"./Model/\"+thread_model.__name__+\"_\"+\"log.txt\",f\"LAYER: {[layer for layer in thread_model().children()]}\")\n",
    "\n",
    "for epoch in testing_epochs:\n",
    "    result = cv_process(dataset, criterion, modelClass=thread_model, events=all_event, target=all_y, epochs=epoch, verbose=False, scaling=False)\n",
    "    testing_results.append(result)\n",
    "\n",
    "writeLog().writeWithoutCR(\"./Model/\"+thread_model.__name__+\"_\"+\"log.txt\",f\"RESULT:\\n{epochs_diff(testing_results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 's' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-ded5ba42480f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 's' is not defined"
     ]
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "************************************************************\n",
      "STARTING A CROSS-VALIDATION ... [100] epochs\n",
      "************************************************************\n",
      "TIME: 31/03/2021 22:21:29\n",
      "LAYER: [Sequential(\n",
      "  (0): Linear(in_features=101, out_features=24, bias=True)\n",
      "  (1): ELU(alpha=1.0)\n",
      "  (2): Dropout(p=0.5, inplace=False)\n",
      "  (3): Linear(in_features=24, out_features=1, bias=True)\n",
      ")]\n",
      "\n",
      "STARTING TEST of 100 EPOCH\n",
      "\n",
      "> FOLD 1\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-c351fdf55d7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtesting_epochs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelClass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_sparse_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_event\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mtesting_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-118-8019942f25d6>\u001b[0m in \u001b[0;36mcv_process\u001b[0;34m(dataset, criterion, modelClass, target, epochs, events, verbose, scaling)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0;31m# Perform backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                 \u001b[0;31m# Perform optimization and Scheduler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class all_sparse_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(all_sparse_model, self).__init__() # 1*20\n",
    "        self.layers = nn.Sequential(\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(101, 24),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(24, 1),\n",
    "            # nn.ELU(),\n",
    "            # nn.Dropout(0.5),\n",
    "            # nn.Linear(6, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "# model = thread_model()\n",
    "dataset = all_root_thread\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# epochs = 10\n",
    "\n",
    "testing_epochs = [100]\n",
    "testing_results = []\n",
    "\n",
    "writeLog().write(\"./Model/\"+all_sparse_model.__name__+\"_\"+\"log.txt\",f\"\\n\\n************************************************************\\nSTARTING A CROSS-VALIDATION ... {testing_epochs} epochs\\n************************************************************\")\n",
    "writeLog().write(\"./Model/\"+all_sparse_model.__name__+\"_\"+\"log.txt\",f\"TIME: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\")\n",
    "writeLog().write(\"./Model/\"+all_sparse_model.__name__+\"_\"+\"log.txt\",f\"LAYER: {[layer for layer in all_sparse_model().children()]}\")\n",
    "\n",
    "for epoch in testing_epochs:\n",
    "    result = cv_process(dataset, criterion, modelClass=all_sparse_model, events=all_event, target=all_y, epochs=epoch, verbose=False, scaling=False)\n",
    "    testing_results.append(result)\n",
    "\n",
    "# writeLog().writeWithoutCR(\"./Model/\"+all_sparse_model.__name__+\"_\"+\"log.txt\",f\"RESULT:\\n{epochs_diff(testing_results)}\")2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "************************************************************\n",
      "STARTING A CROSS-VALIDATION ... [100] epochs\n",
      "************************************************************\n",
      "\n",
      "STARTING TEST of 100 EPOCH\n",
      "\n",
      "> FOLD 1\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 2\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 3\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 4\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 5\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 6\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 7\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 8\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 9\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      ">>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 78.73977873977874, F1 45.625470023800524\n",
      "Fold 1: Acc 72.44094488188976, F1 43.50742731422256\n",
      "Fold 2: Acc 68.65671641791045, F1 41.51088821098379\n",
      "Fold 3: Acc 74.6067415730337, F1 44.43060995288757\n",
      "Fold 4: Acc 72.48157248157248, F1 42.85610780556853\n",
      "Fold 5: Acc 85.71428571428571, F1 46.153846153846146\n",
      "Fold 6: Acc 57.08154506437768, F1 37.5900551246698\n",
      "Fold 7: Acc 60.08403361344538, F1 35.96407494406936\n",
      "Fold 8: Acc 55.79710144927537, F1 35.321918530488155\n",
      "Average: 69.511%\n",
      "F1: 41.440%\n",
      "Loss: 0.626\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 78.74%, F1 45.63%, Loss 0.49\n",
      "Fold 1: Acc 72.44%, F1 43.51%, Loss 0.58\n",
      "Fold 2: Acc 68.66%, F1 41.51%, Loss 0.63\n",
      "Fold 3: Acc 74.61%, F1 44.43%, Loss 0.54\n",
      "Fold 4: Acc 72.48%, F1 42.86%, Loss 0.60\n",
      "Fold 5: Acc 85.71%, F1 46.15%, Loss 0.35\n",
      "Fold 6: Acc 57.08%, F1 37.59%, Loss 0.73\n",
      "Fold 7: Acc 60.08%, F1 35.96%, Loss 0.80\n",
      "Fold 8: Acc 55.80%, F1 35.32%, Loss 0.90\n",
      "-----------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Average: 69.51%\\nF1: 41.44%\\nLoss: 0.63\\n'"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class bert_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(bert_model, self).__init__() # 1*20\n",
    "        self.layers = nn.Sequential(\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(768, 50, bias=True),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(50, 8, bias=True),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(8, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# model = bert_model()\n",
    "dataset = all_bert_simple\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# epochs = 10\n",
    "\n",
    "testing_epochs = [100]\n",
    "testing_results = []\n",
    "\n",
    "writeLog().write(\"./Model/\"+bert_model.__name__+\"_\"+\"log.txt\",f\"\\n\\n************************************************************\\nSTARTING A CROSS-VALIDATION ... {testing_epochs} epochs\\n************************************************************\")\n",
    "\n",
    "\n",
    "for epoch in testing_epochs:\n",
    "    result = cv_process(dataset, criterion, modelClass=bert_model, events=all_event, target=all_y, epochs=epoch, verbose=False)\n",
    "    testing_results.append(result)\n",
    "\n",
    "epochs_diff(testing_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "************************************************************\n",
      "STARTING A CROSS-VALIDATION ... [100, 200] epochs\n",
      "************************************************************\n",
      "TIME: 31/03/2021 21:43:35\n",
      "LAYER: [Sequential(\n",
      "  (0): Linear(in_features=869, out_features=72, bias=True)\n",
      "  (1): ELU(alpha=1.0)\n",
      "  (2): Dropout(p=0.5, inplace=False)\n",
      "  (3): Linear(in_features=72, out_features=10, bias=True)\n",
      "  (4): ELU(alpha=1.0)\n",
      "  (5): Dropout(p=0.5, inplace=False)\n",
      "  (6): Linear(in_features=10, out_features=1, bias=True)\n",
      ")]\n",
      "\n",
      "STARTING TEST of 100 EPOCH\n",
      "\n",
      "> FOLD 1\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 2\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 3\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 4\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 5\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 6\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 7\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 8\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 9\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      ">>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 50.55315055315055, F1 33.257280404346574\n",
      "Fold 1: Acc 49.86876640419948, F1 32.94471483295705\n",
      "Fold 2: Acc 48.8272921108742, F1 32.30743150493777\n",
      "Fold 3: Acc 51.01123595505618, F1 33.588206113064516\n",
      "Fold 4: Acc 49.385749385749385, F1 32.88896584482881\n",
      "Fold 5: Acc 50.0, F1 33.33333333333333\n",
      "Fold 6: Acc 52.36051502145923, F1 34.461065214564\n",
      "Fold 7: Acc 52.52100840336135, F1 34.92412003482518\n",
      "Fold 8: Acc 58.69565217391305, F1 37.4393139294167\n",
      "Average: 51.469%\n",
      "F1: 33.905%\n",
      "Loss: 0.950\n",
      "\n",
      "\n",
      "STARTING TEST of 200 EPOCH\n",
      "\n",
      "> FOLD 1\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "Starting epoch 150\n",
      "Starting epoch 200\n",
      "> FOLD 2\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "Starting epoch 150\n",
      "Starting epoch 200\n",
      "> FOLD 3\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "Starting epoch 150\n",
      "Starting epoch 200\n",
      "> FOLD 4\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "Starting epoch 150\n",
      "Starting epoch 200\n",
      "> FOLD 5\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "Starting epoch 150\n",
      "Starting epoch 200\n",
      "> FOLD 6\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "Starting epoch 150\n",
      "Starting epoch 200\n",
      "> FOLD 7\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "Starting epoch 150\n",
      "Starting epoch 200\n",
      "> FOLD 8\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "Starting epoch 150\n",
      "Starting epoch 200\n",
      "> FOLD 9\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "Starting epoch 150\n",
      "Starting epoch 200\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      ">>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 49.254449254449256, F1 32.71179264550313\n",
      "Fold 1: Acc 49.95625546806649, F1 32.886820729136524\n",
      "Fold 2: Acc 48.40085287846482, F1 32.482880315603616\n",
      "Fold 3: Acc 51.79775280898876, F1 34.14379168751419\n",
      "Fold 4: Acc 48.730548730548726, F1 32.41808221022559\n",
      "Fold 5: Acc 42.857142857142854, F1 30.0\n",
      "Fold 6: Acc 54.506437768240346, F1 35.60881207904906\n",
      "Fold 7: Acc 52.94117647058824, F1 35.35089557595952\n",
      "Fold 8: Acc 50.72463768115942, F1 34.29147039377218\n",
      "Average: 49.908%\n",
      "F1: 33.322%\n",
      "Loss: 0.709\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 50.55%, F1 33.26%, Loss 2.13\n",
      "Fold 1: Acc 49.87%, F1 32.94%, Loss 0.73\n",
      "Fold 2: Acc 48.83%, F1 32.31%, Loss 0.71\n",
      "Fold 3: Acc 51.01%, F1 33.59%, Loss 0.74\n",
      "Fold 4: Acc 49.39%, F1 32.89%, Loss 1.41\n",
      "Fold 5: Acc 50.00%, F1 33.33%, Loss 0.71\n",
      "Fold 6: Acc 52.36%, F1 34.46%, Loss 0.70\n",
      "Fold 7: Acc 52.52%, F1 34.92%, Loss 0.70\n",
      "Fold 8: Acc 58.70%, F1 37.44%, Loss 0.72\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "class bert_sparse_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(bert_sparse_model, self).__init__() # 1*20\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(869, 72, bias=True),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(72, 10, bias = True),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(10, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "# model = bert_model()\n",
    "dataset = all_total\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# epochs = 10\n",
    "\n",
    "testing_epochs = [100,200]\n",
    "testing_results = []\n",
    "\n",
    "writeLog().write(\"./Model/\"+bert_sparse_model.__name__+\"_\"+\"log.txt\",f\"\\n\\n************************************************************\\nSTARTING A CROSS-VALIDATION ... {testing_epochs} epochs\\n************************************************************\")\n",
    "writeLog().write(\"./Model/\"+bert_sparse_model.__name__+\"_\"+\"log.txt\",f\"TIME: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\")\n",
    "writeLog().write(\"./Model/\"+bert_sparse_model.__name__+\"_\"+\"log.txt\",f\"LAYER: {[layer for layer in bert_sparse_model().children()]}\")\n",
    "\n",
    "\n",
    "for epoch in testing_epochs:\n",
    "    result = cv_process(dataset, criterion, modelClass=bert_sparse_model, events=all_event, target=all_y, epochs=epoch, verbose=False)\n",
    "    testing_results.append(result)\n",
    "\n",
    "epochs_diff(testing_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[{0: [30.014430014430015, 20.329881502230815, 0.9727699329441358],\n  1: [52.31846019247593, 34.094144605369294, 0.7706452375530467],\n  2: [52.23880597014925, 33.81135426518758, 1.5158748644501416],\n  3: [51.348314606741575, 33.655633914142015, 0.7604606889606862],\n  4: [47.338247338247335, 31.74001647471132, 5.580640545299461],\n  5: [50.0, 33.33333333333333, 0.6937494874000549],\n  6: [42.48927038626609, 29.919186399219985, 0.737345610821196],\n  7: [50.84033613445378, 33.669406786111594, 0.7304117864921313],\n  8: [52.17391304347826, 35.17515949242477, 0.7004137376080388]}]"
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>30.014430</td>\n      <td>52.318460</td>\n      <td>52.238806</td>\n      <td>51.348315</td>\n      <td>47.338247</td>\n      <td>50.000000</td>\n      <td>42.489270</td>\n      <td>50.840336</td>\n      <td>52.173913</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20.329882</td>\n      <td>34.094145</td>\n      <td>33.811354</td>\n      <td>33.655634</td>\n      <td>31.740016</td>\n      <td>33.333333</td>\n      <td>29.919186</td>\n      <td>33.669407</td>\n      <td>35.175159</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.972770</td>\n      <td>0.770645</td>\n      <td>1.515875</td>\n      <td>0.760461</td>\n      <td>5.580641</td>\n      <td>0.693749</td>\n      <td>0.737346</td>\n      <td>0.730412</td>\n      <td>0.700414</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "           0          1          2          3          4          5  \\\n0  30.014430  52.318460  52.238806  51.348315  47.338247  50.000000   \n1  20.329882  34.094145  33.811354  33.655634  31.740016  33.333333   \n2   0.972770   0.770645   1.515875   0.760461   5.580641   0.693749   \n\n           6          7          8  \n0  42.489270  50.840336  52.173913  \n1  29.919186  33.669407  35.175159  \n2   0.737346   0.730412   0.700414  "
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(testing_results[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "************************************************************\n",
      "STARTING A CROSS-VALIDATION ... [100] epochs\n",
      "************************************************************\n",
      "TIME: 31/03/2021 18:58:07\n",
      "LAYER: [Sequential(\n",
      "  (0): Linear(in_features=869, out_features=80, bias=True)\n",
      "  (1): ELU(alpha=1.0)\n",
      "  (2): Dropout(p=0.5, inplace=False)\n",
      "  (3): Linear(in_features=80, out_features=16, bias=True)\n",
      "  (4): ELU(alpha=1.0)\n",
      "  (5): Dropout(p=0.5, inplace=False)\n",
      "  (6): Linear(in_features=16, out_features=1, bias=True)\n",
      ")]\n",
      "\n",
      "STARTING TEST of 100 EPOCH\n",
      "\n",
      "> FOLD 1\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 2\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 3\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 4\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 5\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 6\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 7\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 8\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "> FOLD 9\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Parameter Resetted\n",
      "Starting epoch 50\n",
      "Starting epoch 100\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      ">>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 40.4040404040404, F1 27.75096943944642\n",
      "Fold 1: Acc 43.044619422572175, F1 29.38590298049285\n",
      "Fold 2: Acc 49.68017057569296, F1 32.60157023464709\n",
      "Fold 3: Acc 48.31460674157304, F1 32.24092691919141\n",
      "Fold 4: Acc 48.402948402948404, F1 32.291218934414054\n",
      "Fold 5: Acc 57.14285714285714, F1 36.36363636363636\n",
      "Fold 6: Acc 46.78111587982833, F1 32.44367121340438\n",
      "Fold 7: Acc 51.26050420168067, F1 33.36748001453883\n",
      "Fold 8: Acc 48.55072463768116, F1 33.4166252427122\n",
      "Average: 48.176%\n",
      "F1: 32.207%\n",
      "Loss: 0.940\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      "Fold 0: Acc 40.40%, F1 27.75%, Loss 0.81\n",
      "Fold 1: Acc 43.04%, F1 29.39%, Loss 0.76\n",
      "Fold 2: Acc 49.68%, F1 32.60%, Loss 0.71\n",
      "Fold 3: Acc 48.31%, F1 32.24%, Loss 0.74\n",
      "Fold 4: Acc 48.40%, F1 32.29%, Loss 2.55\n",
      "Fold 5: Acc 57.14%, F1 36.36%, Loss 0.64\n",
      "Fold 6: Acc 46.78%, F1 32.44%, Loss 0.75\n",
      "Fold 7: Acc 51.26%, F1 33.37%, Loss 0.79\n",
      "Fold 8: Acc 48.55%, F1 33.42%, Loss 0.72\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "class bert_sparse_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(bert_sparse_model, self).__init__() # 1*20\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(869, 80, bias = True),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(80, 16, bias = True),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(16, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "# model = bert_model()\n",
    "dataset = all_total\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# epochs = 10\n",
    "\n",
    "testing_epochs = [100]\n",
    "testing_results = []\n",
    "\n",
    "writeLog().write(\"./Model/\"+bert_sparse_model.__name__+\"_\"+\"log.txt\",f\"\\n\\n************************************************************\\nSTARTING A CROSS-VALIDATION ... {testing_epochs} epochs\\n************************************************************\")\n",
    "writeLog().write(\"./Model/\"+bert_sparse_model.__name__+\"_\"+\"log.txt\",f\"TIME: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\")\n",
    "writeLog().write(\"./Model/\"+bert_sparse_model.__name__+\"_\"+\"log.txt\",f\"LAYER: {[layer for layer in bert_sparse_model().children()]}\")\n",
    "\n",
    "for epoch in testing_epochs:\n",
    "    result = cv_process(dataset, criterion, modelClass=bert_sparse_model, events=all_event, target=all_y, epochs=epoch, verbose=False)\n",
    "    testing_results.append(result)\n",
    "\n",
    "epochs_diff(testing_results)\n",
    "\n",
    "df = pd.DataFrame(testing_results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class root_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(root_model, self).__init__()  # 1*20\n",
    "        self.layers = nn.Sequential(\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(49, 16),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(16, 5),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(5, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "class root_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(root_model, self).__init__()  # 1*20\n",
    "        self.layers = nn.Sequential(\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(49, 12),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(12, 4),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "class root_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(root_model, self).__init__()  # 1*20\n",
    "        self.layers = nn.Sequential(\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(49, 8),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(8, 3),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(3, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "class thread_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(thread_model, self).__init__() # 1*20\n",
    "        self.layers = nn.Sequential(\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(52, 12),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(12, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "class all_sparse_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(all_sparse_model, self).__init__() # 1*20\n",
    "        self.layers = nn.Sequential(\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(101, 24),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(24, 6),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(6, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "class all_sparse_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(all_sparse_model, self).__init__() # 1*20\n",
    "        self.layers = nn.Sequential(\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(101, 24),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(24, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "class bert_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(bert_model, self).__init__() # 1*20\n",
    "        self.layers = nn.Sequential(\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(768, 50, bias=True),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(50, 8, bias=True),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(8, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = sparse_model()\n",
    "dataset = all_root\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "testing_epochs = [100]\n",
    "testing_results = []\n",
    "\n",
    "writeLog().write(\"./Model/\"+root_model.__name__+\"_\"+\"log.txt\",f\"\\n\\n************************************************************\\nSTARTING A CROSS-VALIDATION ... {testing_epochs} epochs\\n************************************************************\")\n",
    "writeLog().write(\"./Model/\"+root_model.__name__+\"_\"+\"log.txt\",f\"TIME: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\")\n",
    "writeLog().write(\"./Model/\"+root_model.__name__+\"_\"+\"log.txt\",f\"LAYER: {[layer for layer in root_model().children()]}\")\n",
    "\n",
    "for epoch in testing_epochs:\n",
    "    result = cv_process(dataset, criterion, modelClass=root_model, events=all_event, target=all_y, epochs=epoch, verbose=False, scaling=False)\n",
    "    testing_results.append(result)\n",
    "\n",
    "writeLog().writeWithoutCR(\"./Model/\"+root_model.__name__+\"_\"+\"log.txt\",f\"RESULT:\\n{epochs_diff(testing_results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = all_thread\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "testing_epochs = [100]\n",
    "testing_results = []\n",
    "\n",
    "writeLog().write(\"./Model/\"+thread_model.__name__+\"_\"+\"log.txt\",f\"\\n\\n************************************************************\\nSTARTING A CROSS-VALIDATION ... {testing_epochs} epochs\\n************************************************************\")\n",
    "writeLog().write(\"./Model/\"+thread_model.__name__+\"_\"+\"log.txt\",f\"TIME: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\")\n",
    "writeLog().write(\"./Model/\"+thread_model.__name__+\"_\"+\"log.txt\",f\"LAYER: {[layer for layer in thread_model().children()]}\")\n",
    "\n",
    "for epoch in testing_epochs:\n",
    "    result = cv_process(dataset, criterion, modelClass=thread_model, events=all_event, target=all_y, epochs=epoch, verbose=False, scaling=False)\n",
    "    testing_results.append(result)\n",
    "\n",
    "writeLog().writeWithoutCR(\"./Model/\"+thread_model.__name__+\"_\"+\"log.txt\",f\"RESULT:\\n{epochs_diff(testing_results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = all_root_thread\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "testing_epochs = [100]\n",
    "testing_results = []\n",
    "\n",
    "writeLog().write(\"./Model/\"+all_sparse_model.__name__+\"_\"+\"log.txt\",f\"\\n\\n************************************************************\\nSTARTING A CROSS-VALIDATION ... {testing_epochs} epochs\\n************************************************************\")\n",
    "writeLog().write(\"./Model/\"+all_sparse_model.__name__+\"_\"+\"log.txt\",f\"TIME: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\")\n",
    "writeLog().write(\"./Model/\"+all_sparse_model.__name__+\"_\"+\"log.txt\",f\"LAYER: {[layer for layer in all_sparse_model().children()]}\")\n",
    "\n",
    "for epoch in testing_epochs:\n",
    "    result = cv_process(dataset, criterion, modelClass=all_sparse_model, events=all_event, target=all_y, epochs=epoch, verbose=False, scaling=False)\n",
    "    testing_results.append(result)\n",
    "\n",
    "writeLog().writeWithoutCR(\"./Model/\"+all_sparse_model.__name__+\"_\"+\"log.txt\",f\"RESULT:\\n{epochs_diff(testing_results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = all_root_thread\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "testing_epochs = [100]\n",
    "testing_results = []\n",
    "\n",
    "writeLog().write(\"./Model/\"+all_sparse_model.__name__+\"_\"+\"log.txt\",f\"\\n\\n************************************************************\\nSTARTING A CROSS-VALIDATION ... {testing_epochs} epochs\\n************************************************************\")\n",
    "writeLog().write(\"./Model/\"+all_sparse_model.__name__+\"_\"+\"log.txt\",f\"TIME: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\")\n",
    "writeLog().write(\"./Model/\"+all_sparse_model.__name__+\"_\"+\"log.txt\",f\"LAYER: {[layer for layer in all_sparse_model().children()]}\")\n",
    "\n",
    "\n",
    "for epoch in testing_epochs:\n",
    "    result = cv_process(dataset, criterion, modelClass=all_sparse_model, events=all_event, target=all_y, epochs=epoch, verbose=False, scaling=False)\n",
    "    testing_results.append(result)\n",
    "\n",
    "writeLog().writeWithoutCR(\"./Model/\"+all_sparse_model.__name__+\"_\"+\"log.txt\",f\"RESULT:\\n{epochs_diff(testing_results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/x.notebook.stdout": "\n\n************************************************************\nSTARTING A CROSS-VALIDATION ... [100] epochs\n************************************************************\n\nSTARTING TEST of 100 EPOCH\n\n> FOLD 1\nParameter Resetted\nParameter Resetted\nParameter Resetted\nStarting epoch 50\nStarting epoch 100\n> FOLD 2\nParameter Resetted\nParameter Resetted\nParameter Resetted\nStarting epoch 50\nStarting epoch 100\n> FOLD 3\nParameter Resetted\nParameter Resetted\nParameter Resetted\nStarting epoch 50\nStarting epoch 100\n> FOLD 4\nParameter Resetted\nParameter Resetted\nParameter Resetted\nStarting epoch 50\nStarting epoch 100\n> FOLD 5\nParameter Resetted\nParameter Resetted\nParameter Resetted\nStarting epoch 50\nStarting epoch 100\n> FOLD 6\nParameter Resetted\nParameter Resetted\nParameter Resetted\nStarting epoch 50\nStarting epoch 100\n> FOLD 7\nParameter Resetted\nParameter Resetted\nParameter Resetted\nStarting epoch 50\nStarting epoch 100\n> FOLD 8\nParameter Resetted\nParameter Resetted\nParameter Resetted\nStarting epoch 50\nStarting epoch 100\n> FOLD 9\nParameter Resetted\nParameter Resetted\nParameter Resetted\nStarting epoch 50\nStarting epoch 100\n\n\n----------------------------------------------------------------------------\n>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS\n----------------------------------------------------------------------------\nFold 0: Acc 78.73977873977874, F1 45.625470023800524\nFold 1: Acc 72.44094488188976, F1 43.50742731422256\nFold 2: Acc 68.65671641791045, F1 41.51088821098379\nFold 3: Acc 74.6067415730337, F1 44.43060995288757\nFold 4: Acc 72.48157248157248, F1 42.85610780556853\nFold 5: Acc 85.71428571428571, F1 46.153846153846146\nFold 6: Acc 57.08154506437768, F1 37.5900551246698\nFold 7: Acc 60.08403361344538, F1 35.96407494406936\nFold 8: Acc 55.79710144927537, F1 35.321918530488155\nAverage: 69.511%\nF1: 41.440%\nLoss: 0.626\n\n----------------------------------------------------------------------------\nFold 0: Acc 78.74%, F1 45.63%, Loss 0.49\nFold 1: Acc 72.44%, F1 43.51%, Loss 0.58\nFold 2: Acc 68.66%, F1 41.51%, Loss 0.63\nFold 3: Acc 74.61%, F1 44.43%, Loss 0.54\nFold 4: Acc 72.48%, F1 42.86%, Loss 0.60\nFold 5: Acc 85.71%, F1 46.15%, Loss 0.35\nFold 6: Acc 57.08%, F1 37.59%, Loss 0.73\nFold 7: Acc 60.08%, F1 35.96%, Loss 0.80\nFold 8: Acc 55.80%, F1 35.32%, Loss 0.90\n-----------------------------\n"
     },
     "output_type": "unknown"
    },
    {
     "data": {
      "text/plain": "'Average: 69.51%\\nF1: 41.44%\\nLoss: 0.63\\n'"
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "dataset = all_bert_simple\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "testing_epochs = [100]\n",
    "testing_results = []\n",
    "\n",
    "writeLog().write(\"./Model/\"+bert_model.__name__+\"_\"+\"log.txt\",f\"\\n\\n************************************************************\\nSTARTING A CROSS-VALIDATION ... {testing_epochs} epochs\\n************************************************************\")\n",
    "writeLog().write(\"./Model/\"+bert_model.__name__+\"_\"+\"log.txt\",f\"TIME: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\")\n",
    "writeLog().write(\"./Model/\"+bert_model.__name__+\"_\"+\"log.txt\",f\"LAYER: {[layer for layer in bert_model().children()]}\")\n",
    "\n",
    "\n",
    "for epoch in testing_epochs:\n",
    "    result = cv_process(dataset, criterion, modelClass=bert_model, events=all_event, target=all_y, epochs=epoch, verbose=False)\n",
    "    testing_results.append(result)\n",
    "\n",
    "writeLog().writeWithoutCR(\"./Model/\"+all_sparse_model.__name__+\"_\"+\"log.txt\",f\"RESULT:\\n{epochs_diff(testing_results)}\")2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/x.notebook.stdout": "\n\n************************************************************\nSTARTING A CROSS-VALIDATION ... [100, 200] epochs\n************************************************************\nTIME: 31/03/2021 21:43:35\nLAYER: [Sequential(\n  (0): Linear(in_features=869, out_features=72, bias=True)\n  (1): ELU(alpha=1.0)\n  (2): Dropout(p=0.5, inplace=False)\n  (3): Linear(in_features=72, out_features=10, bias=True)\n  (4): ELU(alpha=1.0)\n  (5): Dropout(p=0.5, inplace=False)\n  (6): Linear(in_features=10, out_features=1, bias=True)\n)]\n\nSTARTING TEST of 100 EPOCH\n\n> FOLD 1\nParameter Resetted\nParameter Resetted\nParameter Resetted\nStarting epoch 50\nStarting epoch 100\n> FOLD 2\nParameter Resetted\nParameter Resetted\nParameter Resetted\n"
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "class bert_sparse_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(bert_sparse_model, self).__init__() # 1*20\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(869, 72, bias=True),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(72, 10, bias = True),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(10, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "# model = bert_model()\n",
    "dataset = all_total\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# epochs = 10\n",
    "\n",
    "testing_epochs = [100,200]\n",
    "testing_results = []\n",
    "\n",
    "writeLog().write(\"./Model/\"+bert_sparse_model.__name__+\"_\"+\"log.txt\",f\"\\n\\n************************************************************\\nSTARTING A CROSS-VALIDATION ... {testing_epochs} epochs\\n************************************************************\")\n",
    "writeLog().write(\"./Model/\"+bert_sparse_model.__name__+\"_\"+\"log.txt\",f\"TIME: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\")\n",
    "writeLog().write(\"./Model/\"+bert_sparse_model.__name__+\"_\"+\"log.txt\",f\"LAYER: {[layer for layer in bert_sparse_model().children()]}\")\n",
    "\n",
    "\n",
    "for epoch in testing_epochs:\n",
    "    result = cv_process(dataset, criterion, modelClass=bert_sparse_model, events=all_event, target=all_y, epochs=epoch, verbose=False)\n",
    "    testing_results.append(result)\n",
    "\n",
    "epochs_diff(testing_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[{0: [30.014430014430015, 20.329881502230815, 0.9727699329441358],\n  1: [52.31846019247593, 34.094144605369294, 0.7706452375530467],\n  2: [52.23880597014925, 33.81135426518758, 1.5158748644501416],\n  3: [51.348314606741575, 33.655633914142015, 0.7604606889606862],\n  4: [47.338247338247335, 31.74001647471132, 5.580640545299461],\n  5: [50.0, 33.33333333333333, 0.6937494874000549],\n  6: [42.48927038626609, 29.919186399219985, 0.737345610821196],\n  7: [50.84033613445378, 33.669406786111594, 0.7304117864921313],\n  8: [52.17391304347826, 35.17515949242477, 0.7004137376080388]}]"
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "testing_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>30.014430</td>\n      <td>52.318460</td>\n      <td>52.238806</td>\n      <td>51.348315</td>\n      <td>47.338247</td>\n      <td>50.000000</td>\n      <td>42.489270</td>\n      <td>50.840336</td>\n      <td>52.173913</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20.329882</td>\n      <td>34.094145</td>\n      <td>33.811354</td>\n      <td>33.655634</td>\n      <td>31.740016</td>\n      <td>33.333333</td>\n      <td>29.919186</td>\n      <td>33.669407</td>\n      <td>35.175159</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.972770</td>\n      <td>0.770645</td>\n      <td>1.515875</td>\n      <td>0.760461</td>\n      <td>5.580641</td>\n      <td>0.693749</td>\n      <td>0.737346</td>\n      <td>0.730412</td>\n      <td>0.700414</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "           0          1          2          3          4          5  \\\n0  30.014430  52.318460  52.238806  51.348315  47.338247  50.000000   \n1  20.329882  34.094145  33.811354  33.655634  31.740016  33.333333   \n2   0.972770   0.770645   1.515875   0.760461   5.580641   0.693749   \n\n           6          7          8  \n0  42.489270  50.840336  52.173913  \n1  29.919186  33.669407  35.175159  \n2   0.737346   0.730412   0.700414  "
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "pd.DataFrame(testing_results[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/x.notebook.stdout": "\n\n************************************************************\nSTARTING A CROSS-VALIDATION ... [100] epochs\n************************************************************\nTIME: 31/03/2021 18:58:07\nLAYER: [Sequential(\n  (0): Linear(in_features=869, out_features=80, bias=True)\n  (1): ELU(alpha=1.0)\n  (2): Dropout(p=0.5, inplace=False)\n  (3): Linear(in_features=80, out_features=16, bias=True)\n  (4): ELU(alpha=1.0)\n  (5): Dropout(p=0.5, inplace=False)\n  (6): Linear(in_features=16, out_features=1, bias=True)\n)]\n\nSTARTING TEST of 100 EPOCH\n\n> FOLD 1\nParameter Resetted\nParameter Resetted\nParameter Resetted\nStarting epoch 50\nStarting epoch 100\n> FOLD 2\nParameter Resetted\nParameter Resetted\nParameter Resetted\nStarting epoch 50\nStarting epoch 100\n> FOLD 3\nParameter Resetted\nParameter Resetted\nParameter Resetted\nStarting epoch 50\nStarting epoch 100\n> FOLD 4\nParameter Resetted\nParameter Resetted\nParameter Resetted\nStarting epoch 50\nStarting epoch 100\n> FOLD 5\nParameter Resetted\nParameter Resetted\nParameter Resetted\nStarting epoch 50\nStarting epoch 100\n> FOLD 6\nParameter Resetted\nParameter Resetted\nParameter Resetted\nStarting epoch 50\nStarting epoch 100\n> FOLD 7\nParameter Resetted\nParameter Resetted\nParameter Resetted\nStarting epoch 50\nStarting epoch 100\n> FOLD 8\nParameter Resetted\nParameter Resetted\nParameter Resetted\nStarting epoch 50\nStarting epoch 100\n> FOLD 9\nParameter Resetted\nParameter Resetted\nParameter Resetted\nStarting epoch 50\nStarting epoch 100\n\n\n----------------------------------------------------------------------------\n>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS\n----------------------------------------------------------------------------\nFold 0: Acc 40.4040404040404, F1 27.75096943944642\nFold 1: Acc 43.044619422572175, F1 29.38590298049285\nFold 2: Acc 49.68017057569296, F1 32.60157023464709\nFold 3: Acc 48.31460674157304, F1 32.24092691919141\nFold 4: Acc 48.402948402948404, F1 32.291218934414054\nFold 5: Acc 57.14285714285714, F1 36.36363636363636\nFold 6: Acc 46.78111587982833, F1 32.44367121340438\nFold 7: Acc 51.26050420168067, F1 33.36748001453883\nFold 8: Acc 48.55072463768116, F1 33.4166252427122\nAverage: 48.176%\nF1: 32.207%\nLoss: 0.940\n\n----------------------------------------------------------------------------\nFold 0: Acc 40.40%, F1 27.75%, Loss 0.81\nFold 1: Acc 43.04%, F1 29.39%, Loss 0.76\nFold 2: Acc 49.68%, F1 32.60%, Loss 0.71\nFold 3: Acc 48.31%, F1 32.24%, Loss 0.74\nFold 4: Acc 48.40%, F1 32.29%, Loss 2.55\nFold 5: Acc 57.14%, F1 36.36%, Loss 0.64\nFold 6: Acc 46.78%, F1 32.44%, Loss 0.75\nFold 7: Acc 51.26%, F1 33.37%, Loss 0.79\nFold 8: Acc 48.55%, F1 33.42%, Loss 0.72\n-----------------------------\n"
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "class bert_sparse_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(bert_sparse_model, self).__init__() # 1*20\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(869, 80, bias = True),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(80, 16, bias = True),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(16, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "# model = bert_model()\n",
    "dataset = all_total\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# epochs = 10\n",
    "\n",
    "testing_epochs = [100]\n",
    "testing_results = []\n",
    "\n",
    "writeLog().write(\"./Model/\"+bert_sparse_model.__name__+\"_\"+\"log.txt\",f\"\\n\\n************************************************************\\nSTARTING A CROSS-VALIDATION ... {testing_epochs} epochs\\n************************************************************\")\n",
    "writeLog().write(\"./Model/\"+bert_sparse_model.__name__+\"_\"+\"log.txt\",f\"TIME: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\")\n",
    "writeLog().write(\"./Model/\"+bert_sparse_model.__name__+\"_\"+\"log.txt\",f\"LAYER: {[layer for layer in bert_sparse_model().children()]}\")\n",
    "\n",
    "for epoch in testing_epochs:\n",
    "    result = cv_process(dataset, criterion, modelClass=bert_sparse_model, events=all_event, target=all_y, epochs=epoch, verbose=False)\n",
    "    testing_results.append(result)\n",
    "\n",
    "epochs_diff(testing_results)\n",
    "\n",
    "df = pd.DataFrame(testing_results[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit (conda)",
   "name": "python388jvsc74a57bd0b3e779290c3971bcb91630500d66c3c3cecd721489b4b277b4ac4fef67ef773c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "metadata": {
   "interpreter": {
    "hash": "b3e779290c3971bcb91630500d66c3c3cecd721489b4b277b4ac4fef67ef773c"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}