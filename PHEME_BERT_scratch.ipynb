{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PHEME_BERT_scratch.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "vtIMlTiMUFzS",
        "fJjwums-kI2t"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "orig_nbformat": 2,
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1bd1e9fe81934cf3885154196e620c03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bd458a99a85e4a13afd1cf36b0a57ef7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f954f9c5e5954c2bb96b5993a9395109",
              "IPY_MODEL_ce478aa49888428c8b784e7389e191f4"
            ]
          }
        },
        "bd458a99a85e4a13afd1cf36b0a57ef7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f954f9c5e5954c2bb96b5993a9395109": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0660f1c2cada41d3bdfe2589d7184b56",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0c3cc67272e24e0c807af12b592c3a55"
          }
        },
        "ce478aa49888428c8b784e7389e191f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f228d1ac81f6413a997d164c52f2ce02",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 301kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_930e5993b2fb4a07943e2d0006d54dba"
          }
        },
        "0660f1c2cada41d3bdfe2589d7184b56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0c3cc67272e24e0c807af12b592c3a55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f228d1ac81f6413a997d164c52f2ce02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "930e5993b2fb4a07943e2d0006d54dba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ba4fccff2e7248dc8ebced01cdfec1e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cb31c57f96a74fafbc00cb588b5088e3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ca96c35395424cb08052f00d74ff1751",
              "IPY_MODEL_9991f144be6347399295a3e08d9fe659"
            ]
          }
        },
        "cb31c57f96a74fafbc00cb588b5088e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ca96c35395424cb08052f00d74ff1751": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_55acb3ddba064474a2a87af185c31df2",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1f69180117754d19984af686646c902f"
          }
        },
        "9991f144be6347399295a3e08d9fe659": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4d48494062c94f20b6b93f953d3a8506",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 3.06MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a38f07ac3db342b589f48dd45656b55c"
          }
        },
        "55acb3ddba064474a2a87af185c31df2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1f69180117754d19984af686646c902f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4d48494062c94f20b6b93f953d3a8506": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a38f07ac3db342b589f48dd45656b55c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zzunebye/Capstone-code-data/blob/main/PHEME_BERT_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQSdijCsmtPH",
        "outputId": "64338c6f-dd00-434c-eb05-060b5f316242"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install torch"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.3.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.8.0+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FaLWxNckcCp",
        "outputId": "52d85c64-3313-4900-cfd8-c2e589ffeebf"
      },
      "source": [
        "import os\n",
        "print(os.getcwd())\n",
        "\n",
        "# 실행시 등장하는 URL을 클릭하여 허용해주면 인증KEY가 나타난다. 복사하여 URL아래 빈칸에 붙여넣으면 마운트에 성공하게된다.\n",
        "from google.colab import drive\n",
        "drive.mount('./MyDrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Drive already mounted at ./MyDrive; to attempt to forcibly remount, call drive.mount(\"./MyDrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTiePp9YlA8R",
        "outputId": "e701d449-77c6-4f5e-edd6-b73e71b13270"
      },
      "source": [
        "cd MyDrive/MyDrive/Capstone/code_data"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/MyDrive/MyDrive/Capstone/code_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ml-UXy1nkI_x"
      },
      "source": [
        "import os\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAXZNl6bmM7J",
        "outputId": "8ad365e5-b87b-4bf5-a500-5ccae9a68209"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'2021 Spring.code-workspace'\n",
            " BERT_raw_to_fine_tune_ord.pt\n",
            " BERT_raw_to_fine_tune_test.pt\n",
            " data\n",
            " data2.ipynb\n",
            " data.ipynb\n",
            " FYP_DataScience.code-workspace\n",
            "'Mobile Computing Group Project Outline.gdoc'\n",
            " Model\n",
            "\"Other's code\"\n",
            "'Other'\\''s code (1)'\n",
            " PHEME_baseline.ipynb\n",
            " PHEME_BERTweet.py\n",
            " PHEME_BERTweets.ipynb\n",
            " PHEME_BERTweets_to_fclayer.ipynb\n",
            " PHEME_data_annotated.ipynb\n",
            " PHEME_data_integration.ipynb\n",
            " PHEME_data.ipynb\n",
            " PHEME_data_reaction.ipynb\n",
            " PHEME_data_whole_valid.ipynb\n",
            " PHEME_DeepLearning.ipynb\n",
            " PHEME_eda.ipynb\n",
            "'PHEME_ipynb to .ipynb'\n",
            " pheme_parse.ipynb\n",
            " PHEME.py\n",
            " PHEME.webscrolling.ipynb\n",
            " __pycache__\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myxMVEcGkI2n"
      },
      "source": [
        "# Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kc19B4_akI_5"
      },
      "source": [
        "# raw_text = pd.read_csv('./data/_PHEME_text.csv')\n",
        "# y = pd.read_csv('./data/_PHEME_target.csv')\n",
        "# data = pd.concat([raw_text.text, y], axis=1).reset_index(drop=True)\n",
        "\n",
        "# X = data.text.values\n",
        "# y = data.target.values\n",
        "\n",
        "# test_data = pd.read_csv('data/_PHEMEext_text.csv').drop(['Event'],axis=1)\n",
        "# test_X = test_data.text.values\n",
        "# test_y = test_data.target.values\n",
        "\n",
        "# # from sklearn.model_selection import train_test_split\n",
        "# # # X_train, X_val, y_train, y_val =\\\n",
        "# # #     train_test_split(X, y, test_size=0.1, random_state=2020)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjaTgNvxkI_6",
        "outputId": "49336c38-9798-4d09-8f5c-70f34d3ea504"
      },
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():       \n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "Device name: Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGv2-sRPkI_-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "c28ebe85-f115-42e3-c080-202173005295"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-4b37ef281455>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    |\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtIMlTiMUFzS"
      },
      "source": [
        "# TFIDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adkKLRH4kI_7",
        "outputId": "b2382fb4-6ff7-4030-842a-d1e15e6bc565"
      },
      "source": [
        "import nltk\n",
        "# Uncomment to download \"stopwords\"\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "def text_preprocessing(s):\n",
        "    \"\"\"\n",
        "    - Lowercase the sentence\n",
        "    - Change \"'t\" to \"not\"\n",
        "    - Remove \"@name\"\n",
        "    - Isolate and remove punctuations except \"?\"\n",
        "    - Remove other special characters\n",
        "    - Remove stop words except \"not\" and \"can\"\n",
        "    - Remove trailing whitespace\n",
        "    \"\"\"\n",
        "    s = s.lower()\n",
        "    # Change 't to 'not'\n",
        "    s = re.sub(r\"\\'t\", \" not\", s)\n",
        "    # Remove @name\n",
        "    s = re.sub(r'(@.*?)[\\s]', ' ', s)\n",
        "    # Isolate and remove punctuations except '?'\n",
        "    s = re.sub(r'([\\'\\\"\\.\\(\\)\\!\\?\\\\\\/\\,])', r' \\1 ', s)\n",
        "    s = re.sub(r'[^\\w\\s\\?]', ' ', s)\n",
        "    # Remove some special characters\n",
        "    s = re.sub(r'([\\;\\:\\|•«\\n])', ' ', s)\n",
        "    # Remove stopwords except 'not' and 'can'\n",
        "    s = \" \".join([word for word in s.split()\n",
        "                  if word not in stopwords.words('english')\n",
        "                  or word in ['not', 'can']])\n",
        "    # Remove trailing whitespace\n",
        "    s = re.sub(r'\\s+', ' ', s).strip()\n",
        "    \n",
        "    return s"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YahIdy3XkI_9",
        "outputId": "0e75a5bd-c64c-4394-a1c0-709ae6ef0ccc"
      },
      "source": [
        "%%time\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Preprocess text\n",
        "X_train_preprocessed = np.array([text_preprocessing(text) for text in X])\n",
        "X_val_preprocessed = np.array([text_preprocessing(text) for text in test_X])\n",
        "\n",
        "# Calculate TF-IDF\n",
        "tf_idf = TfidfVectorizer(ngram_range=(1, 3),\n",
        "                         binary=True,\n",
        "                         smooth_idf=False)\n",
        "X_train_tfidf = tf_idf.fit_transform(X_train_preprocessed)\n",
        "X_val_tfidf = tf_idf.transform(X_val_preprocessed)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-838a357a3484>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'from sklearn.feature_extraction.text import TfidfVectorizer\\n\\n# Preprocess text\\nX_train_preprocessed = np.array([text_preprocessing(text) for text in X])\\nX_val_preprocessed = np.array([text_preprocessing(text) for text in test_X])\\n\\n# Calculate TF-IDF\\ntf_idf = TfidfVectorizer(ngram_range=(1, 3),\\n                         binary=True,\\n                         smooth_idf=False)\\nX_train_tfidf = tf_idf.fit_transform(X_train_preprocessed)\\nX_val_tfidf = tf_idf.transform(X_val_preprocessed)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-88ed875ee9d6>\u001b[0m in \u001b[0;36mtext_preprocessing\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'([\\;\\:\\|•«\\n])'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# Remove stopwords except 'not' and 'can'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     s = \" \".join([word for word in s.split()\n\u001b[0m\u001b[1;32m     28\u001b[0m                   \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                   or word in ['not', 'can']])\n",
            "\u001b[0;32m<ipython-input-19-88ed875ee9d6>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# Remove stopwords except 'not' and 'can'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     s = \" \".join([word for word in s.split()\n\u001b[0;32m---> 28\u001b[0;31m                   \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                   or word in ['not', 'can']])\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# Remove trailing whitespace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/corpus/reader/wordlist.py\u001b[0m in \u001b[0;36mwords\u001b[0;34m(self, fileids, ignore_lines_startswith)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \"\"\"\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_lines_startswith\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         return [line for line in line_tokenize(self.raw(fileids))\n\u001b[0m\u001b[1;32m     23\u001b[0m                 if not line.startswith(ignore_lines_startswith)]\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/corpus/reader/wordlist.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_lines_startswith\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         return [line for line in line_tokenize(self.raw(fileids))\n\u001b[0;32m---> 23\u001b[0;31m                 if not line.startswith(ignore_lines_startswith)]\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86QdYvNrkI_9",
        "outputId": "4884b136-aa77-410d-f6e9-e0e201376b02"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(X_train_tfidf.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-6ca3cc28359f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLOxl1JDkI_9"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "\n",
        "def get_auc_CV(model):\n",
        "    \"\"\"\n",
        "    Return the average AUC score from cross-validation.\n",
        "    \"\"\"\n",
        "    # Set KFold to shuffle data before the split\n",
        "    kf = StratifiedKFold(5, shuffle=True, random_state=1)\n",
        "\n",
        "    # Get AUC scores\n",
        "    auc = cross_val_score(\n",
        "        model, X_train_tfidf, y_train, scoring=\"roc_auc\", cv=kf)\n",
        "\n",
        "    return auc.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "3Bi1JS2IkI_9",
        "outputId": "6c986067-c6ca-4f99-9732-d2302aed588e"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "res = pd.Series([get_auc_CV(MultinomialNB(i))\n",
        "                 for i in np.arange(1, 10, 0.1)],\n",
        "                index=np.arange(1, 10, 0.1))\n",
        "\n",
        "best_alpha = np.round(res.idxmax(), 2)\n",
        "print('Best alpha: ', best_alpha)\n",
        "\n",
        "plt.plot(res)\n",
        "plt.title('AUC vs. Alpha')\n",
        "plt.xlabel('Alpha')\n",
        "plt.ylabel('AUC')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best alpha:  1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "PZi8GU6dkI_-",
        "outputId": "eae6e8c0-0ffe-49aa-922c-ab0ab749b5e4"
      },
      "source": [
        "# Compute predicted probabilities\n",
        "nb_model = MultinomialNB(alpha=1.8)\n",
        "nb_model.fit(X_train_tfidf, y_train)\n",
        "probs = nb_model.predict_proba(X_val_tfidf)\n",
        "\n",
        "# Evaluate the classifier\n",
        "evaluate_roc(probs, y_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC: 0.9015\n",
            "Accuracy: 82.10%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "MKMBotb3lbfB",
        "outputId": "53155806-9c82-4a9b-b1d3-19917cce2562"
      },
      "source": [
        "# Compute predicted probabilities\n",
        "\n",
        "# X_data = pd.concat([X_train_tfidf, X_val_tfidf], axis=0)\n",
        "# y_data = pd.concat([X_train_tfidf, X_val_tfidf], axis=0)\n",
        "\n",
        "X_test = test_data.text.values\n",
        "y_test = test_data.isRumor.values\n",
        "\n",
        "X_preprocessed = np.array([text_preprocessing(text) for text in X])\n",
        "X_tfidf = tf_idf.transform(X_preprocessed)\n",
        "X_test_preprocessed = np.array([text_preprocessing(text) for text in X_test])\n",
        "X_test_tfidf = tf_idf.transform(X_test_preprocessed)\n",
        "\n",
        "nb_model = MultinomialNB(alpha=1.8)\n",
        "nb_model.fit(X_tfidf, y)\n",
        "probs = nb_model.predict_proba(X_test_tfidf)\n",
        "\n",
        "# Evaluate the classifier\n",
        "evaluate_roc(probs, test_data.isRumor)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC: 0.5743\n",
            "Accuracy: 50.00%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd5gUZfLA8W+B5KSidxIFBVQQROBEVEDFgIiiggQjCGIWEyeKZ0AMHJh/JlAPTKBiAgXxVMIZQMlREEFhQSQjWVjq90f1usOyOzsbemZ2tz7PM89Oh+mu6d2dmu6333pFVXHOOeeyUizRATjnnEtuniicc85F5YnCOedcVJ4onHPOReWJwjnnXFSeKJxzzkXlicLliIgsEJHTEx1HshCRe0XklQTte7iIDEzEvvObiFwuIp/n8rX+NxkyTxQFmIj8IiI7RWSbiKwJPjjKh7lPVW2gqpPC3EcaESklIo+JyIrgff4kIn1FROKx/0ziOV1EUiLnqeqjqtorpP2JiNwqIvNFZLuIpIjIeyLSMIz95ZaIPCgib+ZlG6r6lqqeE8O+DkiO8fybLKo8URR8F6hqeaAxcCJwT4LjyTEROSiLRe8BbYB2QAXgSqA38EwIMYiIJNv/wzNAH+BW4FCgHvARcH5+7yjK7yB0idy3i5Gq+qOAPoBfgLMipv8NfBoxfTLwLbAZmAOcHrHsUOA/wGpgE/BRxLL2wOzgdd8CjTLuE6gK7AQOjVh2IrAeKBFMXwMsCrY/ATgyYl0FbgJ+ApZn8t7aALuAGhnmNwdSgTrB9CTgMeB74A/g4wwxRTsGk4BHgG+C91IH6BHEvBVYBlwXrFsuWGcfsC14VAUeBN4M1qkVvK+rgRXBsegfsb8ywIjgeCwC/gmkZPG7rRu8z5Oi/P6HA88DnwbxTgOOjlj+DLAyOC4zgJYRyx4ERgNvBst7AScB3wXH6jfg/4CSEa9pAPwX2Aj8DtwLtAX+BPYEx2ROsG4l4NVgO6uAgUDxYFn34Jg/BWwIlnUHvg6WS7BsbRDbPOB47EvCnmB/24CxGf8PgOJBXD8Hx2QGGf6G/JGLz5pEB+CPPPzy9v8HqR78Qz0TTFcL/gnbYWeOZwfThwfLPwXeAQ4BSgCtg/knBv+gzYN/uquD/ZTKZJ9fAddGxDMYeCl43gFYChwHHATcB3wbsa4GHzqHAmUyeW+PA5OzeN+/kv4BPin4IDoe+zB/n/QP7uyOwSTsA71BEGMJ7Nv60cGHVWtgB9AkWP90Mnywk3miGIYlhROA3cBxke8pOObVgbkZtxex3euBX7P5/Q8P3s9JQfxvAaMill8BVA6W3QmsAUpHxL0HuCg4NmWAplhiPSh4L4uA24L1K2Af+ncCpYPp5hmPQcS+PwReDn4nf8MSedrvrDuwF7gl2FcZ9k8U52If8AcHv4fjgCoR73lglP+Dvtj/wTHBa08AKif6f7WgPxIegD/y8Muzf5Bt2DcnBb4EDg6W3Q28kWH9CdgHfxXsm/EhmWzzReDhDPMWk55IIv8pewFfBc8F+/baKpgeD/SM2EYx7EP3yGBagTOjvLdXIj/0MiybSvBNHfuwfzxiWX3sG2fxaMcg4rUDsjnGHwF9guenE1uiqB6x/Huga/B8GXBuxLJeGbcXsaw/MDWb2IYDr0RMtwN+jLL+JuCEiLinZLP924APg+fdgFlZrPfXMQim/44lyDIR87oBE4Pn3YEVGbbRnfREcSawBEtaxTJ5z9ESxWKgQxj/b0X5kWzXZF3OXaSqFbAPsWOBw4L5RwKXisjmtAdwGpYkagAbVXVTJts7Ergzw+tqYJdZMnofaCEiVYBWWPL5X8R2nonYxkYsmVSLeP3KKO9rfRBrZqoEyzPbzq/YmcFhRD8GmcYgIueJyFQR2Ris3470YxqrNRHPdwBpNxhUzbC/aO9/A1m//1j2hYjcJSKLRGRL8F4qsf97yfje64nIJ8GNEX8Aj0asXwO7nBOLI7HfwW8Rx/1l7Mwi031HUtWvsMtezwNrRWSoiFSMcd85idPFyBNFIaGqk7FvW0OCWSuxb9MHRzzKqerjwbJDReTgTDa1Engkw+vKqurITPa5Cfgc6AJchp0BaMR2rsuwnTKq+m3kJqK8pS+A5iJSI3KmiDTHPgy+ipgduU5N7JLK+myOwQExiEgpLPkNAf6uqgcD47AEl128sfgNu+SUWdwZfQlUF5FmudmRiLTE2kA6Y2eOBwNbSH8vcOD7eRH4EairqhWxa/1p668Ejspidxm3sxI7ozgs4rhXVNUGUV6z/wZVn1XVptgZYj3sklK2rwv2fXQ267gc8kRRuDwNnC0iJ2CNlBeIyLkiUlxESge3d1ZX1d+wS0MviMghIlJCRFoF2xgGXC8izYM7gcqJyPkiUiGLfb4NXAV0Cp6neQm4R0QaAIhIJRG5NNY3oqpfYB+W74tIg+A9nBy8rxdV9aeI1a8QkfoiUhYYAIxW1dRoxyCL3ZYESgHrgL0ich4Qecvm70BlEakU6/vI4F3smBwiItWAm7NaMXh/LwAjg5hLBvF3FZF+MeyrAtYOsA44SETuB7L7Vl4BazzeJiLHAjdELPsEqCIitwW3LVcIkjbYcamVdtdY8Pf1OfCEiFQUkWIicrSItI4hbkTkH8HfXwlgO3ZTw76IfWWVsMAuWT4sInWDv99GIlI5lv26rHmiKERUdR3wOnC/qq7EGpTvxT4sVmLfytJ+51di37x/xBqvbwu2MR24Fjv134Q1SHePstsx2B06a1R1TkQsHwKDgFHBZYz5wHk5fEsdgYnAZ1hbzJvYnTS3ZFjvDexsag3W0HprEEN2x2A/qro1eO272Hu/LHh/act/BEYCy4JLKpldjotmAJACLMfOmEZj37yzcivpl2A2Y5dULgbGxrCvCdhxW4JdjttF9EtdAHdh73kr9oXhnbQFwbE5G7gAO84/AWcEi98Lfm4QkZnB86uwxLsQO5ajie1SGlhCGxa87lfsMtzgYNmrQP3g+H+UyWufxH5/n2NJ71WssdzlgaRfKXCu4BGRSVhDakJ6R+eFiNyANXTH9E3buUTxMwrn4kREqojIqcGlmGOwW00/THRczmUntEQhIq+JyFoRmZ/FchGRZ0VkqYjMFZEmYcXiXJIoid39sxVrjP8Ya4dwLqmFdukpaBzdBryuqsdnsrwddq25Hda56xlVbZ5xPeecc4kV2hmFqk7B7p3PSgcsiaiqTgUODu7Hd845l0QSWYyrGvvfhZESzPst44oi0hur80K5cuWaHnvssXEJ0Dnnkt2ePbB9e/rzFSv2X16TXzmYzcxl73pVPTw3+ygQVRtVdSgwFKBZs2Y6ffr0BEfknHOJtWcPzJwJ//wnzJ27/7LR7ynNmwMilHv9RYptWMvBTz74a273lchEsYr9e6ZWD+Y555zLxrPPwl132fNTT4XnnrPnFbeu4qghNyC7u8Dll8O9Qb/JJx/M9b4SeXvsGOCq4O6nk4EtQY9O55xz2fjjD/s5YQKMHg0nNlZOnD6Moy+oj3zxBWzblm/7Cu2MQkRGYoXqDhMbFewBrFAYqvoSVkOnHdbzdwc2DoBzzrkcOOcc4Oefoc21MHEinHEGDBsGR+dfyavQEoWqdstmedrANc4552K0eDE0b25nFMXSrgnNmwczZsDQodCrF+TzaMEFojHbOeec+fVX2LIF7rlgPu2OmAlcBRddBMuWQeVw6h96onDOuQJE9vzJAzzK/eMfpdgRf4ddnaF06dCSBHitJ+ecKxBU4dEO06jdqQkP8hDr23SBWbMsSYTME4VzziW5ESPguvaruGtMS8ru2cIDTT+hxMg34LCcDr6YO37pyTnnktTs2fDJk0t4elw9du2qRunq79B1WBseahvryLD5wxOFc84lo82b2XbZP7l30St8V34SLe9rRb9+FyckFE8UzjmXbMaMgRtu4JTf1vB82b58uvYfCR2nz9sonHMumfTqBR06QOXKDLp4GgPLD4IyiR3N1c8onHMugbZsgdmzgnGBRKhSsRklrjmSld3uZupzJRMbXMAThXPOJdBDvVbSZvT1jKIrb3IlcL0teM1+5GMljlzzROGcc3G2bRvs3L6P0iNeZuBHd4OkcvQdF3PN+Qeue9RR8Y8vI08UzjkXR8uWwfn1fuKl1F60Zgr/5SyeqT+UT4bUJlmHZPPGbOeci4O5c6F2bbuUVC91If8oNZcvL3+NJc99zgPDayc6vKj8jMI550L2v//BPe3mcFGJ2VS8/2rKl++AXL6MNlUPoU2ig4uBJwrnnAvRpx/sZm7ngUxMfRypWoWD7ukS1Gc6JNGhxcwvPTnnXD5btQrOOw9uaPwdtTueyD2pA0ntfBkHzY1PEb/85mcUzjmXz2bMgLmfrWKMtOaPckewY8Q4ynY8L9Fh5ZqfUTjnXH5atAiA1VRjxeB3qfzbggKdJMDPKJxzLk8WLIB33oHSOzfR9r930mTOf5hxxhSgJVvOuAgqJDrCvPNE4ZxzefD007D+lQ95gRs5nHU8xj38e+I/OOQQqFo10dHlD08UzjkXo1mzYPHi/edd/Mk1tOM/0LgxvPop9zRpwj2JCS80niiccy4bGzbYIEJdu8L69QBBET+EazmZn6vU5Zbv74ISJRIYZXg8UTjnXCaWLYOtW+35PffA+PH2/L4rf+Xu5dfxx/mX8cdFVwG9qVYNKJw5AvBE4Zxz+9m+HaZNgzYZukyfeMI+3jvzRY4a1g9RpXz3S6marMWZ8pknCudckbdnj/3ct8+qta5da9OPPw716kH5VYtpOaIXpZ/6Gs45B15+GWrVSli88eaJwjlXpD3/PNx88/7zLrkEOnWCSy+Fgw4CxiyGnxfA8OFw1VUgkohQE8YThXOuSJozB9q2hY0bbaTR/v1tfvHicPXVUGXNLHhjNvToARdeaI0WBx+c2KATxBOFc67QmjoVrrkm/dJSpK1b4fff4Yor4KyzLDkAsGsXDBgA//43VKsG3bpZfaYimiTAE4VzrhCbMcMqalxySea1+A49FJ58MuKu1m++gZ49rbNEjx7wxBMFsohffvNE4Zwr9F56CQ4/PJuVVq2CM86ws4gJE6zR2gFeFNA5V9QtXGg/q1WD99+HefM8SWTgZxTOuaS3cCG8+SaoZr9upBkzoizcuBHuuANGjIDJk6FVK7jggjzFWVh5onDOJa1t2+D11+Htt635oGTJnG/jqKOgYsUMM99/H266yWpz9O8PJ52UL/EWVp4onHNJ65NP7PMc7LN82rR82Gj37nYW0aQJfPaZFfNzUXmicM4lrb177efMmdCwYR42lHbNSgROOQWOOw7uvDPoTeeyE2pjtoi0FZHFIrJURPplsrymiEwUkVkiMldE2oUZj3OuYKpQIQ+f6cuXW+P066/bdO/ecPfdniRyILQjJSLFgeeBs4EU4AcRGaOqCyNWuw94V1VfFJH6wDigVlgxOefyZu9eWL06fvuzkt65lJpq9TnuuQeKFYPLL8+3uIqaMFPqScBSVV0GICKjgA5AZKJQIK2ZqRIQxz9B51ws9uxJvwR0441W7ijeSpXK4QsWLbKOc999B+edZx0patYMJbaiIMxEUQ1YGTGdAjTPsM6DwOcicgtQDjgrsw2JSG+gN0BN/2U7Fzc//QSNGllVizRHHw333hu/GA4/HGrUyOGLli613tVvvGFnEkWsiF9+S/RFum7AcFV9QkRaAG+IyPGqui9yJVUdCgwFaNasWQ7vpHbO5dbq1ZYkrr3WEgRYd4MWLRIbV6ZmzLBKf9dcY/0hli/P5L5YlxthJopVQOT3gOrBvEg9gbYAqvqdiJQGDgPWhhiXcy6Ke++FkSPt+c6d9rNbN6tukZR27oSHHoIhQ+zU47LLrD6TJ4l8E2ai+AGoKyK1sQTRFbgswzorgDbAcBE5DigNrAsxJueKtLffhqeeir7OwoVWKPWs4EJwhQrQrFn4seXKlCnQq5ddI+vZ05KFF/HLd6ElClXdKyI3AxOA4sBrqrpARAYA01V1DHAnMExEbscatrur5rSTvnMuVp9+CgsWRD87+NvfbGyeLl3iF1eurFpl45XWqAFffHHg2KUu34TaRqGq47BbXiPn3R/xfCFwapgxOOf2V62aJYwCa948631XrRp8+KFlvXLlEh1VoZboxmznXIj27oVBg2DTJpueOTOx8eTJ+vVw++1WHTCtiF/79omOqkjwROFcITV2LHz1FTz9tPVDSOuIXOAKpKrCe+/ZwNabNsEDD0DzjHfauzB5onCukNi40ZJDaqpN33yz3RBUooRVXm3aNLHx5drVV1t/iGbN4Msv81j0yeWGJwrnCokXX4T77tt/3uOP29Wa3JTnTqjIIn6tW1uvv9tu8/pMCeJH3blC4s8/7eevv9rPYsWsvbfAdUpetsx6+F1xhY1b3bNnoiMq8nwoVOcKgd9+s0tPYCWNataE6tULWJJITbUGlYYN4YcfLNO5pOBnFM4VcDNnprc/5Lh4XrJYuNBKb0ybBuefb0X8qldPdFQu4InCuQIurRT3v/4F556b2Fhybfly+Pln6zretWsBOxUq/DxROFdItG1rg7cVGD/8ALNnW3vE+edb20SFComOymXCLwI65+Jrxw646y44+WR47LH0GuaeJJKWJwrnXPxMmmS3uj7xhJ1JzJrlRfwKAL/05JyLj5QUOPtsOPJI6zKetHXLXUZ+RuGcC9ecOfazenX4+GOYO9eTRAHjicI5F45162wQocaNrYgfQLt2ULZsYuNyOeaXnpxz+UsVRo2CW2+FLVts9LmkHDvVxcoThXMF0KxZ8P339nzhwsTGcoArr4S33rIKr6++Cg0aJDoil0cxJwoRKauqO8IMxjkXm969Yfr09OnixW1kuoTZt886yYlY+0PTpnZGUbx4AoNy+SXbNgoROUVEFgI/BtMniMgLoUfmnMvSn39aB7vVq+2xYQPUqZOgYJYutWFI//Mfm+7Z00rWepIoNGJpzH4KOBfYAKCqc4BWYQblnMte6dJQpYo9KlVKQAB798KQIVbEb9asAljL3MUqpktPqrpS9q+9khpOOM4VbVu22OdvdmJZJ1Tz51sJ8OnToUMHeOEFqFo1wUG5sMSSKFaKyCmAikgJoA+wKNywnCt63n0XunSJff2EthGvWGEDX4waBZ07exG/Qi6WRHE98AxQDVgFfA7cGGZQzhVFKSn2c9AgKFMm+/XjXil22jTrPNe7t/WHWLYMypePcxAuEWJJFMeo6uWRM0TkVOCbcEJyruho08au4gBs324/b7ghyerjbd9uNcyffhqOOsrGsC5VypNEERJLongOaBLDPOdcDk2aZB2XTzrJpmvVSrIk8dVXVrxv2TLLYI8/XoBHR3K5lWWiEJEWwCnA4SJyR8SiioDf9+ZcPmnXDh5+ONFRZCIlxa5v1a5tJTha+c2ORVW0M4qSQPlgncjvOH8AncIMyrnCbtQo+OAD66eWdGbNghNPtCJ+Y8dC69axNZq4QivLRKGqk4HJIjJcVX+NY0zOFXrPPw8zZsDxx8NppyU6msDvv1tv6nfftWtirVtbrz5X5MXSRrFDRAYDDYC/RhhR1TNDi8q5IqBFC/jyy0RHgRXxe+st6NMHtm2DgQML2JiqLmyxJIq3gHeA9titslcD68IMyrnCZvduePttGwUUrOxGrVoJDSndZZfZtbAWLayI33HHJToil2RiSRSVVfVVEekTcTnqh7ADc64w+eoruOaa/ecl9JJTZBG/c86xJHHTTV6fyWUqlkSxJ/j5m4icD6wGDg0vJOcKh9WrYfFiez5jhv384gsbMhqgcuXExMWSJXbL61VXWQG/Hj0SFIgrKGJJFANFpBJwJ9Z/oiJwW6hROVcIXHhheoJIU7MmHH54YuJh71548kl44AGrKOh3MrkYZZsoVPWT4OkW4Az4q2e2cy6KrVvhzDPh/vtt+uCDoW7dBAUzd65d+5oxAy6+2G67qlIlQcG4giZah7viQGesxtNnqjpfRNoD9wJlgBPjE6JzyUs1674QqjaYUOvW8Y0pUykpsHIlvPcedOzoRfxcjkQbj+JVoBdQGXhWRN4EhgD/VtWYkoSItBWRxSKyVET6ZbFOZxFZKCILROTtnL4B5xLplFPgoIMyf/z0U4Lbhr/9Fl56yZ6nFfHr1MmThMuxaJeemgGNVHWfiJQG1gBHq+qGWDYcnJE8D5wNpAA/iMgYVV0YsU5d4B7gVFXdJCKJHMzRuRz78UcbGvr88zNffvHF8Y0HsL4Q/fvDc8/B0UdbY3WpUlCuXAKCcYVBtETxp6ruA1DVXSKyLNYkETgJWKqqywBEZBTQAYgcCv5a4HlV3RTsZ22OoncuCTRvbsVVk8Lnn1sZ8BUr7HbXRx/1In4uz6IlimNFZG7wXICjg2kBVFUbZbPtasDKiOkUoHmGdeoBiMg3WKHBB1X1s4wbEpHeQG+AmjVrZrNb54qolSvt1Oboo2HKlCSqDeIKumiJIh7dMw8C6gKnA9WBKSLSUFU3R66kqkOBoQDNmjXTOMTlXFQffABvvGFXeRJuxgxo2hRq1IBx46BlS7v91bl8Eq0oYF4LAa4CakRMVw/mRUoBpqnqHmC5iCzBEof3/HZJ6aefrCvCp5/CunU2HOmZiap6tmYN3HILjB6dXsTv7LMTFIwrzKLd9ZRXPwB1RaS2iJQEugJjMqzzEXY2gYgchl2KWhZiTM7lyejRdiPRnj02js/s2dChQ5yDUIURI6B+fSsD/uijXsTPhSqWntm5oqp7ReRmYALW/vCaqi4QkQHAdFUdEyw7R0QWAqlA3xw2mDsXVxpc+Pz1VyhZMkFBdO1qpcBPPRVeeQWOPTZBgbiiIqZEISJlgJqqujgnG1fVccC4DPPuj3iuwB3BwzmXlcgifu3aWTvEjTdCsTAvCjhnsk0UInIB1tGuJFBbRBoDA1T1wrCDcy4ZLFxoHZvB2iji7scfoVcv6N7dfl59dQKCcEVZLGcUD2J9IiYBqOpsEakdYkzOJY3UVLuhaNeu9Hlly8bpi/yePTB4MDz0kHWWK18+Djt17kAxlRlX1S2yf7d/v0XVFQn79lmSuPZa+0IPULWqlegI1ezZ1qN69mwru/Hcc3DEESHv1LnMxfLnvkBELgOKByU3bgW+DTcs55LLkUfG+caiNWvs8f77cMklcdyxcweK5QT6Fmy87N3A21i5cR+Pwrn89vXX8MIL9rxtW/j5Z08SLinEkiiOVdX+qvqP4HGfqu7K/mXOFSyzZ8Pf/w4VK6Y/Dg3Gcgy1TWLrVrj5ZruT6emnbYBtsMYQ55JALJeenhCRI4DRwDuqOj/kmJyLq927oU0bu6Np7VobITRymNLixaFbt5B2PmGCFfFbuRL69IGBA72In0s6sYxwd0aQKDoDL4tIRSxhDAw9OufiYP16+OYbqwLbtSsMGQIlSsRhxytXQvv2UKeOXXby3tUuScV0Qq2qa1T1WeB6YDZwfzYvca7A6dkTnnkm5CShCt9/b89r1IDx42HWLE8SLqllmyhE5DgReVBE5gHPYXc8VQ89MucKm99+s2FImzeHyZNt3llneaVXl/RiaaN4DXgHOFdVV4ccj3OFjyoMHw533GGdMgYNsjpNzhUQsbRRtIhHIM6Fad8+ePVV2Lz5wGVbtoS8886drexsy5ZWxK9evZB36Fz+yjJRiMi7qto5uOQU2RM71hHunEuIjRttvIjU1PR5q1fbMNJZKVbMOtXlm9RUK+BXrBhccIENWnHddV7EzxVI0c4o+gQ/28cjEOfyy0svZZ0UvvzSmggyKl48H5sKFi2ylvEePaz2x1VX5dOGnUuMaCPc/RY8vVFV745cJiKDgLsPfJVziZfWX2358v3nlyljHepCs2ePtT88/LAV8KtUKcSdORc/sTRmn82BSeG8TOY5l1Rq1YrjzmbNsqqBc+dCly7w7LPwt7/FMQDnwhOtjeIG4EbgKBGZG7GoAvBN2IE5V6D8/rv13PvoowSMjepcuKKdUbwNjAceA/pFzN+qqhtDjcq5gmDKFJg3D266yYr4LV1q17ecK2SiJQpV1V9E5KaMC0TkUE8WLlns3QuNGqW3SezZE/LNRX/8Af36wYsv2q2uvXpZfSZPEq6Qyu6Moj0wA7s9NnLkIgWOCjEu52K2a5fdaHT66XDSSTbv2GND2tm4cXab6+rV1oFuwAAv4ucKvWh3PbUPfvqwpy7pfPghPPKIdXpO6y9x/vlw110h7nTlSmt/OOYY60CX2X22zhVCsdR6OlVEygXPrxCRJ0WkZvihOZe1zz+3G4yqVrXaehddZM0E+U4Vpk615zVq2I5nzvQk4YqUWG6PfRE4QUROAO4EXgHeAFqHGZhz2TnkEBg7NsQdrF4NN9wAY8bApEnQujWccUaIO3QuOcWSKPaqqopIB+D/VPVVEekZdmDORVKFxx+Hdets+pswb9BWtcJQd91lvfeGDPEifq5IiyVRbBWRe4ArgZYiUgyIx7AuzgHw2Wfw1VcweLC1G5csafNPPz2kHXbqBB98YGcQr7xiAws5V4TFkii6AJcB16jqmqB9YnC4YTmXrlcvWLUKDjrImghatQphJ5FF/C66CM45x+o0eRE/57JvzFbVNcBbQCURaQ/sUtXXQ4/MuUBqqtXY27kzpCQxf75dWnr1VZu+8kqv9OpchFjueuoMfA9cio2bPU1EOoUdmHORihe3M4p89eef8NBD0KQJ/PyztY475w4Qy79ef+AfqroWQEQOB74ARocZmHOhmjHDivjNnw+XXQZPPw2HH57oqJxLSrEkimJpSSKwgRjORJxLahs22HB3Y8dCex9yxbloYkkUn4nIBGBkMN0FGBdeSM6FZOJEK+J3663WWP3TT/k4WpFzhVcsjdl9gZeBRsFjaMaBjJxLalu2WOP0mWdaIb+0kY08STgXkywThYjUFZGPRWQ+1pD9hKreoaofxi88V5Q98QRUqWJDPYhkv36mxo6F+vWtP8Rdd1nbhBfxcy5Hop1RvAZ8AnTEKsg+F5eInAt8+619+e/d2/pS5NjKldCxI1SubPWaBg+GsmXzPU7nCrtobRQVVHVY8HyxiMyMR0DORapWDV56KQcvUIXvvoNTTkkv4nfKKcGP/6sAABuISURBVOnduZ1zORbtjKK0iJwoIk1EpAlQJsN0tkSkrYgsFpGlItIvynodRURFpFlO34Bzf0lJgQsvtM5zkyfbvNNP9yThXB5FO6P4DXgyYnpNxLQCZ0bbsIgUB54HzgZSgB9EZIyqLsywXgWgDzAtZ6E7F9i3D4YNg759bbi7J5+E005LdFTOFRrRBi7Kaz3lk4ClqroMQERGAR2AhRnWexgYBPTN4/5cUdWxI3z0kd3VNGwYHOWDLzqXn/K7KEKkasDKiOkUYL/RXoJLWDVU9VMRyTJRiEhvoDdAzZo+ZlJh9MUX1q0h0s8/R3nB3r1Wi6lYMUsU559vBaFyfXuUcy4rYSaKqIJy5U8C3bNbV1WHAkMBmjVrpuFG5sK0d6+1L+/Ysf/8yy+30ksZnXtuJhuZO9eSQq9e1j/iiitCidU5Z8JMFKuAGhHT1YN5aSoAxwOTxL4FHgGMEZELVXV6iHG5BPnxRxg/Hu64I/PlDz9slb0jHXpoxMTu3fDoo/Y45BCvzeRcnGSbKMQ+xS8HjlLVAcF4FEeo6vfZvPQHoK6I1MYSRFdsXAsAVHULcFjEfiYBd3mSKJy2bYOGDe2MAmDcOLt7NU3x4nDMMVEqe//wgxXxW7jQyoA/9ZT1j3DOhS6WM4oXgH3YXU4DgK3A+8A/or1IVfeKyM3ABKA48JqqLhCRAcB0VR2Tp8hdUtq27cDLSgAbN1qSuPlmuOYaOPHEHG540ybb+LhxcN55+RKrcy42sSSK5qraRERmAajqJhGJ6cZ0VR1HhgKCqnp/FuueHss2XfLQDK1Fa9fCkUeml1LKzPHH5yBJfPWVFfHr08eK+C1Z4uU3nEuAWBLFnqBPhMJf41HsCzUql/RGj4YuXawLQ0bXXguNGx84v0QJ6Nw5ho1v3mx9Il55BY47Dq6/3hKEJwnnEiKWRPEs8CHwNxF5BOgE3BdqVC5prVgBrVtbob59++Bf/7L2hTRlytjnesWKudzBxx/DDTfYDv75T3jwQU8QziVYtolCVd8SkRlAG0CAi1R1UeiRuaS0fDn88gt06ABnnGFXhfLNihVw6aV2FjFmDDTzii7OJYNY7nqqCewAxkbOU9UVYQbmklufPpYo8kwVvv4aWraEmjWt593JJ3t9JueSSCyXnj7F2icEKA3UBhYDDUKMyyWRESPsCz7AunX5uOEVK+w61fjxMGmSXdNq1Sofd+Ccyw+xXHpqGDkdlN24MbSIXMKtXw+PPAI7d9r0Bx/Y81q1bLpFCzj22DzsYN8+qx1+9912RvHss17Ez7kkluOe2ao6U0SaZ7+mKwjmzLE7mCItWgTvv2+9okuUsE5w/fpB//75tNNLLrFG67PPhqFD0zOQcy4pxdJGEVlwoRjQBFgdWkQuroYMgTffPLBH9GGHWcmNfOv8HFnEr0sXaw3v3t2L+DlXAMRyRlEh4vlerM3i/XDCcWH45Rcb9C0zy5ZBnToHVm7NV3PmWHfsa6+1Nolu3ULcmXMuv0VNFEFHuwqqelec4nEhuOUW+OSTrJeffHJIO961CwYOhEGD7DrWEUeEtCPnXJiyTBQiclBQr+nUeAbk8k9qqrU3rFtnZTNGjsx8vWrVQtj599/D1Vfb9aurr7ZR5/YrBeucKyiinVF8j7VHzBaRMcB7wPa0har6QcixuTx67jm4/XZ7ftZZVp01bv74w26V+uyzLAaVcM4VFLG0UZQGNmDVY9P6UyjgiSKJpababa5gt7c2aRKHnX7+OSxYYNnprLNg8WIvv+FcIRAtUfwtuONpPukJIo2PMpfEFi6Epk2tiaB4cbj44pB3uGmTjUY0fDg0aAA33uhF/JwrRKIliuJAefZPEGk8USSh1FQrj7RkiSWJ666zL/ah+uADuOkmawi55x64/35PEM4VMtESxW+qOiBukbiY7NhhH/5r1x64bN8+K9p32mlWh6l//5A/s1esgK5dbZCJceNyMRqRc64giJYovCdUElqzxvpEtGgBRx114PJWreDee6FevZACUIUpU6wuU82aNrhQ8+bWhds5VyhFSxRt4haFy9SCBTbeQ9o40wDbg/vOrr8erroqzgH9+qtdz5owIb2In9docq7QyzJRqOrGeAbi0u3caZeNvvnGuiM0arT/4EAnnxznoRr27YMXXrCCT2D33bZsGccAnHOJlOOigC58c+bAU09ZnaXTTrMv75GJIu4uugjGjrX+EC+/bANjO+eKDE8USWbsWPjvf+35m29C27YJCmTPHstOxYpZbaZOneDKK72In3NFkCeKJLFkCUydCr162Wd0iRJQtWqCgpk5E3r2tCJ+N97oRfycK+KKZb+Ki4cbb7SSSHv2wODBVgGjUaM4B7Fzp/WFOOkku72qRo04B+CcS0Z+RpEgqlawb8cOm16/3m55HTnS7jqN+xWeqVMtUy1ZYiXBhwyBQw6JcxDOuWTkiSKfbd+eXmMpmh9+gEsv3X9e+/YJbCfevt1OZ/773zh053bOFSSeKPJZ06ZWCy9WL74I1aunvzauPvvMOmvceSe0aWMlwUuWjHMQzrlk54kin/3+u33mXn559usefLDdeRr3y0wbNlgRv9dfh4YNbWSjkiU9STjnMuWJIgQNGkCPHomOIhOq8P77VsRv40a47z57eIJwzkXhdz3lkyFDoFYt2LIl0ZFEsWIFXHaZ3c00fTo8/LBXenXOZcsTRT6ZNAm2brUbh+JegykaVSvcB9ZSPmmS3eF0wgkJDcs5V3B4osijWbPgggtg2jSoXRv+858ENEpnZflyOOccazSZPNnmnXIKHORXHJ1zsfNEkUfjx8Mnn9iX9Yy3uyZMaio884yNEzFtmt1a5UX8nHO55F8tc+Hll+Gnn+z51Kn289tvk6hNuEMH+PRTaNcOXnrJe1g75/LEE0UOfPcdTJxoJcBLlEhPDCeemARXcyKL+F15pdVnuuwyL+LnnMuzUC89iUhbEVksIktFpF8my+8QkYUiMldEvhSRpKxf/fvv8Npr1kjdv7999o4YAdu22WPmTPt8Tpjp022AihdftOkuXawjhycJ51w+CO3jTUSKA88D5wH1gW4iUj/DarOAZqraCBgN/DusePLiySetmOrSpZYsdu5MkoKqO3fC3XfbUKTr1vk4Ec65UIR5weQkYKmqLgMQkVFAB2Bh2gqqOjFi/anAFSHGkyNLl9pnL8Avv0CFClbtomrVBA8ilOa77+xe3J9+strkgwdbV2/nnMtnYSaKasDKiOkUoHmU9XsC4zNbICK9gd4ANWvWzK/4MrV9uxVQbdbMRgBNU7VqkrUJ79xpAX7xhd3+6pxzIUl0EywAInIF0AxondlyVR0KDAVo1qyZ5vf+t22zO0oBzjzT2hzAruqccYY9P+qo/N5rLowbZ6c1fftaoIsWWau6c86FKMxEsQqI/A5ePZi3HxE5C+gPtFbV3SHGk6kxY+xu0khnnAHXX28d6cqUiXdEmVi/Hm67Dd56y3pU9+ljt1x5knDOxUGYieIHoK6I1MYSRFfgssgVRORE4GWgraquDTGWLK0MLo4NGADly9vzCy+Eo49ORDQZqMI771h11y1b4IEH4N57k6jDhnOuKAgtUajqXhG5GZgAFAdeU9UFIjIAmK6qY4DBQHngPbFbOVeo6oVhxRTN9dfD4YcnYs9RrFhhDdYnnACvvmolwZ1zLs5CbaNQ1XHAuAzz7o947kOpZaQKX35po8wdeaTVaPrHP5LkVivnXFHktZ6Syc8/2x1MZ5+dXsTv5JM9STjnEsoTRTJITbVefQ0bwowZVkzKi/g555JEUtwemwh799q4PWlf3BPqggusDG379vsPou2cc0mgyCaKBQvsTqeyZa0ad6VKcQ7gzz+tkmCxYtC9uxXy69rV6zM555JOkb30pEG3vbfegnnz4nzH6fff2+hGL7xg0507W/EoTxLOuSRUZBNFQuzYAXfeCS1awKZNSdJZwznnoiuyl57i7uuvrU/EsmVw3XUwaFACrnc551zOFalEsWuXDSMN9nkdV2kDC02cCKefHuedO+dc7hX6RLF1K+wOKkhddx188MH+y0Ot5TR2rBXu++c/rYDUwoVJMBSec87lTKH+1Jo7F5o0Sa8MC9CgAfzrX/a8bNmQKnSvW2eF+0aOhMaNraBfyZKeJJxzBVKh/uRas8aSxO23p5cJb9nSSieFQtWSw623wh9/2P23d9/tRfyccwVaoU4UaTp1glNOicOOVqyAHj3gxBOtiF+DBnHYqXPOhctvj82rfftgwgR7fuSR8L//wTffeJJwzhUanijy4qefbKS5tm1hyhSbd9JJXsTPOVeoeKLIjb17YfBgaNQIZs+2y0xexM85V0gViTaKfNe+vV1u6tDBynBUrZroiJxLSnv27CElJYVdu3YlOpQio3Tp0lSvXp0S+ThUsieKWO3ebWNUFysGvXrBNdfApZd6fSbnokhJSaFChQrUqlUL8f+V0KkqGzZsICUlhdq1a+fbdv3SUyymTrUOGc8/b9OdOlkhP//Ddy6qXbt2UblyZU8ScSIiVK5cOd/P4Ar8GcXu3fDZZ1aeI6M5c/K48e3b4b774JlnbIyIunXzuEHnih5PEvEVxvEu8Ili7Fi7AhTNoYfmYsP/+58V8Vu+HG68ER57DCpWzFWMzjlXkBX4S09pZxLjx1sppYyPlSvh2GNzseG9e61NYvJku+TkScK5Auujjz5CRPjxxx//mjdp0iTat2+/33rdu3dn9OjRgDXE9+vXj7p169KkSRNatGjB+PHj8xzLY489Rp06dTjmmGOYkNYHK4Pu3btTu3ZtGjduTOPGjZk9ezYAgwcP/mve8ccfT/Hixdm4cWOeY8pOgT6j2LYNNm+253Xq2CNPPvrIivjdc48V8VuwwOszOVcIjBw5ktNOO42RI0fy0EMPxfSaf/3rX/z222/Mnz+fUqVK8fvvvzM5j2MnL1y4kFGjRrFgwQJWr17NWWedxZIlSyieSd+rwYMH06lTp/3m9e3bl759+wIwduxYnnrqKQ7N1SWTnCmwn4IbN0K1aulnFHkqp/T773DLLfDee9ZofeedXsTPuXx2223W7Sg/NW4MTz8dfZ1t27bx9ddfM3HiRC644IKYEsWOHTsYNmwYy5cvp1SpUgD8/e9/p3PnznmK9+OPP6Zr166UKlWK2rVrU6dOHb7//ntatGiR422NHDmSbt265SmeWBXYS0+bN1uSuPpqGD0aatbMxUZU4Y03oH59+PhjeOQRu8PJi/g5V2h8/PHHtG3blnr16lG5cmVmzJiR7WuWLl1KzZo1qRjDJefbb7/9r8tBkY/HH3/8gHVXrVpFjRo1/pquXr06q1atynS7/fv3p1GjRtx+++3sThsrIbBjxw4+++wzOnbsmG18+aHAf2U+80zI9bFascL6RDRrZr2rc9WY4ZyLRXbf/MMycuRI+vTpA0DXrl0ZOXIkTZs2zfLuoJzeNfTUU0/lOcaMHnvsMY444gj+/PNPevfuzaBBg7j//vv/Wj527FhOPfXUuFx2gkKQKHIsrYjfeedZEb9vvrFqr16fyblCZ+PGjXz11VfMmzcPESE1NRURYfDgwVSuXJlNmzYdsP5hhx1GnTp1WLFiBX/88Ue2ZxW33347EydOPGB+165d6dev337zqlWrxsqVK/+aTklJoVq1age8tkqVKgCUKlWKHj16MGTIkP2Wjxo1Km6XnQDryVeQHk2bNlVV1Z9/VgXVESM0dosXq7ZsaS+cNCkHL3TO5cbChQsTuv+XX35Ze/fuvd+8Vq1a6eTJk3XXrl1aq1atv2L85ZdftGbNmrp582ZVVe3bt692795dd+/eraqqa9eu1XfffTdP8cyfP18bNWqku3bt0mXLlmnt2rV17969B6y3evVqVVXdt2+f9unTR+++++6/lm3evFkPOeQQ3bZtW5b7yey4A9M1l5+7BbaNIkf27oVBg6yI37x58J//QKtWiY7KOReykSNHcvHFF+83r2PHjowcOZJSpUrx5ptv0qNHDxo3bkynTp145ZVXqFSpEgADBw7k8MMPp379+hx//PG0b98+pjaLaBo0aEDnzp2pX78+bdu25fnnn//rjqd27dqxevVqAC6//HIaNmxIw4YNWb9+Pffdd99f2/jwww8555xzKFeuXJ5iyQmxRFNwNGvWTG+4YTqffw7vvgsjRsBVV2XzonPPhc8/h0susT4RRxwRl1idK+oWLVrEcccdl+gwipzMjruIzFDVZrnZXoFro1i1yoaj3rcPateG44/PYsVdu6zDXPHi0Lu3PeJ0h4BzzhUmBe7S05o1sGePXUlatsy6PRzgm2/sBuu0In4dO3qScM65XCpwZxSlS8POnVks3LYN7r0X/u//rGOFn/I6l3Cq6oUB4yiM5oQCd0aRpcmT7TrU//0f3HwzzJ8PZ5+d6KicK9JKly7Nhg0bQvnwcgfSYDyK0qVL5+t2C9wZRVRly1rV11NPTXQkzjms53FKSgrr1q1LdChFRtoId/mpwN31VKZMM925c7pNfPAB/PijXW4CSE31jnPOOZeJvNz1FOqlJxFpKyKLRWSpiPTLZHkpEXknWD5NRGrFtOE1a2yUuY4d4cMP4c8/bb4nCeecy3ehJQoRKQ48D5wH1Ae6iUj9DKv1BDapah3gKWBQdts9OHWDNVJ/8okNJvTtt17EzznnQhTmGcVJwFJVXaaqfwKjgA4Z1ukAjAiejwbaSDa3R1Td86s1Ws+ZA/36WV8J55xzoQmzMbsasDJiOgVontU6qrpXRLYAlYH1kSuJSG+gdzC5W77+er5XegXgMDIcqyLMj0U6Pxbp/FikOya3LywQdz2p6lBgKICITM9tg0xh48cinR+LdH4s0vmxSCci03P72jAvPa0CakRMVw/mZbqOiBwEVAI2hBiTc865HAozUfwA1BWR2iJSEugKjMmwzhjg6uB5J+ArLWj36zrnXCEX2qWnoM3hZmACUBx4TVUXiMgArC76GOBV4A0RWQpsxJJJdoaGFXMB5McinR+LdH4s0vmxSJfrY1HgOtw555yLr8JT68k551woPFE455yLKmkTRWjlPwqgGI7FHSKyUETmisiXInJkIuKMh+yORcR6HUVERaTQ3hoZy7EQkc7B38YCEXk73jHGSwz/IzVFZKKIzAr+T9olIs6wichrIrJWROZnsVxE5NngOM0VkcxG9DlQbgfbDvOBNX7/DBwFlATmAPUzrHMj8FLwvCvwTqLjTuCxOAMoGzy/oSgfi2C9CsAUYCrQLNFxJ/Dvoi4wCzgkmP5bouNO4LEYCtwQPK8P/JLouEM6Fq2AJsD8LJa3A8YDApwMTItlu8l6RhFK+Y8CKttjoaoTVXVHMDkV67NSGMXydwHwMFY3bFc8g4uzWI7FtcDzqroJQFXXxjnGeInlWChQMXheCVgdx/jiRlWnYHeQZqUD8LqaqcDBIlIlu+0ma6LIrPxHtazWUdW9QFr5j8ImlmMRqSf2jaEwyvZYBKfSNVT103gGlgCx/F3UA+qJyDciMlVE2sYtuviK5Vg8CFwhIinAOOCW+ISWdHL6eQIUkBIeLjYicgXQDGid6FgSQUSKAU8C3RMcSrI4CLv8dDp2ljlFRBqq6uaERpUY3YDhqvqEiLTA+m8dr6r7Eh1YQZCsZxRe/iNdLMcCETkL6A9cqKq74xRbvGV3LCoAxwOTROQX7BrsmELaoB3L30UKMEZV96jqcmAJljgKm1iORU/gXQBV/Q4ojRUMLGpi+jzJKFkThZf/SJftsRCRE4GXsSRRWK9DQzbHQlW3qOphqlpLVWth7TUXqmqui6ElsVj+Rz7CziYQkcOwS1HL4hlknMRyLFYAbQBE5DgsURTF8VnHAFcFdz+dDGxR1d+ye1FSXnrS8Mp/FDgxHovBQHngvaA9f4WqXpiwoEMS47EoEmI8FhOAc0RkIZAK9FXVQnfWHeOxuBMYJiK3Yw3b3QvjF0sRGYl9OTgsaI95ACgBoKovYe0z7YClwA6gR0zbLYTHyjnnXD5K1ktPzjnnkoQnCuecc1F5onDOOReVJwrnnHNReaJwzjkXlScKl5REJFVEZkc8akVZd1s+7G+4iCwP9jUz6L2b0228IiL1g+f3Zlj2bV5jDLaTdlzmi8hYETk4m/UbF9ZKqS5+/PZYl5REZJuqls/vdaNsYzjwiaqOFpFzgCGq2igP28tzTNltV0RGAEtU9ZEo63fHKujenN+xuKLDzyhcgSAi5YOxNmaKyDwROaBqrIhUEZEpEd+4WwbzzxGR74LXvici2X2ATwHqBK+9I9jWfBG5LZhXTkQ+FZE5wfwuwfxJItJMRB4HygRxvBUs2xb8HCUi50fEPFxEOolIcREZLCI/BOMEXBfDYfmOoKCbiJwUvMdZIvKtiBwT9FIeAHQJYukSxP6aiHwfrJtZ9V3n9pfo+un+8EdmD6wn8ezg8SFWRaBisOwwrGdp2hnxtuDnnUD/4HlxrPbTYdgHf7lg/t3A/ZnsbzjQKXh+KTANaArMA8phPd8XACcCHYFhEa+tFPycRDD+RVpMEeukxXgxMCJ4XhKr5FkG6A3cF8wvBUwHamcS57aI9/ce0DaYrggcFDw/C3g/eN4d+L+I1z8KXBE8Pxir/1Qu0b9vfyT3IylLeDgH7FTVxmkTIlICeFREWgH7sG/SfwfWRLzmB+C1YN2PVHW2iLTGBqr5JihvUhL7Jp6ZwSJyH1YDqCdWG+hDVd0exPAB0BL4DHhCRAZhl6v+l4P3NR54RkRKAW2BKaq6M7jc1UhEOgXrVcIK+C3P8PoyIjI7eP+LgP9GrD9CROpiJSpKZLH/c4ALReSuYLo0UDPYlnOZ8kThCorLgcOBpqq6R6w6bOnIFVR1SpBIzgeGi8iTwCbgv6raLYZ99FXV0WkTItIms5VUdYnYuBftgIEi8qWqDojlTajqLhGZBJwLdMEG2QEbcewWVZ2QzSZ2qmpjESmL1Ta6CXgWG6xpoqpeHDT8T8ri9QJ0VNXFscTrHHgbhSs4KgFrgyRxBnDAuOBiY4X/rqrDgFewISGnAqeKSFqbQzkRqRfjPv8HXCQiZUWkHHbZ6H8iUhXYoapvYgUZMxt3eE9wZpOZd7BibGlnJ2Af+jekvUZE6gX7zJTaiIa3AndKepn9tHLR3SNW3YpdgkszAbhFgtMrscrDzkXlicIVFG8BzURkHnAV8GMm65wOzBGRWdi39WdUdR32wTlSROZil52OjWWHqjoTa7v4HmuzeEVVZwENge+DS0APAAMzeflQYG5aY3YGn2ODS32hNnQnWGJbCMwUkflY2fioZ/xBLHOxQXn+DTwWvPfI100E6qc1ZmNnHiWC2BYE085F5bfHOueci8rPKJxzzkXlicI551xUniicc85F5YnCOedcVJ4onHPOReWJwjnnXFSeKJxzzkX1/wFdxooQBECRAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCYueNHxlO5C",
        "outputId": "a05dc3c3-72e8-4665-afc6-85b7249591d9"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "preds = np.argmax(probs, axis = 1)\n",
        "print(classification_report(test_data.isRumor, preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      1.00      0.66       189\n",
            "           1       1.00      0.03      0.06       201\n",
            "\n",
            "    accuracy                           0.50       390\n",
            "   macro avg       0.75      0.51      0.36       390\n",
            "weighted avg       0.75      0.50      0.35       390\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9jeKNBykI_-"
      },
      "source": [
        "# Fine-tuning BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tplyZTEYkI2p"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel\n",
        "\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "import random\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wx6TKCN2kI_-"
      },
      "source": [
        "def evaluate_roc(probs, y_true):\n",
        "    \"\"\"\n",
        "    - Print AUC and accuracy on the test set\n",
        "    - Plot ROC\n",
        "    @params    probs (np.array): an array of predicted probabilities with shape (len(y_true), 2)\n",
        "    @params    y_true (np.array): an array of the true values with shape (len(y_true),)\n",
        "    \"\"\"\n",
        "    preds = probs[:, 1]\n",
        "    fpr, tpr, threshold = roc_curve(y_true, preds)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    print(f'AUC: {roc_auc:.4f}')\n",
        "\n",
        "    # Get accuracy over the test set\n",
        "    y_pred = np.where(preds >= 0.5, 1, 0)\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    print(f'Accuracy: {accuracy*100:.2f}%')\n",
        "\n",
        "    # Plot ROC AUC\n",
        "    plt.title('Receiver Operating Characteristic')\n",
        "    plt.plot(fpr, tpr, 'b', label='AUC = %0.2f' % roc_auc)\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.plot([0, 1], [0, 1], 'r--')\n",
        "    plt.xlim([0, 1])\n",
        "    plt.ylim([0, 1])\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def text_preprocessing(text):\n",
        "    \"\"\"\n",
        "    - Remove entity mentions (eg. '@united')\n",
        "    - Correct errors (eg. '&amp;' to '&')\n",
        "    @param    text (str): a string to be processed.\n",
        "    @return   text (Str): the processed string.\n",
        "    \"\"\"\n",
        "    # Remove '@name'\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'(@.*?)[\\s]', ' ', text)\n",
        "    text = re.sub(r\"(#)(\\S+)\", r'\\1 \\2', text)\n",
        "\n",
        "    text = re.sub(r\"http\\S+\", \"*\", text)  # http link -> '*'\n",
        "\n",
        "    # text = re.sub(r\"@\\S+\", \"@\", text)   # mention -> '@'\n",
        "    text = re.sub(r\"@[^\\s]+\", \"@\", text)   # mention -> '@'\n",
        "\n",
        "    # sent = re.sub(r\"(#)(\\S+)\", r'\\1 \\2', sent)\n",
        "    # sent = re.sub(r'([^\\s\\w@#\\*]|_)+', '', sent) # Erasing Special Characters\n",
        "\n",
        "    # Replace '&amp;' with '&'\n",
        "    text = re.sub(r'&amp;', '&', text)\n",
        "\n",
        "    # Remove trailing whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text\n",
        "\n",
        "# Create a function to tokenize a set of texts\n",
        "\n",
        "\n",
        "def preprocessing_for_bert(data):\n",
        "    \"\"\"Perform required preprocessing steps for pretrained BERT.\n",
        "    @param    data (np.array): Array of texts to be processed.\n",
        "    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
        "    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n",
        "                  tokens should be attended to by the model.\n",
        "    \"\"\"\n",
        "    # Create empty lists to store outputs (빈 리스트 2개 생성)\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    # For every sentence...\n",
        "    for sent in data:\n",
        "        # `encode_plus` will:\n",
        "        #    (1) Tokenize the sentence\n",
        "        #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n",
        "        #    (3) Truncate/Pad sentence to max length\n",
        "        #    (4) Map tokens to their IDs\n",
        "        #    (5) Create attention mask\n",
        "        #    (6) Return a dictionary of outputs\n",
        "        encoded_sent = tokenizer.encode_plus(\n",
        "            text=text_preprocessing(sent),  # Preprocess sentence\n",
        "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
        "            max_length=MAX_LEN,                  # Max length to truncate/pad\n",
        "            pad_to_max_length=True,         # Pad sentence to max length\n",
        "            # return_tensors='pt',           # Return PyTorch tensor\n",
        "            return_attention_mask=True      # Return attention mask\n",
        "        )\n",
        "\n",
        "        # Add the outputs to the lists (위의 빈 리스트에 상응하는 값 추가)\n",
        "        input_ids.append(encoded_sent.get('input_ids'))\n",
        "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
        "\n",
        "    # Convert lists to tensors (리스트들을 텐서화)\n",
        "    input_ids = torch.tensor(input_ids)\n",
        "    attention_masks = torch.tensor(attention_masks)\n",
        "\n",
        "    return input_ids, attention_masks\n",
        "\n",
        "# Create the BertClassfier class\n",
        "\n",
        "\n",
        "class BertClassifier(nn.Module):\n",
        "    \"\"\"Bert Model for Classification Tasks.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, freeze_bert=False):\n",
        "        \"\"\"\n",
        "        @param    bert: a BertModel object\n",
        "        @param    classifier: a torch.nn.Module classifier\n",
        "        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n",
        "        \"\"\"\n",
        "        super(BertClassifier, self).__init__()\n",
        "        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
        "        D_in, H, D_out = 768, 50, 2\n",
        "\n",
        "        # Instantiate BERT model\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        # Instantiate an one-layer feed-forward classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(D_in, H),\n",
        "            nn.ReLU(),\n",
        "            # nn.Dropout(0.5),\n",
        "            nn.Linear(H, D_out)\n",
        "        )\n",
        "\n",
        "        # Freeze the BERT model\n",
        "        if freeze_bert:\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        \"\"\"\n",
        "        Feed input to BERT and the classifier to compute logits.\n",
        "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
        "                      max_length)\n",
        "        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
        "                      information with shape (batch_size, max_length)\n",
        "        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
        "                      num_labels)\n",
        "        \"\"\"\n",
        "        # Feed input to BERT\n",
        "        outputs = self.bert(input_ids=input_ids,\n",
        "                            attention_mask=attention_mask)\n",
        "\n",
        "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
        "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
        "\n",
        "        # Feed input to classifier to compute logits\n",
        "        logits = self.classifier(last_hidden_state_cls)\n",
        "\n",
        "        return logits\n",
        "\n",
        "\n",
        "def initialize_model(epochs=4):\n",
        "    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n",
        "    \"\"\"\n",
        "    # Instantiate Bert Classifier\n",
        "    bert_classifier = BertClassifier(freeze_bert=False)\n",
        "\n",
        "    # Tell PyTorch to run the model on GPU\n",
        "    bert_classifier.to(device)\n",
        "\n",
        "    # Create the optimizer\n",
        "    optimizer = AdamW(bert_classifier.parameters(),\n",
        "                      lr=5e-5,    # Default learning rate\n",
        "                      eps=1e-8    # Default epsilon value\n",
        "                      )\n",
        "\n",
        "    # Total number of training steps\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Set up the learning rate scheduler\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                                num_warmup_steps=0,  # Default value\n",
        "                                                num_training_steps=total_steps)\n",
        "    return bert_classifier, optimizer, scheduler, criterion\n",
        "\n",
        "\n",
        "def set_seed(seed_value=42):\n",
        "    \"\"\"Set seed for reproducibility.\n",
        "    \"\"\"\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    torch.cuda.manual_seed_all(seed_value)\n",
        "\n",
        "\n",
        "def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n",
        "    \"\"\"Train the BertClassifier model.\n",
        "    \"\"\"\n",
        "    # Start training loop\n",
        "    print(\"Start training...\\n\")\n",
        "    for epoch_i in range(epochs):\n",
        "        # =======================================\n",
        "        #               Training\n",
        "        # =======================================\n",
        "        # Print the header of the result table\n",
        "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
        "        print(\"-\"*70)\n",
        "\n",
        "        # Measure the elapsed time of each epoch\n",
        "        t0_epoch, t0_batch = time.time(), time.time()\n",
        "\n",
        "        # Reset tracking variables at the beginning of each epoch\n",
        "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
        "\n",
        "        # Put the model into the training mode\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            batch_counts += 1\n",
        "            # Load batch to GPU\n",
        "            b_input_ids, b_attn_mask, b_labels = tuple(\n",
        "                t.to(device) for t in batch)\n",
        "\n",
        "            # Zero out any previously calculated gradients\n",
        "            model.zero_grad()\n",
        "\n",
        "            # Perform a forward pass. This will return logits.\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "            # Compute loss and accumulate the loss values\n",
        "            loss = loss_fn(logits, b_labels)\n",
        "            batch_loss += loss.item()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and the learning rate\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            # Print the loss values and time elapsed for every 20 batches\n",
        "            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
        "                # Calculate time elapsed for 20 batches\n",
        "                time_elapsed = time.time() - t0_batch\n",
        "\n",
        "                # Print training results\n",
        "                print(\n",
        "                    f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
        "\n",
        "                # Reset batch tracking variables\n",
        "                batch_loss, batch_counts = 0, 0\n",
        "                t0_batch = time.time()\n",
        "\n",
        "        # Calculate the average loss over the entire training data\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "        print(\"-\"*70)\n",
        "        # =======================================\n",
        "        #               Evaluation\n",
        "        # =======================================\n",
        "        if evaluation == True:\n",
        "            # After the completion of each training epoch, measure the model's performance\n",
        "            # on our validation set.\n",
        "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
        "\n",
        "            # Print performance over the entire training data\n",
        "            time_elapsed = time.time() - t0_epoch\n",
        "\n",
        "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
        "            print(\"-\"*70)\n",
        "        print(\"\\n\")\n",
        "\n",
        "    print(\"Training complete!\")\n",
        "\n",
        "\n",
        "def evaluate(model, val_dataloader):\n",
        "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
        "    on our validation set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    val_accuracy = []\n",
        "    val_loss = []\n",
        "\n",
        "    # For each batch in our validation set...\n",
        "    for batch in val_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(logits, b_labels)\n",
        "        val_loss.append(loss.item())\n",
        "\n",
        "        # Get the predictions\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "\n",
        "        # Calculate the accuracy rate\n",
        "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
        "        val_accuracy.append(accuracy)\n",
        "\n",
        "    # Compute the average accuracy and loss over the validation set.\n",
        "    val_loss = np.mean(val_loss)\n",
        "    val_accuracy = np.mean(val_accuracy)\n",
        "\n",
        "    return val_loss, val_accuracy\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJjwums-kI2t"
      },
      "source": [
        "## Pre-Proecess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwH4PQ90kI2v"
      },
      "source": [
        "raw_text = pd.read_csv('./data/_PHEME_text.csv')\n",
        "y = pd.read_csv('./data/_PHEME_target.csv')\n",
        "data = pd.concat([raw_text.text, y], axis=1).reset_index(drop=True)\n",
        "val = pd.read_csv('data/_PHEMEext_text.csv')\n",
        "\n",
        "X_train = data.text.values\n",
        "y_train = data.target.values\n",
        "\n",
        "X_val = val.drop(['Event'],axis=1).text.values\n",
        "y_val = val.target.values\n",
        "\n",
        "rhi_data = pd.read_csv('data/_RHI_text.csv')\n",
        "rhi_y = pd.read_csv('data/_RHI_text.csv')\n",
        "\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# # X_train, X_val, y_train, y_val =\\\n",
        "# #     train_test_split(X, y, test_size=0.1, random_state=2020)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHN2kh2rkI_-",
        "outputId": "50916f5b-b215-42db-f2ae-669afd37068a"
      },
      "source": [
        "# Print sentence 0\n",
        "print('Original: ', X_val[0])\n",
        "print('Processed: ', text_preprocessing(X_val[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  Micheal Essien denying the Ebola rumours like https://t.co/H2E1TAzeha\n",
            "Processed:  micheal essien denying the ebola rumours like *\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65,
          "referenced_widgets": [
            "1bd1e9fe81934cf3885154196e620c03",
            "bd458a99a85e4a13afd1cf36b0a57ef7",
            "f954f9c5e5954c2bb96b5993a9395109",
            "ce478aa49888428c8b784e7389e191f4",
            "0660f1c2cada41d3bdfe2589d7184b56",
            "0c3cc67272e24e0c807af12b592c3a55",
            "f228d1ac81f6413a997d164c52f2ce02",
            "930e5993b2fb4a07943e2d0006d54dba"
          ]
        },
        "id": "b_elwoqWkI_-",
        "outputId": "7e17b2ef-50e3-43e5-c787-a80ad06ad132"
      },
      "source": [
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1bd1e9fe81934cf3885154196e620c03",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeUcrmthkI__",
        "outputId": "636bd926-dfb1-4240-9a4d-0ad1d58715e2"
      },
      "source": [
        "# Concatenate train data and test data\n",
        "all_tweets = np.concatenate([data.text.values, test_data.text.values])\n",
        "\n",
        "# Encode our concatenated data\n",
        "encoded_tweets = [tokenizer.encode(sent, add_special_tokens=True) for sent in all_tweets]\n",
        "\n",
        "# Find the maximum length\n",
        "max_len = max([len(sent) for sent in encoded_tweets])\n",
        "print('Max length: ', max_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max length:  69\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPdV4V0QkJAA",
        "outputId": "a11ef879-a82e-437b-ff09-72ab2fdf897a"
      },
      "source": [
        "# Specify `MAX_LEN`\n",
        "MAX_LEN = 64\n",
        "\n",
        "# # Print sentence 0 and its encoded token ids\n",
        "# token_ids = list(preprocessing_for_bert([X[0]])[0].squeeze().numpy())\n",
        "# print('Original: ', X[0])\n",
        "# print('\\nToken IDs: ', token_ids)\n",
        "\n",
        "# Run function `preprocessing_for_bert` on the train set and the validation set\n",
        "print('\\nTokenizing data...')\n",
        "train_inputs, train_masks = preprocessing_for_bert(X_train)\n",
        "val_inputs, val_masks = preprocessing_for_bert(X_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Tokenizing data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2155: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7hatUZskJAA"
      },
      "source": [
        "# Convert other data types to torch.Tensor\n",
        "train_labels = torch.tensor(y_train)\n",
        "val_labels = torch.tensor(y_val)\n",
        "\n",
        "# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rIFQkBukI2w"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnC8COuokJAB"
      },
      "source": [
        "set_seed(42)    # Set seed for reproducibility\n",
        "bert_classifier, optimizer, scheduler, loss_fn = initialize_model(epochs=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lMzlYbokJAC",
        "outputId": "16455e97-7a49-4940-d596-00e12c50fffd"
      },
      "source": [
        "train(bert_classifier, train_dataloader, val_dataloader, epochs=4, evaluation=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start training...\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   1    |   20    |   0.545895   |     -      |     -     |   13.60  \n",
            "   1    |   40    |   0.431758   |     -      |     -     |   12.85  \n",
            "   1    |   60    |   0.419819   |     -      |     -     |   12.92  \n",
            "   1    |   80    |   0.408936   |     -      |     -     |   12.91  \n",
            "   1    |   100   |   0.364633   |     -      |     -     |   12.93  \n",
            "   1    |   120   |   0.350773   |     -      |     -     |   12.95  \n",
            "   1    |   140   |   0.348678   |     -      |     -     |   12.96  \n",
            "   1    |   160   |   0.342240   |     -      |     -     |   12.95  \n",
            "   1    |   180   |   0.320228   |     -      |     -     |   12.97  \n",
            "   1    |   181   |   0.209871   |     -      |     -     |   0.29   \n",
            "----------------------------------------------------------------------\n",
            "   1    |    -    |   0.392390   |  0.885340  |   46.80   |  120.61  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   2    |   20    |   0.227295   |     -      |     -     |   13.57  \n",
            "   2    |   40    |   0.247884   |     -      |     -     |   12.95  \n",
            "   2    |   60    |   0.231736   |     -      |     -     |   12.95  \n",
            "   2    |   80    |   0.240648   |     -      |     -     |   12.96  \n",
            "   2    |   100   |   0.185628   |     -      |     -     |   12.95  \n",
            "   2    |   120   |   0.247057   |     -      |     -     |   12.95  \n",
            "   2    |   140   |   0.217445   |     -      |     -     |   12.95  \n",
            "   2    |   160   |   0.190913   |     -      |     -     |   12.95  \n",
            "   2    |   180   |   0.194698   |     -      |     -     |   12.96  \n",
            "   2    |   181   |   0.285361   |     -      |     -     |   0.28   \n",
            "----------------------------------------------------------------------\n",
            "   2    |    -    |   0.220762   |  2.083310  |   35.35   |  120.78  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   3    |   20    |   0.122823   |     -      |     -     |   13.58  \n",
            "   3    |   40    |   0.121248   |     -      |     -     |   12.92  \n",
            "   3    |   60    |   0.152879   |     -      |     -     |   12.93  \n",
            "   3    |   80    |   0.098159   |     -      |     -     |   12.91  \n",
            "   3    |   100   |   0.120083   |     -      |     -     |   12.93  \n",
            "   3    |   120   |   0.076811   |     -      |     -     |   12.94  \n",
            "   3    |   140   |   0.105630   |     -      |     -     |   12.92  \n",
            "   3    |   160   |   0.120352   |     -      |     -     |   12.92  \n",
            "   3    |   180   |   0.097088   |     -      |     -     |   12.94  \n",
            "   3    |   181   |   0.076236   |     -      |     -     |   0.28   \n",
            "----------------------------------------------------------------------\n",
            "   3    |    -    |   0.112640   |  2.375853  |   40.62   |  120.57  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   4    |   20    |   0.072653   |     -      |     -     |   13.56  \n",
            "   4    |   40    |   0.105584   |     -      |     -     |   12.91  \n",
            "   4    |   60    |   0.038721   |     -      |     -     |   12.86  \n",
            "   4    |   80    |   0.079732   |     -      |     -     |   12.90  \n",
            "   4    |   100   |   0.050438   |     -      |     -     |   12.90  \n",
            "   4    |   120   |   0.053360   |     -      |     -     |   12.88  \n",
            "   4    |   140   |   0.065261   |     -      |     -     |   12.93  \n",
            "   4    |   160   |   0.058267   |     -      |     -     |   12.93  \n",
            "   4    |   180   |   0.056957   |     -      |     -     |   12.88  \n",
            "   4    |   181   |   0.396380   |     -      |     -     |   0.29   \n",
            "----------------------------------------------------------------------\n",
            "   4    |    -    |   0.066420   |  2.963038  |   37.70   |  120.33  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiESwlsRkJAC"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def bert_predict(model, test_dataloader):\n",
        "    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities\n",
        "    on the test set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "\n",
        "    all_logits = []\n",
        "\n",
        "    # For each batch in our test set...\n",
        "    for batch in test_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask = tuple(t.to(device) for t in batch)[:2]\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "        all_logits.append(logits)\n",
        "    \n",
        "    # Concatenate logits from each batch\n",
        "    all_logits = torch.cat(all_logits, dim=0)\n",
        "\n",
        "    # Apply softmax to calculate probabilities\n",
        "    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n",
        "\n",
        "    return probs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "POlisyX_kJAC",
        "outputId": "86f2cd35-b976-481b-dfb1-74687ce66d53"
      },
      "source": [
        "# Compute predicted probabilities on the test set\n",
        "probs = bert_predict(bert_classifier, val_dataloader)\n",
        "\n",
        "# Evaluate the Bert classifier\n",
        "evaluate_roc(probs, y_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC: 0.7720\n",
            "Accuracy: 34.23%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORseUrD3kJAC"
      },
      "source": [
        "torch.save(bert_classifier.state_dict(), './Model/BERT_raw_to_fine_tune_ord.pt')\n",
        "# torch.save(bert_classifier.state_dict(), './BERT_raw_to_fine_tune_test.pt')\n",
        "# torch.save(model.state_dict, 'model.pt') # saving state dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmCy5mzZkI2w"
      },
      "source": [
        "## Training (full)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGnU5iiokJAC",
        "outputId": "9deeaa79-ac83-4dbb-c632-64ac737a1b5d"
      },
      "source": [
        "# Concatenate the train set and the validation set\n",
        "full_train_data = torch.utils.data.ConcatDataset([train_data, val_data])\n",
        "full_train_sampler = RandomSampler(full_train_data)\n",
        "full_train_dataloader = DataLoader(full_train_data, sampler=full_train_sampler, batch_size=32)\n",
        "\n",
        "# Train the Bert Classifier on the entire training data\n",
        "set_seed(42)\n",
        "bert_classifier, optimizer, scheduler = initialize_model(epochs=2)\n",
        "train(bert_classifier, full_train_dataloader, epochs=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start training...\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   1    |   20    |   0.519470   |     -      |     -     |   8.42   \n",
            "   1    |   40    |   0.458738   |     -      |     -     |   8.27   \n",
            "   1    |   60    |   0.411981   |     -      |     -     |   8.16   \n",
            "   1    |   80    |   0.388299   |     -      |     -     |   7.95   \n",
            "   1    |   100   |   0.378233   |     -      |     -     |   7.75   \n",
            "   1    |   120   |   0.321618   |     -      |     -     |   7.62   \n",
            "   1    |   140   |   0.334600   |     -      |     -     |   7.57   \n",
            "   1    |   160   |   0.355007   |     -      |     -     |   7.52   \n",
            "   1    |   180   |   0.343738   |     -      |     -     |   7.55   \n",
            "   1    |   181   |   0.211648   |     -      |     -     |   0.14   \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   2    |   20    |   0.214941   |     -      |     -     |   7.98   \n",
            "   2    |   40    |   0.221853   |     -      |     -     |   7.71   \n",
            "   2    |   60    |   0.216489   |     -      |     -     |   7.76   \n",
            "   2    |   80    |   0.241423   |     -      |     -     |   7.82   \n",
            "   2    |   100   |   0.216051   |     -      |     -     |   7.84   \n",
            "   2    |   120   |   0.194518   |     -      |     -     |   7.83   \n",
            "   2    |   140   |   0.224164   |     -      |     -     |   7.81   \n",
            "   2    |   160   |   0.193176   |     -      |     -     |   7.74   \n",
            "   2    |   180   |   0.231373   |     -      |     -     |   7.72   \n",
            "   2    |   181   |   0.057531   |     -      |     -     |   0.14   \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7YdsbbKkI2w"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtvXnLkXUYAT",
        "outputId": "4f27822d-d09d-48b6-aa4b-50aa38640e26"
      },
      "source": [
        "PATH = './Model/BERT_raw_to_fine_tune_ord.pt'\n",
        "# bn_state_dict = torch.load('./BERT_raw_to_fine_tune_ord.pt')\n",
        "# bert_classifier.load_state_dict(bn_state_dict)\n",
        "bert_classifier.load_state_dict(torch.load(PATH))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbGz7NFrkJAC",
        "outputId": "0e45c9fa-f670-4af1-d3ca-b644022a292f"
      },
      "source": [
        "#  Run `preprocessing_for_bert` on the test set\n",
        "print('Tokenizing data...')\n",
        "test_inputs, test_masks = preprocessing_for_bert(test_data.text)\n",
        "\n",
        "# Create the DataLoader for our test set\n",
        "test_dataset = TensorDataset(test_inputs, test_masks)\n",
        "test_sampler = SequentialSampler(test_dataset)\n",
        "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenizing data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2155: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHgcr79RkJAC",
        "outputId": "db2fa9a0-d788-466c-b4b3-750278f6e15a"
      },
      "source": [
        "# Compute predicted probabilities on the test set\n",
        "probs = bert_predict(bert_classifier, test_dataloader)\n",
        "\n",
        "# Get predictions from the probabilities\n",
        "threshold = 0.5\n",
        "preds = np.where(probs[:, 1] > threshold, 1, 0)\n",
        "\n",
        "# Number of tweets predicted non-negative\n",
        "print(\"Number of tweets predicted as Rumor: \", preds.sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of tweets predicted as Rumor:  54\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "X9dcv6x5cyQd",
        "outputId": "aca38ff3-5101-4bbb-d0ec-a738d17f65ba"
      },
      "source": [
        "pd.DataFrame(probs)#.idxmax(axis=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.925041</td>\n",
              "      <td>0.074959</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.994930</td>\n",
              "      <td>0.005070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.980860</td>\n",
              "      <td>0.019140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.952689</td>\n",
              "      <td>0.047311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.967151</td>\n",
              "      <td>0.032849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>480</th>\n",
              "      <td>0.870599</td>\n",
              "      <td>0.129401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>481</th>\n",
              "      <td>0.996000</td>\n",
              "      <td>0.004000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>482</th>\n",
              "      <td>0.994768</td>\n",
              "      <td>0.005232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>483</th>\n",
              "      <td>0.996281</td>\n",
              "      <td>0.003719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>484</th>\n",
              "      <td>0.997700</td>\n",
              "      <td>0.002300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>485 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            0         1\n",
              "0    0.925041  0.074959\n",
              "1    0.994930  0.005070\n",
              "2    0.980860  0.019140\n",
              "3    0.952689  0.047311\n",
              "4    0.967151  0.032849\n",
              "..        ...       ...\n",
              "480  0.870599  0.129401\n",
              "481  0.996000  0.004000\n",
              "482  0.994768  0.005232\n",
              "483  0.996281  0.003719\n",
              "484  0.997700  0.002300\n",
              "\n",
              "[485 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Fv_8oE2fmJT",
        "outputId": "71da4a04-3e04-4271-ed71-238e332a5ad5"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "preds = np.argmax(probs, axis = 1)\n",
        "print(classification_report(test_data.target, preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.26      0.98      0.42       116\n",
            "           1       0.96      0.14      0.25       369\n",
            "\n",
            "    accuracy                           0.34       485\n",
            "   macro avg       0.61      0.56      0.33       485\n",
            "weighted avg       0.80      0.34      0.29       485\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        },
        "id": "vtUsm5tDkJAC",
        "outputId": "d1938b91-f9e0-4b5f-d957-a6f8ab845a92"
      },
      "source": [
        "output = test_data[preds==1]\n",
        "output\n",
        "# list(output.text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>isRumor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Family claims #CorneliusGurlitt was mentally u...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>The plot thickens: #Gurlitt's cousin claims Mu...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>Munich District Court has confirmed the applic...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134</th>\n",
              "      <td>Munich District Court has confirmed the applic...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>Unconfirmed reports claim that Michael Essien ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>AC Milan have denied reports that midfielder M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>Breaking news: Ghana international and AC Mila...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>BREAKING: Unconfirmed reports claim AC Milan m...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>AC Milan midfielder Michael Essien has been di...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151</th>\n",
              "      <td>AC Milan have confirmed that the reports about...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157</th>\n",
              "      <td>Putin \"disappearance\" Rumor: He Is In Switzerl...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>Well, this might explain everything: Kabayeva ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>Swiss Paper #Putin missing due to daughter bor...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>And you thought it was Putin's back? Alina Kab...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>Who's the daddy? One explanation for #Putin's ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>Reports claim that the military may be organiz...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190</th>\n",
              "      <td>\"Putin's continued absence suggests a palace c...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194</th>\n",
              "      <td>Rumor is that Primakov orchestrated coup again...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>208</th>\n",
              "      <td>RT @L0gg0l: Rumors in Switzerland: #Putin abse...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>210</th>\n",
              "      <td>Coup scenario:Ivanov killed Nemtsov,blamed it ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>218</th>\n",
              "      <td>According to this article http://t.co/pWZaRxHy...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223</th>\n",
              "      <td>No Russian leader as charismatic as Putin exce...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228</th>\n",
              "      <td>Maybe Putin has just been on paternity leave? ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>232</th>\n",
              "      <td>NEWEST #Putin rumour, his girlfriend just gave...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>247</th>\n",
              "      <td>Rumour: #Ivanov to take over for #Putin in #Ru...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>252</th>\n",
              "      <td>Rumours emerging that a coup has taken place i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253</th>\n",
              "      <td>Coup? RT @jimgeraghty: Rumors all Russian mili...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>264</th>\n",
              "      <td>Фейк?! или #Путина #убили! According to report...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>275</th>\n",
              "      <td>Reports claim Putin disappeared due to impendi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>This man was seen in Grozny yesterday evening ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>372</th>\n",
              "      <td>#PutinDead Putin unfortunately not dead, altho...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text  isRumor\n",
              "7    Family claims #CorneliusGurlitt was mentally u...        1\n",
              "110  The plot thickens: #Gurlitt's cousin claims Mu...        0\n",
              "113  Munich District Court has confirmed the applic...        0\n",
              "134  Munich District Court has confirmed the applic...        0\n",
              "144  Unconfirmed reports claim that Michael Essien ...        1\n",
              "147  AC Milan have denied reports that midfielder M...        1\n",
              "148  Breaking news: Ghana international and AC Mila...        1\n",
              "149  BREAKING: Unconfirmed reports claim AC Milan m...        1\n",
              "150  AC Milan midfielder Michael Essien has been di...        1\n",
              "151  AC Milan have confirmed that the reports about...        1\n",
              "157  Putin \"disappearance\" Rumor: He Is In Switzerl...        1\n",
              "165  Well, this might explain everything: Kabayeva ...        1\n",
              "167  Swiss Paper #Putin missing due to daughter bor...        1\n",
              "171  And you thought it was Putin's back? Alina Kab...        1\n",
              "173  Who's the daddy? One explanation for #Putin's ...        1\n",
              "175  Reports claim that the military may be organiz...        1\n",
              "190  \"Putin's continued absence suggests a palace c...        1\n",
              "194  Rumor is that Primakov orchestrated coup again...        1\n",
              "208  RT @L0gg0l: Rumors in Switzerland: #Putin abse...        1\n",
              "210  Coup scenario:Ivanov killed Nemtsov,blamed it ...        1\n",
              "218  According to this article http://t.co/pWZaRxHy...        1\n",
              "223  No Russian leader as charismatic as Putin exce...        1\n",
              "228  Maybe Putin has just been on paternity leave? ...        1\n",
              "232  NEWEST #Putin rumour, his girlfriend just gave...        1\n",
              "247  Rumour: #Ivanov to take over for #Putin in #Ru...        1\n",
              "252  Rumours emerging that a coup has taken place i...        1\n",
              "253  Coup? RT @jimgeraghty: Rumors all Russian mili...        1\n",
              "264  Фейк?! или #Путина #убили! According to report...        1\n",
              "275  Reports claim Putin disappeared due to impendi...        1\n",
              "298  This man was seen in Grozny yesterday evening ...        0\n",
              "372  #PutinDead Putin unfortunately not dead, altho...        0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ggmjfp2ZVeV-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whaUxM0Gr6dG"
      },
      "source": [
        "## Testing (RHI)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mx97JzRr_lD"
      },
      "source": [
        "# raw_text = pd.read_csv('./data/_RHI_text.csv')\n",
        "# # y = pd.read_csv('./data/_RHI_target.csv')\n",
        "# data = pd.concat([raw_text.text, y], axis=1).reset_index(drop=True)\n",
        "# val = pd.read_csv('data/_PHEMEext_text.csv')\n",
        "\n",
        "# X_train = data.text.values\n",
        "# y_train = data.target.values\n",
        "\n",
        "# X_val = val.drop(['Event'],axis=1).text.values\n",
        "# y_val = val.target.values\n",
        "\n",
        "rhi_data = pd.read_csv('data/_RHI_text.csv')\n",
        "rhi_y = pd.read_csv('data/_RHI_text.csv')\n",
        "\n",
        "X_test = rhi_data.text.values\n",
        "y_test = rhi_y.isRumor.values\n",
        "\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# # X_train, X_val, y_train, y_val =\\\n",
        "# #     train_test_split(X, y, test_size=0.1, random_state=2020)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PltGfRMr6dH",
        "outputId": "6ff4c2a5-71d5-41a8-bf69-e11f9ef05f84"
      },
      "source": [
        "PATH = './Model/BERT_raw_to_fine_tune_ord.pt'\n",
        "# bn_state_dict = torch.load('./BERT_raw_to_fine_tune_ord.pt')\n",
        "# bert_classifier.load_state_dict(bn_state_dict)\n",
        "bert_classifier.load_state_dict(torch.load(PATH))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExKeyBFfr6dI",
        "outputId": "5b12ea54-d51c-4ad7-eb76-1005665f443b"
      },
      "source": [
        "#  Run `preprocessing_for_bert` on the test set\n",
        "print('Tokenizing data...')\n",
        "test_inputs, test_masks = preprocessing_for_bert(X_test)\n",
        "\n",
        "# Create the DataLoader for our test set\n",
        "test_dataset = TensorDataset(test_inputs, test_masks)\n",
        "test_sampler = SequentialSampler(test_dataset)\n",
        "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=32)\n",
        "\n",
        "# Convert other data types to torch.Tensor\n",
        "test_labels = torch.tensor(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenizing data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2155: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKgdcM3er6dI",
        "outputId": "677aa6d6-0d72-4c30-db66-86eea28c40fe"
      },
      "source": [
        "# Compute predicted probabilities on the test set\n",
        "probs = bert_predict(bert_classifier, test_dataloader)\n",
        "\n",
        "# Get predictions from the probabilities\n",
        "threshold = 0.5\n",
        "preds = np.where(probs[:, 1] > threshold, 1, 0)\n",
        "\n",
        "# Number of tweets predicted non-negative\n",
        "print(\"Number of tweets predicted as Rumor: \", preds.sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of tweets predicted as Rumor:  91\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "jlQV-70er6dI",
        "outputId": "871cb1b6-b7d5-4085-b7dc-803b5876147d"
      },
      "source": [
        "pd.DataFrame(probs)#.idxmax(axis=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.483309</td>\n",
              "      <td>0.516691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.997296</td>\n",
              "      <td>0.002704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.997502</td>\n",
              "      <td>0.002498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.927679</td>\n",
              "      <td>0.072321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.997721</td>\n",
              "      <td>0.002279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5222</th>\n",
              "      <td>0.997374</td>\n",
              "      <td>0.002626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5223</th>\n",
              "      <td>0.998007</td>\n",
              "      <td>0.001993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5224</th>\n",
              "      <td>0.996135</td>\n",
              "      <td>0.003865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5225</th>\n",
              "      <td>0.993574</td>\n",
              "      <td>0.006426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5226</th>\n",
              "      <td>0.996873</td>\n",
              "      <td>0.003127</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5227 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             0         1\n",
              "0     0.483309  0.516691\n",
              "1     0.997296  0.002704\n",
              "2     0.997502  0.002498\n",
              "3     0.927679  0.072321\n",
              "4     0.997721  0.002279\n",
              "...        ...       ...\n",
              "5222  0.997374  0.002626\n",
              "5223  0.998007  0.001993\n",
              "5224  0.996135  0.003865\n",
              "5225  0.993574  0.006426\n",
              "5226  0.996873  0.003127\n",
              "\n",
              "[5227 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "fXQYp8rar6dI",
        "outputId": "c89d7715-2a3e-4bc4-8ecf-a4ce40ff22b5"
      },
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "preds = np.argmax(probs, axis = 1)\n",
        "print(classification_report(y_test, preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-26d5925c3c70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkXv5vrcr6dJ",
        "outputId": "1fd3d2e5-4d6d-4107-be15-2c3f1b5bbb63"
      },
      "source": [
        "output = y_test[preds==0].sum()\n",
        "output\n",
        "# list(output.text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4682"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "uJ_f_mK0yjkA",
        "outputId": "d62921bf-1b6a-4bf0-a215-d41bfd11922d"
      },
      "source": [
        "test_data[preds==0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-0370dfaf5e11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2895\u001b[0m         \u001b[0;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_bool_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;31m# We are left with two options: a single key, and a collection of keys,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_bool_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2942\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2943\u001b[0m             raise ValueError(\n\u001b[0;32m-> 2944\u001b[0;31m                 \u001b[0;34mf\"Item wrong length {len(key)} instead of {len(self.index)}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2945\u001b[0m             )\n\u001b[1;32m   2946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Item wrong length 5227 instead of 485."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPq-JIFL_xOs"
      },
      "source": [
        "# Training + Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQqcD-TCAHiM"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "480XRXKaDIux"
      },
      "source": [
        "import os\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "%matplotlib inline\n",
        "from transformers import BertTokenizer\n",
        "from sklearn.metrics import accuracy_score, roc_curve, auc, classification_report, f1_score\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel\n",
        "\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "import random\n",
        "import time\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ss5N4L0pHj4o",
        "outputId": "312b556b-0851-486c-9a92-306eca337395"
      },
      "source": [
        "if torch.cuda.is_available():       \n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "Device name: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzqRcitCr6dJ"
      },
      "source": [
        "def evaluate_roc(probs, y_true):\n",
        "    \"\"\"\n",
        "    - Print AUC and accuracy on the test set\n",
        "    - Plot ROC\n",
        "    @params    probs (np.array): an array of predicted probabilities with shape (len(y_true), 2)\n",
        "    @params    y_true (np.array): an array of the true values with shape (len(y_true),)\n",
        "    \"\"\"\n",
        "    preds = probs[:, 1]\n",
        "    fpr, tpr, threshold = roc_curve(y_true, preds)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    print(f'AUC: {roc_auc:.4f}')\n",
        "\n",
        "    # Get accuracy over the test set\n",
        "    y_pred = np.where(preds >= 0.5, 1, 0)\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    print(f'Accuracy: {accuracy*100:.2f}%')\n",
        "\n",
        "    # Plot ROC AUC\n",
        "    plt.title('Receiver Operating Characteristic')\n",
        "    plt.plot(fpr, tpr, 'b', label='AUC = %0.2f' % roc_auc)\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.plot([0, 1], [0, 1], 'r--')\n",
        "    plt.xlim([0, 1])\n",
        "    plt.ylim([0, 1])\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def text_preprocessing(text):\n",
        "    \"\"\"\n",
        "    - Remove entity mentions (eg. '@united')\n",
        "    - Correct errors (eg. '&amp;' to '&')\n",
        "    @param    text (str): a string to be processed.\n",
        "    @return   text (Str): the processed string.\n",
        "    \"\"\"\n",
        "    # Remove '@name'\n",
        "    text = text.lower()\n",
        "    # text = re.sub(r'(@.*?)[\\s]', ' ', text)\n",
        "    # text = re.sub(r\"(#)(\\S+)\", r'\\1 \\2', text)\n",
        "\n",
        "    text = re.sub(r\"http\\S+\", \"*\", text)  # http link -> '*'\n",
        "\n",
        "    # text = re.sub(r\"@\\S+\", \"@\", text)   # mention -> '@'\n",
        "    # text = re.sub(r\"@[^\\s]+\", \"@\", text)   # mention -> '@'\n",
        "\n",
        "    # sent = re.sub(r\"(#)(\\S+)\", r'\\1 \\2', sent)\n",
        "    # sent = re.sub(r'([^\\s\\w@#\\*]|_)+', '', sent) # Erasing Special Characters\n",
        "\n",
        "    # Replace '&amp;' with '&'\n",
        "    text = re.sub(r'&amp;', '&', text)\n",
        "\n",
        "    # Remove trailing whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text\n",
        "\n",
        "# Create a function to tokenize a set of texts\n",
        "\n",
        "\n",
        "def preprocessing_for_bert(data):\n",
        "    \"\"\"Perform required preprocessing steps for pretrained BERT.\n",
        "    @param    data (np.array): Array of texts to be processed.\n",
        "    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
        "    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n",
        "                  tokens should be attended to by the model.\n",
        "    \"\"\"\n",
        "    # Create empty lists to store outputs (빈 리스트 2개 생성)\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    # For every sentence...\n",
        "    for sent in data:\n",
        "        # `encode_plus` will:\n",
        "        #    (1) Tokenize the sentence\n",
        "        #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n",
        "        #    (3) Truncate/Pad sentence to max length\n",
        "        #    (4) Map tokens to their IDs\n",
        "        #    (5) Create attention mask\n",
        "        #    (6) Return a dictionary of outputs\n",
        "        encoded_sent = tokenizer.encode_plus(\n",
        "            text=text_preprocessing(sent),  # Preprocess sentence\n",
        "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
        "            # max_length=MAX_LEN,                  # Max length to truncate/pad\n",
        "            pad_to_max_length=True,         # Pad sentence to max length\n",
        "            # return_tensors='pt',           # Return PyTorch tensor\n",
        "            return_attention_mask=True,      # Return attention mask\n",
        "\n",
        "            # max_length=True,                  # Max length to truncate/pad\n",
        "            padding='max_length'\n",
        "        )\n",
        "\n",
        "        # Add the outputs to the lists (위의 빈 리스트에 상응하는 값 추가)\n",
        "        input_ids.append(encoded_sent.get('input_ids'))\n",
        "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
        "\n",
        "    # Convert lists to tensors (리스트들을 텐서화)\n",
        "    input_ids = torch.tensor(input_ids)\n",
        "    attention_masks = torch.tensor(attention_masks)\n",
        "\n",
        "    return input_ids, attention_masks\n",
        "\n",
        "# Create the BertClassfier class\n",
        "\n",
        "\n",
        "class BertClassifier(nn.Module):\n",
        "    \"\"\"Bert Model for Classification Tasks.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, freeze_bert=False):\n",
        "        \"\"\"\n",
        "        @param    bert: a BertModel object\n",
        "        @param    classifier: a torch.nn.Module classifier\n",
        "        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n",
        "        \"\"\"\n",
        "        super(BertClassifier, self).__init__()\n",
        "        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
        "        D_in, H, D_out = 768, 50, 2\n",
        "\n",
        "        # Instantiate BERT model\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        # Instantiate an one-layer feed-forward classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(D_in, H),\n",
        "            nn.ReLU(),\n",
        "            # nn.Dropout(0.5),\n",
        "            nn.Linear(H, D_out)\n",
        "        )\n",
        "\n",
        "        # Freeze the BERT model\n",
        "        if freeze_bert:\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        \"\"\"\n",
        "        Feed input to BERT and the classifier to compute logits.\n",
        "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
        "                      max_length)\n",
        "        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
        "                      information with shape (batch_size, max_length)\n",
        "        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
        "                      num_labels)\n",
        "        \"\"\"\n",
        "        # Feed input to BERT\n",
        "        outputs = self.bert(input_ids=input_ids,\n",
        "                            attention_mask=attention_mask)\n",
        "\n",
        "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
        "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
        "\n",
        "        # Feed input to classifier to compute logits\n",
        "        logits = self.classifier(last_hidden_state_cls)\n",
        "\n",
        "        return logits\n",
        "\n",
        "\n",
        "def initialize_model(epochs=4):\n",
        "    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n",
        "    \"\"\"\n",
        "    # Instantiate Bert Classifier\n",
        "    bert_classifier = BertClassifier(freeze_bert=False)\n",
        "\n",
        "    # Tell PyTorch to run the model on GPU\n",
        "    bert_classifier.to(device)\n",
        "\n",
        "    # Create the optimizer\n",
        "    optimizer = AdamW(bert_classifier.parameters(),\n",
        "                      lr=5e-5,    # Default learning rate\n",
        "                      eps=1e-8    # Default epsilon value\n",
        "                      )\n",
        "\n",
        "    # Total number of training steps\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Set up the learning rate scheduler\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                                num_warmup_steps=0,  # Default value\n",
        "                                                num_training_steps=total_steps)\n",
        "    return bert_classifier, optimizer, scheduler, criterion\n",
        "\n",
        "\n",
        "def set_seed(seed_value=42):\n",
        "    \"\"\"Set seed for reproducibility.\n",
        "    \"\"\"\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    torch.cuda.manual_seed_all(seed_value)\n",
        "\n",
        "\n",
        "def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n",
        "    \"\"\"Train the BertClassifier model.\n",
        "    \"\"\"\n",
        "    # Start training loop\n",
        "    print(\"Start training...\\n\")\n",
        "    for epoch_i in range(epochs):\n",
        "        # =======================================\n",
        "        #               Training\n",
        "        # =======================================\n",
        "        # Print the header of the result table\n",
        "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
        "        print(\"-\"*70)\n",
        "\n",
        "        # Measure the elapsed time of each epoch\n",
        "        t0_epoch, t0_batch = time.time(), time.time()\n",
        "\n",
        "        # Reset tracking variables at the beginning of each epoch\n",
        "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
        "\n",
        "        # Put the model into the training mode\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            batch_counts += 1\n",
        "            # Load batch to GPU\n",
        "            b_input_ids, b_attn_mask, b_labels = tuple(\n",
        "                t.to(device) for t in batch)\n",
        "\n",
        "            # Zero out any previously calculated gradients\n",
        "            model.zero_grad()\n",
        "\n",
        "            # Perform a forward pass. This will return logits.\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "            # Compute loss and accumulate the loss values\n",
        "            loss = loss_fn(logits, b_labels)\n",
        "            batch_loss += loss.item()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and the learning rate\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            # Print the loss values and time elapsed for every 20 batches\n",
        "            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
        "                # Calculate time elapsed for 20 batches\n",
        "                time_elapsed = time.time() - t0_batch\n",
        "\n",
        "                # Print training results\n",
        "                print(\n",
        "                    f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
        "\n",
        "                # Reset batch tracking variables\n",
        "                batch_loss, batch_counts = 0, 0\n",
        "                t0_batch = time.time()\n",
        "\n",
        "        # Calculate the average loss over the entire training data\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "        print(\"-\"*70)\n",
        "        # =======================================\n",
        "        #               Evaluation\n",
        "        # =======================================\n",
        "        if evaluation == True:\n",
        "            # After the completion of each training epoch, measure the model's performance\n",
        "            # on our validation set.\n",
        "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
        "\n",
        "            # Print performance over the entire training data\n",
        "            time_elapsed = time.time() - t0_epoch\n",
        "\n",
        "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
        "            print(\"-\"*70)\n",
        "        print(\"\\n\")\n",
        "\n",
        "    print(\"Training complete!\")\n",
        "\n",
        "\n",
        "def evaluate(model, val_dataloader):\n",
        "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
        "    on our validation set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    val_accuracy = []\n",
        "    val_loss = []\n",
        "\n",
        "    # For each batch in our validation set...\n",
        "    for batch in val_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(logits, b_labels)\n",
        "        val_loss.append(loss.item())\n",
        "\n",
        "        # Get the predictions\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "\n",
        "        # Calculate the accuracy rate\n",
        "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
        "        val_accuracy.append(accuracy)\n",
        "\n",
        "    # Compute the average accuracy and loss over the validation set.\n",
        "    val_loss = np.mean(val_loss)\n",
        "    val_accuracy = np.mean(val_accuracy)\n",
        "\n",
        "    return val_loss, val_accuracy\n",
        "\n",
        "def bert_predict(model, test_dataloader):\n",
        "    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities\n",
        "    on the test set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "\n",
        "    all_logits = []\n",
        "\n",
        "    # For each batch in our test set...\n",
        "    for batch in test_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask = tuple(t.to(device) for t in batch)[:2]\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "        all_logits.append(logits)\n",
        "    \n",
        "    # Concatenate logits from each batch\n",
        "    all_logits = torch.cat(all_logits, dim=0)\n",
        "\n",
        "    # Apply softmax to calculate probabilities\n",
        "    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n",
        "\n",
        "    return probs\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gL_g3f2J9gVl"
      },
      "source": [
        "def dataprocess(X_train, y_train, X_val, y_val, batch_size=16):\n",
        "  # Concatenate train data and test data\n",
        "  all_tweets = np.concatenate([X_train, X_val])\n",
        "\n",
        "  # Encode our concatenated data\n",
        "  encoded_tweets = [tokenizer.encode(sent, add_special_tokens=True) for sent in all_tweets]\n",
        "\n",
        "  # Find the maximum length\n",
        "  max_len = max([len(sent) for sent in encoded_tweets])\n",
        "  print('Max length: ', max_len)\n",
        "\n",
        "  # Specify `MAX_LEN`\n",
        "  MAX_LEN = max_len\n",
        "\n",
        "  # Run function `preprocessing_for_bert` on the train set and the validation set\n",
        "  print('\\nTokenizing data...')\n",
        "  train_inputs, train_masks = preprocessing_for_bert(X_train)\n",
        "  val_inputs, val_masks = preprocessing_for_bert(X_val)\n",
        "\n",
        "  # Convert other data types to torch.Tensor\n",
        "  train_labels = torch.tensor(y_train)\n",
        "  val_labels = torch.tensor(y_val)\n",
        "\n",
        "  # For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
        "  batch_size = 8\n",
        "\n",
        "  # Create the DataLoader for our training set\n",
        "  train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "  train_sampler = RandomSampler(train_data)\n",
        "  train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "  # Create the DataLoader for our validation set\n",
        "  val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "  val_sampler = SequentialSampler(val_data)\n",
        "  val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
        "\n",
        "  return train_dataloader, val_dataloader\n",
        "\n",
        "def process(train_dataloader, val_dataloader, epoch=4):\n",
        "  set_seed(42)    # Set seed for reproducibility\n",
        "  bert_classifier, optimizer, scheduler, loss_fn = initialize_model(epochs=epoch)\n",
        "\n",
        "  train(bert_classifier, train_dataloader, loss_fn, epochs=4, evaluation=True)\n",
        "\n",
        "  return bert_classifier\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xB9mSXQwALQ7"
      },
      "source": [
        "## PROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcoOXHxhAMqf"
      },
      "source": [
        "raw_text = pd.read_csv('./data/_PHEME_text.csv')\n",
        "y = pd.read_csv('./data/_PHEME_target.csv')\n",
        "data = pd.concat([raw_text.text, y], axis=1).reset_index(drop=True)\n",
        "val = pd.read_csv('data/_PHEMEext_text.csv')\n",
        "\n",
        "X_train = data.text.values\n",
        "y_train = data.target.values\n",
        "\n",
        "X_val = val.drop(['Event'],axis=1).text.values\n",
        "y_val = val.target.values\n",
        "\n",
        "rhi_data = pd.read_csv('data/_RHI_text.csv').text.values\n",
        "rhi_y = pd.read_csv('data/_RHI_text.csv').isRumor\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "ba4fccff2e7248dc8ebced01cdfec1e3",
            "cb31c57f96a74fafbc00cb588b5088e3",
            "ca96c35395424cb08052f00d74ff1751",
            "9991f144be6347399295a3e08d9fe659",
            "55acb3ddba064474a2a87af185c31df2",
            "1f69180117754d19984af686646c902f",
            "4d48494062c94f20b6b93f953d3a8506",
            "a38f07ac3db342b589f48dd45656b55c"
          ]
        },
        "id": "MtfEmn6zAQXw",
        "outputId": "4f479c61-e08a-434a-e075-93d0a5339704"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "# Concatenate train data and test data\n",
        "all_tweets = np.concatenate([X_train, X_val])\n",
        "\n",
        "# Encode our concatenated data\n",
        "encoded_tweets = [tokenizer.encode(sent, add_special_tokens=True) for sent in all_tweets]\n",
        "\n",
        "# Find the maximum length\n",
        "max_len = max([len(sent) for sent in encoded_tweets])\n",
        "print('Max length: ', max_len)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ba4fccff2e7248dc8ebced01cdfec1e3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Max length:  69\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dI_AongCAT2q",
        "outputId": "777886ca-6b67-4ad7-8ef3-65c4a01018bc"
      },
      "source": [
        "# Specify `MAX_LEN`\n",
        "MAX_LEN = max_len\n",
        "\n",
        "# Run function `preprocessing_for_bert` on the train set and the validation set\n",
        "print('\\nTokenizing data...')\n",
        "train_inputs, train_masks = preprocessing_for_bert(X_train)\n",
        "val_inputs, val_masks = preprocessing_for_bert(X_val)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Tokenizing data...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzdnTp3xAZs8"
      },
      "source": [
        "# Convert other data types to torch.Tensor\n",
        "train_labels = torch.tensor(y_train)\n",
        "val_labels = torch.tensor(y_val)\n",
        "\n",
        "# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
        "batch_size = 8\n",
        "\n",
        "# Create the DataLoader for our training set\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thxU9n7tAqXY"
      },
      "source": [
        "set_seed(42)    # Set seed for reproducibility\n",
        "bert_classifier, optimizer, scheduler, loss_fn = initialize_model(epochs=4)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-cbSt6yAvmK",
        "outputId": "60e85722-230c-4cf0-83eb-465e133d7f13"
      },
      "source": [
        "train(bert_classifier, train_dataloader, val_dataloader, epochs=4, evaluation=True)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start training...\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   1    |   20    |   0.626368   |     -      |     -     |   16.68  \n",
            "   1    |   40    |   0.538421   |     -      |     -     |   16.50  \n",
            "   1    |   60    |   0.589370   |     -      |     -     |   16.73  \n",
            "   1    |   80    |   0.460613   |     -      |     -     |   16.21  \n",
            "   1    |   100   |   0.523127   |     -      |     -     |   15.98  \n",
            "   1    |   120   |   0.485392   |     -      |     -     |   16.09  \n",
            "   1    |   140   |   0.423931   |     -      |     -     |   16.29  \n",
            "   1    |   160   |   0.386682   |     -      |     -     |   16.41  \n",
            "   1    |   180   |   0.449934   |     -      |     -     |   16.31  \n",
            "   1    |   200   |   0.463877   |     -      |     -     |   16.20  \n",
            "   1    |   220   |   0.484881   |     -      |     -     |   16.19  \n",
            "   1    |   240   |   0.465609   |     -      |     -     |   16.27  \n",
            "   1    |   260   |   0.409387   |     -      |     -     |   16.35  \n",
            "   1    |   280   |   0.390163   |     -      |     -     |   16.30  \n",
            "   1    |   300   |   0.435840   |     -      |     -     |   16.23  \n",
            "   1    |   320   |   0.403359   |     -      |     -     |   16.23  \n",
            "   1    |   340   |   0.419130   |     -      |     -     |   16.23  \n",
            "   1    |   360   |   0.354082   |     -      |     -     |   16.26  \n",
            "   1    |   380   |   0.368082   |     -      |     -     |   16.30  \n",
            "   1    |   400   |   0.342324   |     -      |     -     |   16.29  \n",
            "   1    |   420   |   0.393558   |     -      |     -     |   16.29  \n",
            "   1    |   440   |   0.368237   |     -      |     -     |   16.30  \n",
            "   1    |   460   |   0.361155   |     -      |     -     |   16.30  \n",
            "   1    |   480   |   0.395621   |     -      |     -     |   16.30  \n",
            "   1    |   500   |   0.358814   |     -      |     -     |   16.29  \n",
            "   1    |   520   |   0.304158   |     -      |     -     |   16.25  \n",
            "   1    |   540   |   0.462121   |     -      |     -     |   16.25  \n",
            "   1    |   560   |   0.343477   |     -      |     -     |   16.22  \n",
            "   1    |   580   |   0.379006   |     -      |     -     |   16.24  \n",
            "   1    |   600   |   0.428219   |     -      |     -     |   16.24  \n",
            "   1    |   620   |   0.299058   |     -      |     -     |   16.27  \n",
            "   1    |   640   |   0.398049   |     -      |     -     |   16.24  \n",
            "   1    |   660   |   0.296550   |     -      |     -     |   16.24  \n",
            "   1    |   680   |   0.316593   |     -      |     -     |   16.25  \n",
            "   1    |   700   |   0.451630   |     -      |     -     |   16.26  \n",
            "   1    |   720   |   0.317807   |     -      |     -     |   16.26  \n",
            "   1    |   725   |   0.417702   |     -      |     -     |   3.54   \n",
            "----------------------------------------------------------------------\n",
            "   1    |    -    |   0.414060   |  2.149914  |   28.89   |  608.33  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   2    |   20    |   0.236620   |     -      |     -     |   17.04  \n",
            "   2    |   40    |   0.206706   |     -      |     -     |   16.23  \n",
            "   2    |   60    |   0.283370   |     -      |     -     |   16.22  \n",
            "   2    |   80    |   0.338033   |     -      |     -     |   16.21  \n",
            "   2    |   100   |   0.306632   |     -      |     -     |   16.22  \n",
            "   2    |   120   |   0.272980   |     -      |     -     |   16.20  \n",
            "   2    |   140   |   0.279143   |     -      |     -     |   16.22  \n",
            "   2    |   160   |   0.358276   |     -      |     -     |   16.24  \n",
            "   2    |   180   |   0.176631   |     -      |     -     |   16.24  \n",
            "   2    |   200   |   0.330470   |     -      |     -     |   16.26  \n",
            "   2    |   220   |   0.286584   |     -      |     -     |   16.27  \n",
            "   2    |   240   |   0.309169   |     -      |     -     |   16.24  \n",
            "   2    |   260   |   0.292757   |     -      |     -     |   16.23  \n",
            "   2    |   280   |   0.267158   |     -      |     -     |   16.26  \n",
            "   2    |   300   |   0.256308   |     -      |     -     |   16.22  \n",
            "   2    |   320   |   0.274117   |     -      |     -     |   16.23  \n",
            "   2    |   340   |   0.282657   |     -      |     -     |   16.22  \n",
            "   2    |   360   |   0.322629   |     -      |     -     |   16.22  \n",
            "   2    |   380   |   0.191520   |     -      |     -     |   16.24  \n",
            "   2    |   400   |   0.233147   |     -      |     -     |   16.20  \n",
            "   2    |   420   |   0.229920   |     -      |     -     |   16.23  \n",
            "   2    |   440   |   0.259685   |     -      |     -     |   16.24  \n",
            "   2    |   460   |   0.268907   |     -      |     -     |   16.23  \n",
            "   2    |   480   |   0.262755   |     -      |     -     |   16.23  \n",
            "   2    |   500   |   0.211659   |     -      |     -     |   16.23  \n",
            "   2    |   520   |   0.295418   |     -      |     -     |   16.24  \n",
            "   2    |   540   |   0.291754   |     -      |     -     |   16.24  \n",
            "   2    |   560   |   0.216182   |     -      |     -     |   16.24  \n",
            "   2    |   580   |   0.212659   |     -      |     -     |   16.23  \n",
            "   2    |   600   |   0.351376   |     -      |     -     |   16.22  \n",
            "   2    |   620   |   0.198668   |     -      |     -     |   16.21  \n",
            "   2    |   640   |   0.191055   |     -      |     -     |   16.20  \n",
            "   2    |   660   |   0.172983   |     -      |     -     |   16.22  \n",
            "   2    |   680   |   0.188548   |     -      |     -     |   16.23  \n",
            "   2    |   700   |   0.285157   |     -      |     -     |   16.24  \n",
            "   2    |   720   |   0.299046   |     -      |     -     |   16.24  \n",
            "   2    |   725   |   0.102078   |     -      |     -     |   3.51   \n",
            "----------------------------------------------------------------------\n",
            "   2    |    -    |   0.261103   |  2.622325  |   35.66   |  607.12  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   3    |   20    |   0.165231   |     -      |     -     |   17.05  \n",
            "   3    |   40    |   0.105718   |     -      |     -     |   16.26  \n",
            "   3    |   60    |   0.101030   |     -      |     -     |   16.23  \n",
            "   3    |   80    |   0.087528   |     -      |     -     |   16.23  \n",
            "   3    |   100   |   0.168435   |     -      |     -     |   16.23  \n",
            "   3    |   120   |   0.135115   |     -      |     -     |   16.22  \n",
            "   3    |   140   |   0.060753   |     -      |     -     |   16.17  \n",
            "   3    |   160   |   0.126437   |     -      |     -     |   16.19  \n",
            "   3    |   180   |   0.131639   |     -      |     -     |   16.19  \n",
            "   3    |   200   |   0.074873   |     -      |     -     |   16.16  \n",
            "   3    |   220   |   0.252883   |     -      |     -     |   16.21  \n",
            "   3    |   240   |   0.126163   |     -      |     -     |   16.22  \n",
            "   3    |   260   |   0.181956   |     -      |     -     |   16.23  \n",
            "   3    |   280   |   0.129076   |     -      |     -     |   16.25  \n",
            "   3    |   300   |   0.114084   |     -      |     -     |   16.25  \n",
            "   3    |   320   |   0.153110   |     -      |     -     |   16.24  \n",
            "   3    |   340   |   0.177085   |     -      |     -     |   16.23  \n",
            "   3    |   360   |   0.197440   |     -      |     -     |   16.22  \n",
            "   3    |   380   |   0.030909   |     -      |     -     |   16.18  \n",
            "   3    |   400   |   0.288855   |     -      |     -     |   16.22  \n",
            "   3    |   420   |   0.133189   |     -      |     -     |   16.18  \n",
            "   3    |   440   |   0.038288   |     -      |     -     |   16.19  \n",
            "   3    |   460   |   0.040615   |     -      |     -     |   16.18  \n",
            "   3    |   480   |   0.224334   |     -      |     -     |   16.23  \n",
            "   3    |   500   |   0.152098   |     -      |     -     |   16.22  \n",
            "   3    |   520   |   0.086778   |     -      |     -     |   16.22  \n",
            "   3    |   540   |   0.155353   |     -      |     -     |   16.24  \n",
            "   3    |   560   |   0.109040   |     -      |     -     |   16.23  \n",
            "   3    |   580   |   0.201675   |     -      |     -     |   16.23  \n",
            "   3    |   600   |   0.074899   |     -      |     -     |   16.22  \n",
            "   3    |   620   |   0.174756   |     -      |     -     |   16.23  \n",
            "   3    |   640   |   0.160684   |     -      |     -     |   16.25  \n",
            "   3    |   660   |   0.075152   |     -      |     -     |   16.23  \n",
            "   3    |   680   |   0.247903   |     -      |     -     |   16.23  \n",
            "   3    |   700   |   0.107253   |     -      |     -     |   16.24  \n",
            "   3    |   720   |   0.215801   |     -      |     -     |   16.21  \n",
            "   3    |   725   |   0.109876   |     -      |     -     |   3.49   \n",
            "----------------------------------------------------------------------\n",
            "   3    |    -    |   0.138895   |  3.276252  |   38.73   |  606.69  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   4    |   20    |   0.097290   |     -      |     -     |   16.99  \n",
            "   4    |   40    |   0.007598   |     -      |     -     |   16.16  \n",
            "   4    |   60    |   0.040698   |     -      |     -     |   16.18  \n",
            "   4    |   80    |   0.136120   |     -      |     -     |   16.20  \n",
            "   4    |   100   |   0.061263   |     -      |     -     |   16.24  \n",
            "   4    |   120   |   0.126226   |     -      |     -     |   16.21  \n",
            "   4    |   140   |   0.077399   |     -      |     -     |   16.21  \n",
            "   4    |   160   |   0.103933   |     -      |     -     |   16.23  \n",
            "   4    |   180   |   0.058661   |     -      |     -     |   16.23  \n",
            "   4    |   200   |   0.041221   |     -      |     -     |   16.21  \n",
            "   4    |   220   |   0.043339   |     -      |     -     |   16.24  \n",
            "   4    |   240   |   0.004769   |     -      |     -     |   16.24  \n",
            "   4    |   260   |   0.065295   |     -      |     -     |   16.24  \n",
            "   4    |   280   |   0.071810   |     -      |     -     |   16.23  \n",
            "   4    |   300   |   0.072579   |     -      |     -     |   16.22  \n",
            "   4    |   320   |   0.095752   |     -      |     -     |   16.21  \n",
            "   4    |   340   |   0.041214   |     -      |     -     |   16.22  \n",
            "   4    |   360   |   0.052402   |     -      |     -     |   16.22  \n",
            "   4    |   380   |   0.028533   |     -      |     -     |   16.15  \n",
            "   4    |   400   |   0.030966   |     -      |     -     |   16.18  \n",
            "   4    |   420   |   0.020711   |     -      |     -     |   16.17  \n",
            "   4    |   440   |   0.067124   |     -      |     -     |   16.17  \n",
            "   4    |   460   |   0.052959   |     -      |     -     |   16.22  \n",
            "   4    |   480   |   0.078125   |     -      |     -     |   16.24  \n",
            "   4    |   500   |   0.088723   |     -      |     -     |   16.23  \n",
            "   4    |   520   |   0.004700   |     -      |     -     |   16.24  \n",
            "   4    |   540   |   0.100878   |     -      |     -     |   16.24  \n",
            "   4    |   560   |   0.071914   |     -      |     -     |   16.23  \n",
            "   4    |   580   |   0.017320   |     -      |     -     |   16.23  \n",
            "   4    |   600   |   0.058574   |     -      |     -     |   16.23  \n",
            "   4    |   620   |   0.074094   |     -      |     -     |   16.22  \n",
            "   4    |   640   |   0.003241   |     -      |     -     |   16.23  \n",
            "   4    |   660   |   0.006224   |     -      |     -     |   16.20  \n",
            "   4    |   680   |   0.003919   |     -      |     -     |   16.19  \n",
            "   4    |   700   |   0.077163   |     -      |     -     |   16.16  \n",
            "   4    |   720   |   0.066048   |     -      |     -     |   16.19  \n",
            "   4    |   725   |   0.235810   |     -      |     -     |   3.49   \n",
            "----------------------------------------------------------------------\n",
            "   4    |    -    |   0.058198   |  3.304740  |   46.72   |  606.35  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "lCwjeqoRBG_b",
        "outputId": "72ff4828-9aa4-48da-88ad-121969ea0dba"
      },
      "source": [
        "# Compute predicted probabilities on the test set\n",
        "probs = bert_predict(bert_classifier, val_dataloader)\n",
        "\n",
        "# Evaluate the Bert classifier\n",
        "evaluate_roc(probs, y_val)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC: 0.6958\n",
            "Accuracy: 46.39%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzKgnQ9MPV0K"
      },
      "source": [
        "torch.save(bert_classifier.state_dict(), './Model/BERT_raw_to_fine_tune_ord_2.pt')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmE1rdoMBcKS"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqDU7M-oP54i"
      },
      "source": [
        "### EXT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0YAS2lcBYXV",
        "outputId": "9e90a99d-4c35-4612-88d3-c88e35e59c99"
      },
      "source": [
        "PATH = './Model/BERT_raw_to_fine_tune_ord_2.pt'\n",
        "bert_classifier.load_state_dict(torch.load(PATH))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rp8utGamBjud",
        "outputId": "a87b4b1c-cf4c-477f-f5b6-3eb8985cf0ea"
      },
      "source": [
        "#  Run `preprocessing_for_bert` on the test set\n",
        "print('Tokenizing data...')\n",
        "test_inputs, test_masks = preprocessing_for_bert(X_val)\n",
        "\n",
        "# Create the DataLoader for our test set\n",
        "test_dataset = TensorDataset(test_inputs, test_masks)\n",
        "test_sampler = SequentialSampler(test_dataset)\n",
        "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=32)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenizing data...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e022vpbVBzzN",
        "outputId": "48c64cc1-3239-4819-b650-782034a0b878"
      },
      "source": [
        "# Compute predicted probabilities on the test set\n",
        "probs = bert_predict(bert_classifier, test_dataloader)\n",
        "\n",
        "# Get predictions from the probabilities\n",
        "threshold = 0.5\n",
        "preds = np.where(probs[:, 1] > threshold, 1, 0)\n",
        "\n",
        "# Number of tweets predicted non-negative\n",
        "print(\"Number of tweets predicted as Rumor: \", preds.sum())"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of tweets predicted as Rumor:  127\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nj1xb9lHB3xy",
        "outputId": "b2f8ba21-f5a6-44bb-df12-d59d13c5cf6e"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "preds = np.argmax(probs, axis = 1)\n",
        "print(classification_report(y_val, preds))\n",
        "\n",
        "print(accuracy_score(y_val, preds))\n",
        "print(f1_score(y_val, preds, zero_division=1))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.92      0.45       116\n",
            "           1       0.93      0.32      0.48       369\n",
            "\n",
            "    accuracy                           0.46       485\n",
            "   macro avg       0.61      0.62      0.46       485\n",
            "weighted avg       0.78      0.46      0.47       485\n",
            "\n",
            "0.4639175257731959\n",
            "0.47580645161290325\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HtUKy5HP8X8"
      },
      "source": [
        "### RHI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaAXMYlMP8-8",
        "outputId": "37838966-0c13-4f18-91a9-7420553e437f"
      },
      "source": [
        "# rhi_data = pd.read_csv('data/_RHI_text.csv').text.values\n",
        "# rhi_y = pd.read_csv('data/_RHI_text.csv').isRumor\n",
        "\n",
        "X_test = rhi_data.text.values\n",
        "y_test = rhi_y.isRumor.values\n",
        "\n",
        "\n",
        "#  Run `preprocessing_for_bert` on the test set\n",
        "print('Tokenizing data...')\n",
        "test_inputs, test_masks = preprocessing_for_bert(X_test)\n",
        "\n",
        "# Create the DataLoader for our test set\n",
        "test_dataset = TensorDataset(test_inputs, test_masks)\n",
        "test_sampler = SequentialSampler(test_dataset)\n",
        "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=32)\n",
        "\n",
        "# Convert other data types to torch.Tensor\n",
        "test_labels = torch.tensor(y_test)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenizing data...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3NDfwQ5Qk6A",
        "outputId": "776a6e8d-dee4-4a58-bdb8-ea7732870ed5"
      },
      "source": [
        "# Compute predicted probabilities on the test set\n",
        "probs = bert_predict(bert_classifier, test_dataloader)\n",
        "\n",
        "# Get predictions from the probabilities\n",
        "threshold = 0.5\n",
        "preds = np.where(probs[:, 1] > threshold, 1, 0)\n",
        "\n",
        "# Number of tweets predicted non-negative\n",
        "print(\"Number of tweets predicted as Rumor: \", preds.sum())"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of tweets predicted as Rumor:  681\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOPRKd9EQp_M",
        "outputId": "a0a16844-aaa9-4fef-f4a7-102cb113eb2b"
      },
      "source": [
        "preds = np.argmax(probs, axis = 1)\n",
        "print(classification_report(y_test, preds))\n",
        "print(accuracy_score(y_test, preds))\n",
        "print(f1_score(y_test, preds, zero_division=1))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.10      0.94      0.18       475\n",
            "           1       0.96      0.14      0.24      4752\n",
            "\n",
            "    accuracy                           0.21      5227\n",
            "   macro avg       0.53      0.54      0.21      5227\n",
            "weighted avg       0.88      0.21      0.23      5227\n",
            "\n",
            "0.21044576238760282\n",
            "0.24038284557334802\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNAzuZdm-5eY"
      },
      "source": [
        "# 더 빨리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKhXQU5BE2YM"
      },
      "source": [
        "import re\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "%matplotlib inline\n",
        "from transformers import BertTokenizer\n",
        "from sklearn.metrics import accuracy_score, roc_curve, auc, classification_report, f1_score\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "import random\n",
        "import time\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgmOuPxRFhof"
      },
      "source": [
        "def getDevice():\n",
        "  if torch.cuda.is_available():       \n",
        "      device = torch.device(\"cuda\")\n",
        "      print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "      print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "  else:\n",
        "      print('No GPU available, using the CPU instead.')\n",
        "      device = torch.device(\"cpu\")\n",
        "  return device\n",
        "\n",
        "def evaluate_roc(probs, y_true):\n",
        "    \"\"\"\n",
        "    - Print AUC and accuracy on the test set\n",
        "    - Plot ROC\n",
        "    @params    probs (np.array): an array of predicted probabilities with shape (len(y_true), 2)\n",
        "    @params    y_true (np.array): an array of the true values with shape (len(y_true),)\n",
        "    \"\"\"\n",
        "    preds = probs[:, 1]\n",
        "    fpr, tpr, threshold = roc_curve(y_true, preds)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    print(f'AUC: {roc_auc:.4f}')\n",
        "\n",
        "    # Get accuracy over the test set\n",
        "    y_pred = np.where(preds >= 0.5, 1, 0)\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    print(f'Accuracy: {accuracy*100:.2f}%')\n",
        "\n",
        "    # Plot ROC AUC\n",
        "    plt.title('Receiver Operating Characteristic')\n",
        "    plt.plot(fpr, tpr, 'b', label='AUC = %0.2f' % roc_auc)\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.plot([0, 1], [0, 1], 'r--')\n",
        "    plt.xlim([0, 1])\n",
        "    plt.ylim([0, 1])\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.show()\n",
        "\n",
        "def text_preprocessing(text): # Create a function to tokenize a set of texts\n",
        "\n",
        "    \"\"\"\n",
        "    - Remove entity mentions (eg. '@united')\n",
        "    - Correct errors (eg. '&amp;' to '&')\n",
        "    @param    text (str): a string to be processed.\n",
        "    @return   text (Str): the processed string.\n",
        "    \"\"\"\n",
        "    # Remove '@name'\n",
        "    text = text.lower()\n",
        "    # text = re.sub(r'(@.*?)[\\s]', ' ', text)\n",
        "    # text = re.sub(r\"(#)(\\S+)\", r'\\1 \\2', text)\n",
        "\n",
        "    text = re.sub(r\"http\\S+\", \"*\", text)  # http link -> '*'\n",
        "\n",
        "    # text = re.sub(r\"@\\S+\", \"@\", text)   # mention -> '@'\n",
        "    # text = re.sub(r\"@[^\\s]+\", \"@\", text)   # mention -> '@'\n",
        "\n",
        "    # sent = re.sub(r\"(#)(\\S+)\", r'\\1 \\2', sent)\n",
        "    # sent = re.sub(r'([^\\s\\w@#\\*]|_)+', '', sent) # Erasing Special Characters\n",
        "\n",
        "    # Replace '&amp;' with '&'\n",
        "    text = re.sub(r'&amp;', '&', text)\n",
        "\n",
        "    # Remove trailing whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text\n",
        "\n",
        "def preprocessing_for_bert(data): \n",
        "\n",
        "    \"\"\"Perform required preprocessing steps for pretrained BERT.\n",
        "    @param    data (np.array): Array of texts to be processed.\n",
        "    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
        "    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n",
        "                  tokens should be attended to by the model.\n",
        "    \"\"\"\n",
        "    # Create empty lists to store outputs (빈 리스트 2개 생성)\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    # For every sentence...\n",
        "    for sent in data:\n",
        "        # `encode_plus` will:\n",
        "        #    (1) Tokenize the sentence\n",
        "        #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n",
        "        #    (3) Truncate/Pad sentence to max length\n",
        "        #    (4) Map tokens to their IDs\n",
        "        #    (5) Create attention mask\n",
        "        #    (6) Return a dictionary of outputs\n",
        "        encoded_sent = tokenizer.encode_plus(\n",
        "            text=text_preprocessing(sent),  # Preprocess sentence\n",
        "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
        "            # max_length=MAX_LEN,                  # Max length to truncate/pad\n",
        "            pad_to_max_length=True,         # Pad sentence to max length\n",
        "            # return_tensors='pt',           # Return PyTorch tensor\n",
        "            return_attention_mask=True,      # Return attention mask\n",
        "\n",
        "            # max_length=True,                  # Max length to truncate/pad\n",
        "            padding='max_length'\n",
        "        )\n",
        "\n",
        "        # Add the outputs to the lists (위의 빈 리스트에 상응하는 값 추가)\n",
        "        input_ids.append(encoded_sent.get('input_ids'))\n",
        "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
        "\n",
        "    # Convert lists to tensors (리스트들을 텐서화)\n",
        "    input_ids = torch.tensor(input_ids)\n",
        "    attention_masks = torch.tensor(attention_masks)\n",
        "\n",
        "    return input_ids, attention_masks\n",
        "\n",
        "class BertClassifier(nn.Module): # Create the BertClassfier class\n",
        "    \"\"\"Bert Model for Classification Tasks.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, freeze_bert=False):\n",
        "        \"\"\"\n",
        "        @param    bert: a BertModel object\n",
        "        @param    classifier: a torch.nn.Module classifier\n",
        "        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n",
        "        \"\"\"\n",
        "        super(BertClassifier, self).__init__()\n",
        "        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
        "        D_in, H, D_out = 768, 50, 2\n",
        "\n",
        "        # Instantiate BERT model\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        # Instantiate an one-layer feed-forward classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(D_in, H),\n",
        "            nn.ReLU(),\n",
        "            # nn.Dropout(0.5),\n",
        "            nn.Linear(H, D_out)\n",
        "        )\n",
        "\n",
        "        # Freeze the BERT model\n",
        "        if freeze_bert:\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        \"\"\"\n",
        "        Feed input to BERT and the classifier to compute logits.\n",
        "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
        "                      max_length)\n",
        "        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
        "                      information with shape (batch_size, max_length)\n",
        "        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
        "                      num_labels)\n",
        "        \"\"\"\n",
        "        # Feed input to BERT\n",
        "        outputs = self.bert(input_ids=input_ids,\n",
        "                            attention_mask=attention_mask)\n",
        "\n",
        "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
        "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
        "\n",
        "        # Feed input to classifier to compute logits\n",
        "        logits = self.classifier(last_hidden_state_cls)\n",
        "\n",
        "        return logits\n",
        "\n",
        "def initialize_model(epochs=4):\n",
        "    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n",
        "    \"\"\"\n",
        "    # Instantiate Bert Classifier\n",
        "    bert_classifier = BertClassifier(freeze_bert=False)\n",
        "\n",
        "    # Tell PyTorch to run the model on GPU\n",
        "    bert_classifier.to(device)\n",
        "\n",
        "    # Create the optimizer\n",
        "    optimizer = AdamW(bert_classifier.parameters(),\n",
        "                      lr=5e-5,    # Default learning rate\n",
        "                      eps=1e-8    # Default epsilon value\n",
        "                      )\n",
        "\n",
        "    # Total number of training steps\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Set up the learning rate scheduler\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                                num_warmup_steps=0,  # Default value\n",
        "                                                num_training_steps=total_steps)\n",
        "    return bert_classifier, optimizer, scheduler, criterion\n",
        "\n",
        "def set_seed(seed_value=42):\n",
        "    \"\"\"Set seed for reproducibility.\n",
        "    \"\"\"\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    torch.cuda.manual_seed_all(seed_value)\n",
        "\n",
        "def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n",
        "    \"\"\"Train the BertClassifier model.\n",
        "    \"\"\"\n",
        "    # Start training loop\n",
        "    print(\"Start training...\\n\")\n",
        "    for epoch_i in range(epochs):\n",
        "        # =======================================\n",
        "        #               Training\n",
        "        # =======================================\n",
        "        # Print the header of the result table\n",
        "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
        "        print(\"-\"*70)\n",
        "\n",
        "        # Measure the elapsed time of each epoch\n",
        "        t0_epoch, t0_batch = time.time(), time.time()\n",
        "\n",
        "        # Reset tracking variables at the beginning of each epoch\n",
        "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
        "\n",
        "        # Put the model into the training mode\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            batch_counts += 1\n",
        "            # Load batch to GPU\n",
        "            b_input_ids, b_attn_mask, b_labels = tuple(\n",
        "                t.to(device) for t in batch)\n",
        "\n",
        "            # Zero out any previously calculated gradients\n",
        "            model.zero_grad()\n",
        "\n",
        "            # Perform a forward pass. This will return logits.\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "            # Compute loss and accumulate the loss values\n",
        "            loss = loss_fn(logits, b_labels)\n",
        "            batch_loss += loss.item()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and the learning rate\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            # Print the loss values and time elapsed for every 20 batches\n",
        "            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
        "                # Calculate time elapsed for 20 batches\n",
        "                time_elapsed = time.time() - t0_batch\n",
        "\n",
        "                # Print training results\n",
        "                print(\n",
        "                    f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
        "\n",
        "                # Reset batch tracking variables\n",
        "                batch_loss, batch_counts = 0, 0\n",
        "                t0_batch = time.time()\n",
        "\n",
        "        # Calculate the average loss over the entire training data\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "        print(\"-\"*70)\n",
        "        # =======================================\n",
        "        #               Evaluation\n",
        "        # =======================================\n",
        "        if evaluation == True:\n",
        "            # After the completion of each training epoch, measure the model's performance\n",
        "            # on our validation set.\n",
        "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
        "\n",
        "            # Print performance over the entire training data\n",
        "            time_elapsed = time.time() - t0_epoch\n",
        "\n",
        "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
        "            print(\"-\"*70)\n",
        "        print(\"\\n\")\n",
        "\n",
        "    print(\"Training complete!\")\n",
        "\n",
        "def evaluate(model, val_dataloader):\n",
        "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
        "    on our validation set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    val_accuracy = []\n",
        "    val_loss = []\n",
        "\n",
        "    # For each batch in our validation set...\n",
        "    for batch in val_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(logits, b_labels)\n",
        "        val_loss.append(loss.item())\n",
        "\n",
        "        # Get the predictions\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "\n",
        "        # Calculate the accuracy rate\n",
        "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
        "        val_accuracy.append(accuracy)\n",
        "\n",
        "    # Compute the average accuracy and loss over the validation set.\n",
        "    val_loss = np.mean(val_loss)\n",
        "    val_accuracy = np.mean(val_accuracy)\n",
        "\n",
        "    return val_loss, val_accuracy\n",
        "\n",
        "def bert_predict(model, test_dataloader):\n",
        "    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities\n",
        "    on the test set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "\n",
        "    all_logits = []\n",
        "\n",
        "    # For each batch in our test set...\n",
        "    for batch in test_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask = tuple(t.to(device) for t in batch)[:2]\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "        all_logits.append(logits)\n",
        "    \n",
        "    # Concatenate logits from each batch\n",
        "    all_logits = torch.cat(all_logits, dim=0)\n",
        "\n",
        "    # Apply softmax to calculate probabilities\n",
        "    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n",
        "\n",
        "    return probs\n",
        "\n",
        "def data_process(X_train, y_train, X_val, y_val, batch_size=16):\n",
        "  # Concatenate train data and test data\n",
        "  all_tweets = np.concatenate([X_train, X_val])\n",
        "\n",
        "  # Encode our concatenated data\n",
        "  encoded_tweets = [tokenizer.encode(sent, add_special_tokens=True) for sent in all_tweets]\n",
        "\n",
        "  # Find the maximum length\n",
        "  max_len = max([len(sent) for sent in encoded_tweets])\n",
        "  print('Max length: ', max_len)\n",
        "\n",
        "  # Specify `MAX_LEN`\n",
        "  MAX_LEN = max_len\n",
        "\n",
        "  # Run function `preprocessing_for_bert` on the train set and the validation set\n",
        "  print('\\nTokenizing data...')\n",
        "  train_inputs, train_masks = preprocessing_for_bert(X_train)\n",
        "  val_inputs, val_masks = preprocessing_for_bert(X_val)\n",
        "\n",
        "  # Convert other data types to torch.Tensor\n",
        "  train_labels = torch.tensor(y_train)\n",
        "  val_labels = torch.tensor(y_val)\n",
        "\n",
        "  # For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
        "  batch_size = 8\n",
        "\n",
        "  # Create the DataLoader for our training set\n",
        "  train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "  train_sampler = RandomSampler(train_data)\n",
        "  train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "  # Create the DataLoader for our validation set\n",
        "  val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "  val_sampler = SequentialSampler(val_data)\n",
        "  val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
        "\n",
        "  return train_dataloader, val_dataloader\n",
        "\n",
        "def train_process(train_dataloader, val_dataloader, epoch=4):\n",
        "  set_seed(42)    # Set seed for reproducibility\n",
        "  bert_classifier, optimizer, scheduler, loss_fn = initialize_model(epochs=epoch)\n",
        "\n",
        "  train(bert_classifier, train_dataloader, loss_fn, epochs=4, evaluation=True)\n",
        "\n",
        "  return bert_classifier\n",
        "\n",
        "def testing_process(bert_classifier, X_val, y_val):\n",
        "  #  Run `preprocessing_for_bert` on the test set\n",
        "  print('Tokenizing data...')\n",
        "  test_inputs, test_masks = preprocessing_for_bert(X_val)\n",
        "\n",
        "  # Create the DataLoader for our test set\n",
        "  test_dataset = TensorDataset(test_inputs, test_masks)\n",
        "  test_sampler = SequentialSampler(test_dataset)\n",
        "  test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=32)\n",
        "\n",
        "  # Compute predicted probabilities on the test set\n",
        "  probs = bert_predict(bert_classifier, test_dataloader)\n",
        "\n",
        "  # Get predictions from the probabilities\n",
        "  threshold = 0.5\n",
        "  preds = np.where(probs[:, 1] > threshold, 1, 0)\n",
        "\n",
        "  # Number of tweets predicted non-negative\n",
        "  print(\"Number of tweets predicted as Rumor: \", preds.sum())\n",
        "\n",
        "  preds = np.argmax(probs, axis = 1)\n",
        "  print(\"\\n\",classification_report(y_val, preds))\n",
        "  print(accuracy_score(y_val, preds))\n",
        "  print(f1_score(y_val, preds, zero_division=1))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAAH77uL_FiS"
      },
      "source": [
        "raw_text = pd.read_csv('./data/_PHEME_text.csv')\n",
        "y = pd.read_csv('./data/_PHEME_target.csv')\n",
        "data = pd.concat([raw_text.text, y], axis=1).reset_index(drop=True)\n",
        "val = pd.read_csv('data/_PHEMEext_text.csv')\n",
        "\n",
        "X_train = data.text.values\n",
        "y_train = data.target.values\n",
        "\n",
        "X_val = val.drop(['Event'],axis=1).text.values\n",
        "y_val = val.target.values\n",
        "\n",
        "rhi_data = pd.read_csv('data/_RHI_text.csv').text.values\n",
        "rhi_y = pd.read_csv('data/_RHI_text.csv').isRumor"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K84HzvLMbP0X",
        "outputId": "436f8de9-84a1-425c-f10a-0c7d066509d0"
      },
      "source": [
        "device = getDevice()\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "train_dataloader, val_dataloader = data_process(X_train, y_train, X_val, y_val, batch_size=6)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max length:  69\n",
            "\n",
            "Tokenizing data...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFfTQEHZ_Hc6",
        "outputId": "7235da20-443e-46a4-fc76-d13741bb7987"
      },
      "source": [
        "# set_seed(42)    # Set seed for reproducibility\n",
        "# bert_classifier, optimizer, scheduler, loss_fn = initialize_model(epochs=3)\n",
        "train(bert_classifier, train_dataloader, val_dataloader, epochs=1, evaluation=True)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start training...\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   1    |   20    |   0.046122   |     -      |     -     |   15.14  \n",
            "   1    |   40    |   0.037941   |     -      |     -     |   14.50  \n",
            "   1    |   60    |   0.050807   |     -      |     -     |   14.63  \n",
            "   1    |   80    |   0.087826   |     -      |     -     |   14.75  \n",
            "   1    |   100   |   0.072517   |     -      |     -     |   14.84  \n",
            "   1    |   120   |   0.018580   |     -      |     -     |   14.91  \n",
            "   1    |   140   |   0.069709   |     -      |     -     |   15.03  \n",
            "   1    |   160   |   0.091952   |     -      |     -     |   15.04  \n",
            "   1    |   180   |   0.034815   |     -      |     -     |   15.00  \n",
            "   1    |   200   |   0.032252   |     -      |     -     |   15.05  \n",
            "   1    |   220   |   0.123673   |     -      |     -     |   15.14  \n",
            "   1    |   240   |   0.048046   |     -      |     -     |   15.19  \n",
            "   1    |   260   |   0.053183   |     -      |     -     |   15.15  \n",
            "   1    |   280   |   0.108338   |     -      |     -     |   15.17  \n",
            "   1    |   300   |   0.145327   |     -      |     -     |   15.20  \n",
            "   1    |   320   |   0.012484   |     -      |     -     |   15.23  \n",
            "   1    |   340   |   0.043580   |     -      |     -     |   15.26  \n",
            "   1    |   360   |   0.098621   |     -      |     -     |   15.28  \n",
            "   1    |   380   |   0.078348   |     -      |     -     |   15.26  \n",
            "   1    |   400   |   0.007403   |     -      |     -     |   15.21  \n",
            "   1    |   420   |   0.058727   |     -      |     -     |   15.26  \n",
            "   1    |   440   |   0.034458   |     -      |     -     |   15.23  \n",
            "   1    |   460   |   0.087187   |     -      |     -     |   15.30  \n",
            "   1    |   480   |   0.035923   |     -      |     -     |   15.28  \n",
            "   1    |   500   |   0.148209   |     -      |     -     |   15.35  \n",
            "   1    |   520   |   0.200813   |     -      |     -     |   15.35  \n",
            "   1    |   540   |   0.025291   |     -      |     -     |   15.35  \n",
            "   1    |   560   |   0.111516   |     -      |     -     |   15.35  \n",
            "   1    |   580   |   0.031533   |     -      |     -     |   15.36  \n",
            "   1    |   600   |   0.009809   |     -      |     -     |   15.34  \n",
            "   1    |   620   |   0.113688   |     -      |     -     |   15.35  \n",
            "   1    |   640   |   0.116920   |     -      |     -     |   15.38  \n",
            "   1    |   660   |   0.071217   |     -      |     -     |   15.37  \n",
            "   1    |   680   |   0.042276   |     -      |     -     |   15.37  \n",
            "   1    |   700   |   0.059448   |     -      |     -     |   15.37  \n",
            "   1    |   720   |   0.090096   |     -      |     -     |   15.35  \n",
            "   1    |   725   |   0.116031   |     -      |     -     |   3.31   \n",
            "----------------------------------------------------------------------\n",
            "   1    |    -    |   0.069696   |  3.510263  |   37.17   |  566.15  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwDvSUU-GrFW"
      },
      "source": [
        "torch.save(bert_classifier.state_dict(), './Model/BERT_raw_to_fine_tune_ord3.pt')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "16ynZzt_A95T",
        "outputId": "ea75c6d7-e1f3-4650-c2a5-209fccd85a2e"
      },
      "source": [
        "# Compute predicted probabilities on the test set\n",
        "probs = bert_predict(bert_classifier, val_dataloader)\n",
        "\n",
        "# Evaluate the Bert classifier\n",
        "evaluate_roc(probs, y_val)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC: 0.6601\n",
            "Accuracy: 36.91%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 566
        },
        "id": "UNR9pBOAGz8p",
        "outputId": "c3832360-7053-4832-ffd9-69590381d2c9"
      },
      "source": [
        "PATH = './Model/BERT_raw_to_fine_tune_ord3.pt'\n",
        "bert_classifier.load_state_dict(torch.load(PATH))\n",
        "testing_process(bert_classifier, X_val, y_val)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenizing data...\n",
            "Number of tweets predicted as Rumor:  81\n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.26      0.92      0.41       116\n",
            "           1       0.89      0.20      0.32       369\n",
            "\n",
            "    accuracy                           0.37       485\n",
            "   macro avg       0.58      0.56      0.37       485\n",
            "weighted avg       0.74      0.37      0.34       485\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-aef5ba605f08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mPATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./Model/BERT_raw_to_fine_tune_ord3.pt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbert_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtesting_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-20-481a83615ca6>\u001b[0m in \u001b[0;36mtesting_process\u001b[0;34m(bert_classifier, X_val, y_val)\u001b[0m\n\u001b[1;32m    414\u001b[0m   \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \"\"\"\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 212\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [5227, 485]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eKaw3r2bAwg",
        "outputId": "f4407d7c-aaf6-4b54-9e67-027773888408"
      },
      "source": [
        "rhi_data = pd.read_csv('data/_RHI_text.csv')\n",
        "rhi_y = pd.read_csv('data/_RHI_text.csv')\n",
        "X_test = rhi_data.text.values\n",
        "y_test = rhi_y.isRumor.values\n",
        "\n",
        "PATH = './Model/BERT_raw_to_fine_tune_ord3.pt'\n",
        "bert_classifier.load_state_dict(torch.load(PATH))\n",
        "testing_process(bert_classifier, X_test, y_test)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenizing data...\n",
            "Number of tweets predicted as Rumor:  220\n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.09      0.96      0.17       475\n",
            "           1       0.92      0.04      0.08      4752\n",
            "\n",
            "    accuracy                           0.13      5227\n",
            "   macro avg       0.51      0.50      0.12      5227\n",
            "weighted avg       0.85      0.13      0.09      5227\n",
            "\n",
            "0.12645877176200498\n",
            "0.08165728077232501\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSx6mKV2bgB_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}