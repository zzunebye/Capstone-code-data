{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_avg = pd.read_csv('./train_avg.csv')\n",
    "test_avg = pd.read_csv('./test_avg.csv')\n",
    "\n",
    "train_doc = pd.read_csv('./train_doc.csv')\n",
    "test_doc = pd.read_csv('./test_doc.csv')\n",
    "\n",
    "valid_avg = pd.read_csv('./valid_avg.csv')\n",
    "valid_doc = pd.read_csv('./valid_doc.csv')\n",
    "\n",
    "df_bertweet = pd.read_csv('./df_bertweet.csv')\n",
    "df_valid_bertweet = pd.read_csv('./df_valid_bertweet.csv')\n",
    "\n",
    "data_notembeded = pd.read_csv('./data_notembeded.csv')\n",
    "data_rt_notembeded = pd.read_csv('./data_rt_notembeded.csv')\n",
    "data_valid_notembeded = pd.read_csv('./data_valid_notembeded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_sum = pd.read_csv('./urls_sum.csv')\n",
    "urls_sum_valid = pd.read_csv('./valid_urls_sum.csv')\n",
    "\n",
    "raw_text_tokens = pd.read_csv('./raw_text_tokens.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the Train and test data of Avg: (4912, 334)/(890, 334)\n",
      "Shape of the Train and test data of Doc2vec: (4912, 334)/(890, 334)\n",
      "\n",
      "Shape of the validation data of Avg: (328, 334)\n",
      "Shape of the validation data of Doc2vec: (328, 334)\n",
      "\n",
      "Shape of the data w/ BERTweet: (5802, 803)\n",
      "\n",
      "Shape of the validation data w/ BERTweet: (390, 802)\n",
      "\n",
      "Shape of the data w/o tweet embedding: (5802, 35)\n",
      "Shape of the valid data w/o tweet embedding: (390, 35)\n",
      "Shape of the reaction data w/o tweet embedding: (123766, 33)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the Train and test data of Avg: {}/{}\".format(train_avg.shape, test_avg.shape))\n",
    "print(\"Shape of the Train and test data of Doc2vec: {}/{}\".format(train_doc.shape, test_doc.shape))\n",
    "print(\"\\nShape of the validation data of Avg: {}\".format(valid_avg.shape))\n",
    "print(\"Shape of the validation data of Doc2vec: {}\".format(valid_doc.shape))\n",
    "print(\"\\nShape of the data w/ BERTweet: {}\".format(df_bertweet.shape)) #768\n",
    "print(\"\\nShape of the validation data w/ BERTweet: {}\".format(df_valid_bertweet.shape))\n",
    "\n",
    "print(\"\\nShape of the data w/o tweet embedding: {}\".format(data_notembeded.shape)) #768\n",
    "print(\"Shape of the valid data w/o tweet embedding: {}\".format(data_valid_notembeded.shape)) #768\n",
    "print(\"Shape of the reaction data w/o tweet embedding: {}\".format(data_rt_notembeded.shape)) #768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_notembeded = pd.concat([data_notembeded, urls_sum],axis=1)\n",
    "data_valid_notembeded = pd.concat([data_valid_notembeded, urls_sum_valid],axis=1)\n",
    "\n",
    "df_bertweet = pd.concat([df_bertweet, urls_sum],axis=1)\n",
    "df_valid_bertweet = pd.concat([df_valid_bertweet, urls_sum_valid],axis=1)\n",
    "\n",
    "# valid_doc = pd.concat([valid_doc, urls_sum_valid],axis=1)\n",
    "# valid_avg = pd.concat([valid_avg, urls_sum_valid],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the Train and test data of Avg: (4912, 334)/(890, 334)\n",
      "Shape of the Train and test data of Doc2vec: (4912, 334)/(890, 334)\n",
      "\n",
      "Shape of the validation data of Avg: (328, 334)\n",
      "Shape of the validation data of Doc2vec: (328, 334)\n",
      "\n",
      "Shape of the data w/ BERTweet: (5802, 803)\n",
      "\n",
      "Shape of the validation data w/ BERTweet: (390, 803)\n",
      "\n",
      "Shape of the data w/o tweet embedding: (5802, 35)\n",
      "Shape of the valid data w/o tweet embedding: (390, 35)\n",
      "Shape of the reaction data w/o tweet embedding: (123766, 33)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the Train and test data of Avg: {}/{}\".format(train_avg.shape, test_avg.shape))\n",
    "print(\"Shape of the Train and test data of Doc2vec: {}/{}\".format(train_doc.shape, test_doc.shape))\n",
    "print(\"\\nShape of the validation data of Avg: {}\".format(valid_avg.shape))\n",
    "print(\"Shape of the validation data of Doc2vec: {}\".format(valid_doc.shape))\n",
    "print(\"\\nShape of the data w/ BERTweet: {}\".format(df_bertweet.shape)) #768\n",
    "print(\"\\nShape of the validation data w/ BERTweet: {}\".format(df_valid_bertweet.shape))\n",
    "\n",
    "print(\"\\nShape of the data w/o tweet embedding: {}\".format(data_notembeded.shape)) #768\n",
    "print(\"Shape of the valid data w/o tweet embedding: {}\".format(data_valid_notembeded.shape)) #768\n",
    "print(\"Shape of the reaction data w/o tweet embedding: {}\".format(data_rt_notembeded.shape)) #768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_avg.to_csv('./train_avg.csv', index = False)\n",
    "# df_test_avg.to_csv('./test_avg.csv', index = False)\n",
    "# df_train_doc.to_csv('./train_doc.csv', index = False)\n",
    "# df_test_doc.to_csv('./test_doc.csv', index = False)\n",
    "\n",
    "# df_valid_avg.to_csv('./valid_avg.csv', index = False)\n",
    "# df_valid_doc.to_csv('./valid_doc.csv', index = False)\n",
    "\n",
    "# df_valid_bertweet.to_csv('./df_valid_bertweet.csv', index = False)\n",
    "\n",
    "data_notembeded.to_csv('./data_notembeded.csv', index = False)\n",
    "data_valid_notembeded.to_csv('./data_valid_notembeded.csv', index = False)\n",
    "\n",
    "df_bertweet.to_csv('./df_bertweet.csv', index = False)\n",
    "df_valid_bertweet.to_csv('./df_valid_bertweet.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>hasURL</th>\n      <th>urls</th>\n      <th>urls_expanded</th>\n      <th>hasUserURL</th>\n      <th>user_url</th>\n      <th>text_token</th>\n      <th>isNotOnlyText</th>\n      <th>Noun</th>\n      <th>Verb</th>\n      <th>...</th>\n      <th>759</th>\n      <th>760</th>\n      <th>761</th>\n      <th>762</th>\n      <th>763</th>\n      <th>764</th>\n      <th>765</th>\n      <th>766</th>\n      <th>767</th>\n      <th>NumOfUrls</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Schäublin agreement in accepting Gurlitt colle...</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>1</td>\n      <td>http://t.co/HBmaNJvlN3</td>\n      <td>['schäublin', 'agreement', 'in', 'accepting', ...</td>\n      <td>0</td>\n      <td>7</td>\n      <td>4</td>\n      <td>...</td>\n      <td>-0.122139</td>\n      <td>-0.019078</td>\n      <td>0.052331</td>\n      <td>-0.014176</td>\n      <td>-0.187831</td>\n      <td>0.040174</td>\n      <td>0.094445</td>\n      <td>-0.119151</td>\n      <td>-0.100961</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Gurlitt case:   The German Minister of Justice...</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>1</td>\n      <td>http://t.co/HBmaNJvlN3</td>\n      <td>['gurlitt', 'case', 'the', 'german', 'minister...</td>\n      <td>0</td>\n      <td>7</td>\n      <td>3</td>\n      <td>...</td>\n      <td>-0.130033</td>\n      <td>-0.030035</td>\n      <td>-0.118893</td>\n      <td>0.085495</td>\n      <td>-0.092244</td>\n      <td>0.029394</td>\n      <td>0.096299</td>\n      <td>-0.150120</td>\n      <td>-0.197368</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Swiss museum to accept hundreds of works of ar...</td>\n      <td>1</td>\n      <td>['http://t.co/7DHYBAL0QK']</td>\n      <td>['http://bbc.in/15cU4dU']</td>\n      <td>1</td>\n      <td>http://t.co/vBzl7LOaso</td>\n      <td>['swiss', 'museum', 'to', 'accept', 'hundreds'...</td>\n      <td>1</td>\n      <td>8</td>\n      <td>2</td>\n      <td>...</td>\n      <td>-0.089057</td>\n      <td>0.078044</td>\n      <td>0.017417</td>\n      <td>-0.062084</td>\n      <td>-0.051599</td>\n      <td>0.014855</td>\n      <td>0.105530</td>\n      <td>-0.009658</td>\n      <td>0.007420</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>And the accord on the Nazi-era art hoard of Co...</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>1</td>\n      <td>http://t.co/nidDu0pCJM</td>\n      <td>['and', 'the', 'accord', 'on', 'the', 'naziera...</td>\n      <td>1</td>\n      <td>5</td>\n      <td>2</td>\n      <td>...</td>\n      <td>-0.132434</td>\n      <td>0.029472</td>\n      <td>-0.013832</td>\n      <td>0.201400</td>\n      <td>0.021557</td>\n      <td>-0.060076</td>\n      <td>-0.046130</td>\n      <td>0.056954</td>\n      <td>0.005784</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Swiss museum will accept Gurlitt art trove htt...</td>\n      <td>1</td>\n      <td>['http://t.co/PJVU6DJXTW']</td>\n      <td>['http://bit.ly/1xLkEVW']</td>\n      <td>1</td>\n      <td>http://t.co/6lDbZWVqHE</td>\n      <td>['swiss', 'museum', 'will', 'accept', 'gurlitt...</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>...</td>\n      <td>-0.139582</td>\n      <td>0.105845</td>\n      <td>0.111280</td>\n      <td>0.039827</td>\n      <td>-0.009547</td>\n      <td>-0.081555</td>\n      <td>0.010215</td>\n      <td>-0.125582</td>\n      <td>-0.108929</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>385</th>\n      <td>Ex-KGB Yuri Shvets at #Litvinenko inquiry-#Put...</td>\n      <td>1</td>\n      <td>['http://t.co/VF2sNEEQrJ']</td>\n      <td>['http://www.newsweek.com/putin-involved-drug-...</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>['exkgb', 'yuri', 'shvets', 'at', 'litvinenko'...</td>\n      <td>1</td>\n      <td>6</td>\n      <td>2</td>\n      <td>...</td>\n      <td>-0.246650</td>\n      <td>0.075294</td>\n      <td>0.117143</td>\n      <td>0.079787</td>\n      <td>0.027460</td>\n      <td>-0.150436</td>\n      <td>0.049151</td>\n      <td>-0.104192</td>\n      <td>-0.041892</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>386</th>\n      <td>Death came for Pratchett, picked up Putin for ...</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>['death', 'came', 'for', 'pratchett', 'picked'...</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2</td>\n      <td>...</td>\n      <td>-0.307380</td>\n      <td>-0.071767</td>\n      <td>0.124536</td>\n      <td>0.311526</td>\n      <td>-0.121339</td>\n      <td>0.069690</td>\n      <td>0.115200</td>\n      <td>-0.011791</td>\n      <td>-0.120247</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>387</th>\n      <td>the plot thickens - #putindead http://t.co/Vie...</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>['the', 'plot', 'thickens', 'putindead']</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>...</td>\n      <td>-0.216702</td>\n      <td>0.046754</td>\n      <td>0.088841</td>\n      <td>0.162458</td>\n      <td>0.007598</td>\n      <td>-0.115324</td>\n      <td>0.129715</td>\n      <td>-0.041790</td>\n      <td>0.165129</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>388</th>\n      <td>Putin juggling enough instability. He would ma...</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>1</td>\n      <td>http://t.co/jijnf6t5sm</td>\n      <td>['putin', 'juggling', 'enough', 'instability',...</td>\n      <td>0</td>\n      <td>5</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0.113256</td>\n      <td>0.067972</td>\n      <td>0.018784</td>\n      <td>-0.090069</td>\n      <td>-0.005074</td>\n      <td>0.030130</td>\n      <td>0.060407</td>\n      <td>-0.145962</td>\n      <td>-0.297895</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>389</th>\n      <td>Vladimir #Putin #reappears on #television amid...</td>\n      <td>1</td>\n      <td>['http://t.co/Is6dpF5WIp']</td>\n      <td>['http://www.dailymail.co.uk/news/article-2993...</td>\n      <td>1</td>\n      <td>http://t.co/rn2Tku62ly</td>\n      <td>['vladimir', 'putin', 'reappears', 'on', 'tele...</td>\n      <td>1</td>\n      <td>5</td>\n      <td>0</td>\n      <td>...</td>\n      <td>-0.146207</td>\n      <td>0.018105</td>\n      <td>0.044611</td>\n      <td>0.069043</td>\n      <td>-0.053529</td>\n      <td>-0.059823</td>\n      <td>0.053681</td>\n      <td>-0.127183</td>\n      <td>-0.080722</td>\n      <td>nan</td>\n    </tr>\n  </tbody>\n</table>\n<p>390 rows × 803 columns</p>\n</div>",
      "text/plain": [
       "                                                  text  hasURL  \\\n",
       "0    Schäublin agreement in accepting Gurlitt colle...       0   \n",
       "1    Gurlitt case:   The German Minister of Justice...       0   \n",
       "2    Swiss museum to accept hundreds of works of ar...       1   \n",
       "3    And the accord on the Nazi-era art hoard of Co...       0   \n",
       "4    Swiss museum will accept Gurlitt art trove htt...       1   \n",
       "..                                                 ...     ...   \n",
       "385  Ex-KGB Yuri Shvets at #Litvinenko inquiry-#Put...       1   \n",
       "386  Death came for Pratchett, picked up Putin for ...       0   \n",
       "387  the plot thickens - #putindead http://t.co/Vie...       0   \n",
       "388  Putin juggling enough instability. He would ma...       0   \n",
       "389  Vladimir #Putin #reappears on #television amid...       1   \n",
       "\n",
       "                           urls  \\\n",
       "0                            []   \n",
       "1                            []   \n",
       "2    ['http://t.co/7DHYBAL0QK']   \n",
       "3                            []   \n",
       "4    ['http://t.co/PJVU6DJXTW']   \n",
       "..                          ...   \n",
       "385  ['http://t.co/VF2sNEEQrJ']   \n",
       "386                          []   \n",
       "387                          []   \n",
       "388                          []   \n",
       "389  ['http://t.co/Is6dpF5WIp']   \n",
       "\n",
       "                                         urls_expanded  hasUserURL  \\\n",
       "0                                                   []           1   \n",
       "1                                                   []           1   \n",
       "2                            ['http://bbc.in/15cU4dU']           1   \n",
       "3                                                   []           1   \n",
       "4                            ['http://bit.ly/1xLkEVW']           1   \n",
       "..                                                 ...         ...   \n",
       "385  ['http://www.newsweek.com/putin-involved-drug-...           1   \n",
       "386                                                 []           1   \n",
       "387                                                 []           1   \n",
       "388                                                 []           1   \n",
       "389  ['http://www.dailymail.co.uk/news/article-2993...           1   \n",
       "\n",
       "                   user_url  \\\n",
       "0    http://t.co/HBmaNJvlN3   \n",
       "1    http://t.co/HBmaNJvlN3   \n",
       "2    http://t.co/vBzl7LOaso   \n",
       "3    http://t.co/nidDu0pCJM   \n",
       "4    http://t.co/6lDbZWVqHE   \n",
       "..                      ...   \n",
       "385                     NaN   \n",
       "386                     NaN   \n",
       "387                     NaN   \n",
       "388  http://t.co/jijnf6t5sm   \n",
       "389  http://t.co/rn2Tku62ly   \n",
       "\n",
       "                                            text_token  isNotOnlyText  Noun  \\\n",
       "0    ['schäublin', 'agreement', 'in', 'accepting', ...              0     7   \n",
       "1    ['gurlitt', 'case', 'the', 'german', 'minister...              0     7   \n",
       "2    ['swiss', 'museum', 'to', 'accept', 'hundreds'...              1     8   \n",
       "3    ['and', 'the', 'accord', 'on', 'the', 'naziera...              1     5   \n",
       "4    ['swiss', 'museum', 'will', 'accept', 'gurlitt...              1     3   \n",
       "..                                                 ...            ...   ...   \n",
       "385  ['exkgb', 'yuri', 'shvets', 'at', 'litvinenko'...              1     6   \n",
       "386  ['death', 'came', 'for', 'pratchett', 'picked'...              0     5   \n",
       "387           ['the', 'plot', 'thickens', 'putindead']              1     2   \n",
       "388  ['putin', 'juggling', 'enough', 'instability',...              0     5   \n",
       "389  ['vladimir', 'putin', 'reappears', 'on', 'tele...              1     5   \n",
       "\n",
       "     Verb  ...       759       760       761       762       763       764  \\\n",
       "0       4  ... -0.122139 -0.019078  0.052331 -0.014176 -0.187831  0.040174   \n",
       "1       3  ... -0.130033 -0.030035 -0.118893  0.085495 -0.092244  0.029394   \n",
       "2       2  ... -0.089057  0.078044  0.017417 -0.062084 -0.051599  0.014855   \n",
       "3       2  ... -0.132434  0.029472 -0.013832  0.201400  0.021557 -0.060076   \n",
       "4       1  ... -0.139582  0.105845  0.111280  0.039827 -0.009547 -0.081555   \n",
       "..    ...  ...       ...       ...       ...       ...       ...       ...   \n",
       "385     2  ... -0.246650  0.075294  0.117143  0.079787  0.027460 -0.150436   \n",
       "386     2  ... -0.307380 -0.071767  0.124536  0.311526 -0.121339  0.069690   \n",
       "387     1  ... -0.216702  0.046754  0.088841  0.162458  0.007598 -0.115324   \n",
       "388     3  ...  0.113256  0.067972  0.018784 -0.090069 -0.005074  0.030130   \n",
       "389     0  ... -0.146207  0.018105  0.044611  0.069043 -0.053529 -0.059823   \n",
       "\n",
       "          765       766       767  NumOfUrls  \n",
       "0    0.094445 -0.119151 -0.100961        0.0  \n",
       "1    0.096299 -0.150120 -0.197368        0.0  \n",
       "2    0.105530 -0.009658  0.007420        1.0  \n",
       "3   -0.046130  0.056954  0.005784        0.0  \n",
       "4    0.010215 -0.125582 -0.108929        0.0  \n",
       "..        ...       ...       ...        ...  \n",
       "385  0.049151 -0.104192 -0.041892        nan  \n",
       "386  0.115200 -0.011791 -0.120247        nan  \n",
       "387  0.129715 -0.041790  0.165129        nan  \n",
       "388  0.060407 -0.145962 -0.297895        nan  \n",
       "389  0.053681 -0.127183 -0.080722        nan  \n",
       "\n",
       "[390 rows x 803 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid_bertweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_novec= train_avg[['Noun', 'Verb', 'Adjective', 'Pronoun', 'FirstPersonPronoun', 'SecondPersonPronoun', 'ThirdPersonPronoun', 'Adverb', 'Numeral', 'Conjunction_inj', 'Particle', 'Determiner', 'Modal', 'Whs', 'word_count', 'has_question', 'has_exclaim', 'has_period', 'capital_ratio', 'tweet_count', 'listed_count', 'follow_ratio', 'age', 'verified','hasURL', 'hasUserURL', 'isNotOnlyText', 'char_count']]\n",
    "test_novec= test_avg[['Noun', 'Verb', 'Adjective', 'Pronoun', 'FirstPersonPronoun', 'SecondPersonPronoun', 'ThirdPersonPronoun', 'Adverb', 'Numeral', 'Conjunction_inj', 'Particle', 'Determiner', 'Modal', 'Whs', 'word_count', 'has_question', 'has_exclaim', 'has_period', 'capital_ratio', 'tweet_count', 'listed_count', 'follow_ratio', 'age', 'verified', 'hasURL', 'hasUserURL', 'isNotOnlyText', 'char_count']]\n",
    "valid_novec = valid_avg[['Noun', 'Verb', 'Adjective', 'Pronoun', 'FirstPersonPronoun', 'SecondPersonPronoun', 'ThirdPersonPronoun', 'Adverb', 'Numeral', 'Conjunction_inj', 'Particle', 'Determiner', 'Modal', 'Whs', 'word_count', 'has_question', 'has_exclaim', 'has_period', 'capital_ratio', 'tweet_count', 'listed_count', 'follow_ratio', 'age', 'verified', 'hasURL', 'hasUserURL', 'isNotOnlyText', 'char_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Noun</th>\n      <th>Verb</th>\n      <th>Adjective</th>\n      <th>Pronoun</th>\n      <th>FirstPersonPronoun</th>\n      <th>SecondPersonPronoun</th>\n      <th>ThirdPersonPronoun</th>\n      <th>Adverb</th>\n      <th>Numeral</th>\n      <th>Conjunction_inj</th>\n      <th>...</th>\n      <th>capital_ratio</th>\n      <th>tweet_count</th>\n      <th>listed_count</th>\n      <th>follow_ratio</th>\n      <th>age</th>\n      <th>verified</th>\n      <th>hasURL</th>\n      <th>hasUserURL</th>\n      <th>isNotOnlyText</th>\n      <th>char_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0.159091</td>\n      <td>4.803286</td>\n      <td>3.855943</td>\n      <td>5.287349</td>\n      <td>2126</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>88</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.037736</td>\n      <td>3.031812</td>\n      <td>2.146128</td>\n      <td>3.672929</td>\n      <td>1050</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>4</td>\n      <td>8</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0.073529</td>\n      <td>3.856245</td>\n      <td>2.879669</td>\n      <td>4.309651</td>\n      <td>2030</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>136</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.101449</td>\n      <td>4.735814</td>\n      <td>5.009820</td>\n      <td>7.187664</td>\n      <td>2891</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>138</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0.145299</td>\n      <td>5.021181</td>\n      <td>4.132996</td>\n      <td>5.925434</td>\n      <td>1975</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>117</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4907</th>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0.116505</td>\n      <td>3.586024</td>\n      <td>2.876795</td>\n      <td>4.716070</td>\n      <td>531</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>103</td>\n    </tr>\n    <tr>\n      <th>4908</th>\n      <td>5</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0.068182</td>\n      <td>3.466423</td>\n      <td>3.893429</td>\n      <td>5.800086</td>\n      <td>2713</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>88</td>\n    </tr>\n    <tr>\n      <th>4909</th>\n      <td>4</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.039683</td>\n      <td>3.681151</td>\n      <td>1.924279</td>\n      <td>4.557531</td>\n      <td>549</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>126</td>\n    </tr>\n    <tr>\n      <th>4910</th>\n      <td>7</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0.107438</td>\n      <td>4.349879</td>\n      <td>5.007671</td>\n      <td>7.097693</td>\n      <td>2793</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>121</td>\n    </tr>\n    <tr>\n      <th>4911</th>\n      <td>5</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.039604</td>\n      <td>4.245562</td>\n      <td>2.738781</td>\n      <td>4.164650</td>\n      <td>2117</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>101</td>\n    </tr>\n  </tbody>\n</table>\n<p>4912 rows × 28 columns</p>\n</div>",
      "text/plain": [
       "      Noun  Verb  Adjective  Pronoun  FirstPersonPronoun  SecondPersonPronoun  \\\n",
       "0        6     3          0        0                   0                    0   \n",
       "1        2     1          2        0                   0                    0   \n",
       "2        3     4          8        0                   0                    0   \n",
       "3        5     5          0        0                   0                    0   \n",
       "4        7     2          0        0                   0                    0   \n",
       "...    ...   ...        ...      ...                 ...                  ...   \n",
       "4907     2     2          1        1                   0                    1   \n",
       "4908     5     2          1        1                   1                    0   \n",
       "4909     4     3          2        1                   0                    0   \n",
       "4910     7     3          2        0                   0                    0   \n",
       "4911     5     4          0        0                   0                    0   \n",
       "\n",
       "      ThirdPersonPronoun  Adverb  Numeral  Conjunction_inj  ...  \\\n",
       "0                      0       0        0                2  ...   \n",
       "1                      0       0        0                1  ...   \n",
       "2                      0       1        0                2  ...   \n",
       "3                      0       0        0                0  ...   \n",
       "4                      0       0        0                2  ...   \n",
       "...                  ...     ...      ...              ...  ...   \n",
       "4907                   0       0        0                2  ...   \n",
       "4908                   0       0        0                2  ...   \n",
       "4909                   1       0        0                1  ...   \n",
       "4910                   0       0        0                3  ...   \n",
       "4911                   0       0        0                1  ...   \n",
       "\n",
       "      capital_ratio  tweet_count  listed_count  follow_ratio   age  verified  \\\n",
       "0          0.159091     4.803286      3.855943      5.287349  2126         1   \n",
       "1          0.037736     3.031812      2.146128      3.672929  1050         0   \n",
       "2          0.073529     3.856245      2.879669      4.309651  2030         0   \n",
       "3          0.101449     4.735814      5.009820      7.187664  2891         1   \n",
       "4          0.145299     5.021181      4.132996      5.925434  1975         1   \n",
       "...             ...          ...           ...           ...   ...       ...   \n",
       "4907       0.116505     3.586024      2.876795      4.716070   531         1   \n",
       "4908       0.068182     3.466423      3.893429      5.800086  2713         1   \n",
       "4909       0.039683     3.681151      1.924279      4.557531   549         0   \n",
       "4910       0.107438     4.349879      5.007671      7.097693  2793         1   \n",
       "4911       0.039604     4.245562      2.738781      4.164650  2117         0   \n",
       "\n",
       "      hasURL  hasUserURL  isNotOnlyText  char_count  \n",
       "0          1           1              1          88  \n",
       "1          0           1              0          53  \n",
       "2          0           1              0         136  \n",
       "3          1           1              1         138  \n",
       "4          1           1              1         117  \n",
       "...      ...         ...            ...         ...  \n",
       "4907       1           1              1         103  \n",
       "4908       0           1              0          88  \n",
       "4909       1           1              1         126  \n",
       "4910       1           1              1         121  \n",
       "4911       0           1              0         101  \n",
       "\n",
       "[4912 rows x 28 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_novec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_macos_venv",
   "language": "python",
   "name": "tensorflow_macos_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}