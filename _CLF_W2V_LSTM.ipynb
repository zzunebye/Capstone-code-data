{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheme = pd.read_csv('./data/_PHEME_text_AVGw2v.csv').drop(['token'],axis=1)\n",
    "pheme_y = pd.read_csv('./data/_PHEME_target.csv').target\n",
    "pheme_event = pd.read_csv('./data/_PHEME_text.csv').Event\n",
    "\n",
    "ext = pd.read_csv('./data/_PHEMEext_text_AVGw2v.csv').drop(['token'],axis=1)\n",
    "ext_y = pd.read_csv('./data/_PHEMEext_text.csv').target\n",
    "ext_event = pd.read_csv('./data/_PHEMEext_text.csv').Event\n",
    "\n",
    "rhi = pd.read_csv('./data/_RHI_text_AVGw2v.csv').drop(['token'],axis=1)\n",
    "rhi_y = pd.read_csv('./data/_RHI_target.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERTCLF 노트북을 참고한 방법 - Train -> LSTM으로 바꿔보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = torch.tensor(pheme.values).float()\n",
    "val_inputs = torch.tensor(ext.values).float()\n",
    "\n",
    "# Convert other data types to torch.Tensor\n",
    "train_labels = torch.tensor(pheme_y.values).float()\n",
    "val_labels = torch.tensor(ext_y.values).float()\n",
    "\n",
    "# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
    "batch_size = 16\n",
    "\n",
    "# Create the DataLoader for our training set\n",
    "train_data = TensorDataset(train_inputs, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set\n",
    "val_data = TensorDataset(val_inputs, val_labels)\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the Inputs are:\n",
      "Train\ttorch.Size([5802, 200])\n",
      "Val\ttorch.Size([485, 200])\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of the Inputs are:\\nTrain\\t%s\\nVal\\t%s\" %(train_inputs.size(), val_inputs.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class AvgW2VNet(torch.nn.Module):\n",
    "  def __init__(self, freeze_model=False):\n",
    "    \"\"\"\n",
    "    In the constructor we construct three nn.Linear instances that we will use\n",
    "    in the forward pass.\n",
    "    \"\"\"\n",
    "    super(AvgW2VNet, self).__init__()\n",
    "    self.input_size = input_size\n",
    "    self.hidden_size = hidden_size\n",
    "\n",
    "    D_in, H, D_out = 200, 16, 1\n",
    "\n",
    "    self.rnn = nn.LSTM(\n",
    "        input_size = input_size, \n",
    "        hidden_size = hidden_size, \n",
    "        num_layers = 4, \n",
    "        batch_first = True,\n",
    "        bidirectional = True\n",
    "    )\n",
    "\n",
    "    self.layers = nn.Sequential(\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(input_size*2, hidden_size),\n",
    "    )\n",
    "\n",
    "    # self.classifier = nn.Sequential(\n",
    "    #     nn.Linear(D_in, H),\n",
    "    #     nn.BatchNorm1d(H),\n",
    "    #     nn.ReLU(),\n",
    "    #     nn.Dropout(0.2),\n",
    "    #     nn.Linear(H, D_out),\n",
    "    #     nn.Sigmoid()\n",
    "    # )\n",
    "\n",
    "  def forward(self, x):\n",
    "    y,_ = self.rnn(x)\n",
    "    result = self.layers(y)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.nn.optim import Adam\n",
    "\n",
    "def initialize_model(epochs=300):\n",
    "    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n",
    "    \"\"\"\n",
    "    # Instantiate Bert Classifier\n",
    "    model = AvgW2VNet()\n",
    "\n",
    "    # Tell PyTorch to run the model on GPU\n",
    "    model.to(device)\n",
    "\n",
    "    # Create the optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.1, weight_decay=0.1)\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    # loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Total number of training steps\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "    # Set up the learning rate scheduler\n",
    "    # scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "    #                                             num_warmup_steps=0, # Default value\n",
    "    #                                             num_training_steps=total_steps)\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=0.1, gamma= 0.99)       \n",
    "\n",
    "    return model, optimizer, criterion, scheduler\n",
    "    # return bert_classifier, optimizer, scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "def set_seed(seed_value=42):\n",
    "    \"\"\"Set seed for reproducibility.\n",
    "    \"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n",
    "    \"\"\"Train the BertClassifier model.\n",
    "    \"\"\"\n",
    "    # Start training loop\n",
    "    print(\"Start training...\\n\")\n",
    "    val_loss_list = []\n",
    "    val_acc_list = []\n",
    "    for epoch_i in range(epochs):\n",
    "        # =======================================\n",
    "        #               Training\n",
    "        # =======================================\n",
    "        # Print the header of the result table\n",
    "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
    "        # print(\"-\"*70)\n",
    "\n",
    "        # Measure the elapsed time of each epoch\n",
    "        t0_epoch, t0_batch = time.time(), time.time()\n",
    "\n",
    "        # Reset tracking variables at the beginning of each epoch\n",
    "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
    "\n",
    "        # Put the model into the training mode\n",
    "        model.train()\n",
    "\n",
    "        # For each batch of training data...\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            batch_counts +=1\n",
    "            # Load batch to GPU\n",
    "            b_input, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "            # Zero out any previously calculated gradients\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Perform a forward pass. This will return logits.\n",
    "            logits = model(b_input)\n",
    "\n",
    "            # Compute loss and accumulate the loss values\n",
    "            # torch.argmax(logits(i)) for logit, i in enumerate(logits)\n",
    "            \n",
    "            # print(torch.argmax(logits))\n",
    "            # print(logits)\n",
    "            # print(b_labels.type())\n",
    "            # print(torch.argmax(logits, dim=1))\n",
    "            logits = logits.flatten()\n",
    "            loss = criterion(logits, b_labels)\n",
    "            batch_loss += loss.item()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Perform a backward pass to calculate gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            # Update parameters and the learning rate\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # Print the loss values and time elapsed for every 20 batches\n",
    "            if (step % 100 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
    "                # Calculate time elapsed for 20 batches\n",
    "                time_elapsed = time.time() - t0_batch\n",
    "\n",
    "                # Print training results\n",
    "                # print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
    "\n",
    "                # Reset batch tracking variables\n",
    "                batch_loss, batch_counts = 0, 0\n",
    "                t0_batch = time.time()\n",
    "\n",
    "        # Calculate the average loss over the entire training data\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "        print(\"-\"*70)\n",
    "        # =======================================\n",
    "        #               Evaluation\n",
    "        # =======================================\n",
    "        if evaluation == True:\n",
    "            # After the completion of each training epoch, measure the model's performance\n",
    "            # on our validation set.\n",
    "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
    "            val_loss_list.append(val_loss)\n",
    "            val_acc_list.append(val_accuracy)\n",
    "\n",
    "            # Print performance over the entire training data\n",
    "            time_elapsed = time.time() - t0_epoch\n",
    "            # print(val_loss_list)\n",
    "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
    "            print(\"-\"*70)\n",
    "        print(\"\\n\")\n",
    "    # print(val_loss_list)\n",
    "    # print(np.range(1,epochs+1))\n",
    "    fig = plt.figure(figsize=(18,10))\n",
    "    plt.plot(np.arange(0,epochs),val_loss_list)\n",
    "    fig2 = plt.figure(figsize=(18,10))\n",
    "    plt.plot(np.arange(0,epochs),val_acc_list)\n",
    "    print(\"Training complete!\")\n",
    "\n",
    "def evaluate(model, val_dataloader):\n",
    "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
    "    on our validation set.\n",
    "    \"\"\"\n",
    "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
    "    # the test time.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    val_accuracy = []\n",
    "    val_loss = []\n",
    "\n",
    "    # For each batch in our validation set...\n",
    "    for batch in val_dataloader:\n",
    "        # Load batch to GPU\n",
    "        b_input, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # Compute logits\n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input)\n",
    "            # print(logits)\n",
    "            # logits = logits.flatten()\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(logits.flatten(), b_labels)\n",
    "        val_loss.append(loss.item())\n",
    "\n",
    "        # Get the predictions\n",
    "        # print(logits)\n",
    "        # print(torch.argmax(logits), dim=1)\n",
    "        # print(logits)\n",
    "        # print(torch.argmax(logits, dim=1))\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "        # Calculate the accuracy rate\n",
    "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
    "        # print(preds)\n",
    "        # print(b_labels)\n",
    "        # print((preds == b_labels))\n",
    "        # print((preds == b_labels).numpy().mean())\n",
    "        # print(accuracy)\n",
    "        val_accuracy.append(accuracy)\n",
    "\n",
    "    # Compute the average accuracy and loss over the validation set.\n",
    "    val_loss = np.mean(val_loss)\n",
    "    val_accuracy = np.mean(val_accuracy)\n",
    "\n",
    "    return val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)    # Set seed for reproducibility\n",
    "model, optimizer, criterion, scheduler = initialize_model(epochs=100)\n",
    "criterion = nn.BCELoss()\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "# criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   1    |    -    |   0.639528   |  0.610964  |   25.60   |   0.53   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   2    |    -    |   0.647421   |  0.771703  |   25.60   |   0.48   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   3    |    -    |   0.647474   |  0.784059  |   25.60   |   0.48   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   4    |    -    |   0.648490   |  0.875346  |   25.60   |   0.48   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   5    |    -    |   0.648081   |  0.878954  |   25.60   |   0.49   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   6    |    -    |   0.645979   |  0.753151  |   25.60   |   0.59   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   7    |    -    |   0.643810   |  0.814137  |   25.60   |   0.48   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   8    |    -    |   0.646240   |  0.859356  |   25.60   |   0.49   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   9    |    -    |   0.643474   |  0.869719  |   25.60   |   0.53   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "  10    |    -    |   0.647404   |  0.886819  |   25.60   |   0.53   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "  11    |    -    |   0.643991   |  0.793549  |   25.60   |   0.54   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "  12    |    -    |   0.643471   |  0.747277  |   25.60   |   0.48   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "  13    |    -    |   0.640912   |  1.118812  |   25.60   |   0.57   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "  14    |    -    |   0.646596   |  0.849899  |   25.60   |   0.55   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "  15    |    -    |   0.647087   |  0.913701  |   25.60   |   0.54   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "  16    |    -    |   0.646527   |  0.790857  |   25.60   |   0.48   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "  17    |    -    |   0.646991   |  0.815333  |   25.60   |   0.49   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "  18    |    -    |   0.646528   |  0.818208  |   25.60   |   0.55   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "  19    |    -    |   0.646458   |  0.827993  |   25.60   |   0.49   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "  20    |    -    |   0.647680   |  0.818778  |   25.60   |   0.48   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Training complete!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 1296x720 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 1296x720 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(model, train_dataloader, val_dataloader, epochs=20, evaluation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "\n",
    "def evaluate_roc(probs, y_true):\n",
    "    \"\"\"\n",
    "    - Print AUC and accuracy on the test set\n",
    "    - Plot ROC\n",
    "    @params    probs (np.array): an array of predicted probabilities with shape (len(y_true), 2)\n",
    "    @params    y_true (np.array): an array of the true values with shape (len(y_true),)\n",
    "    \"\"\"\n",
    "    preds = probs[:, 1]\n",
    "    fpr, tpr, threshold = roc_curve(y_true, preds)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print(f'AUC: {roc_auc:.4f}')\n",
    "       \n",
    "    # Get accuracy over the test set\n",
    "    y_pred = np.where(preds >= 0.5, 1, 0)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "    \n",
    "    # Plot ROC AUC\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def model_predict(model, test_dataloader):\n",
    "    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities\n",
    "    on the test set.\n",
    "    \"\"\"\n",
    "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
    "    # the test time.\n",
    "    model.eval()\n",
    "\n",
    "    all_logits = []\n",
    "\n",
    "    # For each batch in our test set...\n",
    "    for batch in test_dataloader:\n",
    "        # Load batch to GPU\n",
    "        b_input,b_labels = tuple(t.to(device) for t in batch)\n",
    "        # print(b_input)\n",
    "\n",
    "        # Compute logits\n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input)\n",
    "        all_logits.append(logits)\n",
    "    \n",
    "    # Concatenate logits from each batch\n",
    "    all_logits = torch.cat(all_logits, dim=0)\n",
    "\n",
    "    # Apply softmax to calculate probabilities\n",
    "    probs = F.softmax(all_logits, dim=1).cpu()\n",
    "\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-425-6a157c3629fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# print(target)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mevaluate_roc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-370-bde1be800687>\u001b[0m in \u001b[0;36mevaluate_roc\u001b[0;34m(probs, y_true)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mparams\u001b[0m    \u001b[0my_true\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0man\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtrue\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \"\"\"\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mroc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 1 with size 1"
     ]
    }
   ],
   "source": [
    "# Compute predicted probabilities on the test set\n",
    "probs = model_predict(model, val_dataloader)\n",
    "probs = probs.numpy()\n",
    "# print(probs)\n",
    "# print(type(probs))\n",
    "\n",
    "# # Evaluate the Bert classifier\n",
    "# print(len(probs))\n",
    "target = torch.tensor(ext_y)\n",
    "target = target.unsqueeze(dim=1).numpy()\n",
    "# print(target)\n",
    "evaluate_roc(probs, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "test_loss = 0\n",
    "outputs_list = []\n",
    "y_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    val_loss = 0\n",
    "\n",
    "    for i, data in enumerate(test_loader):\n",
    "        x, y = data\n",
    "        x, y = x.float(), y.long()\n",
    "        outputs = task1_model(x)\n",
    "        loss = criterion(outputs, y.unsqueeze(1).float())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        outputs_list.append(predicted[:])\n",
    "        total += y.size(0)\n",
    "        correct += (predicted == y).double().sum().item()\n",
    "        val_loss += loss.item()\n",
    "        y_list.append(y)\n",
    "\n",
    "print('Accuracy of the test dataset is: %d %%' % (100 * correct / total))\n",
    "print(\"Loss of validation set: {:.5f}\".format((val_loss / test_size)))\n",
    "acc = (100 * correct / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task1_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "test_loss = 0\n",
    "outputs_list = []\n",
    "y_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    val_loss = 0\n",
    "\n",
    "    for i, data in enumerate(task1_test_dataloader):\n",
    "        x, y = data\n",
    "        x, y = x.float(), y.long()\n",
    "        outputs = task1_model(x)\n",
    "        loss = criterion(outputs, y.unsqueeze(1).float())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        outputs_list.append(predicted[:])\n",
    "        total += y.size(0)\n",
    "        correct += (predicted == y).double().sum().item()\n",
    "        val_loss += loss.item()\n",
    "        y_list.append(y)\n",
    "\n",
    "print('Accuracy of the test dataset is: %d %%' % (100 * correct / total))\n",
    "print(\"Loss of validation set: {:.5f}\".format((val_loss / test_size)))\n",
    "acc = (100 * correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of FC_net(\n",
      "  (fc1): Linear(in_features=792, out_features=130, bias=True)\n",
      "  (fc2): Linear(in_features=130, out_features=60, bias=True)\n",
      "  (fc3): Linear(in_features=60, out_features=1, bias=True)\n",
      "  (drop_2): Dropout(p=0.2, inplace=False)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "print(task1_model.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "# optimizer = optim.SGD(task1_model.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(task1_model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "train_accuracy = []\n",
    "\n",
    "prev_loss = 10\n",
    "PATH = \"./state_dict_BERT_fc.pt\"\n",
    "best_acc = 10.0\n",
    "num_epochs = 10\n",
    "\n",
    "val_corrects_list = []\n",
    "val_loss_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "Train) Loss: 0.3190 Acc: 0.0042\n",
      "Epoch 1/9\n",
      "----------\n",
      "Train) Loss: 5.4705 Acc: 0.6325\n",
      "Epoch 2/9\n",
      "----------\n",
      "Train) Loss: 5.7149 Acc: 0.6568\n",
      "Epoch 3/9\n",
      "----------\n",
      "Train) Loss: 5.7213 Acc: 0.6568\n",
      "Epoch 4/9\n",
      "----------\n",
      "Train) Loss: 5.7149 Acc: 0.6568\n",
      "Epoch 5/9\n",
      "----------\n",
      "Train) Loss: 5.7213 Acc: 0.6568\n",
      "Epoch 6/9\n",
      "----------\n",
      "Train) Loss: 5.7149 Acc: 0.6568\n",
      "Epoch 7/9\n",
      "----------\n",
      "Train) Loss: 5.7149 Acc: 0.6568\n",
      "Epoch 8/9\n",
      "----------\n",
      "Train) Loss: 5.7213 Acc: 0.6568\n",
      "Epoch 9/9\n",
      "----------\n",
      "Train) Loss: 5.7213 Acc: 0.6568\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "    print('-' * 10)\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    task1_model.train()  # Set model to training mode\n",
    "    for i, data in enumerate(task1_train_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        # inputs, labels = inputs.float(), labels.long()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = task1_model(inputs)\n",
    "\n",
    "        labels = labels.unsqueeze(1).float()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()    \n",
    "\n",
    "        running_loss += loss.item()\n",
    "        running_corrects += torch.sum(outputs == labels.data)\n",
    "        # print(running_corrects)\n",
    "\n",
    "    epoch_loss = running_loss / train_size\n",
    "    epoch_acc = running_corrects.double() / train_size\n",
    "    train_loss.append(epoch_loss)\n",
    "    train_accuracy.append(epoch_acc)\n",
    "\n",
    "    print('Train) Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
    "\n",
    "    # if epoch_loss < best_acc:\n",
    "    #     # print(\"prev_loss: {:.5f}\".format(prev_loss))\n",
    "    #     # print(\"loss: {:.5f}\".format(loss))\n",
    "    #     print(\"Saving the best model w/ loss {:.4f}\".format(epoch_loss))\n",
    "    #     torch.save(task1_model.state_dict(),PATH)\n",
    "    #     best_acc = epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the test dataset is: 68 %\n",
      "Loss of validation set: 5.20883\n"
     ]
    }
   ],
   "source": [
    "task1_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "test_loss = 0\n",
    "outputs_list = []\n",
    "y_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    val_loss = 0\n",
    "\n",
    "    for i, data in enumerate(task1_test_dataloader):\n",
    "        x, y = data\n",
    "        x, y = x.float(), y.long()\n",
    "        outputs = task1_model(x)\n",
    "        loss = criterion(outputs, y.unsqueeze(1).float())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        outputs_list.append(predicted[:])\n",
    "        total += y.size(0)\n",
    "        correct += (predicted == y).double().sum().item()\n",
    "        val_loss += loss.item()\n",
    "        y_list.append(y)\n",
    "\n",
    "print('Accuracy of the test dataset is: %d %%' % (100 * correct / total))\n",
    "print(\"Loss of validation set: {:.5f}\".format((val_loss / test_size)))\n",
    "acc = (100 * correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sents(sents, pad_token):\n",
    "    \"\"\" Pad list of sentences to the longest length in the batch.\n",
    "    @param sents (list[list[str]]): list of tokenized strings\n",
    "    @param pad_token (int): pad token\n",
    "    @returns sents_padded (list[list[int]]): list of tokenized sentences with padding shape: (batch_size, max_sentence_length)\n",
    "    \"\"\"\n",
    "    sents_padded = []\n",
    "\n",
    "    max_len = max(len(s) for s in sents)\n",
    "    for s in sents:\n",
    "        padded = [pad_token] * max_len\n",
    "        padded[:len(s)] = s\n",
    "        sents_padded.append(padded)\n",
    "    return sents_padded\n",
    "\n",
    "def sents_to_tensor(tokenizer, sents):\n",
    "    \"\"\"\n",
    "    :param tokenizer\n",
    "    :param sents: list[str], list of untokenized strings\n",
    "    \"\"\"\n",
    "    tokens_list = [tokenizer.tokenize(sent) for sent in sents]\n",
    "    sents_lengths = [len(tokens) for tokens in tokens_list]\n",
    "    sents_lengths = torch.tensor(sents_lengths)\n",
    "    \n",
    "    tokens_list_padded = pad_sents(tokens_list, '[PAD]')\n",
    "    masks = np.asarray(tokens_list_padded)!='[PAD]'\n",
    "    masks_tensor = torch.tensor(masks, dtype=torch.long)\n",
    "    tokens_id_list = [tokenizer.convert_tokens_to_ids(tokens) for tokens in tokens_list_padded]\n",
    "    sents_tensor = torch.tensor(tokens_id_list, dtype=torch.long)\n",
    "\n",
    "    return sents_tensor, masks_tensor, sents_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "import sys\n",
    "import pickle\n",
    "from vocab import VocabEntry\n",
    "\n",
    "class BaselineModel(nn.Module):\n",
    "    def __init__(self, rnn_state_size, embedding, vocab, num_tweet_class, dropout_rate=0):\n",
    "        \"\"\"\n",
    "        @param hidden_size (int): size of lstm hidden layer\n",
    "        @param embedding (torch.Tensor): shape (num_of_words_in_dict, embed_dim), glove embedding matrix\n",
    "        @param vocab (VocabEntry): GloVe word dictionary/index\n",
    "        @param num_tweet_class (int): number of labels / classes\n",
    "        @param dropout_rate (float): dropout rate for training\n",
    "        \"\"\"\n",
    "\n",
    "        super(BaselineModel, self).__init__()\n",
    "        self.rnn_state_size = rnn_state_size\n",
    "        # self.embed_dim = embedding.size(1)\n",
    "        # self.vocab = vocab\n",
    "        self.num_tweet_class = num_tweet_class\n",
    "        self.padding_idx = self.vocab['<pad>']\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.embedding_layer = nn.Embedding.from_pretrained(embeddings = embedding, \n",
    "                                                            freeze=True, # freeze weights from training\n",
    "                                                            padding_idx=self.padding_idx, \n",
    "                                                            max_norm=None, \n",
    "                                                            norm_type=2.0, \n",
    "                                                            scale_grad_by_freq=False, \n",
    "                                                            sparse=False)\n",
    "        # Create a embedding using GloVE pretrained weights\n",
    "        self.lstm = nn.LSTM(input_size = self.embed_dim, \n",
    "                            hidden_size = self.rnn_state_size, \n",
    "                            num_layers = 1, \n",
    "                            bias = True, \n",
    "                            batch_first = False, \n",
    "                            dropout = 0, \n",
    "                            bidirectional = True #use a bi-directional LSTM\n",
    "                           )\n",
    "        self.affine = nn.Linear(in_features = 2*self.rnn_state_size, #the hidden stats of the biLSTM is stacked\n",
    "                                out_features = self.num_tweet_class, \n",
    "                                bias=True)\n",
    "        # fully connected layer before softmax\n",
    "        self.dropout = nn.Dropout(p=self.dropout_rate)\n",
    "\n",
    "    def forward(self, sents):\n",
    "        \"\"\"\n",
    "        @param sents (list[list[str]]): a list of a list of words, sorted in descending length\n",
    "        @return output (torch.Tensor): logits to put into softmax function to calculate prob\n",
    "        \"\"\"\n",
    "        text_lengths = torch.tensor([len(sent) for sent in sents])\n",
    "        sents_tensor = self.vocab.to_input_tensor(sents)  # Convert from list to tensor (max_sent_length, batch_size)\n",
    "        x_embed = self.embedding_layer(sents_tensor)  # create embedding for words (max_sent_length, batch_size, embed_size)\n",
    "        seq = pack_padded_sequence(x_embed.float(), text_lengths)\n",
    "        enc_hiddens, (last_hidden, last_cell) = self.lstm(seq)\n",
    "        output_hidden = torch.cat((last_hidden[0], last_hidden[1]), dim=1)  # (batch_size, 2*hidden_size)\n",
    "        output_hidden = self.dropout(output_hidden)\n",
    "        output = self.affine(output_hidden)  # (batch_size, n_class)\n",
    "\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def load(model_path: str):\n",
    "        \"\"\" Load the model from a file.\n",
    "        @param model_path (str): path to model\n",
    "        @return model (nn.Module): model with saved parameters\n",
    "        \"\"\"\n",
    "        params = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
    "        args = params['args']\n",
    "        model = BaselineModel(vocab=params['vocab'], embedding=params['embedding'], **args)\n",
    "        model.load_state_dict(params['state_dict'])\n",
    "\n",
    "        return model​\n",
    "\n",
    "    def save(self, path: str):\n",
    "        \"\"\" Save the model to a file.\n",
    "        @param path (str): path to the model\n",
    "        \"\"\"\n",
    "        print('save model parameters to [%s]' % path, file=sys.stderr)\n",
    "\n",
    "        params = {\n",
    "            'args': dict(rnn_state_size=self.rnn_state_size,    \n",
    "                         dropout_rate=self.dropout_rate,\n",
    "                         num_tweet_class=self.num_tweet_class),\n",
    "            'vocab': self.vocab,\n",
    "            'embedding': self.embedding_layer.weight,\n",
    "            'state_dict': self.state_dict()\n",
    "        }\n",
    "        torch.save(params, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_pretrained_bert import BertAdam\n",
    "from bert import default_bert, LSTM_bert \n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "from utils import batch_iter\n",
    "\n",
    "def validation(model, df_val, loss_func, bert_size):\n",
    "    \"\"\" validation of model during training.\n",
    "    @param model (nn.Module): the model being trained\n",
    "    @param df_val (dataframe): validation dataset, sorted in descending text length\n",
    "    @param loss_func(nn.Module): loss function\n",
    "    @return avg loss value across validation dataset\n",
    "    \"\"\"\n",
    "    was_training = model.training\n",
    "    model.eval() #model.eval() put all layers in model in eval mode, that way, batchnorm or dropout layers will work in eval mode instead of training mode.\n",
    "\n",
    "    df_val = df_val.sort_values(by='tweet_proc_BERT'+bert_size+'_length', ascending=False)\n",
    "    \n",
    "    tweet_proc_bert = list(df_val['tweet_proc_bert'])\n",
    "    type_label = list(df_val['type_label'])\n",
    "\n",
    "    val_batch_size = 32\n",
    "    num_val_samples = df_val.shape[0]\n",
    "    ​\n",
    "    n_batch = int(np.ceil(num_val_samples/val_batch_size))\n",
    "\n",
    "    total_loss = 0.\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(n_batch):\n",
    "            sents = tweet_proc_bert[i*val_batch_size: (i+1)*val_batch_size]\n",
    "            targets = torch.tensor(type_label[i*val_batch_size: (i+1)*val_batch_size],\n",
    "                                   dtype=torch.long)\n",
    "            batch_size = len(sents)\n",
    "            output = model(sents)\n",
    "            batch_loss = loss_func(output, targets)\n",
    "            total_loss += batch_loss.item()*batch_size\n",
    "\n",
    "    if was_training:\n",
    "        model.train()\n",
    "\n",
    "    return total_loss/num_val_samples    \n",
    "\n",
    "def train(args):\n",
    "    \n",
    "    label_name = ['not informative', \n",
    "            'other useful information', \n",
    "            'caution and advice',\n",
    "            'affected individuals', \n",
    "            'infrastructure and utilities damage',\n",
    "            'donations and volunteering',\n",
    "            'sympathy and support',\n",
    "            ]\n",
    "    \n",
    "    # save_file_name = args['--model']+'_model.bin'\n",
    "    bert_size = args['--bert-config'].split('-')[1]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    print('Importing data...', file=sys.stderr)\n",
    "    df_train = pd.read_csv(args['--train'], index_col=0)\n",
    "    df_val = pd.read_csv(args['--dev'], index_col=0)\n",
    "    train_label = dict(df_train['type_label'].value_counts())\n",
    "    label_max = float(max(train_label.values()))\n",
    "    print(train_label, file=sys.stderr)\n",
    "    train_label_weight = torch.tensor([label_max/train_label[i] for i in range(len(train_label))])\n",
    "    print('Done! time elapsed %.2f sec' % (time.time() - start_time), file=sys.stderr)\n",
    "    print('-' * 80, file=sys.stderr)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    print('Set up model...', file=sys.stderr)\n",
    "    \n",
    "    if args['--model'] == 'default_bert':\n",
    "        model = default_bert(num_class=len(label_name), bert_config=args['--bert-config'])\n",
    "        optimizer_grouped_parameters = [\n",
    "                {'params': model.model.bert.parameters()},\n",
    "                {'params': model.model.classifier.parameters(), 'lr': float(args['--lr'])}\n",
    "                ]\n",
    "        optimizer = BertAdam(optimizer_grouped_parameters, \n",
    "                             lr=float(args['--lr-bert']),\n",
    "                             max_grad_norm=float(args['--clip-grad'])\n",
    "                             )\n",
    "    elif args['--model'] == 'LSTM_bert':\n",
    "        model = LSTM_bert(num_class=len(label_name), dropout_rate=float(args['--dropout']), bert_config=args['--bert-config'])\n",
    "        optimizer_grouped_parameters = [\n",
    "                {'params': model.bert.parameters()},\n",
    "                {'params': model.lstm.parameters(), 'lr': float(args['--lr'])},\n",
    "                {'params': model.fc.parameters(), 'lr': float(args['--lr'])}]\n",
    "        optimizer = BertAdam(optimizer_grouped_parameters, \n",
    "                             lr=float(args['--lr-bert']),\n",
    "                             max_grad_norm=float(args['--clip-grad'])\n",
    "                             )\n",
    "    else:\n",
    "        print('wrong model...', file=sys.stderr)\n",
    "            \n",
    "        \n",
    "    print('Done! time elapsed %.2f sec' % (time.time() - start_time), file=sys.stderr)\n",
    "    print('-' * 80, file=sys.stderr)\n",
    "    \n",
    "    model.train() #set model for training mode\n",
    "    criterion = torch.nn.CrossEntropyLoss(weight=train_label_weight, reduction='mean')\n",
    "    torch.save(criterion, 'loss_func')  # for later testing\n",
    "\n",
    "    train_batch_size = int(args['--batch-size'])\n",
    "    valid_niter = int(args['--valid-niter'])\n",
    "    display_num = int(args['--display_num'])\n",
    "    model_save_path = args['--save-to']\n",
    "\n",
    "    num_restarts = 0\n",
    "    train_iter = patience = cum_loss = report_loss = 0\n",
    "    total_samples = display_samples = epoch = 0\n",
    "    valid_loss_hist = []\n",
    "    train_time = begin_time = time.time()\n",
    "    print('Begin training...')\n",
    "    \n",
    "    while True:\n",
    "        epoch += 1\n",
    "\n",
    "        for sents, targets in batch_iter(df_train, batch_size=train_batch_size, shuffle=False, bert=(args['--bert-config'])):  # for each epoch\n",
    "            train_iter += 1\n",
    "            \n",
    "            batch_size = len(sents)\n",
    "            labels = torch.tensor(targets, dtype=torch.long)\n",
    "            \n",
    "            optimizer.zero_grad() #restarting the grad accumulations between mini-batches\n",
    "            output = model(sents) #pass through model\n",
    "            loss = criterion(output, labels) #calculate loss\n",
    "            loss.backward() #back prop\n",
    "            optimizer.step() #update weights           \n",
    "\n",
    "            batch_losses_val = loss.item() * batch_size\n",
    "            report_loss += batch_losses_val\n",
    "            cum_loss += batch_losses_val\n",
    "\n",
    "            display_samples += batch_size\n",
    "            total_samples += batch_size\n",
    "\n",
    "            if train_iter % display_num == 0:\n",
    "                print('epoch %d, iter %d, avg. loss %.2f, '\n",
    "                      'total samples %d, speed %.2f samples/sec, '\n",
    "                      'time elapsed %.2f sec' % \n",
    "                      (epoch, train_iter, report_loss / display_samples,\n",
    "                       total_samples, display_samples / (time.time() - train_time),\n",
    "                       time.time() - begin_time), file=sys.stderr)\n",
    "\n",
    "                train_time = time.time()\n",
    "                report_loss = display_samples = 0.\n",
    "\n",
    "            # perform validation\n",
    "            if train_iter % valid_niter == 0:\n",
    "                print('epoch %d, iter %d, cum. loss %.2f, cum. examples %d' % \n",
    "                      (epoch, train_iter, cum_loss / total_samples, total_samples), file=sys.stderr)\n",
    "\n",
    "                cum_loss = total_samples = 0.\n",
    "\n",
    "                print('begin validation ...', file=sys.stderr)\n",
    "\n",
    "                valid_loss = validation(model, df_val, criterion, bert_size=bert_size)                \n",
    "                print('validation: iter %d, loss %f' % (train_iter, valid_loss), file=sys.stderr)\n",
    "                \n",
    "                # scheduler.step(valid_loss)\n",
    "                improved_loss = len(valid_loss_hist)==0 or valid_loss < min(valid_loss_hist)\n",
    "                valid_loss_hist.append(valid_loss)\n",
    "\n",
    "                if improved_loss:\n",
    "                    patience = 0\n",
    "                    print('save currently the best model to [%s]' % args['--model']+'_model.bin', file=sys.stderr)\n",
    "                    model.save(args['--model']+'_model.bin')\n",
    "\n",
    "                    # also save the optimizers' state\n",
    "                    torch.save(optimizer.state_dict(), args['--model'] + '.optim')\n",
    "                else: #if valid loss did not improve\n",
    "                    patience += 1\n",
    "                    print('hit patience %d out of %d' % (patience, int(args['--patience'])), file=sys.stderr)\n",
    "                    \n",
    "                    if patience >= int(args['--patience']):\n",
    "                        num_restarts += 1\n",
    "                        print('hit #%d restart out of max %d restarts' % (num_restarts, int(args['--max-num-trial'])), file=sys.stderr)\n",
    "                        if num_restarts >= int(args['--max-num-trial']):\n",
    "                            print('early termination!', file=sys.stderr)\n",
    "                            exit(0)\n",
    "\n",
    "                        # decay lr, and restore from previously best checkpoint\n",
    "                        lr = optimizer.param_groups[0]['lr'] * float(args['--lr-decay'])\n",
    "                        print('load previously best model and decay learning rate to %f' % lr, file=sys.stderr)\n",
    "                        \n",
    "                        # load model\n",
    "                        params = torch.load(args['--model'], map_location=lambda storage, loc: storage)\n",
    "                        model.load_state_dict(params['state_dict'])\n",
    "\n",
    "                        print('restore parameters of the optimizers', file=sys.stderr)\n",
    "                        optimizer.load_state_dict(torch.load(args['--model'] + '.optim'))\n",
    "\n",
    "                        # set new lr\n",
    "                        for param_group in optimizer.param_groups:\n",
    "                            param_group['lr'] = lr\n",
    "\n",
    "                        # reset patience\n",
    "                        patience = 0\n",
    "\n",
    "                if epoch == int(args['--max-epoch']):\n",
    "                    print('reached maximum number of epochs!', file=sys.stderr)\n",
    "                    exit(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM (https://github.com/prakashpandey9/Text-Classification-Pytorch/blob/master/models/LSTM.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheme = pd.read_csv('./data/_PHEME_text_AVGw2v.csv').drop(['token'],axis=1)\n",
    "pheme_y = pd.read_csv('./data/_PHEME_target.csv').target\n",
    "pheme_event = pd.read_csv('./data/_PHEME_text.csv').Event\n",
    "\n",
    "ext = pd.read_csv('./data/_PHEMEext_text_AVGw2v.csv').drop(['token'],axis=1)\n",
    "ext_y = pd.read_csv('./data/_PHEMEext_text.csv').target\n",
    "ext_event = pd.read_csv('./data/_PHEMEext_text.csv').Event\n",
    "\n",
    "rhi = pd.read_csv('./data/_RHI_text_AVGw2v.csv').drop(['token'],axis=1)\n",
    "rhi_y = pd.read_csv('./data/_RHI_target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _*_ coding: utf-8 _*_\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from torchtext.vocab import Vectors, GloVe\n",
    "from nltk import SnowballStemmer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import string\n",
    "\n",
    "def getTokenization(raw_data):\n",
    "\n",
    "    lmt = WordNetLemmatizer()\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    freqdist = nltk.FreqDist()\n",
    "    tweet_tokenizer = TweetTokenizer()\n",
    "    tweet_tokens = []\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    for sent in raw_data.text:\n",
    "\n",
    "        sent = re.sub(r\"http\\S+\", \"&\", sent)\n",
    "        # sent = re.sub(r\"@\\S+\", \"@\", sent)\n",
    "        sent = re.sub(r\"(#)(\\S+)\", r'\\1 \\2', sent)\n",
    "\n",
    "        sent = re.sub(r'([^\\s\\w@#&]|_)+', '', sent)\n",
    "        sent = re.sub('@[^\\s]+','atUser',sent)\n",
    "        # sent = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','url',sent)\n",
    "        # sent = re.sub(r'#([^\\s]+)', r'\\1', sent)\n",
    "\n",
    "        sent = replaceContraction(sent)\n",
    "\n",
    "        # sent = re.sub('', '', sent.lower())\n",
    "        # sent = [tweet_tokenizer.tokenize(sent)]\n",
    "        sent = tweet_tokenizer.tokenize(sent.lower())\n",
    "        sent = [stemmer.stem(token) for token in sent]\n",
    "        # sent = [lmt.lemmatize(token) for token in sent]\n",
    "\n",
    "        temp = [token for token in sent if not token in stop_words]\n",
    "        tweet_tokens.append([temp])\n",
    "        # tweet_tokens.append(tweet_tokenizer.tokenize(sent))\n",
    "    df_tokens = pd.DataFrame(tweet_tokens, columns=['token'])\n",
    "\n",
    "def load_dataset(test_sen=None):\n",
    "\n",
    "    \"\"\"\n",
    "    tokenizer : Breaks sentences into a list of words. If sequential=False, no tokenization is applied\n",
    "    Field : A class that stores information about the way of preprocessing\n",
    "    fix_length : An important property of TorchText is that we can let the input to be variable length, and TorchText will\n",
    "                 dynamically pad each sequence to the longest sequence in that \"batch\". But here we are using fi_length which\n",
    "                 will pad each sequence to have a fix length of 200.\n",
    "                 \n",
    "    build_vocab : It will first make a vocabulary or dictionary mapping all the unique words present in the train_data to an\n",
    "                  idx and then after it will use GloVe word embedding to map the index to the corresponding word embedding.\n",
    "                  \n",
    "    vocab.vectors : This returns a torch tensor of shape (vocab_size x embedding_dim) containing the pre-trained word embeddings.\n",
    "    BucketIterator : Defines an iterator that batches examples of similar lengths together to minimize the amount of padding needed.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    tokenize = lambda x: x.split()\n",
    "    TEXT = data.Field(sequential=True, tokenize=tokenize, lower=True, include_lengths=True, batch_first=True, fix_length=200)\n",
    "    LABEL = data.LabelField(tensor_type=torch.FloatTensor)\n",
    "    train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n",
    "    TEXT.build_vocab(train_data, vectors=GloVe(name='6B', dim=300))\n",
    "    LABEL.build_vocab(train_data)\n",
    "\n",
    "    word_embeddings = TEXT.vocab.vectors\n",
    "    print (\"Length of Text Vocabulary: \" + str(len(TEXT.vocab)))\n",
    "    print (\"Vector size of Text Vocabulary: \", TEXT.vocab.vectors.size())\n",
    "    print (\"Label Length: \" + str(len(LABEL.vocab)))\n",
    "\n",
    "    train_data, valid_data = train_data.split() # Further splitting of training_data to create new training_data & validation_data\n",
    "    train_iter, valid_iter, test_iter = data.BucketIterator.splits((train_data, valid_data, test_data), batch_size=32, sort_key=lambda x: len(x.text), repeat=False, shuffle=True)\n",
    "\n",
    "    '''Alternatively we can also use the default configurations'''\n",
    "    # train_iter, test_iter = datasets.IMDB.iters(batch_size=32)\n",
    "\n",
    "    vocab_size = len(TEXT.vocab)\n",
    "\n",
    "    return TEXT, vocab_size, word_embeddings, train_iter, valid_iter, test_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_gradient(model, clip_value):\n",
    "    params = list(filter(lambda p: p.grad is not None, model.parameters()))\n",
    "    for p in params:\n",
    "        p.grad.data.clamp_(-clip_value, clip_value)\n",
    "    \n",
    "def train_model(model, train_iter, epoch):\n",
    "    total_epoch_loss = 0\n",
    "    total_epoch_acc = 0\n",
    "    model.cuda()\n",
    "    optim = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "    steps = 0\n",
    "    model.train()\n",
    "    for idx, batch in enumerate(train_iter):\n",
    "        text = batch.text[0]\n",
    "        target = batch.label\n",
    "        target = torch.autograd.Variable(target).long()\n",
    "        if torch.cuda.is_available():\n",
    "            text = text.cuda()\n",
    "            target = target.cuda()\n",
    "        if (text.size()[0] is not 32):# One of the batch returned by BucketIterator has length different than 32.\n",
    "            continue\n",
    "        optim.zero_grad()\n",
    "        prediction = model(text)\n",
    "        loss = loss_fn(prediction, target)\n",
    "        num_corrects = (torch.max(prediction, 1)[1].view(target.size()).data == target.data).float().sum()\n",
    "        acc = 100.0 * num_corrects/len(batch)\n",
    "        loss.backward()\n",
    "        clip_gradient(model, 1e-1)\n",
    "        optim.step()\n",
    "        steps += 1\n",
    "        \n",
    "        if steps % 100 == 0:\n",
    "            print (f'Epoch: {epoch+1}, Idx: {idx+1}, Training Loss: {loss.item():.4f}, Training Accuracy: {acc.item(): .2f}%')\n",
    "        \n",
    "        total_epoch_loss += loss.item()\n",
    "        total_epoch_acc += acc.item()\n",
    "        \n",
    "    return total_epoch_loss/len(train_iter), total_epoch_acc/len(train_iter)\n",
    "\n",
    "def eval_model(model, val_iter):\n",
    "    total_epoch_loss = 0\n",
    "    total_epoch_acc = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(val_iter):\n",
    "            text = batch.text[0]\n",
    "            if (text.size()[0] is not 32):\n",
    "                continue\n",
    "            target = batch.label\n",
    "            target = torch.autograd.Variable(target).long()\n",
    "            if torch.cuda.is_available():\n",
    "                text = text.cuda()\n",
    "                target = target.cuda()\n",
    "            prediction = model(text)\n",
    "            loss = loss_fn(prediction, target)\n",
    "            num_corrects = (torch.max(prediction, 1)[1].view(target.size()).data == target.data).sum()\n",
    "            acc = 100.0 * num_corrects/len(batch)\n",
    "            total_epoch_loss += loss.item()\n",
    "            total_epoch_acc += acc.item()\n",
    "\n",
    "    return total_epoch_loss/len(val_iter), total_epoch_acc/len(val_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "\tdef __init__(self, batch_size, output_size, hidden_size, vocab_size, embedding_length, weights):\n",
    "\t\tsuper(LSTMClassifier, self).__init__()\n",
    "\t\t\n",
    "\t\t\"\"\"\n",
    "\t\tArguments\n",
    "\t\t---------\n",
    "\t\tbatch_size : Size of the batch which is same as the batch_size of the data returned by the TorchText BucketIterator\n",
    "\t\toutput_size : 2 = (pos, neg)\n",
    "\t\thidden_sie : Size of the hidden_state of the LSTM\n",
    "\t\tvocab_size : Size of the vocabulary containing unique words\n",
    "\t\tembedding_length : Embeddding dimension of GloVe word embeddings\n",
    "\t\tweights : Pre-trained GloVe word_embeddings which we will use to create our word_embedding look-up table \n",
    "\t\t\n",
    "\t\t\"\"\"\n",
    "\t\t\n",
    "\t\tself.batch_size = batch_size\n",
    "\t\tself.output_size = output_size\n",
    "\t\tself.hidden_size = hidden_size\n",
    "\t\tself.vocab_size = vocab_size\n",
    "\t\tself.embedding_length = embedding_length\n",
    "\t\t\n",
    "\t\tself.word_embeddings = nn.Embedding(vocab_size, embedding_length)# Initializing the look-up table.\n",
    "\t\tself.word_embeddings.weight = nn.Parameter(weights, requires_grad=False) # Assigning the look-up table to the pre-trained GloVe word embedding.\n",
    "\t\tself.lstm = nn.LSTM(embedding_length, hidden_size)\n",
    "\t\tself.label = nn.Linear(hidden_size, output_size)\n",
    "\t\t\n",
    "\tdef forward(self, input_sentence, batch_size=None):\n",
    "\t\n",
    "\t\t\"\"\" \n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\tinput_sentence: input_sentence of shape = (batch_size, num_sequences)\n",
    "\t\tbatch_size : default = None. Used only for prediction on a single sentence after training (batch_size = 1)\n",
    "\t\t\n",
    "\t\tReturns\n",
    "\t\t-------\n",
    "\t\tOutput of the linear layer containing logits for positive & negative class which receives its input as the final_hidden_state of the LSTM\n",
    "\t\tfinal_output.shape = (batch_size, output_size)\n",
    "\t\t\n",
    "\t\t\"\"\"\n",
    "\t\t\n",
    "\t\t''' Here we will map all the indexes present in the input sequence to the corresponding word vector using our pre-trained word_embedddins.'''\n",
    "\t\tinput = self.word_embeddings(input_sentence) # embedded input of shape = (batch_size, num_sequences,  embedding_length)\n",
    "\t\tinput = input.permute(1, 0, 2) # input.size() = (num_sequences, batch_size, embedding_length)\n",
    "\t\tif batch_size is None:\n",
    "\t\t\th_0 = Variable(torch.zeros(1, self.batch_size, self.hidden_size).cuda()) # Initial hidden state of the LSTM\n",
    "\t\t\tc_0 = Variable(torch.zeros(1, self.batch_size, self.hidden_size).cuda()) # Initial cell state of the LSTM\n",
    "\t\telse:\n",
    "\t\t\th_0 = Variable(torch.zeros(1, batch_size, self.hidden_size).cuda())\n",
    "\t\t\tc_0 = Variable(torch.zeros(1, batch_size, self.hidden_size).cuda())\n",
    "\t\toutput, (final_hidden_state, final_cell_state) = self.lstm(input, (h_0, c_0))\n",
    "\t\tfinal_output = self.label(final_hidden_state[-1]) # final_hidden_state.size() = (1, batch_size, hidden_size) & final_output.size() = (batch_size, output_size)\n",
    "\t\t\n",
    "\t\treturn final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torchtext.data' has no attribute 'Field'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-880152eedf2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-887316bb93c0>\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(test_sen)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mtokenize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mTEXT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequential\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_lengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfix_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0mLABEL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLabelField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMDB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLABEL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torchtext.data' has no attribute 'Field'"
     ]
    }
   ],
   "source": [
    "TEXT, vocab_size, word_embeddings, train_iter, valid_iter, test_iter = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 2e-5\n",
    "batch_size = 32\n",
    "output_size = 2\n",
    "hidden_size = 256\n",
    "embedding_length = 300\n",
    "\n",
    "model = LSTMClassifier(batch_size, output_size, hidden_size, vocab_size, embedding_length, word_embeddings)\n",
    "loss_fn = F.cross_entropy\n",
    "\n",
    "for epoch in range(10):\n",
    "    train_loss, train_acc = train_model(model, train_iter, epoch)\n",
    "    val_loss, val_acc = eval_model(model, valid_iter)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02}, Train Loss: {train_loss:.3f}, Train Acc: {train_acc:.2f}%, Val. Loss: {val_loss:3f}, Val. Acc: {val_acc:.2f}%')\n",
    "    \n",
    "test_loss, test_acc = eval_model(model, test_iter)\n",
    "print(f'Test Loss: {test_loss:.3f}, Test Acc: {test_acc:.2f}%')\n",
    "\n",
    "''' Let us now predict the sentiment on a single sentence just for the testing purpose. '''\n",
    "test_sen1 = \"This is one of the best creation of Nolan. I can say, it's his magnum opus. Loved the soundtrack and especially those creative dialogues.\"\n",
    "test_sen2 = \"Ohh, such a ridiculous movie. Not gonna recommend it to anyone. Complete waste of time and money.\"\n",
    "\n",
    "test_sen1 = TEXT.preprocess(test_sen1)\n",
    "test_sen1 = [[TEXT.vocab.stoi[x] for x in test_sen1]]\n",
    "\n",
    "test_sen2 = TEXT.preprocess(test_sen2)\n",
    "test_sen2 = [[TEXT.vocab.stoi[x] for x in test_sen2]]\n",
    "\n",
    "test_sen = np.asarray(test_sen1)\n",
    "test_sen = torch.LongTensor(test_sen)\n",
    "test_tensor = Variable(test_sen, volatile=True)\n",
    "test_tensor = test_tensor.cuda()\n",
    "model.eval()\n",
    "output = model(test_tensor, 1)\n",
    "out = F.softmax(output, 1)\n",
    "if (torch.argmax(out[0]) == 1):\n",
    "    print (\"Sentiment: Positive\")\n",
    "else:\n",
    "    print (\"Sentiment: Negative\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM (https://www.analyticsvidhya.com/blog/2020/01/first-text-classification-in-pytorch/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheme = pd.read_csv('./data/_PHEME_text_AVGw2v.csv').drop(['token'],axis=1)\n",
    "pheme_y = pd.read_csv('./data/_PHEME_target.csv').target\n",
    "pheme_event = pd.read_csv('./data/_PHEME_text.csv').Event\n",
    "\n",
    "ext = pd.read_csv('./data/_PHEMEext_text_AVGw2v.csv').drop(['token'],axis=1)\n",
    "ext_y = pd.read_csv('./data/_PHEMEext_text.csv').target\n",
    "ext_event = pd.read_csv('./data/_PHEMEext_text.csv').Event\n",
    "\n",
    "rhi = pd.read_csv('./data/_RHI_text_AVGw2v.csv').drop(['token'],axis=1)\n",
    "rhi_y = pd.read_csv('./data/_RHI_target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deal with tensors\n",
    "import torch   \n",
    "\n",
    "#handling text data\n",
    "from torchtext import data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reproducing same results\n",
    "SEED = 2019\n",
    "\n",
    "#Torch\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "#Cuda algorithms\n",
    "torch.backends.cudnn.deterministic = True  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torchtext.data' has no attribute 'Field'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d79e44260e49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTEXT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'spacy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minclude_lengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mLABEL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLabelField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torchtext.data' has no attribute 'Field'"
     ]
    }
   ],
   "source": [
    "TEXT = data.Field(tokenize='spacy',batch_first=True,include_lengths=True)\n",
    "LABEL = data.LabelField(dtype = torch.float,batch_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# https://colab.research.google.com/drive/1cpn6pk2J4liha9jgDLNWhEWeWJb2cdch?usp=sharing#scrollTo=tgWpYREtQns9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Field' from 'torchtext.data' (/Users/june/miniconda3/envs/rosetta/lib/python3.8/site-packages/torchtext/data/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-72f689523530>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Preliminaries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mField\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTabularDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBucketIterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Field' from 'torchtext.data' (/Users/june/miniconda3/envs/rosetta/lib/python3.8/site-packages/torchtext/data/__init__.py)"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Preliminaries\n",
    "\n",
    "from torchtext.data import Field, TabularDataset, BucketIterator\n",
    "\n",
    "# Models\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "# Training\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# https://blog.floydhub.com/long-short-term-memory-from-zero-to-hero-with-pytorch/ (AvgW2V vectors to LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheme = pd.read_csv('./data/_PHEME_text_AVGw2v.csv').drop(['token'],axis=1)\n",
    "pheme_text = pd.read_csv('./data/_PHEME_text.csv').text\n",
    "pheme_y = pd.read_csv('./data/_PHEME_target.csv').target\n",
    "pheme_event = pd.read_csv('./data/_PHEME_text.csv').Event\n",
    "\n",
    "ext = pd.read_csv('./data/_PHEMEext_text_AVGw2v.csv').drop(['token'],axis=1)\n",
    "ext_y = pd.read_csv('./data/_PHEMEext_text.csv').target\n",
    "ext_event = pd.read_csv('./data/_PHEMEext_text.csv').Event\n",
    "\n",
    "rhi = pd.read_csv('./data/_RHI_text_AVGw2v.csv').drop(['token'],axis=1)\n",
    "rhi_y = pd.read_csv('./data/_RHI_target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = pheme.values\n",
    "train_labels = np.array(pheme_y)\n",
    "test_sentences = ext.values\n",
    "test_labels = np.array(ext_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Extracting labels from sentences\n",
    "# train_labels = [0 if x.split(' ')[0] == '__label__1' else 1 for x in train_file]\n",
    "# train_sentences = [x.split(' ', 1)[1][:-1].lower() for x in train_file]\n",
    "\n",
    "# test_labels = [0 if x.split(' ')[0] == '__label__1' else 1 for x in test_file]\n",
    "# test_sentences = [x.split(' ', 1)[1][:-1].lower() for x in test_file]\n",
    "\n",
    "# # Some simple cleaning of data\n",
    "# for i in range(len(train_sentences)):\n",
    "#     train_sentences[i] = re.sub('\\d','0',train_sentences[i])\n",
    "\n",
    "# for i in range(len(test_sentences)):\n",
    "#     test_sentences[i] = re.sub('\\d','0',test_sentences[i])\n",
    "\n",
    "# Modify URLs to <url>\n",
    "for i in range(len(train_sentences)):\n",
    "    if 'www.' in train_sentences[i] or 'http:' in train_sentences[i] or 'https:' in train_sentences[i] or '.com' in train_sentences[i]:\n",
    "        train_sentences[i] = re.sub(r\"([^ ]+(?<=\\.[a-z]{3}))\", \"<url>\", train_sentences[i])\n",
    "        \n",
    "for i in range(len(test_sentences)):\n",
    "    if 'www.' in test_sentences[i] or 'http:' in test_sentences[i] or 'https:' in test_sentences[i] or '.com' in test_sentences[i]:\n",
    "        test_sentences[i] = re.sub(r\"([^ ]+(?<=\\.[a-z]{3}))\", \"<url>\", test_sentences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_frac = 0.5 # 50% validation, 50% test\n",
    "split_id = int(split_frac * len(test_sentences))\n",
    "val_sentences, test_sentences = test_sentences[:split_id], test_sentences[split_id:]\n",
    "val_labels, test_labels = test_labels[:split_id], test_labels[split_id:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(torch.from_numpy(train_sentences), torch.from_numpy(train_labels))\n",
    "val_data = TensorDataset(torch.from_numpy(val_sentences), torch.from_numpy(val_labels))\n",
    "test_data = TensorDataset(torch.from_numpy(test_sentences), torch.from_numpy(test_labels))\n",
    "\n",
    "batch_size = 36\n",
    "\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class w2vLSTMnet(nn.Module):\n",
    "    def __init__(self, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
    "        super(w2vLSTMnet, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.lstm = nn.LSTM(embedding_length, hidden_size)\n",
    "\t\tself.label = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        # self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True)\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        batch_size = x.size(0)\n",
    "        x = x.long()\n",
    "        # embeds = self.embedding(x)\n",
    "        lstm_out, hidden = self.lstm(x, hidden)\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        out = self.sigmoid(out)\n",
    "        \n",
    "        out = out.view(batch_size, -1)\n",
    "        out = out[:,-1]\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device))\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_size = len(word2idx) + 1\n",
    "output_size = 1\n",
    "embedding_dim = 200\n",
    "hidden_dim = 300\n",
    "n_layers = 2\n",
    "\n",
    "model = w2vLSTMnet(output_size, embedding_dim, hidden_dim, n_layers)\n",
    "model.to(device)\n",
    "\n",
    "lr=0.005\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2479, -0.2071, -0.1009,  ..., -0.1315,  0.0691,  0.0240],\n",
      "        [-0.3277, -0.0378,  0.0541,  ..., -0.1889,  0.0005,  0.0583],\n",
      "        [-0.1066, -0.0538,  0.0317,  ..., -0.1781,  0.2298,  0.1307],\n",
      "        ...,\n",
      "        [-0.0132, -0.2491,  0.0972,  ..., -0.3312,  0.0225,  0.1964],\n",
      "        [-0.1428,  0.1684, -0.0373,  ...,  0.1296, -0.0436, -0.0444],\n",
      "        [ 0.1610, -0.0846,  0.0036,  ..., -0.0674,  0.0078,  0.1238]],\n",
      "       dtype=torch.float64)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "input must have 3 dimensions, got 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-a81019196842>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-cb370f38576b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, hidden)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# embeds = self.embedding(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mlstm_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    657\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[0;31m# See torch/nn/modules/module.py::_forward_unimplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m         self.check_hidden_size(hidden[0], self.get_expected_hidden_size(input, batch_sizes),\n\u001b[1;32m    607\u001b[0m                                'Expected hidden[0] size {}, got {}')\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mexpected_input_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mexpected_input_dim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m    199\u001b[0m                 'input must have {} dimensions, got {}'.format(\n\u001b[1;32m    200\u001b[0m                     expected_input_dim, input.dim()))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input must have 3 dimensions, got 2"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "counter = 0\n",
    "print_every = 1000\n",
    "clip = 5\n",
    "valid_loss_min = np.Inf\n",
    "\n",
    "model.train()\n",
    "for i in range(epochs):\n",
    "    h = model.init_hidden(batch_size)\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        counter += 1\n",
    "        h = tuple([e.data for e in h])\n",
    "        print(inputs)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        model.zero_grad()\n",
    "        output, h = model(inputs, h)\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        if counter%print_every == 0:\n",
    "            val_h = model.init_hidden(batch_size)\n",
    "            val_losses = []\n",
    "            model.eval()\n",
    "            for inp, lab in val_loader:\n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "                inp, lab = inp.to(device), lab.to(device)\n",
    "                out, val_h = model(inp, val_h)\n",
    "                val_loss = criterion(out.squeeze(), lab.float())\n",
    "                val_losses.append(val_loss.item())\n",
    "                \n",
    "            model.train()\n",
    "            print(\"Epoch: {}/{}...\".format(i+1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))\n",
    "            if np.mean(val_losses) <= valid_loss_min:\n",
    "                torch.save(model.state_dict(), './state_dict.pt')\n",
    "                print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,np.mean(val_losses)))\n",
    "                valid_loss_min = np.mean(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rosetta",
   "language": "python",
   "name": "rosetta"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}