{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zzunebye/Capstone-code-data/blob/main/_RumorEval_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5pLteIxD88o",
        "outputId": "696261be-017b-4f19-d295-4b690761b03f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "Mounted at ./MyDrive\n"
          ]
        }
      ],
      "source": [
        "# 실행시 등장하는 URL을 클릭하여 허용해주면 인증KEY가 나타난다. 복사하여 URL아래 빈칸에 붙여넣으면 마운트에 성공하게된다.\n",
        "from google.colab import drive\n",
        "drive.mount('./MyDrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSU42bHqFeZ2",
        "outputId": "d4dbf91f-a385-4bae-dff1-243f3e877933"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'MyDrive/MyDrive/Capstone/code_data'\n",
            "/content/MyDrive/MyDrive/Capstone/code_data\n"
          ]
        }
      ],
      "source": [
        "cd MyDrive/MyDrive/Capstone/code_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kzqWy-ubCmUn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from glob2 import glob\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FUNCTION TO FECTH TEXT FROM JSON DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fetchRawText(path, events, tweetType):\n",
        "    jsons = []\n",
        "    for i, event in enumerate(events):\n",
        "        jsons.append(glob('%s/%s/**/%s/*.json' % (path, event,tweetType)))\n",
        "    for i,d in enumerate(jsons): print(\"%s's length is %d\" %(events[i], len(d)))\n",
        "\n",
        "    targets = []\n",
        "    features = []\n",
        "    for index, dataset in enumerate(jsons):\n",
        "        targetEvent = []\n",
        "        dataEvent = []\n",
        "        count = 0  # help var\n",
        "        for jsonFile in dataset:\n",
        "            count += 1\n",
        "            if jsonFile.find(\"non-rumours\") == -1:\n",
        "                targetEvent.append(1)\n",
        "            else:\n",
        "                targetEvent.append(0)\n",
        "\n",
        "            with open(jsonFile, 'r') as f:\n",
        "                for l in f.readlines():\n",
        "                    if not l.strip():  # skip empty lines\n",
        "                        continue\n",
        "                    # print(jsonFile)\n",
        "                    json_data = json.loads(l)\n",
        "                    # print (json_data,\"\\n\\n\")\n",
        "                    dataEvent.append(json_data)\n",
        "        print(index, events[index], len(targetEvent), len(dataEvent))\n",
        "        targets.append(targetEvent)\n",
        "        features.append(dataEvent)\n",
        "\n",
        "    # print(\"\\nNumber of Events:\", len(targets))\n",
        "    # print(\"Number of tweets in the first event:\", len(targets[0]))\n",
        "\n",
        "    # targets은 targetEvent들을 리스트에 담은 것\n",
        "    target_list = []\n",
        "    for event in targets:\n",
        "        for elem in event:\n",
        "            target_list.append(elem)\n",
        "    target = pd.DataFrame(target_list, columns=[\"target\"])\n",
        "\n",
        "    extracted_features = []\n",
        "\n",
        "    extracted = []\n",
        "\n",
        "    for obj_list in features:\n",
        "        extracted_event = []\n",
        "        for obj in obj_list:\n",
        "            output_f = dict()\n",
        "            output_f['text'] = obj['text']\n",
        "            extracted_event.append(output_f)\n",
        "        extracted_features.append(extracted_event)\n",
        "\n",
        "    extracted_df = []\n",
        "    for i, data in enumerate(extracted_features):\n",
        "        temp = pd.DataFrame(data)\n",
        "        temp[\"Event\"] = events[i]\n",
        "        extracted_df.append(pd.DataFrame(temp))\n",
        "\n",
        "    final = pd.concat(extracted_df, ignore_index=True)\n",
        "    final = pd.concat([final, target], axis=1)\n",
        "    return final\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PHEME (5 Events)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "path = \"../pheme-rnr-dataset\"\n",
        "events = ['charliehebdo', 'ferguson',\n",
        "          'germanwings-crash', 'ottawashooting', 'sydneysiege']\n",
        "tweetType = 'source-tweet'\n",
        "jsons = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "charliehebdo's length is 2079\n",
            "ferguson's length is 1143\n",
            "germanwings-crash's length is 469\n",
            "ottawashooting's length is 890\n",
            "sydneysiege's length is 1221\n",
            "0 charliehebdo 2079 2079\n",
            "1 ferguson 1143 1143\n",
            "2 germanwings-crash 469 469\n",
            "3 ottawashooting 890 890\n",
            "4 sydneysiege 1221 1221\n"
          ]
        }
      ],
      "source": [
        "final = fetchRawText(path, events, tweetType)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "final.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "# final.to_csv('./data/_PHEME_text.csv', index = False)\n",
        "# target.to_csv('./data/_PHEME_target.csv', index = False)\n",
        "# # d = pd.read_csv(\"./data/_PHEME_text.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PHEME (Additional)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('../PHEME/all-rnr-annotated-threads/ebola-essien/rumours/521310417696858112/source-tweets/521310417696858112.json','r') as f:\n",
        "    s = f.read()\n",
        "    s = s.replace('\\t','')\n",
        "    s = s.replace('\\n','')\n",
        "    s = s.replace(',}','}')\n",
        "    s = s.replace(',]',']')\n",
        "    data = json.loads(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ebola-essien's length is 14\n",
            "prince-toronto's length is 233\n",
            "putinmissing's length is 238\n",
            "0 ebola-essien 14 14\n",
            "1 prince-toronto 233 233\n",
            "2 putinmissing 238 238\n"
          ]
        },
        {
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>Event</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Micheal Essien denying the Ebola rumours like ...</td>\n      <td>ebola-essien</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>No truth in internet rumours that I have contr...</td>\n      <td>ebola-essien</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Essien and his lawyers are considering to file...</td>\n      <td>ebola-essien</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Good news: The rumours that Michael Essien has...</td>\n      <td>ebola-essien</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Milan have stated that the reports about Essie...</td>\n      <td>ebola-essien</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "                                                text         Event  target\n0  Micheal Essien denying the Ebola rumours like ...  ebola-essien       1\n1  No truth in internet rumours that I have contr...  ebola-essien       1\n2  Essien and his lawyers are considering to file...  ebola-essien       1\n3  Good news: The rumours that Michael Essien has...  ebola-essien       1\n4  Milan have stated that the reports about Essie...  ebola-essien       1"
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "path = \"../PHEME/all-rnr-annotated-threads\"\n",
        "events = ['ebola-essien', 'prince-toronto', 'putinmissing']\n",
        "tweetType = 'source-tweets'\n",
        "jsons = []\n",
        "final = fetchRawText(path,events,tweetType)\n",
        "final.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "final.to_csv('./data/_PHEMEext_text.csv', index = False)\n",
        "# target.to_csv('./data/_PHEMEext_target.csv', index = False)\n",
        "# # d = pd.read_csv(\"./data/_PHEME_text.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ebola-essien's length is 28\n",
            "prince-toronto's length is 466\n",
            "putinmissing's length is 476\n"
          ]
        }
      ],
      "source": [
        "path = \"../PHEME/all-rnr-annotated-threads\"\n",
        "\n",
        "putinmissing_jsons = glob('../pheme-rumour-scheme-dataset/threads/en/putinmissing/**/source-tweets/*.json')\n",
        "germanwing_scrash_jsons = glob('../pheme-rnr-dataset/germanwings-crash/**/source-tweet/*.json')\n",
        "\n",
        "events = ['ebola-essien', 'prince-toronto', 'putinmissing']\n",
        "jsons = []\n",
        "\n",
        "for i, event in enumerate(events):\n",
        "    # print('%s/%s/*/*/source-tweets/*.json' % (path, event))\n",
        "    jsons.append(glob('%s/%s/**/**/source-tweets/*.json' % (path, event)))\n",
        "for i,d in enumerate(jsons): print(\"%s's length is %d\" %(events[i], len(d)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 ebola-essien 28 28\n",
            "1 prince-toronto 466 466\n",
            "2 putinmissing 476 476\n",
            "\n",
            "Number of Events: 3\n",
            "Number of tweets in the first event: 28\n"
          ]
        }
      ],
      "source": [
        "targets = []\n",
        "features = []\n",
        "for index, dataset in enumerate(jsons):\n",
        "    targetEvent = []\n",
        "    dataEvent = []\n",
        "    count = 0  # help var\n",
        "    for jsonFile in dataset:\n",
        "        count += 1\n",
        "        if jsonFile.find(\"non-rumours\") == -1:\n",
        "            targetEvent.append(1)\n",
        "        else:\n",
        "            targetEvent.append(0)\n",
        "\n",
        "        with open(jsonFile, 'r') as f:\n",
        "            for l in f.readlines():\n",
        "                if not l.strip():  # skip empty lines\n",
        "                    continue\n",
        "                json_data = json.loads(l)\n",
        "                # print (json_data,\"\\n\\n\")\n",
        "                dataEvent.append(json_data)\n",
        "    print(index, events[index], len(targetEvent), len(dataEvent))\n",
        "    targets.append(targetEvent)\n",
        "    features.append(dataEvent)\n",
        "\n",
        "print(\"\\nNumber of Events:\", len(targets))\n",
        "print(\"Number of tweets in the first event:\", len(targets[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# targets은 targetEvent들을 리스트에 담은 것\n",
        "target_list = []\n",
        "for event in targets:\n",
        "    for elem in event:\n",
        "        target_list.append(elem)\n",
        "target = pd.DataFrame(target_list, columns=[\"target\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "extracted_features = []\n",
        "\n",
        "extracted = []\n",
        "\n",
        "for obj_list in features:\n",
        "    extracted_event = []\n",
        "    for obj in obj_list:\n",
        "        output_f = dict()\n",
        "        output_f['text'] = obj['text']\n",
        "        extracted_event.append(output_f)\n",
        "    extracted_features.append(extracted_event)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "extracted_df = []\n",
        "for i, data in enumerate(extracted_features):\n",
        "    temp = pd.DataFrame(data)\n",
        "    temp[\"Event\"] = events[i]\n",
        "    extracted_df.append(pd.DataFrame(temp))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Event</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>",
            "text/plain": "Empty DataFrame\nColumns: [Event, target]\nIndex: []"
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final = pd.concat(extracted_df, ignore_index=True)\n",
        "final = pd.concat([final, target], axis=1)\n",
        "final.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOqgxhgf7r7b1nXDjRfAzrw",
      "include_colab_link": true,
      "name": "_RumorEval_data.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "rosetta",
      "language": "python",
      "name": "rosetta"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}