{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zzunebye/Capstone-code-data/blob/main/_RumorEval_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5pLteIxD88o",
        "outputId": "696261be-017b-4f19-d295-4b690761b03f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "Mounted at ./MyDrive\n"
          ]
        }
      ],
      "source": [
        "# 실행시 등장하는 URL을 클릭하여 허용해주면 인증KEY가 나타난다. 복사하여 URL아래 빈칸에 붙여넣으면 마운트에 성공하게된다.\n",
        "from google.colab import drive\n",
        "drive.mount('./MyDrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSU42bHqFeZ2",
        "outputId": "d4dbf91f-a385-4bae-dff1-243f3e877933"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'MyDrive/MyDrive/Capstone/code_data'\n",
            "/content/MyDrive/MyDrive/Capstone/code_data\n"
          ]
        }
      ],
      "source": [
        "cd MyDrive/MyDrive/Capstone/code_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kzqWy-ubCmUn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from glob2 import glob\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [],
      "source": [
        "path = \"../pheme-rnr-dataset\"\n",
        "events = ['charliehebdo', 'ferguson',\n",
        "          'germanwings-crash', 'ottawashooting', 'sydneysiege']\n",
        "jsons = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i, event in enumerate(events):\n",
        "    # print(i, event)\n",
        "    jsons.append(glob('%s/%s/*/*/source-tweet/*.json' % (path, event)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": "5"
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(jsons)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 charliehebdo 2079 2079\n",
            "1 ferguson 1143 1143\n",
            "2 germanwings-crash 469 469\n",
            "3 ottawashooting 890 890\n",
            "4 sydneysiege 1221 1221\n"
          ]
        }
      ],
      "source": [
        "targets = []\n",
        "features = []\n",
        "for index, dataset in enumerate(jsons):\n",
        "    targetEvent = []\n",
        "    dataEvent = []\n",
        "    count = 0  # help var\n",
        "    for jsonFile in dataset:\n",
        "        count += 1\n",
        "        if jsonFile.find(\"non-rumours\") == -1:\n",
        "            targetEvent.append(1)\n",
        "        else:\n",
        "            targetEvent.append(0)\n",
        "\n",
        "        with open(jsonFile, 'r') as f:\n",
        "            for l in f.readlines():\n",
        "                if not l.strip():  # skip empty lines\n",
        "                    continue\n",
        "                json_data = json.loads(l)\n",
        "                # print (json_data,\"\\n\\n\")\n",
        "                dataEvent.append(json_data)\n",
        "    print(index, events[index], len(targetEvent), len(dataEvent))\n",
        "    targets.append(targetEvent)\n",
        "    features.append(dataEvent)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [],
      "source": [
        "extracted_features = []\n",
        "\n",
        "extracted = []\n",
        "# total_tokens_l = []\n",
        "\n",
        "# Iterate through each tweet\n",
        "for obj_list in features:\n",
        "    extracted_event = []\n",
        "    for obj in obj_list:\n",
        "        output_f = dict()\n",
        "        # print(tweet_obj['text'])\n",
        "        output_f['text'] = obj['text']\n",
        "        # urls_dicts = obj['entities']['urls']\n",
        "        # output_f['verified'] = obj['user']['verified']\n",
        "        extracted_event.append(output_f)\n",
        "    extracted_features.append(extracted_event)\n",
        "# unk_tokens_l = list(set(total_tokens_l))\n",
        "# print(\"Number of total tokens appeared: {}\\nNumber of unique tokens appeared: {}\\n\".format(\n",
        "# len(total_tokens_l), len(unk_tokens_l)))  # number of tokens and unique tokens\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {},
      "outputs": [],
      "source": [
        "extracted_df = []\n",
        "for i, data in enumerate(extracted_features):\n",
        "    temp = pd.DataFrame(data)\n",
        "    temp[\"Event\"] = events[i]\n",
        "    extracted_df.append(pd.DataFrame(temp))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5802, 2)\n"
          ]
        },
        {
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>Event</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3785</th>\n      <td>UPDATED: Gunman on the loose after soldier sho...</td>\n      <td>ottawashooting</td>\n    </tr>\n    <tr>\n      <th>2380</th>\n      <td>The #Ferguson chief, the County chief, County ...</td>\n      <td>ferguson</td>\n    </tr>\n    <tr>\n      <th>876</th>\n      <td>\"Yo, Charlie Hebdo, I'm really sad for you, I'...</td>\n      <td>charliehebdo</td>\n    </tr>\n    <tr>\n      <th>4837</th>\n      <td>Seven people reportedly taken away on stretche...</td>\n      <td>sydneysiege</td>\n    </tr>\n    <tr>\n      <th>5587</th>\n      <td>My thoughts and prayers go out to the people a...</td>\n      <td>sydneysiege</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "                                                   text           Event\n3785  UPDATED: Gunman on the loose after soldier sho...  ottawashooting\n2380  The #Ferguson chief, the County chief, County ...        ferguson\n876   \"Yo, Charlie Hebdo, I'm really sad for you, I'...    charliehebdo\n4837  Seven people reportedly taken away on stretche...     sydneysiege\n5587  My thoughts and prayers go out to the people a...     sydneysiege"
          },
          "execution_count": 164,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(final.shape)\n",
        "final.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {},
      "outputs": [],
      "source": [
        "final.to_csv('./data/_PHEME_text.csv', index = False)\n",
        "# d = pd.read_csv(\"./data/_PHEME_text.csv\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOqgxhgf7r7b1nXDjRfAzrw",
      "include_colab_link": true,
      "name": "_RumorEval_data.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "x86VenvTest",
      "language": "python",
      "name": "venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}