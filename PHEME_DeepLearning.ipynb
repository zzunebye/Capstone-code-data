{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On top of the Embeddedings gained from Bertweet, I added simple Neural network to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_avg = pd.read_csv('./train_avg.csv')\n",
    "test_avg = pd.read_csv('./test_avg.csv')\n",
    "\n",
    "train_doc = pd.read_csv('./train_doc.csv')\n",
    "test_doc = pd.read_csv('./test_doc.csv')\n",
    "\n",
    "valid_avg = pd.read_csv('./valid_avg.csv')\n",
    "valid_doc = pd.read_csv('./valid_doc.csv')\n",
    "\n",
    "df_bertweet = pd.read_csv('./df_bertweet.csv')\n",
    "df_valid_bertweet = pd.read_csv('./df_valid_bertweet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in [train_avg, test_avg, train_doc, test_doc, valid_avg, valid_doc, df_bertweet, df_valid_bertweet]:\n",
    "    dataset.drop(['text','text_token','urls', 'urls_expanded','user_url'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data with BERTweet Embedding consists of 797 Dimensions: which are 767 Embeddings and 30 additional features\n",
    "\n",
    "### Other Dataset consists of 328 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the Train and test data of Averaged Word2Vec: (4912, 329)/(890, 329)\n",
      "Shape of the Train and test data of Doc2vec: (4912, 329)/(890, 329)\n",
      "\n",
      "Shape of the validation data of Avg: (328, 329)\n",
      "Shape of the validation data of Doc2vec: (328, 329)\n",
      "\n",
      "Shape of the data w/ BERTweet: (5802, 797)\n",
      "\n",
      "Shape of the validation data w/ BERTweet: (390, 797)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the Train and test data of Averaged Word2Vec: {}/{}\".format(train_avg.shape, test_avg.shape))\n",
    "print(\"Shape of the Train and test data of Doc2vec: {}/{}\".format(train_doc.shape, test_doc.shape))\n",
    "print(\"\\nShape of the validation data of Avg: {}\".format(valid_avg.shape))\n",
    "print(\"Shape of the validation data of Doc2vec: {}\".format(valid_doc.shape))\n",
    "print(\"\\nShape of the data w/ BERTweet: {}\".format(df_bertweet.shape))\n",
    "print(\"\\nShape of the validation data w/ BERTweet: {}\".format(df_valid_bertweet.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Target values from the dataset\n",
    "train_y = train_avg.isRumor\n",
    "test_y = test_avg.isRumor\n",
    "valid_y = valid_avg.isRumor\n",
    "df_bertweet_y = df_bertweet.isRumor\n",
    "df_valid_bertweet_y = df_valid_bertweet.isRumor\n",
    "for dataset in [train_avg, test_avg, train_doc, test_doc, valid_avg, valid_doc, df_bertweet, df_valid_bertweet]:\n",
    "    dataset.drop(['isRumor'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4912,) (890,) (328,) (5802,) (390,)\n"
     ]
    }
   ],
   "source": [
    "print(train_y.shape, test_y.shape, valid_y.shape, df_bertweet_y.shape, df_valid_bertweet_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base dataset are the baseline feature set to be inputted to the model\n",
    "# Here, 4 features are dropped for their lack of predictive power\n",
    "\n",
    "train_avg_base = train_avg.drop(['hasURL', 'hasUserURL', 'isNotOnlyText', 'char_count'],axis=1)\n",
    "test_avg_base = test_avg.drop(['hasURL', 'hasUserURL', 'isNotOnlyText', 'char_count'],axis=1)\n",
    "valid_avg_base = valid_avg.drop(['hasURL', 'hasUserURL', 'isNotOnlyText', 'char_count'],axis=1)\n",
    "train_doc_base = train_doc.drop(['hasURL', 'hasUserURL', 'isNotOnlyText', 'char_count'],axis=1)\n",
    "test_doc_base = test_doc.drop(['hasURL', 'hasUserURL', 'isNotOnlyText', 'char_count'],axis=1)\n",
    "valid_doc_base = valid_doc.drop(['hasURL', 'hasUserURL', 'isNotOnlyText', 'char_count'],axis=1)\n",
    "bertweet_base = df_bertweet.drop(['hasURL', 'hasUserURL', 'isNotOnlyText', 'char_count'],axis=1)\n",
    "bertweet_valid_base = df_valid_bertweet.drop(['hasURL', 'hasUserURL', 'isNotOnlyText', 'char_count'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Noun</th>\n      <th>Verb</th>\n      <th>Adjective</th>\n      <th>Pronoun</th>\n      <th>FirstPersonPronoun</th>\n      <th>SecondPersonPronoun</th>\n      <th>ThirdPersonPronoun</th>\n      <th>Adverb</th>\n      <th>Numeral</th>\n      <th>Conjunction_inj</th>\n      <th>...</th>\n      <th>758</th>\n      <th>759</th>\n      <th>760</th>\n      <th>761</th>\n      <th>762</th>\n      <th>763</th>\n      <th>764</th>\n      <th>765</th>\n      <th>766</th>\n      <th>767</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0.080576</td>\n      <td>-0.049174</td>\n      <td>0.014364</td>\n      <td>0.135755</td>\n      <td>0.120841</td>\n      <td>-0.019499</td>\n      <td>-0.092559</td>\n      <td>0.037895</td>\n      <td>-0.026119</td>\n      <td>-0.037888</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.065754</td>\n      <td>-0.008325</td>\n      <td>0.039999</td>\n      <td>0.267778</td>\n      <td>0.049828</td>\n      <td>0.036786</td>\n      <td>-0.076806</td>\n      <td>0.090258</td>\n      <td>-0.006316</td>\n      <td>0.135195</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>4</td>\n      <td>8</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0.037640</td>\n      <td>-0.017665</td>\n      <td>0.026855</td>\n      <td>0.044829</td>\n      <td>0.037694</td>\n      <td>-0.000555</td>\n      <td>-0.025542</td>\n      <td>0.087989</td>\n      <td>0.146719</td>\n      <td>0.105573</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>-0.013915</td>\n      <td>-0.057492</td>\n      <td>0.044381</td>\n      <td>0.163093</td>\n      <td>-0.009258</td>\n      <td>0.032880</td>\n      <td>-0.051174</td>\n      <td>0.089870</td>\n      <td>0.100986</td>\n      <td>-0.036360</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>...</td>\n      <td>-0.001629</td>\n      <td>-0.001269</td>\n      <td>0.042457</td>\n      <td>0.149599</td>\n      <td>0.114457</td>\n      <td>0.021848</td>\n      <td>-0.135230</td>\n      <td>0.047658</td>\n      <td>0.151301</td>\n      <td>-0.004796</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5797</th>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0.029064</td>\n      <td>0.093296</td>\n      <td>0.016626</td>\n      <td>0.213296</td>\n      <td>-0.138641</td>\n      <td>0.002770</td>\n      <td>0.038687</td>\n      <td>-0.118342</td>\n      <td>0.048587</td>\n      <td>-0.007331</td>\n    </tr>\n    <tr>\n      <th>5798</th>\n      <td>5</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>...</td>\n      <td>-0.060785</td>\n      <td>0.063776</td>\n      <td>0.005694</td>\n      <td>0.109999</td>\n      <td>0.124272</td>\n      <td>0.051577</td>\n      <td>0.152288</td>\n      <td>0.192712</td>\n      <td>-0.036597</td>\n      <td>0.031372</td>\n    </tr>\n    <tr>\n      <th>5799</th>\n      <td>4</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.101352</td>\n      <td>0.036456</td>\n      <td>0.062657</td>\n      <td>0.156872</td>\n      <td>0.106964</td>\n      <td>0.037552</td>\n      <td>-0.016714</td>\n      <td>0.061652</td>\n      <td>0.222777</td>\n      <td>-0.101658</td>\n    </tr>\n    <tr>\n      <th>5800</th>\n      <td>7</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>...</td>\n      <td>-0.019152</td>\n      <td>-0.143544</td>\n      <td>0.130950</td>\n      <td>0.113090</td>\n      <td>0.227164</td>\n      <td>-0.087948</td>\n      <td>-0.073185</td>\n      <td>-0.042964</td>\n      <td>0.112651</td>\n      <td>-0.094290</td>\n    </tr>\n    <tr>\n      <th>5801</th>\n      <td>5</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>-0.061934</td>\n      <td>0.104405</td>\n      <td>0.069960</td>\n      <td>0.083150</td>\n      <td>0.126365</td>\n      <td>0.019983</td>\n      <td>0.090401</td>\n      <td>0.120009</td>\n      <td>0.011764</td>\n      <td>-0.038472</td>\n    </tr>\n  </tbody>\n</table>\n<p>5802 rows × 792 columns</p>\n</div>",
      "text/plain": [
       "      Noun  Verb  Adjective  Pronoun  FirstPersonPronoun  SecondPersonPronoun  \\\n",
       "0        6     3          0        0                   0                    0   \n",
       "1        2     1          2        0                   0                    0   \n",
       "2        3     4          8        0                   0                    0   \n",
       "3        5     5          0        0                   0                    0   \n",
       "4        7     2          0        0                   0                    0   \n",
       "...    ...   ...        ...      ...                 ...                  ...   \n",
       "5797     2     2          1        1                   0                    1   \n",
       "5798     5     2          1        1                   1                    0   \n",
       "5799     4     3          2        1                   0                    0   \n",
       "5800     7     3          2        0                   0                    0   \n",
       "5801     5     4          0        0                   0                    0   \n",
       "\n",
       "      ThirdPersonPronoun  Adverb  Numeral  Conjunction_inj  ...       758  \\\n",
       "0                      0       0        0                2  ...  0.080576   \n",
       "1                      0       0        0                1  ...  0.065754   \n",
       "2                      0       1        0                2  ...  0.037640   \n",
       "3                      0       0        0                0  ... -0.013915   \n",
       "4                      0       0        0                2  ... -0.001629   \n",
       "...                  ...     ...      ...              ...  ...       ...   \n",
       "5797                   0       0        0                2  ...  0.029064   \n",
       "5798                   0       0        0                2  ... -0.060785   \n",
       "5799                   1       0        0                1  ...  0.101352   \n",
       "5800                   0       0        0                3  ... -0.019152   \n",
       "5801                   0       0        0                1  ... -0.061934   \n",
       "\n",
       "           759       760       761       762       763       764       765  \\\n",
       "0    -0.049174  0.014364  0.135755  0.120841 -0.019499 -0.092559  0.037895   \n",
       "1    -0.008325  0.039999  0.267778  0.049828  0.036786 -0.076806  0.090258   \n",
       "2    -0.017665  0.026855  0.044829  0.037694 -0.000555 -0.025542  0.087989   \n",
       "3    -0.057492  0.044381  0.163093 -0.009258  0.032880 -0.051174  0.089870   \n",
       "4    -0.001269  0.042457  0.149599  0.114457  0.021848 -0.135230  0.047658   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5797  0.093296  0.016626  0.213296 -0.138641  0.002770  0.038687 -0.118342   \n",
       "5798  0.063776  0.005694  0.109999  0.124272  0.051577  0.152288  0.192712   \n",
       "5799  0.036456  0.062657  0.156872  0.106964  0.037552 -0.016714  0.061652   \n",
       "5800 -0.143544  0.130950  0.113090  0.227164 -0.087948 -0.073185 -0.042964   \n",
       "5801  0.104405  0.069960  0.083150  0.126365  0.019983  0.090401  0.120009   \n",
       "\n",
       "           766       767  \n",
       "0    -0.026119 -0.037888  \n",
       "1    -0.006316  0.135195  \n",
       "2     0.146719  0.105573  \n",
       "3     0.100986 -0.036360  \n",
       "4     0.151301 -0.004796  \n",
       "...        ...       ...  \n",
       "5797  0.048587 -0.007331  \n",
       "5798 -0.036597  0.031372  \n",
       "5799  0.222777 -0.101658  \n",
       "5800  0.112651 -0.094290  \n",
       "5801  0.011764 -0.038472  \n",
       "\n",
       "[5802 rows x 792 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertweet_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위의 데이터들을 torchTensor로 변환한뒤 Unsqueeze한다.\n",
    "# 이후 TensorDataset를 생성한다. (X, y 값을 담은 텐서들을 인자로 넘겨줌)\n",
    "\n",
    "tensor_x = torch.Tensor(np.array(bertweet_base))\n",
    "tensor_y = torch.Tensor(np.array(df_bertweet_y))\n",
    "\n",
    "tensor_x = tensor_x.unsqueeze(1)\n",
    "tensor_y = tensor_y.unsqueeze(1)\n",
    "\n",
    "task1_dataset = TensorDataset(tensor_x,tensor_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the Inputs are:  5802 5222 580\n",
      "5222 580\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터 / 테스트 데이터를 torch.utils.data.random_split()를 통해서 나눠준다\n",
    "input_len = len(task1_dataset)\n",
    "test_ratio = 0.1\n",
    "test_size = int(input_len * test_ratio)\n",
    "train_size = input_len - test_size\n",
    "\n",
    "print(\"Length of the Inputs are: \",input_len, train_size, test_size)\n",
    "\n",
    "train_data, test_data = torch.utils.data.random_split(task1_dataset, (train_size, test_size))\n",
    "print(len(train_data), len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에서 생성한 훈련/테스트 데이터를 각각 DataLoader를 호출해 데이터 로더를 생성한다.\n",
    "# 참고로 이 코드에서는 task1_dataset -> tensor_x/y -> train_avg_base/train_y를 사용하고 있다.\n",
    "task1_train_dataloader = DataLoader(train_data, batch_size=6, shuffle=True, num_workers=2)\n",
    "task1_test_dataloader = DataLoader(test_data, batch_size=6, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FC_net을 생성 -> \n",
    "class FC_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FC_net, self).__init__() # 1*20\n",
    "        self.fc1 = nn.Linear(792, 130) # 420\n",
    "        self.fc2 = nn.Linear(130, 60)\n",
    "        self.fc3 = nn.Linear(60, 1)\n",
    "\n",
    "        self.drop_2 = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "        \n",
    "task1_model = FC_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of FC_net(\n",
      "  (fc1): Linear(in_features=792, out_features=130, bias=True)\n",
      "  (fc2): Linear(in_features=130, out_features=60, bias=True)\n",
      "  (fc3): Linear(in_features=60, out_features=1, bias=True)\n",
      "  (drop_2): Dropout(p=0.2, inplace=False)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "print(task1_model.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "# optimizer = optim.SGD(task1_model.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(task1_model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "train_accuracy = []\n",
    "\n",
    "prev_loss = 10\n",
    "PATH = \"./state_dict_BERT_fc.pt\"\n",
    "best_acc = 10.0\n",
    "num_epochs = 10\n",
    "\n",
    "val_corrects_list = []\n",
    "val_loss_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "Train) Loss: 0.3190 Acc: 0.0042\n",
      "Epoch 1/9\n",
      "----------\n",
      "Train) Loss: 5.4705 Acc: 0.6325\n",
      "Epoch 2/9\n",
      "----------\n",
      "Train) Loss: 5.7149 Acc: 0.6568\n",
      "Epoch 3/9\n",
      "----------\n",
      "Train) Loss: 5.7213 Acc: 0.6568\n",
      "Epoch 4/9\n",
      "----------\n",
      "Train) Loss: 5.7149 Acc: 0.6568\n",
      "Epoch 5/9\n",
      "----------\n",
      "Train) Loss: 5.7213 Acc: 0.6568\n",
      "Epoch 6/9\n",
      "----------\n",
      "Train) Loss: 5.7149 Acc: 0.6568\n",
      "Epoch 7/9\n",
      "----------\n",
      "Train) Loss: 5.7149 Acc: 0.6568\n",
      "Epoch 8/9\n",
      "----------\n",
      "Train) Loss: 5.7213 Acc: 0.6568\n",
      "Epoch 9/9\n",
      "----------\n",
      "Train) Loss: 5.7213 Acc: 0.6568\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "    print('-' * 10)\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    task1_model.train()  # Set model to training mode\n",
    "    for i, data in enumerate(task1_train_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        # inputs, labels = inputs.float(), labels.long()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = task1_model(inputs)\n",
    "\n",
    "        labels = labels.unsqueeze(1).float()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()    \n",
    "\n",
    "        running_loss += loss.item()\n",
    "        running_corrects += torch.sum(outputs == labels.data)\n",
    "        # print(running_corrects)\n",
    "\n",
    "    epoch_loss = running_loss / train_size\n",
    "    epoch_acc = running_corrects.double() / train_size\n",
    "    train_loss.append(epoch_loss)\n",
    "    train_accuracy.append(epoch_acc)\n",
    "\n",
    "    print('Train) Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
    "\n",
    "    # if epoch_loss < best_acc:\n",
    "    #     # print(\"prev_loss: {:.5f}\".format(prev_loss))\n",
    "    #     # print(\"loss: {:.5f}\".format(loss))\n",
    "    #     print(\"Saving the best model w/ loss {:.4f}\".format(epoch_loss))\n",
    "    #     torch.save(task1_model.state_dict(),PATH)\n",
    "    #     best_acc = epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the test dataset is: 68 %\n",
      "Loss of validation set: 5.20883\n"
     ]
    }
   ],
   "source": [
    "task1_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "test_loss = 0\n",
    "outputs_list = []\n",
    "y_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    val_loss = 0\n",
    "\n",
    "    for i, data in enumerate(task1_test_dataloader):\n",
    "        x, y = data\n",
    "        x, y = x.float(), y.long()\n",
    "        outputs = task1_model(x)\n",
    "        loss = criterion(outputs, y.unsqueeze(1).float())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        outputs_list.append(predicted[:])\n",
    "        total += y.size(0)\n",
    "        correct += (predicted == y).double().sum().item()\n",
    "        val_loss += loss.item()\n",
    "        y_list.append(y)\n",
    "\n",
    "print('Accuracy of the test dataset is: %d %%' % (100 * correct / total))\n",
    "print(\"Loss of validation set: {:.5f}\".format((val_loss / test_size)))\n",
    "acc = (100 * correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_macos_venv",
   "language": "python",
   "name": "tensorflow_macos_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}