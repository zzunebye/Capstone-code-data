{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행시 등장하는 URL을 클릭하여 허용해주면 인증KEY가 나타난다. 복사하여 URL아래 빈칸에 붙여넣으면 마운트에 성공하게된다.\n",
    "from google.colab import drive\n",
    "drive.mount('./MyDrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd MyDrive/MyDrive/Capstone/code_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/june/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/june/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob2 import glob\n",
    "import json\n",
    "\n",
    "import matplotlib as plt\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "import gensim\n",
    "import gensim.models.word2vec as w2v\n",
    "from gensim.test.utils import common_texts\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "\n",
    "from nltk import SnowballStemmer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import emoji\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', 400)\n",
    "# pd.set_option('display.max_rowwidth', 100)\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmt = WordNetLemmatizer()\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "freqdist = nltk.FreqDist()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tweet_tokenizer = TweetTokenizer()\n",
    "\n",
    "\"\"\" Replaces contractions from a string to their equivalents \"\"\"\n",
    "contraction_patterns = [ (r'won\\'t', 'will not'), (r'can\\'t', 'cannot'), (r'i\\'m', 'i am'), (r'ain\\'t', 'is not'), (r'(\\w+)\\'ll', '\\g<1> will'), (r'(\\w+)n\\'t', '\\g<1> not'),\n",
    "                         (r'(\\w+)\\'ve', '\\g<1> have'), (r'(\\w+)\\'s', '\\g<1> is'), (r'(\\w+)\\'re', '\\g<1> are'), (r'(\\w+)\\'d', '\\g<1> would'), (r'&', 'and'), (r'dammit', 'damn it'), (r'dont', 'do not'), (r'wont', 'will not'), \n",
    "                         (r'i\\'d', 'i would'), (r'I\\'d', 'I would'), (r'he\\'d', 'he would'), (r'she\\'d', 'she would'), (r'they\\'d', 'they would'), (r'we\\'d', 'we would')]\n",
    "def replaceContraction(text):\n",
    "    patterns = [(re.compile(regex), repl) for (regex, repl) in contraction_patterns]\n",
    "    for (pattern, repl) in patterns:\n",
    "        (text, count) = re.subn(pattern, repl, text)\n",
    "    return text\n",
    "\n",
    "def capitalratio(tweet_text):\n",
    "    uppers = [l for l in tweet_text if l.isupper()]\n",
    "    capitalratio = len(uppers) / len(tweet_text)\n",
    "    return capitalratio \n",
    "\n",
    "def getTokenization(sent):\n",
    "    tweet_tokens = []\n",
    "    sent = sent.lower()\n",
    "    sent = replaceContraction(sent)\n",
    "\n",
    "    sent = re.sub(r\"http\\S+\", \"*\", sent) # http link -> '*'\n",
    "    # sent = re.sub(r\"@\\S+\", \"@\", sent)   # mention -> '@'\n",
    "    sent = re.sub(r\"@[^\\s]+\", \"@\", sent)   # mention -> '@'\n",
    "    sent = re.sub(r\"(#)(\\S+)\", r'\\1 \\2', sent) \n",
    "\n",
    "    sent = re.sub(r'([^\\s\\w@#\\*]|_)+', '', sent) # Erasing Special Characters\n",
    "    # sent = re.sub('@[^\\s]+','atUser',sent)\n",
    "    # sent = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','url',sent)\n",
    "    # sent = re.sub(r'#([^\\s]+)', r'\\1', sent)\n",
    "\n",
    "\n",
    "    # sent = re.sub('', '', sent.lower())\n",
    "    # sent = [tweet_tokenizer.tokenize(sent)]\n",
    "    sent = tweet_tokenizer.tokenize(sent)\n",
    "    sent = [stemmer.stem(token) for token in sent]\n",
    "    sent = [lmt.lemmatize(token) for token in sent]\n",
    "\n",
    "    temp = [token for token in sent if not token in stop_words]\n",
    "    url=0\n",
    "    for token in temp:\n",
    "        if token.startswith('*'):\n",
    "            url+=1\n",
    "    # tweet_tokens.append([temp])\n",
    "    # tweet_tokens.append(tweet_tokenizer.tokenize(sent))\n",
    "    # df_tokens = pd.DataFrame(tweet_tokens, columns=['token'])\n",
    "    return temp, url\n",
    "\n",
    "def extract_urls(entities_dicts):\n",
    "    if len(entities_dicts) < 1:\n",
    "        return 0\n",
    "    if len(entities_dicts) == 1:\n",
    "        return 1\n",
    "    if len(entities_dicts) == 2:\n",
    "        return 2\n",
    "\n",
    "    # urls = []\n",
    "    # urls_expanded = []\n",
    "\n",
    "    # key = 'url'\n",
    "    # key2 = 'expanded_url'\n",
    "    # # print(len(entities_dict))\n",
    "    # for i in entities_dicts:\n",
    "    #     urls.append(i[key])\n",
    "    #     urls_expanded.append(i[key2])\n",
    "    # return 1, urls, urls_expanded\n",
    "\n",
    "def getposcount(tokens):\n",
    "    postag = []\n",
    "    poscount = {}\n",
    "    poscount['Noun']=0\n",
    "    poscount['Verb']=0\n",
    "    poscount['Adjective'] = 0\n",
    "    poscount['Pronoun']=0\n",
    "    poscount['FirstPersonPronoun']=0\n",
    "    poscount['SecondPersonPronoun']=0\n",
    "    poscount['ThirdPersonPronoun']=0\n",
    "    poscount['Adverb']=0\n",
    "    poscount['Numeral']=0\n",
    "    poscount['Conjunction_inj']=0\n",
    "    poscount['Particle']=0\n",
    "    poscount['Determiner']=0\n",
    "    poscount['Modal']=0\n",
    "    poscount['Whs']=0\n",
    "\n",
    "    Nouns = {'NN','NNS','NNP','NNPS'}\n",
    "    Adverbs = {'RB','RBR','RBS'}\n",
    "    Whs = {'WDT','WP','WRB'} # Composition of wh-determiner(that,what), wh-pronoun(who), wh-adverb(how)\n",
    "    Verbs={'VB','VBP','VBZ','VBN','VBG','VBD','To'}\n",
    "    first_person_pronouns=['i','I','me','my','mine','we','us','our','ours'] #'i',\n",
    "    second_person_pronouns=['you','your','yours', 'ya']\n",
    "    third_person_pronouns=['he','she','it','him','her','it','his','hers','its','they','them','their','theirs']\n",
    "    test_auxiliary=['be','will','have','am','is','was','were','can','could','dare','did','may','might','must','ought','shall','should','would']\n",
    "    test_tentat=['maybe','perhaps','possibly','probably','guess']\n",
    "    test_certain=['always','never', \"can't\", 'cannot']\n",
    "\n",
    "    for word in tokens:\n",
    "        w_lower=word.lower()\n",
    "        if w_lower in first_person_pronouns:\n",
    "            poscount['FirstPersonPronoun']+=1\n",
    "        elif w_lower in second_person_pronouns:\n",
    "            poscount['SecondPersonPronoun']+=1\n",
    "        elif w_lower in third_person_pronouns:\n",
    "            poscount['ThirdPersonPronoun']+=1\n",
    "        \n",
    "    for word in tokens:\n",
    "        w_lower=word.lower()\n",
    "        if w_lower in test_auxiliary:\n",
    "            poscount['test_auxiliary']+=1\n",
    "        elif w_lower in test_tentat:\n",
    "            poscount['test_tentat']+=1\n",
    "        elif w_lower in test_certain:\n",
    "            poscount['test_certain']+=1\n",
    "\n",
    "    postag = nltk.pos_tag(tokens)\n",
    "    for g1 in postag:\n",
    "        if g1[1] in Nouns:\n",
    "            poscount['Noun'] += 1\n",
    "        elif g1[1] in Verbs:\n",
    "            poscount['Verb']+= 1\n",
    "        elif g1[1]=='ADJ'or g1[1]=='JJ':\n",
    "            poscount['Adjective']+=1\n",
    "        elif g1[1]=='PRP' or g1[1]=='PRON' or g1[1]=='PRP$':\n",
    "            poscount['Pronoun']+=1\n",
    "        elif g1[1] in Adverbs or g1[1]=='ADV':\n",
    "            poscount['Adverb']+=1\n",
    "        elif g1[1]=='CD':\n",
    "            poscount['Numeral']+=1\n",
    "        elif g1[1]=='CC' or g1[1]=='IN':\n",
    "            poscount['Conjunction_inj']+=1\n",
    "        elif g1[1]=='RP':\n",
    "            poscount['Particle']+=1\n",
    "        elif g1[1]=='MD':\n",
    "            poscount['Modal']+=1\n",
    "        elif g1[1]=='DT':\n",
    "            poscount['Determiner']+=1\n",
    "        elif g1[1] in Whs:\n",
    "            poscount['Whs']+=1\n",
    "    return poscount\n",
    "\n",
    "def fetchRawText(path, events, tweetType):\n",
    "    jsons = []\n",
    "    for i, event in enumerate(events):\n",
    "        jsons.append(glob('%s/%s/**/%s/*.json' % (path, event,tweetType)))\n",
    "    for i,d in enumerate(jsons): print(\"%s's length is %d\" %(events[i], len(d)))\n",
    "\n",
    "    targets = []\n",
    "    features = []\n",
    "    for index, dataset in enumerate(jsons):\n",
    "        targetEvent = []\n",
    "        dataEvent = []\n",
    "        count = 0  # help var\n",
    "        for jsonFile in dataset:\n",
    "            count += 1\n",
    "            if jsonFile.find(\"non-rumours\") == -1:\n",
    "                targetEvent.append(1)\n",
    "            else:\n",
    "                targetEvent.append(0)\n",
    "\n",
    "            with open(jsonFile, 'r') as f:\n",
    "                for l in f.readlines():\n",
    "                    if not l.strip():  # skip empty lines\n",
    "                        continue\n",
    "                    try:\n",
    "                        json_data = json.loads(l)\n",
    "                    except:\n",
    "                        print (l,\"\\n\\n\")\n",
    "                        break\n",
    "                    dataEvent.append(json_data)\n",
    "        print(index, events[index], len(targetEvent), len(dataEvent))\n",
    "        targets.append(targetEvent)\n",
    "        features.append(dataEvent)\n",
    "\n",
    "    # print(\"\\nNumber of Events:\", len(targets))\n",
    "    # print(\"Number of tweets in the first event:\", len(targets[0]))\n",
    "\n",
    "    # targets은 targetEvent들을 리스트에 담은 것\n",
    "    target_list = []\n",
    "    for event in targets:\n",
    "        for elem in event:\n",
    "            target_list.append(elem)\n",
    "    target = pd.DataFrame(target_list, columns=[\"target\"])\n",
    "\n",
    "    extracted_features = []\n",
    "\n",
    "    extracted = []\n",
    "\n",
    "    for obj_list in features:\n",
    "        extracted_event = []\n",
    "        for obj in obj_list:\n",
    "            output_f = dict()\n",
    "            output_f['text'] = obj['text']\n",
    "            urls_dicts = obj['entities']['urls']\n",
    "            # output_f['URLcount'] = extract_urls(urls_dicts)\n",
    "\n",
    "            # NEW Features from fetchRawText_all\n",
    "            output_f['emoji_count'] = emoji.emoji_count(obj['text'])\n",
    "            urls_dicts = obj['entities']['urls']\n",
    "            output_f['URLcount'] = len(urls_dicts)\n",
    "            if \"media\" in obj['entities']:\n",
    "                output_f['has_media'] = len(obj['entities']['media'])\n",
    "                # output_f['media_type'] = obj['entities']['media'][0]['type']\n",
    "            else:\n",
    "                output_f['has_media'] = 0\n",
    "            temp = re.sub(r\"http\\S+\", \"HTTPURL\", obj['text'])\n",
    "            verification = 0\n",
    "            verification += len(re.findall(r'is(that|this|it) true', obj['text']))\n",
    "            verification += len(re.findall(r'wh[a]*t[?!|!?][?!|!?]*', obj['text']))\n",
    "            verification += len(re.findall(r'(rumour|rumor|debunk)', obj['text']))\n",
    "            verification += len(re.findall(r'(real?|really?|uncomfirmed)', obj['text']))\n",
    "            verification += len(re.findall(r'(that|this|it) is not true', obj['text']))\n",
    "            verification += len(re.findall(r'(that|this|it) is false', obj['text']))\n",
    "            verification += len(re.findall(r'(h[m]*)', obj['text']))\n",
    "            output_f['Skepticism'] = verification    \n",
    "            mention = 0\n",
    "            for token in temp:\n",
    "                if token.startswith('@'):\n",
    "                    mention+=1 \n",
    "            output_f['MentionCount'] = mention      \n",
    "\n",
    "        \n",
    "            \n",
    "\n",
    "            output_f['text_token'], output_f['URLcount'] = getTokenization(obj['text'])\n",
    "            '''POS Tagging and text cleansing for POS'''\n",
    "            # temp = output_f['text']\n",
    "            # temp=  emoji.demojize(temp)\n",
    "            # temp = re.sub(r\"(#)(\\S+)\", r'\\1 \\2', temp)\n",
    "            # temp = re.sub(r\"http\\S+\", \"\", temp)\n",
    "            # temp = replaceContraction(temp.lower())\n",
    "            # temp = temp.split()\n",
    "            # pos_dict=getposcount(temp)\n",
    "\n",
    "            '''POS Tagging'''\n",
    "            temp = output_f['text']\n",
    "            temp = replaceContraction(temp.lower())\n",
    "            temp = re.sub(r\"(#)(\\S+)\", '', temp)\n",
    "            temp = re.sub(r\"(@)(\\S+)\", '', temp)\n",
    "            temp = re.sub(r\"http\\S+\", \"\", temp)\n",
    "            temp = re.sub(r'([^\\s\\w#\\*]|_)+', '', temp) # Erasing Special Characters\n",
    "            temp = temp.split()\n",
    "            pos_dict=getposcount_all(temp)\n",
    "            output_f.update(pos_dict)\n",
    "\n",
    "            output_f['char_count'] = len(output_f['text'])\n",
    "            output_f['word_count'] = len(output_f['text'].split())\n",
    "\n",
    "            output_f['HashTag'] = len(obj['entities']['hashtags'])\n",
    "\n",
    "            output_f['has_question'] = \"?\" in output_f[\"text\"]\n",
    "            output_f['has_exclaim'] = \"!\" in output_f[\"text\"]\n",
    "            output_f['has_period'] = \".\" in output_f[\"text\"]\n",
    "\n",
    "            output_f['capital_ratio']=(capitalratio(obj['text']))\n",
    "            output_f['retweet_count'] = obj['retweet_count']\n",
    "            output_f['isRT'] = obj['retweeted']\n",
    "\n",
    "            output_f['tweet_count'] = np.log10(obj['user']['statuses_count']+0.0000000001)\n",
    "            output_f['listed_count'] = np.log10(obj['user']['listed_count']+0.0000000001)\n",
    "            output_f['friends_count'] = np.log10(obj['user']['friends_count']+0.0000000001)\n",
    "            output_f['follower_count'] = np.log10(obj['user']['followers_count']+0.0000000001)\n",
    "\n",
    "            if (output_f['friends_count'] <= 0):\n",
    "                output_f['followers/friend'] = obj['user']['followers_count']\n",
    "            else:\n",
    "                output_f['followers/friend'] = obj['user']['followers_count']/obj['user']['friends_count']\n",
    "\n",
    "            output_f['favourites_count'] = np.log10(obj['user']['favourites_count']+0.0000000001)\n",
    "\n",
    "            acc_created = datetime.strptime(obj['user']['created_at'], '%a %b %d %H:%M:%S %z %Y')\n",
    "            tweet_created = datetime.strptime(obj['created_at'], '%a %b %d %H:%M:%S %z %Y')\n",
    "            age = (tweet_created - acc_created)\n",
    "            output_f['account_age_days'] = age.days\n",
    "            \n",
    "            output_f['capital_ratio']=(capitalratio(obj['text']))\n",
    "            output_f['verified'] = obj['user']['verified']\n",
    "\n",
    "            extracted_event.append(output_f)\n",
    "        extracted_features.append(extracted_event)\n",
    "\n",
    "    extracted_df = []\n",
    "    for i, data in enumerate(extracted_features):\n",
    "        temp = pd.DataFrame(data)\n",
    "        temp[\"Event\"] = events[i]\n",
    "        extracted_df.append(pd.DataFrame(temp))\n",
    "\n",
    "    final = pd.concat(extracted_df, ignore_index=True)\n",
    "    final = pd.concat([final, target], axis=1)\n",
    "    return final\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHEME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../pheme-rnr-dataset\"\n",
    "events = ['charliehebdo', 'ferguson',\n",
    "          'germanwings-crash', 'ottawashooting', 'sydneysiege']\n",
    "tweetType = 'source-tweet'\n",
    "jsons = []\n",
    "final = fetchRawText(path, events, tweetType)\n",
    "target = final.target\n",
    "final.verified = final.verified.replace({True: 1, False: 0}) \n",
    "final.has_question = final.has_question.replace({True: 1, False: 0}) \n",
    "final.has_exclaim = final.has_exclaim.replace({True: 1, False: 0}) \n",
    "final.has_period = final.has_period.replace({True: 1, False: 0}) \n",
    "final.isRT = final.isRT.replace({True: 1, False: 0}) \n",
    "\n",
    "final = final.replace(-np.inf, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>emoji_count</th>\n      <th>URLcount</th>\n      <th>has_media</th>\n      <th>Skepticism</th>\n      <th>MentionCount</th>\n      <th>Noun</th>\n      <th>Verb</th>\n      <th>Adjective</th>\n      <th>Pronoun</th>\n      <th>FirstPersonPronoun</th>\n      <th>SecondPersonPronoun</th>\n      <th>ThirdPersonPronoun</th>\n      <th>Adverb</th>\n      <th>Numeral</th>\n      <th>Conjunction_inj</th>\n      <th>Particle</th>\n      <th>Determiner</th>\n      <th>Modal</th>\n      <th>Whs</th>\n      <th>char_count</th>\n      <th>word_count</th>\n      <th>HashTag</th>\n      <th>has_question</th>\n      <th>has_exclaim</th>\n      <th>has_period</th>\n      <th>capital_ratio</th>\n      <th>retweet_count</th>\n      <th>isRT</th>\n      <th>tweet_count</th>\n      <th>listed_count</th>\n      <th>friends_count</th>\n      <th>follower_count</th>\n      <th>followers/friend</th>\n      <th>favourites_count</th>\n      <th>account_age_days</th>\n      <th>verified</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>6</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>88</td>\n      <td>12</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.15909</td>\n      <td>177</td>\n      <td>0</td>\n      <td>4.80329</td>\n      <td>3.85594</td>\n      <td>2.78817</td>\n      <td>5.28735</td>\n      <td>315.63192</td>\n      <td>1.88649</td>\n      <td>2126</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>53</td>\n      <td>6</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.03774</td>\n      <td>134</td>\n      <td>0</td>\n      <td>3.03181</td>\n      <td>2.14613</td>\n      <td>2.57403</td>\n      <td>3.67293</td>\n      <td>12.55733</td>\n      <td>-10.00000</td>\n      <td>1050</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>4</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>136</td>\n      <td>18</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.07353</td>\n      <td>148</td>\n      <td>0</td>\n      <td>3.85625</td>\n      <td>2.87967</td>\n      <td>2.77232</td>\n      <td>4.30965</td>\n      <td>34.46115</td>\n      <td>2.17319</td>\n      <td>2030</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>8</td>\n      <td>0</td>\n      <td>4</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>138</td>\n      <td>16</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.10145</td>\n      <td>684</td>\n      <td>0</td>\n      <td>4.73581</td>\n      <td>5.00982</td>\n      <td>3.01620</td>\n      <td>7.18766</td>\n      <td>14841.13295</td>\n      <td>2.95279</td>\n      <td>2891</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>117</td>\n      <td>13</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.14530</td>\n      <td>113</td>\n      <td>0</td>\n      <td>5.02118</td>\n      <td>4.13300</td>\n      <td>2.66276</td>\n      <td>5.92543</td>\n      <td>1830.94783</td>\n      <td>1.41497</td>\n      <td>1975</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   emoji_count  URLcount  has_media  Skepticism  MentionCount  Noun  Verb  \\\n0            0         1          0           4             0     6     3   \n1            0         0          0           1             0     2     2   \n2            0         0          0           3             0     3     4   \n3            0         2          0           8             0     4     5   \n4            0         2          1           3             0     6     2   \n\n   Adjective  Pronoun  FirstPersonPronoun  SecondPersonPronoun  \\\n0          0        0                   0                    0   \n1          0        0                   0                    0   \n2          6        0                   0                    0   \n3          0        0                   0                    0   \n4          0        0                   0                    0   \n\n   ThirdPersonPronoun  Adverb  Numeral  Conjunction_inj  Particle  Determiner  \\\n0                   0       0        0                2         0           0   \n1                   0       0        0                1         0           0   \n2                   0       1        0                2         0           0   \n3                   0       0        0                0         0           2   \n4                   0       0        0                2         0           0   \n\n   Modal  Whs  char_count  word_count  HashTag  has_question  has_exclaim  \\\n0      0    0          88          12        0             0            0   \n1      0    0          53           6        1             0            0   \n2      0    0         136          18        2             0            0   \n3      0    1         138          16        1             0            0   \n4      0    0         117          13        1             0            0   \n\n   has_period  capital_ratio  retweet_count isRT  tweet_count  listed_count  \\\n0           1        0.15909            177    0      4.80329       3.85594   \n1           1        0.03774            134    0      3.03181       2.14613   \n2           1        0.07353            148    0      3.85625       2.87967   \n3           1        0.10145            684    0      4.73581       5.00982   \n4           1        0.14530            113    0      5.02118       4.13300   \n\n   friends_count  follower_count  followers/friend  favourites_count  \\\n0        2.78817         5.28735         315.63192           1.88649   \n1        2.57403         3.67293          12.55733         -10.00000   \n2        2.77232         4.30965          34.46115           2.17319   \n3        3.01620         7.18766       14841.13295           2.95279   \n4        2.66276         5.92543        1830.94783           1.41497   \n\n   account_age_days  verified  \n0              2126         1  \n1              1050         0  \n2              2030         0  \n3              2891         1  \n4              1975         1  "
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.drop(['text_token','text','Event','target'], axis=1, inplace=True)\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv('./data/_PHEME_sparse.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHEME (Extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ebola-essien's length is 14\n",
      "prince-toronto's length is 233\n",
      "putinmissing's length is 238\n",
      "0 ebola-essien 14 14\n",
      "1 prince-toronto 233 233\n",
      "2 putinmissing 238 238\n"
     ]
    }
   ],
   "source": [
    "path = \"../PHEME/all-rnr-annotated-threads\"\n",
    "events = ['ebola-essien', 'prince-toronto', 'putinmissing']\n",
    "tweetType = 'source-tweets'\n",
    "jsons = []\n",
    "final_ext = fetchRawText(path,events,tweetType)\n",
    "ext_target = final_ext.target\n",
    "final_ext.verified = final_ext.verified.replace({True: 1, False: 0}) \n",
    "final_ext.has_question = final_ext.has_question.replace({True: 1, False: 0}) \n",
    "final_ext.has_exclaim = final_ext.has_exclaim.replace({True: 1, False: 0}) \n",
    "final_ext.has_period = final_ext.has_period.replace({True: 1, False: 0}) \n",
    "final_ext.isRT = final_ext.isRT.replace({True: 1, False: 0}) \n",
    "final_ext = final_ext.replace(-np.inf, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>emoji_count</th>\n      <th>URLcount</th>\n      <th>has_media</th>\n      <th>Skepticism</th>\n      <th>MentionCount</th>\n      <th>text_token</th>\n      <th>Noun</th>\n      <th>Verb</th>\n      <th>Adjective</th>\n      <th>Pronoun</th>\n      <th>FirstPersonPronoun</th>\n      <th>SecondPersonPronoun</th>\n      <th>ThirdPersonPronoun</th>\n      <th>Adverb</th>\n      <th>Numeral</th>\n      <th>Conjunction_inj</th>\n      <th>Particle</th>\n      <th>Determiner</th>\n      <th>Modal</th>\n      <th>Whs</th>\n      <th>test_auxiliary</th>\n      <th>test_tentat</th>\n      <th>test_certain</th>\n      <th>char_count</th>\n      <th>word_count</th>\n      <th>HashTag</th>\n      <th>has_question</th>\n      <th>has_exclaim</th>\n      <th>has_period</th>\n      <th>capital_ratio</th>\n      <th>retweet_count</th>\n      <th>isRT</th>\n      <th>tweet_count</th>\n      <th>listed_count</th>\n      <th>friends_count</th>\n      <th>follower_count</th>\n      <th>followers/friend</th>\n      <th>favourites_count</th>\n      <th>account_age_days</th>\n      <th>verified</th>\n      <th>Event</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Micheal Essien denying the Ebola rumours like https://t.co/H2E1TAzeha</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>[micheal, essien, deni, ebola, rumour, like, *]</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>69</td>\n      <td>8</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.10145</td>\n      <td>117</td>\n      <td>0</td>\n      <td>4.60934</td>\n      <td>2.17026</td>\n      <td>2.81425</td>\n      <td>4.33911</td>\n      <td>33.48620</td>\n      <td>3.98453</td>\n      <td>1570</td>\n      <td>0</td>\n      <td>ebola-essien</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>No truth in internet rumours that I have contracted Ebola.i m very well &amp;amp; I'm doing very gud &amp;amp; will be training as usual tomorrow.#falsenews</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>[truth, internet, rumour, contract, ebolai, veri, well, andamp, veri, gud, andamp, train, usual, tomorrow, #, falsenew]</td>\n      <td>8</td>\n      <td>6</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>148</td>\n      <td>25</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.02703</td>\n      <td>10402</td>\n      <td>0</td>\n      <td>2.70672</td>\n      <td>3.21032</td>\n      <td>2.24551</td>\n      <td>5.68886</td>\n      <td>2775.54545</td>\n      <td>0.84510</td>\n      <td>579</td>\n      <td>1</td>\n      <td>ebola-essien</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Essien and his lawyers are considering to file a lawsuit against the Nigerian media that reported the fake Ebola story.</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>[essien, lawyer, consid, file, lawsuit, nigerian, medium, report, fake, ebola, stori]</td>\n      <td>6</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>119</td>\n      <td>20</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.02521</td>\n      <td>126</td>\n      <td>0</td>\n      <td>4.92029</td>\n      <td>3.33546</td>\n      <td>2.15836</td>\n      <td>5.36614</td>\n      <td>1613.52083</td>\n      <td>2.27646</td>\n      <td>2042</td>\n      <td>0</td>\n      <td>ebola-essien</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Good news: The rumours that Michael Essien has contracted the Ebola virus are false. http://t.co/5d7hCL46mR http://t.co/VtGuLnjWBD</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>9</td>\n      <td>0</td>\n      <td>[good, news, rumour, michael, essien, ha, contract, ebola, virus, fals, *, *]</td>\n      <td>6</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>130</td>\n      <td>16</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.10769</td>\n      <td>192</td>\n      <td>0</td>\n      <td>4.18887</td>\n      <td>2.78390</td>\n      <td>2.85491</td>\n      <td>4.86657</td>\n      <td>102.72067</td>\n      <td>2.00432</td>\n      <td>468</td>\n      <td>1</td>\n      <td>ebola-essien</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Milan have stated that the reports about Essien having Ebola are completely false.\\nhttp://t.co/Sb9v9ulfTX\\n@MichaelEssien</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>6</td>\n      <td>1</td>\n      <td>[milan, state, report, essien, ebola, complet, fals, *, @]</td>\n      <td>3</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>120</td>\n      <td>15</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.06667</td>\n      <td>196</td>\n      <td>0</td>\n      <td>4.92029</td>\n      <td>3.33546</td>\n      <td>2.15836</td>\n      <td>5.36614</td>\n      <td>1613.52083</td>\n      <td>2.27646</td>\n      <td>2039</td>\n      <td>0</td>\n      <td>ebola-essien</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                                                                                                                                   text  \\\n0                                                                                 Micheal Essien denying the Ebola rumours like https://t.co/H2E1TAzeha   \n1  No truth in internet rumours that I have contracted Ebola.i m very well &amp; I'm doing very gud &amp; will be training as usual tomorrow.#falsenews   \n2                               Essien and his lawyers are considering to file a lawsuit against the Nigerian media that reported the fake Ebola story.   \n3                    Good news: The rumours that Michael Essien has contracted the Ebola virus are false. http://t.co/5d7hCL46mR http://t.co/VtGuLnjWBD   \n4                            Milan have stated that the reports about Essien having Ebola are completely false.\\nhttp://t.co/Sb9v9ulfTX\\n@MichaelEssien   \n\n   emoji_count  URLcount  has_media  Skepticism  MentionCount  \\\n0            0         1          0           5             0   \n1            0         0          0           4             0   \n2            0         0          0           4             0   \n3            0         2          1           9             0   \n4            0         1          0           6             1   \n\n                                                                                                                text_token  \\\n0                                                                          [micheal, essien, deni, ebola, rumour, like, *]   \n1  [truth, internet, rumour, contract, ebolai, veri, well, andamp, veri, gud, andamp, train, usual, tomorrow, #, falsenew]   \n2                                    [essien, lawyer, consid, file, lawsuit, nigerian, medium, report, fake, ebola, stori]   \n3                                            [good, news, rumour, michael, essien, ha, contract, ebola, virus, fals, *, *]   \n4                                                               [milan, state, report, essien, ebola, complet, fals, *, @]   \n\n   Noun  Verb  Adjective  Pronoun  FirstPersonPronoun  SecondPersonPronoun  \\\n0     2     2          1        0                   0                    0   \n1     8     6          3        0                   2                    0   \n2     6     4          2        1                   0                    0   \n3     6     3          2        0                   0                    0   \n4     3     4          2        0                   0                    0   \n\n   ThirdPersonPronoun  Adverb  Numeral  Conjunction_inj  Particle  Determiner  \\\n0                   0       0        0                1         0           1   \n1                   0       3        0                4         0           1   \n2                   1       0        0                2         0           3   \n3                   0       0        0                1         0           2   \n4                   0       1        0                2         0           1   \n\n   Modal  Whs  test_auxiliary  test_tentat  test_certain  char_count  \\\n0      0    0               0            0             0          69   \n1      1    0               4            0             0         148   \n2      0    1               0            0             0         119   \n3      0    0               0            0             0         130   \n4      0    0               1            0             0         120   \n\n   word_count  HashTag  has_question  has_exclaim  has_period  capital_ratio  \\\n0           8        0             0            0           1        0.10145   \n1          25        1             0            0           1        0.02703   \n2          20        0             0            0           1        0.02521   \n3          16        0             0            0           1        0.10769   \n4          15        0             0            0           1        0.06667   \n\n   retweet_count isRT  tweet_count  listed_count  friends_count  \\\n0            117    0      4.60934       2.17026        2.81425   \n1          10402    0      2.70672       3.21032        2.24551   \n2            126    0      4.92029       3.33546        2.15836   \n3            192    0      4.18887       2.78390        2.85491   \n4            196    0      4.92029       3.33546        2.15836   \n\n   follower_count  followers/friend  favourites_count  account_age_days  \\\n0         4.33911          33.48620           3.98453              1570   \n1         5.68886        2775.54545           0.84510               579   \n2         5.36614        1613.52083           2.27646              2042   \n3         4.86657         102.72067           2.00432               468   \n4         5.36614        1613.52083           2.27646              2039   \n\n   verified         Event  target  \n0         0  ebola-essien       1  \n1         1  ebola-essien       1  \n2         0  ebola-essien       1  \n3         1  ebola-essien       1  \n4         0  ebola-essien       1  "
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_ext.drop(['text_token','text','Event','target'], axis=1, inplace=True)\n",
    "final_ext.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_ext.to_csv('./data/_PHEMEext_sparse.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHEME ALL (Reactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from glob2 import glob\n",
    "import json\n",
    "\n",
    "pd.options.display.float_format = '{:.5f}'.format\n",
    "\n",
    "def getposcount_all(tokens):\n",
    "    postag = []\n",
    "    poscount = {}\n",
    "    poscount['Noun']=0\n",
    "    poscount['Verb']=0\n",
    "    poscount['Adjective'] = 0\n",
    "    poscount['Pronoun']=0\n",
    "    poscount['FirstPersonPronoun']=0\n",
    "    poscount['SecondPersonPronoun']=0\n",
    "    poscount['ThirdPersonPronoun']=0\n",
    "    poscount['Adverb']=0\n",
    "    poscount['Numeral']=0\n",
    "    poscount['Conjunction_inj']=0\n",
    "    poscount['Particle']=0\n",
    "    poscount['Determiner']=0\n",
    "    poscount['Modal']=0\n",
    "    poscount['Whs']=0\n",
    "    poscount['test_auxiliary']=0\n",
    "    poscount['test_tentat']=0\n",
    "    poscount['test_certain']=0\n",
    "\n",
    "    Nouns = {'NN','NNS','NNP','NNPS'}\n",
    "    Adverbs = {'RB','RBR','RBS'}\n",
    "    Whs = {'WDT','WP','WRB'} # Composition of wh-determiner(that,what), wh-pronoun(who), wh-adverb(how)\n",
    "    Verbs={'VB','VBP','VBZ','VBN','VBG','VBD','To'}\n",
    "    first_person_pronouns=['i','me','my','mine','we','us','our','ours'] #'i',\n",
    "    second_person_pronouns=['you','your','yours', 'ya']\n",
    "    third_person_pronouns=['he','she','it','him','her','it','his','hers','its','they','them','their','theirs']\n",
    "    test_auxiliary=['be','will','have','am','is','was','were','can','could','dare','did','may','might','must','ought','shall','should','would']\n",
    "    test_tentat=['maybe','perhaps','possibly','probably','guess']\n",
    "    test_certain=['always','never']\n",
    "\n",
    "    for word in tokens:\n",
    "        w_lower=word.lower()\n",
    "        if w_lower in first_person_pronouns:\n",
    "            poscount['FirstPersonPronoun']+=1\n",
    "        elif w_lower in second_person_pronouns:\n",
    "            poscount['SecondPersonPronoun']+=1\n",
    "        elif w_lower in third_person_pronouns:\n",
    "            poscount['ThirdPersonPronoun']+=1\n",
    "        \n",
    "    for word in tokens:\n",
    "        w_lower=word.lower()\n",
    "        if w_lower in test_auxiliary:\n",
    "            poscount['test_auxiliary']+=1\n",
    "        elif w_lower in test_tentat:\n",
    "            poscount['test_tentat']+=1\n",
    "        elif w_lower in test_certain:\n",
    "            poscount['test_certain']+=1\n",
    "    \n",
    "    postag = nltk.pos_tag(tokens)\n",
    "    for g1 in postag:\n",
    "        if g1[1] in Nouns:\n",
    "            poscount['Noun'] += 1\n",
    "        elif g1[1] in Verbs:\n",
    "            poscount['Verb']+= 1\n",
    "        elif g1[1]=='ADJ'or g1[1]=='JJ':\n",
    "            poscount['Adjective']+=1\n",
    "        elif g1[1]=='PRP' or g1[1]=='PRON' or g1[1]=='PRP$':\n",
    "            poscount['Pronoun']+=1\n",
    "        elif g1[1] in Adverbs or g1[1]=='ADV':\n",
    "            poscount['Adverb']+=1\n",
    "        elif g1[1]=='CD':\n",
    "            poscount['Numeral']+=1\n",
    "        elif g1[1]=='CC' or g1[1]=='IN':\n",
    "            poscount['Conjunction_inj']+=1\n",
    "        elif g1[1]=='RP':\n",
    "            poscount['Particle']+=1\n",
    "        elif g1[1]=='MD':\n",
    "            poscount['Modal']+=1\n",
    "        elif g1[1]=='DT':\n",
    "            poscount['Determiner']+=1\n",
    "        elif g1[1] in Whs:\n",
    "            poscount['Whs']+=1\n",
    "    return poscount\n",
    "\n",
    "def fetchRawText_all(path, events, tweetType):\n",
    "    jsons = []\n",
    "    for i, event in enumerate(events):\n",
    "        jsons.append(glob('%s/%s/**/%s/[0-9]*.json' % (path, event, tweetType)))\n",
    "    for i,d in enumerate(jsons): print(\"%s's length is %d\" %(events[i], len(d)))\n",
    "\n",
    "    targets = []\n",
    "    features = []\n",
    "    isSrcTweet = []\n",
    "    for index, dataset in enumerate(jsons):\n",
    "        targetEvent = []\n",
    "        dataEvent = []\n",
    "        count = 0  # help var\n",
    "        for jsonFile in dataset:\n",
    "            count += 1\n",
    "            if jsonFile.find(\"non-rumours\") == -1:\n",
    "                targetEvent.append(1)\n",
    "            else:\n",
    "                targetEvent.append(0)\n",
    "            if jsonFile.find(\"source-tweet\") == -1:\n",
    "                isSrcTweet.append(0)\n",
    "            else: #if jsonFile.find(\"reactions\") == 1:\n",
    "                isSrcTweet.append(1)\n",
    "                \n",
    "\n",
    "            with open(jsonFile, 'r') as f:\n",
    "                for l in f.readlines():\n",
    "                    if not l.strip():  # skip empty lines\n",
    "                        continue\n",
    "                    json_data = json.loads(l)\n",
    "                    dataEvent.append(json_data)\n",
    "        targets.append(targetEvent)\n",
    "        features.append(dataEvent)\n",
    "        # isSrcTweet.append(isSrcTweet)\n",
    "\n",
    "    # print(\"\\nNumber of Events:\", len(targets))\n",
    "    # print(\"Number of tweets in the first event:\", len(targets[0]))\n",
    "\n",
    "    # targets은 targetEvent들을 리스트에 담은 것\n",
    "    target_list = []\n",
    "    for event in targets:\n",
    "        for elem in event:\n",
    "            target_list.append(elem)\n",
    "    target = pd.DataFrame(target_list, columns=[\"target\"])\n",
    "    isSrcTweet = pd.DataFrame(isSrcTweet, columns=[\"isSrcTweet\"])\n",
    "\n",
    "    extracted_features = []\n",
    "\n",
    "    extracted = []\n",
    "\n",
    "    NoneList = []\n",
    "\n",
    "    for obj_list in features:\n",
    "        extracted_event = []\n",
    "        for obj in obj_list:\n",
    "            output_f = dict()\n",
    "\n",
    "            if (('id' not in obj)):\n",
    "                print('sth happend')\n",
    "                return obj\n",
    "\n",
    "            if ('text' in obj):\n",
    "                output_f['text'] = obj['text']\n",
    "            else:\n",
    "                output_f['text'] = None\n",
    "            if ('text' in obj):\n",
    "                output_f['text'] = obj['text']\n",
    "            else:\n",
    "                output_f['text'] = None\n",
    "            if ('id' in obj):\n",
    "                output_f['id'] = obj['id']\n",
    "            else:\n",
    "                output_f['id'] = None\n",
    "            if ('in_reply_to_status_id' in obj):\n",
    "                output_f['pid'] = obj['in_reply_to_status_id']\n",
    "            else:\n",
    "                output_f['pid'] = None\n",
    "            output_f['userid'] = obj['user']['id']\n",
    "            \n",
    "            output_f['emoji_count'] = emoji.emoji_count(obj['text'])\n",
    "            urls_dicts = obj['entities']['urls']\n",
    "            if \"media\" in obj['entities']:\n",
    "                output_f['has_media'] = len(obj['entities']['media'])\n",
    "                # output_f['media_type'] = obj['entities']['media'][0]['type']\n",
    "            else:\n",
    "                output_f['has_media'] = 0\n",
    "                # output_f['media_type'] = 0\n",
    "            output_f['URLcount'] = len(urls_dicts)\n",
    "            # output_f['URLcount'] = extract_urls(urls_dicts)\n",
    "            # temp = obj['text'].lower()\n",
    "            # temp = re.sub(r\"http\\S+\", \"HTTPURL\", obj['text'])\n",
    "            verification = 0\n",
    "            verification += len(re.findall(r'is(that|this|it) true', obj['text']))\n",
    "            verification += len(re.findall(r'wh[a]*t[?!|!?][?!|!?]*', obj['text']))\n",
    "            verification += len(re.findall(r'(rumour|rumor|debunk)', obj['text']))\n",
    "            verification += len(re.findall(r'(real?|really?|uncomfirmed)', obj['text']))\n",
    "            verification += len(re.findall(r'(that|this|it) is not true', obj['text']))\n",
    "            verification += len(re.findall(r'(that|this|it) is false', obj['text']))\n",
    "            verification += len(re.findall(r'(h[m]*)', obj['text']))\n",
    "            output_f['Skepticism'] = verification            \n",
    "            url, mention = 0, 0\n",
    "            for token in obj['text']:\n",
    "                # if token.startswith('HTTPURL'):\n",
    "                # if token.startswith (r\"http\\S+\"):\n",
    "                    # url+=1\n",
    "                if token.startswith('@'):\n",
    "                    mention+=1 \n",
    "            # output_f['URLcount'] = url\n",
    "            output_f['MentionCount'] = mention\n",
    "\n",
    "            '''POS Tagging'''\n",
    "            temp = output_f['text']\n",
    "            temp = replaceContraction(temp.lower())\n",
    "            temp = re.sub(r\"(#)(\\S+)\", '', temp)\n",
    "            temp = re.sub(r\"(@)(\\S+)\", '', temp)\n",
    "            temp = re.sub(r\"http\\S+\", \"\", temp)\n",
    "            temp = re.sub(r'([^\\s\\w#\\*]|_)+', '', temp) # Erasing Special Characters\n",
    "            temp = temp.split()\n",
    "            pos_dict=getposcount_all(temp)\n",
    "\n",
    "            output_f['token_for_POS'] = temp\n",
    "            output_f.update(pos_dict)\n",
    "\n",
    "            output_f['char_count'] = len(output_f['text'])\n",
    "            output_f['word_count'] = len(output_f['text'].split())\n",
    "\n",
    "            # output_f['HashTag'] = len(obj['entities'][0]['hashtags'])\n",
    "            output_f['HashTag'] = len(obj['entities']['hashtags'])\n",
    "\n",
    "            output_f['has_question'] = \"?\" in output_f[\"text\"]\n",
    "            output_f['has_exclaim'] = \"!\" in output_f[\"text\"]\n",
    "            output_f['has_period'] = \".\" in output_f[\"text\"]\n",
    "\n",
    "            output_f['retweet_count'] = obj['retweet_count']\n",
    "            output_f['isRT'] = obj['retweeted']\n",
    "\n",
    "            # output_f['statuses_count'] = np.log10(obj['user']['statuses_count']+0.0000000001)\n",
    "            # output_f['listed_count'] = np.log10(obj['user']['listed_count']+0.000000001)\n",
    "            # output_f['friends_count'] = np.log10(obj['user']['friends_count']+0.0000000001)\n",
    "            # output_f['followers_count'] = np.log10(obj['user']['followers_count']+0.0000000001)\n",
    "\n",
    "            output_f['statuses_count'] = obj['user']['statuses_count']\n",
    "            output_f['listed_count'] = np.log10(obj['user']['listed_count'])\n",
    "            output_f['friends_count'] = obj['user']['friends_count']\n",
    "            output_f['followers_count'] = obj['user']['followers_count']\n",
    "\n",
    "            output_f['location'] = obj['user']['location']\n",
    "            output_f['name'] = obj['user']['name']\n",
    "\n",
    "            if (output_f['friends_count'] <= 0):\n",
    "                output_f['followers/friend'] = obj['user']['followers_count']\n",
    "            else:\n",
    "                output_f['followers/friend'] = obj['user']['followers_count']/obj['user']['friends_count']\n",
    "\n",
    "            output_f['favourites_count'] = obj['user']['favourites_count']\n",
    "            \n",
    "            acc_created = datetime.strptime(obj['user']['created_at'], '%a %b %d %H:%M:%S %z %Y')\n",
    "            tweet_created = datetime.strptime(obj['created_at'], '%a %b %d %H:%M:%S %z %Y')\n",
    "            age = (tweet_created - acc_created)\n",
    "            output_f['account_age_days'] = age.days\n",
    "            output_f['tweet_created'] = datetime.timestamp(tweet_created)\n",
    "            # output_f['tweet_created2'] = tweet_created\n",
    "\n",
    "            output_f['capital_ratio']=(capitalratio(obj['text']))\n",
    "            output_f['verified'] = obj['user']['verified']\n",
    "\n",
    "            extracted_event.append(output_f)\n",
    "        extracted_features.append(extracted_event)\n",
    "\n",
    "    extracted_df = []\n",
    "    # print(events)\n",
    "    # print(len(extracted_features))\n",
    "    for i, data in enumerate(extracted_features):\n",
    "        temp = pd.DataFrame(data)\n",
    "        temp[\"Event\"] = events[i]\n",
    "        extracted_df.append(pd.DataFrame(temp))\n",
    "\n",
    "    final = pd.concat(extracted_df, ignore_index=True)\n",
    "    final = pd.concat([final, isSrcTweet ,target], axis=1)\n",
    "    final.pid = final.pid\n",
    "    return final\n",
    "\n",
    "def depth(x):\n",
    "    if type(x) is dict and x:\n",
    "        return 1 + max(depth(x[a]) for a in x)\n",
    "    if type(x) is list and x:\n",
    "        return 1 + max(depth(a) for a in x)\n",
    "    return 0\n",
    "\n",
    "def getThreadData(path, events):\n",
    "    import re\n",
    "\n",
    "    sources = []\n",
    "    for i, event in enumerate(events):\n",
    "        sources.append(glob('%s/%s/*/*' % (path, event)))\n",
    "    roots = []\n",
    "    children = []\n",
    "    features = []\n",
    "    isSrcTweet = []\n",
    "    for num, event in enumerate(sources):\n",
    "        for index, dataset in enumerate(event):\n",
    "            # print(dataset)\n",
    "            # children.append(glob('%s/reactions/*/*' % (dataset)))\n",
    "            childs = [os.path.basename(x) for x in glob('%s/reactions/*.json' % (dataset))]\n",
    "            reext = re.compile(r'(.*?)\\.json')\n",
    "            childs = (reext.match(child) for child in childs)\n",
    "            children.append([match.group(1) for match in childs if match])\n",
    "            # print(dataset)\n",
    "            roots.append(os.path.basename(dataset))\n",
    "\n",
    "    df = pd.DataFrame(roots, columns=['Root'])\n",
    "    df = pd.concat([df,pd.DataFrame(children)],axis=1)\n",
    "    \n",
    "    structfile = []\n",
    "    annotatedfile= []\n",
    "    for i, event in enumerate(events):\n",
    "        structfile.append(glob('%s/%s/**/[0-9]*/structure.json' % (path, event)))\n",
    "        annotatedfile.append(glob('%s/%s/**/[0-9]*/annotation.json' % (path, event)))\n",
    "\n",
    "    for i,d in enumerate(structfile): print(\"%s's structure.json number is %d\" %(events[i], len(d)))\n",
    "    for i,d in enumerate(annotatedfile): print(\"%s's annotated.json number is %d\" %(events[i], len(d)))\n",
    "    # print(structfile)\n",
    "\n",
    "    thread_depths = []\n",
    "    thread_roots = []\n",
    "    for index, dataset in enumerate(structfile):\n",
    "        targetEvent = []\n",
    "        dataEvent = []\n",
    "        count = 0  # help var\n",
    "        for jsonFile in dataset:\n",
    "            # print(jsonFile)\n",
    "            match = re.search(\"/([0-9]*)/\", jsonFile)\n",
    "            rootname = match.group(1) if match else None\n",
    "            # print(rootname)\n",
    "            with open(jsonFile, 'r') as f:\n",
    "                for l in f.readlines():\n",
    "                    if not l.strip():  # skip empty lines\n",
    "                        continue\n",
    "                json_data = json.loads(l)\n",
    "                # print(json_data)\n",
    "                thread_depth = depth(json_data)\n",
    "                thread_depths.append([rootname,thread_depth])\n",
    "                # thread_roots.append(rootname)\n",
    "    df_depth = pd.DataFrame(thread_depths, columns=['Root', 'depth'])\n",
    "    df = pd.merge(df, df_depth, on=\"Root\")\n",
    "    \n",
    "    isTrue = []\n",
    "    misinfo = []\n",
    "    for index, dataset in enumerate(annotatedfile):\n",
    "        targetEvent = []\n",
    "        dataEvent = []\n",
    "        count = 0  # help var\n",
    "        for jsonFile in dataset:\n",
    "            match = re.search(\"/([0-9]*)/\", jsonFile)\n",
    "            rootname = match.group(1) if match else None\n",
    "            with open(jsonFile, 'r') as f:\n",
    "                for l in f.readlines():\n",
    "                    if not l.strip():  # skip empty lines\n",
    "                        continue\n",
    "                json_data = json.loads(l)\n",
    "                if ('misinformation' in json_data ):\n",
    "                    misinformation = json_data['misinformation']\n",
    "                else:\n",
    "                    misinformation = -1\n",
    "                if (json_data['is_rumour'] == \"nonrumour\"):\n",
    "                    truth = 0\n",
    "                elif (json_data['is_rumour'] == \"rumour\" and 'true' in json_data):\n",
    "                    if (json_data['true']==1):\n",
    "                        truth = 1\n",
    "                    elif (json_data['true']==0):\n",
    "                        truth = 2\n",
    "                else:\n",
    "                    truth = -1\n",
    "                misinfo.append([rootname,misinformation,truth])\n",
    "                # print(json_data)\n",
    "                # print(json_data)\n",
    "                # misinfo = json_data['misinformation']\n",
    "                # misinfo.append([rootname,json_data['misinformation']])\n",
    "                # thread_roots.append(rootname)\n",
    "    df_annotation = pd.DataFrame(misinfo,columns=['Root', 'misinformation', 'truth'])\n",
    "                \n",
    "    # return pd.DataFrame(thread_depths)\n",
    "    return df , df_annotation\n",
    "\n",
    "def getThreadDataPHEME(path, events):\n",
    "    import re\n",
    "\n",
    "    sources = []\n",
    "    for i, event in enumerate(events):\n",
    "        sources.append(glob('%s/%s/*/*' % (path, event)))\n",
    "    roots = []\n",
    "    children = []\n",
    "    features = []\n",
    "    isSrcTweet = []\n",
    "    childs_list=[]\n",
    "    for num, event in enumerate(sources):\n",
    "        for index, dataset in enumerate(event):\n",
    "            # print(dataset)\n",
    "            # children.append(glob('%s/reactions/*/*' % (dataset)))\n",
    "            childs = [os.path.basename(x) for x in glob('%s/reactions/*.json' % (dataset))]\n",
    "            reext = re.compile(r'(.*?)\\.json')\n",
    "            childs = (reext.match(child) for child in childs)\n",
    "            children.append([match.group(1) for match in childs if match])\n",
    "            # print(dataset)\n",
    "            roots.append(os.path.basename(dataset))\n",
    "\n",
    "            # childs_list.append(children)\n",
    "\n",
    "    df = pd.DataFrame(roots, columns=['Root'])\n",
    "    return pd.concat([df,pd.DataFrame(children)],axis=1)\n",
    "    return df\n",
    "    \n",
    "    structfile = []\n",
    "    for i, event in enumerate(events):\n",
    "        structfile.append(glob('%s/%s/**/[0-9]*/structure.json' % (path, event)))\n",
    "\n",
    "    for i,d in enumerate(structfile): print(\"%s's structure.json number is %d\" %(events[i], len(d)))\n",
    "    # print(structfile)\n",
    "\n",
    "    thread_depths = []\n",
    "    thread_roots = []\n",
    "    for index, dataset in enumerate(structfile):\n",
    "        targetEvent = []\n",
    "        dataEvent = []\n",
    "        count = 0  # help var\n",
    "        for jsonFile in dataset:\n",
    "            # print(jsonFile)\n",
    "            match = re.search(\"/([0-9]*)/\", jsonFile)\n",
    "            # p.match(\"lalalaI want this partlalala\").group(1)\n",
    "            rootname = match.group(1) if match else None\n",
    "            # print(rootname)\n",
    "            with open(jsonFile, 'r') as f:\n",
    "                for l in f.readlines():\n",
    "                    if not l.strip():  # skip empty lines\n",
    "                        continue\n",
    "                json_data = json.loads(l)\n",
    "                # print(json_data)\n",
    "                thread_depth = depth(json_data)\n",
    "                thread_depths.append([rootname,thread_depth])\n",
    "                # thread_roots.append(rootname)\n",
    "    df_depth = pd.DataFrame(thread_depths, columns=['Root', 'depth'])\n",
    "    df = pd.merge(df, df_depth, on=\"Root\")\n",
    "                \n",
    "    \n",
    "    # return pd.DataFrame(thread_depths)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def getThreadInfo_AVG(structure, df):\n",
    "    threadInfo = []\n",
    "    thread_depth = structure[['Root', 'depth']]\n",
    "    structure = structure.drop('depth', axis=1)\n",
    "    for index, data in enumerate(structure.Root):\n",
    "        tweetInfo = []\n",
    "        # print(\"data: %s\\n\" %(data))\n",
    "        # print(\"data: %s\\n%s\\n\" %(data, structure.loc[index,0:].values))\n",
    "        # print(\"root: %s\\tFirst reaction: %s\\n\" %(data, structure.loc[index,0]))\n",
    "\n",
    "        pid = int(data)\n",
    "        thread = structure.loc[structure['Root']==pid].dropna(axis=1)\n",
    "        thread_node_count = len([childid for childid in structure.loc[index,:].dropna()]) \n",
    "\n",
    "        # threadRange = structure.loc[structure['Root']==data].any().sum()-1\n",
    "        # print(structure)\n",
    "        threadRange = len(structure.iloc[index,:].dropna())\n",
    "\n",
    "        # 아래로는 성공적인 Features\n",
    "        friends_sum = np.sum([np.sum(df.loc[(df['id'] == int(childid))]['friends_count'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        friends_avg = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['friends_count'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        \n",
    "        words_sum = np.sum([np.sum(df.loc[(df['id'] == int(childid))]['word_count'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        words_avg = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['word_count'].values) for childid in structure.loc[index,:].dropna()])\n",
    "\n",
    "        char_avg = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['char_count'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        \n",
    "        hashtagsum = np.sum([np.sum(df.loc[(df['id'] == int(childid))]['HashTag'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        hashtagavg = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['HashTag'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        hashtagratio = np.mean([np.any(df.loc[(df['id'] == int(childid))]['HashTag']) for childid in structure.loc[index,:].dropna()])\n",
    "        \n",
    "        urlsum = np.sum([np.sum(df.loc[(df['id'] == int(childid))]['URLcount'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        # urlavg = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['URLcount'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        urlavg = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['URLcount'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        urlratio = np.mean([np.any(df.loc[(df['id'] == int(childid))]['URLcount'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        \n",
    "        mentionsum = np.sum([np.sum(df.loc[(df['id'] == int(childid))]['MentionCount'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        mentionavg = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['MentionCount'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        mentionratio = np.mean([np.any(df.loc[(df['id'] == int(childid))]['MentionCount'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        \n",
    "        statuesavg = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['statuses_count'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        \n",
    "        listedavg = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['listed_count'].values) for childid in structure.loc[index,:].dropna()])\n",
    "\n",
    "        followeravg = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['followers_count'].values) for childid in structure.loc[index,:].dropna()])\n",
    "\n",
    "        followers_friendratio = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['followers/friend'].values) for childid in structure.loc[index,:].dropna()])\n",
    "\n",
    "        favoriteavg = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['favourites_count'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        \n",
    "        verifiedsum = np.sum([np.sum(df.loc[(df['id'] == int(childid))]['verified'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        verifiedratio = np.mean([np.any(df.loc[(df['id'] == int(childid))]['verified'].values) for childid in structure.loc[index,:].dropna()])\n",
    "\n",
    "        retweetsum = np.sum([np.sum(df.loc[(df['id'] == int(childid))]['retweet_count'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        retweetavg = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['retweet_count'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        # retweetstd = np.std([np.sum(df.loc[(df['id'] == int(childid))]['retweet_count'].values) for childid in structure.loc[index,:].dropna()])\n",
    "\n",
    "        accageavg = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['account_age_days'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        # accagestd = np.std([np.sum(df.loc[(df['id'] == int(childid))]['account_age_days'].values) for childid in structure.loc[index,:].dropna()])\n",
    "\n",
    "        emojiavg = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['emoji_count'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        emojiratio = np.mean([np.any(df.loc[(df['id'] == int(childid))]['emoji_count'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        # emojistd = np.std([np.sum(df.loc[(df['id'] == int(childid))]['emoji_count'].values) for childid in structure.loc[index,:].dropna()])\n",
    "\n",
    "        mediaratio = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['has_media'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        questionratio = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['has_question'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        exclamationratio = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['has_exclaim'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        periodratio = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['has_period'].values) for childid in structure.loc[index,:].dropna()])\n",
    "\n",
    "        FPPmean = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['FirstPersonPronoun'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        SPPmean = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['SecondPersonPronoun'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        TPPmean = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['ThirdPersonPronoun'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        # FPPstd = np.std([np.sum(df.loc[(df['id'] == int(childid))]['FirstPersonPronoun'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        # SPPstd = np.std([np.sum(df.loc[(df['id'] == int(childid))]['SecondPersonPronoun'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        # TPPstd = np.std([np.sum(df.loc[(df['id'] == int(childid))]['ThirdPersonPronoun'].values) for childid in structure.loc[index,:].dropna()])\n",
    "\n",
    "        Skepticismmean = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['Skepticism'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        Skepticismratio = np.mean([np.any(df.loc[(df['id'] == int(childid))]['Skepticism'].values) for childid in structure.loc[index,:].dropna()])\n",
    "\n",
    "        test_auxiliaryratio = np.mean([np.any(df.loc[(df['id'] == int(childid))]['test_auxiliary'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        test_tentatratio = np.mean([np.any(df.loc[(df['id'] == int(childid))]['test_tentat'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        test_certainratio = np.mean([np.any(df.loc[(df['id'] == int(childid))]['test_certain'].values) for childid in structure.loc[index,:].dropna()])\n",
    "\n",
    "        # 루트 트윗 작성자가 쓰레드에서 차지하는 비율\n",
    "        root_user_ratio = np.sum([np.any(all_ext.loc[(all_ext['id'] == int(childid)) & (all_ext['userid'] == p_userid)]['userid'].values) for childid in structure_ext.loc[0, :].dropna()]) / thread_node_count\n",
    "\n",
    "        unique_user_ratio = len(np.unique([np.sum(all_ext.loc[(all_ext['id'] == int(childid))]['userid'].values) for childid in structure_ext.loc[0, :].dropna()])) / thread_node_count\n",
    "\n",
    "        unique_user_sum = len(np.unique([np.sum(all_ext.loc[(all_ext['id'] == int(childid))]['userid'].values) for childid in structure_ext.loc[0, :].dropna()]))\n",
    "\n",
    "        # Get the lifetime of thread\n",
    "        # root_created = df.loc[(df['id'] == int(pid))].tweet_created.sum()\n",
    "        # try:\n",
    "        #     thread_latest = np.max([np.sum(df.loc[(df['id'] == childid)]['tweet_created'].values) for childid in structure.loc[index,'0':].dropna()])\n",
    "        # except:\n",
    "        # #     print([df.loc[(df['id'] == int(childid))]['tweet_created'].values for childid in structure.loc[index,'0':].dropna()])\n",
    "        #     print(\"error\")\n",
    "\n",
    "        # thread_life = thread_latest - root_created\n",
    "        try:\n",
    "            thread_life = np.max([np.sum(df.loc[(df['id'] == childid)]['tweet_created']) for childid in structure.loc[index,:].dropna()] - df.loc[(df['id'] == pid)].tweet_created.sum())\n",
    "            # if thread_life < 0: thread_life=0\n",
    "        except:\n",
    "            print(\"index:\", index)\n",
    "\n",
    "        # 해당 스레드의 트윗 개수\n",
    "        # print(\"thread_node_count:\",thread_node_count,\", threadRange:\",threadRange, \"lastest Thread:\", thread_latest )\n",
    "        # print(structure.loc[structure.Root == data])\n",
    "\n",
    "        tweetInfo.append(data)\n",
    "        # friends_sum = np.log(friends_sum, where=0<friends_sum, out=np.nan*friends_sum)\n",
    "        # friends_sum = np.log10(friends_sum-friends_sum.min()+1)\n",
    "        tweetInfo.append(friends_sum)\n",
    "        tweetInfo.append(friends_avg)\n",
    "        tweetInfo.append(words_avg)\n",
    "        tweetInfo.append(words_sum)\n",
    "        tweetInfo.append(char_avg)\n",
    "\n",
    "        tweetInfo.append(hashtagavg)\n",
    "        tweetInfo.append(hashtagsum)\n",
    "        tweetInfo.append(hashtagratio)\n",
    "        tweetInfo.append(urlsum)\n",
    "        tweetInfo.append(urlavg)\n",
    "        # tweetInfo.append(urlstd)\n",
    "        tweetInfo.append(urlratio)\n",
    "        tweetInfo.append(mentionsum)\n",
    "        tweetInfo.append(mentionavg)\n",
    "        tweetInfo.append(mentionratio)\n",
    "        tweetInfo.append(statuesavg)\n",
    "        tweetInfo.append(listedavg)\n",
    "        tweetInfo.append(followeravg)\n",
    "        tweetInfo.append(followers_friendratio)\n",
    "        tweetInfo.append(favoriteavg)\n",
    "         \n",
    "        tweetInfo.append(thread_node_count)\n",
    "        tweetInfo.append(verifiedratio)\n",
    "        tweetInfo.append(verifiedsum)\n",
    "        tweetInfo.append(retweetsum)\n",
    "        tweetInfo.append(retweetavg)\n",
    "        # tweetInfo.append(retweetstd)\n",
    "        tweetInfo.append(accageavg)\n",
    "        # tweetInfo.append(accagestd)\n",
    "        tweetInfo.append(thread_life)\n",
    "        # tweetInfo.append(emojistd)\n",
    "        tweetInfo.append(emojiavg)\n",
    "        tweetInfo.append(emojiratio)\n",
    "        tweetInfo.append(mediaratio)\n",
    "        tweetInfo.append(questionratio)\n",
    "        tweetInfo.append(exclamationratio)\n",
    "        tweetInfo.append(periodratio)\n",
    "        tweetInfo.append(FPPmean)\n",
    "        # tweetInfo.append(FPPstd)\n",
    "        tweetInfo.append(SPPmean)\n",
    "        # tweetInfo.append(SPPstd)\n",
    "        tweetInfo.append(TPPmean)\n",
    "        # tweetInfo.append(TPPstd)\n",
    "        tweetInfo.append(Skepticismmean)\n",
    "        tweetInfo.append(Skepticismratio)\n",
    "        tweetInfo.append(test_auxiliaryratio)\n",
    "        tweetInfo.append(test_tentatratio)\n",
    "        tweetInfo.append(test_certainratio)\n",
    "        tweetInfo.append(root_user_ratio)\n",
    "        tweetInfo.append(unique_user_ratio)\n",
    "        tweetInfo.append(unique_user_sum)\n",
    "\n",
    "        threadInfo.append(tweetInfo)\n",
    "\n",
    "        result = pd.DataFrame(threadInfo, columns=['Root', 'SUM FriendsCount','AVG FriendsCount', 'AVG WordCount','SUM WordCount', 'AVG CharCount', 'AVG HashTag', 'SUM HashTag', 'Ratio HashTag','SUM Url', 'AVG Url','RATIO Url','SUM Mention', 'AVG Mention', 'Ratio Mention','AVG Statues','AVG Listed','AVG Follower','AVG followers/friend','AVG favorite', 'Tweets Count', 'Ratio Verified','SUM Verified','SUM RT', 'AVG RT','AVG AccAge', 'thread_time', \"AVG Emoji\",\"RATIO Emoji\",\"Ratio Media\",'RATIO Question', 'RATIO Exclaim','RATIO Period', 'AVG FPP', 'AVG SPP','AVG TPP','AVG Skepticism','Ratio Skepticism', 'test_auxiliary','test_tentat','test_certain', 'root_user_ratio','unique_user_ratio','unique_user_sum'])\n",
    "        result = pd.merge(thread_depth, result, on=\"Root\").drop(['Root'], axis=1)\n",
    "    # result.friends_sum = np.log10(result.friends_sum-result.friends_sum.min()+1)\n",
    "    # result.friends_avg = np.log10(result.friends_avg-result.friends_avg.min()+1)\n",
    "\n",
    "    # print(threadInfo)\n",
    "    # result['SUM FriendsCount'] = np.log10(result['SUM FriendsCount']-result['SUM FriendsCount'].min()+1)\n",
    "    # result['AVG FriendsCount'] = np.log10(result['AVG FriendsCount']-result['AVG FriendsCount'].min()+1)\n",
    "    # result['AVG Statues'] = np.log10(result['AVG Statues']-result['AVG Statues'].min()+1)\n",
    "    # result['AVG Listed'] = np.log10(result['AVG Listed']-result['AVG Listed'].min()+1)\n",
    "    # result['AVG Follower'] = np.log10(result['AVG Follower']-result['AVG Follower'].min()+1)\n",
    "    # result['AVG favorite'] = np.log10(result['AVG favorite']-result['AVG favorite'].min()+1)\n",
    "    # # result['SUM RT'] = np.log10(result['SUM RT']-result['SUM RT'].min()+1)\n",
    "    # # result['AVG RT'] = np.log10(result['AVG RT']-result['AVG RT'].min()+1)\n",
    "    # # result['AVG AccAge'] = np.log10(result['AVG AccAge']-result['AVG AccAge'].min()+1)\n",
    "    # result['thread_time'] = np.log10(result['thread_time']-result['thread_time'].min()+1)\n",
    "    # # result['SUM WordCount'] = np.log10(result['SUM WordCount']-result['SUM WordCount'].min()+1)\n",
    "    # result['AVG followers/friend'] = np.log10(result['AVG followers/friend']-result['AVG followers/friend'].min()+1)\n",
    "    # result['AVG CharCount'] = np.log10(result['AVG CharCount']-result['AVG CharCount'].min()+1)\n",
    "    # result['Tweets Count'] = np.log10(result['Tweets Count']-result['Tweets Count'].min()+1)\n",
    "\n",
    "    result = result.fillna(0)\n",
    "    result = result.replace(-np.inf, 0)\n",
    "    return result\n",
    "\n",
    "def getThreadInfo_STD(structure, df):\n",
    "    threadInfo = []\n",
    "    thread_depth = structure[['Root', 'depth']]\n",
    "    structure = structure.drop('depth', axis=1)\n",
    "    for index, data in enumerate(structure.Root):\n",
    "        tweetInfo = []\n",
    "        # print(\"data: %s\\n\" %(data))\n",
    "        # print(\"data: %s\\n%s\\n\" %(data, structure.loc[index,0:].values))\n",
    "        # print(\"root: %s\\tFirst reaction: %s\\n\" %(data, structure.loc[index,0]))\n",
    "        \n",
    "        pid = int(data)\n",
    "        thread = structure.loc[structure['Root']==pid].dropna(axis=1)\n",
    "        # threadRange = structure.loc[structure['Root']==data].any().sum()-1\n",
    "        # print(structure)\n",
    "        threadRange = len(structure.iloc[index,:].dropna())\n",
    "\n",
    "        # 해당 스레드의 트윗 개수\n",
    "        thread_node_count = len([childid for childid in structure.loc[index,:].dropna()]) \n",
    "\n",
    "        # 아래로는 성공적인 Features\n",
    "        friends_sum = np.sum([np.sum(df.loc[(df['id'] == int(childid))]['friends_count'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        friends_std = np.std([np.sum(df.loc[(df['id'] == int(childid))]['friends_count'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        \n",
    "        words_sum = np.sum([np.sum(df.loc[(df['id'] == int(childid))]['word_count'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        words_std = np.std([np.sum(df.loc[(df['id'] == int(childid))]['word_count'].values) for childid in structure.loc[index,:].dropna()])\n",
    "\n",
    "        char_std = np.std([np.sum(df.loc[(df['id'] == int(childid))]['char_count'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        \n",
    "        hashtagsum = np.sum([np.sum(df.loc[(df['id'] == int(childid))]['HashTag'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        hashtagstd = np.std([np.sum(df.loc[(df['id'] == int(childid))]['HashTag'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        hashtagratio = np.mean([np.any(df.loc[(df['id'] == int(childid))]['HashTag']) for childid in structure.loc[index,:].dropna()])\n",
    "        \n",
    "        urlsum = np.sum([np.sum(df.loc[(df['id'] == int(childid))]['URLcount'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        # urlavg = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['URLcount'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        urlstd = np.std([np.sum(df.loc[(df['id'] == int(childid))]['URLcount'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        urlratio = np.mean([np.any(df.loc[(df['id'] == int(childid))]['URLcount'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        \n",
    "        mentionsum = np.sum([np.sum(df.loc[(df['id'] == int(childid))]['MentionCount'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        mentionstd = np.std([np.sum(df.loc[(df['id'] == int(childid))]['MentionCount'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        mentionratio = np.mean([np.any(df.loc[(df['id'] == int(childid))]['MentionCount'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        \n",
    "        statuesstd = np.std([np.sum(df.loc[(df['id'] == int(childid))]['statuses_count'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        \n",
    "        listedstd = np.std([np.sum(df.loc[(df['id'] == int(childid))]['listed_count'].values) for childid in structure.loc[index,:].dropna()])\n",
    "\n",
    "        followerstd = np.std([np.sum(df.loc[(df['id'] == int(childid))]['followers_count'].values) for childid in structure.loc[index,:].dropna()])\n",
    "\n",
    "        followers_friendratio = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['followers/friend'].values) for childid in structure.loc[index,:].dropna()])\n",
    "\n",
    "        favoritestd = np.std([np.sum(df.loc[(df['id'] == int(childid))]['favourites_count'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        \n",
    "        verifiedsum = np.sum([np.sum(df.loc[(df['id'] == int(childid))]['verified'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        verifiedratio = np.mean([np.any(df.loc[(df['id'] == int(childid))]['verified'].values) for childid in structure.loc[index,:].dropna()])\n",
    "\n",
    "        retweetsum = np.sum([np.sum(df.loc[(df['id'] == int(childid))]['retweet_count'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        retweetstd = np.std([np.sum(df.loc[(df['id'] == int(childid))]['retweet_count'].values) for childid in structure.loc[index,:].dropna()])\n",
    "\n",
    "        accagestd = np.std([np.sum(df.loc[(df['id'] == int(childid))]['account_age_days'].values) for childid in structure.loc[index,:].dropna()])\n",
    "\n",
    "        emojiratio = np.mean([np.any(df.loc[(df['id'] == int(childid))]['emoji_count'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        emojistd = np.std([np.sum(df.loc[(df['id'] == int(childid))]['emoji_count'].values) for childid in structure.loc[index,:].dropna()])\n",
    "\n",
    "        mediaratio = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['has_media'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        questionratio = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['has_question'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        exclamationratio = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['has_exclaim'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        periodratio = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['has_period'].values) for childid in structure.loc[index,:].dropna()])\n",
    "\n",
    "        FPPstd = np.std([np.sum(df.loc[(df['id'] == int(childid))]['FirstPersonPronoun'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        SPPstd = np.std([np.sum(df.loc[(df['id'] == int(childid))]['SecondPersonPronoun'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        TPPstd = np.std([np.sum(df.loc[(df['id'] == int(childid))]['ThirdPersonPronoun'].values) for childid in structure.loc[index,:].dropna()])\n",
    "\n",
    "        Skepticismmean = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['Skepticism'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        Skepticismratio = np.mean([np.any(df.loc[(df['id'] == int(childid))]['Skepticism'].values) for childid in structure.loc[index,:].dropna()])\n",
    "\n",
    "        test_auxiliaryratio = np.std([np.any(df.loc[(df['id'] == int(childid))]['test_auxiliary'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        test_tentatratio = np.std([np.any(df.loc[(df['id'] == int(childid))]['test_tentat'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        test_certainratio = np.std([np.any(df.loc[(df['id'] == int(childid))]['test_certain'].values) for childid in structure.loc[index,:].dropna()])\n",
    "\n",
    "        # 루트 트윗 작성자가 쓰레드에서 차지하는 비율\n",
    "        root_user_ratio = np.sum([np.any(all_ext.loc[(all_ext['id'] == int(childid)) & (all_ext['userid'] == p_userid)]['userid'].values) for childid in structure_ext.loc[0, :].dropna()]) / thread_node_count\n",
    "\n",
    "        unique_user_ratio = len(np.unique([np.sum(all_ext.loc[(all_ext['id'] == int(childid))]['userid'].values) for childid in structure_ext.loc[0, :].dropna()])) / thread_node_count\n",
    "\n",
    "        unique_user_sum = len(np.unique([np.sum(all_ext.loc[(all_ext['id'] == int(childid))]['userid'].values) for childid in structure_ext.loc[0, :].dropna()]))\n",
    "\n",
    "        # Get the lifetime of thread\n",
    "        # root_created = df.loc[(df['id'] == int(pid))].tweet_created.sum()\n",
    "        # try:\n",
    "        #     thread_latest = np.max([np.sum(df.loc[(df['id'] == childid)]['tweet_created'].values) for childid in structure.loc[index,'0':].dropna()])\n",
    "        # except:\n",
    "        # #     print([df.loc[(df['id'] == int(childid))]['tweet_created'].values for childid in structure.loc[index,'0':].dropna()])\n",
    "        #     print(\"error\")\n",
    "\n",
    "        # thread_life = thread_latest - root_created\n",
    "        try:\n",
    "            thread_life = np.max([np.sum(df.loc[(df['id'] == childid)]['tweet_created']) for childid in structure.loc[index,:].dropna()] - df.loc[(df['id'] == pid)].tweet_created.sum())\n",
    "            # if thread_life < 0: thread_life=0\n",
    "        except:\n",
    "            print(\"index:\", index)\n",
    "\n",
    "        \n",
    "        # print(structure.loc[structure.Root == data])\n",
    "\n",
    "        tweetInfo.append(data)\n",
    "        # friends_sum = np.log(friends_sum, where=0<friends_sum, out=np.nan*friends_sum)\n",
    "        # friends_sum = np.log10(friends_sum-friends_sum.min()+1)\n",
    "        tweetInfo.append(friends_sum)\n",
    "        tweetInfo.append(friends_std)\n",
    "        tweetInfo.append(words_std)\n",
    "        tweetInfo.append(words_sum)\n",
    "        tweetInfo.append(char_std)\n",
    "\n",
    "        tweetInfo.append(hashtagstd)\n",
    "        tweetInfo.append(hashtagsum)\n",
    "        tweetInfo.append(hashtagratio)\n",
    "        tweetInfo.append(urlsum)\n",
    "        tweetInfo.append(urlstd)\n",
    "        tweetInfo.append(urlratio)\n",
    "        tweetInfo.append(mentionsum)\n",
    "        tweetInfo.append(mentionstd)\n",
    "        tweetInfo.append(mentionratio)\n",
    "        tweetInfo.append(statuesstd)\n",
    "        tweetInfo.append(listedstd)\n",
    "        tweetInfo.append(followerstd)\n",
    "        tweetInfo.append(followers_friendratio)\n",
    "        tweetInfo.append(favoritestd)\n",
    "         \n",
    "        tweetInfo.append(thread_node_count)\n",
    "        tweetInfo.append(verifiedratio)\n",
    "        tweetInfo.append(verifiedsum)\n",
    "        tweetInfo.append(retweetsum)\n",
    "        tweetInfo.append(retweetstd)\n",
    "        tweetInfo.append(accagestd)\n",
    "        tweetInfo.append(thread_life)\n",
    "        tweetInfo.append(emojistd)\n",
    "        tweetInfo.append(emojiratio)\n",
    "        tweetInfo.append(mediaratio)\n",
    "        tweetInfo.append(questionratio)\n",
    "        tweetInfo.append(exclamationratio)\n",
    "        tweetInfo.append(periodratio)\n",
    "        tweetInfo.append(FPPstd)\n",
    "        tweetInfo.append(SPPstd)\n",
    "        tweetInfo.append(TPPstd)\n",
    "        tweetInfo.append(Skepticismstd)\n",
    "        tweetInfo.append(Skepticismratio)\n",
    "        tweetInfo.append(test_auxiliaryratio)\n",
    "        tweetInfo.append(test_tentatratio)\n",
    "        tweetInfo.append(test_certainratio)\n",
    "        tweetInfo.append(root_user_ratio)\n",
    "        tweetInfo.append(unique_user_ratio)\n",
    "        tweetInfo.append(unique_user_sum)\n",
    "\n",
    "        threadInfo.append(tweetInfo)\n",
    "\n",
    "        result = pd.DataFrame(threadInfo, columns=['Root', 'SUM FriendsCount','STD FriendsCount', 'STD WordCount','SUM WordCount', 'STD CharCount', 'STD HashTag', 'SUM HashTag', 'Ratio HashTag','SUM Url', 'STD Url','RATIO Url','SUM Mention', 'STD Mention', 'Ratio Mention','STD Statues','STD Listed','STD Follower','STD followers/friend','STD favorite', 'Tweets Count', 'Ratio Verified','SUM Verified','SUM RT', 'STD RT','STD AccAge', 'thread_time', \"STD Emoji\",\"RATIO Emoji\",\"Ratio Media\",'RATIO Question', 'RATIO Exclaim','RATIO Period', 'STD FPP', 'STD SPP','STD TPP','STD Skepticism','Ratio Skepticism', 'test_auxiliary','test_tentat','test_certain', 'root_user_ratio','unique_user_ratio','unique_user_sum'])\n",
    "        result = pd.merge(thread_depth, result, on=\"Root\").drop(['Root'], axis=1)\n",
    "\n",
    "    result = result.fillna(0)\n",
    "    result = result.replace(-np.inf, 0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PHEME ALL Create\n",
    "\n",
    "420120 Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "charliehebdo's length is 38268\n",
      "ferguson's length is 24175\n",
      "germanwings-crash's length is 4489\n",
      "ottawashooting's length is 12284\n",
      "sydneysiege's length is 23996\n"
     ]
    }
   ],
   "source": [
    "path = \"../pheme-rnr-dataset\"\n",
    "events = ['charliehebdo', 'ferguson',\n",
    "          'germanwings-crash', 'ottawashooting', 'sydneysiege']\n",
    "# events = ['germanwings-sydneysiege']\n",
    "# # # # events = [eventname+\"-all-rnr-threads\" for eventname in events]\n",
    "\n",
    "tweetType = '*'\n",
    "final = fetchRawText_all(path, events, tweetType)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.isRT = final.isRT.replace({True: 1, False: 0}) \n",
    "final.verified = final.verified.replace({True: 1, False: 0}) \n",
    "final.has_question = final.has_question.replace({True: 1, False: 0}) \n",
    "final.has_exclaim = final.has_exclaim.replace({True: 1, False: 0}) \n",
    "final.has_period = final.has_period.replace({True: 1, False: 0}) \n",
    "final = final.replace(-np.inf, 0)\n",
    "\n",
    "all_pheme = final\n",
    "all_pheme.to_csv('./data/all/_PHEMEall.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "charliehebdo-all-rnr-threads's structure.json number is 2079\n",
      "ferguson-all-rnr-threads's structure.json number is 1143\n",
      "germanwings-crash-all-rnr-threads's structure.json number is 469\n",
      "ottawashooting-all-rnr-threads's structure.json number is 890\n",
      "sydneysiege-all-rnr-threads's structure.json number is 1221\n"
     ]
    }
   ],
   "source": [
    "path = \"../PHEME/all-rnr-annotated-threads\"\n",
    "events = ['charliehebdo', 'ferguson',\n",
    "          'germanwings-crash', 'ottawashooting', 'sydneysiege']\n",
    "events = [eventname+\"-all-rnr-threads\" for eventname in events]\n",
    "pheme_structure = getThreadData(path, events)\n",
    "# pheme_structure.to_csv('./data/all/_PHEME_structure.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PHEME ALL Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125208, 50)\n",
      "(5802, 347)\n"
     ]
    }
   ],
   "source": [
    "all_pheme = pd.read_csv(\"./data/all/_PHEMEall.csv\")\n",
    "structure_pheme = pd.read_csv(\"./data/all/_PHEME_structure.csv\")\n",
    "print(all_pheme.shape)\n",
    "print(structure_pheme.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pheme_thread = getThreadInfo(structure_pheme, all_pheme)\n",
    "# pheme_thread = pheme_thread.fillna(0)\n",
    "# pheme_thread = pheme_thread.replace(-np.inf, 0)\n",
    "# pheme_thread.head(15)\n",
    "# pheme_thread.to_csv('./data/_PHEME_thread.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pheme_thread_avg = getThreadInfo_AVG(structure_pheme, all_pheme)\n",
    "# pheme_thread_avg.head(5)\n",
    "pheme_thread_avg.to_csv('./data/_PHEME_thread_avg.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Skepticismstd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-ac099d848104>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpheme_thread_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetThreadInfo_STD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure_pheme\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_pheme\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpheme_thread_std\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpheme_thread_std\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/_PHEME_thread_std.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-76-3c0977794ef6>\u001b[0m in \u001b[0;36mgetThreadInfo_STD\u001b[0;34m(structure, df)\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0mtweetInfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTPPstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# tweetInfo.append(TPPstd)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m         \u001b[0mtweetInfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSkepticismstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         \u001b[0mtweetInfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSkepticismratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0mtweetInfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_auxiliaryratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Skepticismstd' is not defined"
     ]
    }
   ],
   "source": [
    "pheme_thread_std = getThreadInfo_STD(structure_pheme, all_pheme)\n",
    "pheme_thread_std.head(5)\n",
    "pheme_thread_std.to_csv('./data/_PHEME_thread_std.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PHEMEext Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ebola-essien's length is 226\n",
      "prince-toronto's length is 902\n",
      "putinmissing's length is 835\n",
      "(1963, 50)\n"
     ]
    },
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>id</th>\n      <th>pid</th>\n      <th>userid</th>\n      <th>emoji_count</th>\n      <th>has_media</th>\n      <th>URLcount</th>\n      <th>Skepticism</th>\n      <th>MentionCount</th>\n      <th>token_for_POS</th>\n      <th>Noun</th>\n      <th>Verb</th>\n      <th>Adjective</th>\n      <th>Pronoun</th>\n      <th>FirstPersonPronoun</th>\n      <th>SecondPersonPronoun</th>\n      <th>ThirdPersonPronoun</th>\n      <th>Adverb</th>\n      <th>Numeral</th>\n      <th>Conjunction_inj</th>\n      <th>Particle</th>\n      <th>Determiner</th>\n      <th>Modal</th>\n      <th>Whs</th>\n      <th>test_auxiliary</th>\n      <th>test_tentat</th>\n      <th>test_certain</th>\n      <th>char_count</th>\n      <th>word_count</th>\n      <th>HashTag</th>\n      <th>has_question</th>\n      <th>has_exclaim</th>\n      <th>has_period</th>\n      <th>retweet_count</th>\n      <th>isRT</th>\n      <th>statuses_count</th>\n      <th>listed_count</th>\n      <th>friends_count</th>\n      <th>followers_count</th>\n      <th>location</th>\n      <th>name</th>\n      <th>followers/friend</th>\n      <th>favourites_count</th>\n      <th>account_age_days</th>\n      <th>tweet_created</th>\n      <th>capital_ratio</th>\n      <th>verified</th>\n      <th>Event</th>\n      <th>isSrcTweet</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>@Mourinholic 😕😕 http://t.co/sFoV1v8uDo</td>\n      <td>521410632953131008</td>\n      <td>521369179392581632.00000</td>\n      <td>159811191</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>38</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>78030</td>\n      <td>1.20412</td>\n      <td>1374</td>\n      <td>3636</td>\n      <td>Dortmund</td>\n      <td>#Jinxed</td>\n      <td>2.64629</td>\n      <td>1088</td>\n      <td>1569</td>\n      <td>1413148956.00000</td>\n      <td>0.10526</td>\n      <td>0</td>\n      <td>ebola-essien</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>“@Mourinholic: Micheal Essien denying the Ebola rumours like https://t.co/8Yo8iLgISS”</td>\n      <td>521373142347153409</td>\n      <td>521369179392581632.00000</td>\n      <td>2338265452</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>5</td>\n      <td>1</td>\n      <td>[micheal, essien, denying, the, ebola, rumours, like]</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>85</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3875</td>\n      <td>0.90309</td>\n      <td>1261</td>\n      <td>1278</td>\n      <td>Stamford Bridge</td>\n      <td>Diegooooooooo</td>\n      <td>1.01348</td>\n      <td>62</td>\n      <td>242</td>\n      <td>1413140018.00000</td>\n      <td>0.10588</td>\n      <td>0</td>\n      <td>ebola-essien</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@Mourinholic Hmmm.</td>\n      <td>521369380249432064</td>\n      <td>521369179392581632.00000</td>\n      <td>1042012837</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>[hmmm]</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>18</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>33334</td>\n      <td>1.17609</td>\n      <td>78</td>\n      <td>1394</td>\n      <td>Cairo</td>\n      <td>Ahmed Wagih</td>\n      <td>17.87179</td>\n      <td>2651</td>\n      <td>653</td>\n      <td>1413139121.00000</td>\n      <td>0.11111</td>\n      <td>0</td>\n      <td>ebola-essien</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                                                                    text  \\\n0                                                 @Mourinholic 😕😕 http://t.co/sFoV1v8uDo   \n1  “@Mourinholic: Micheal Essien denying the Ebola rumours like https://t.co/8Yo8iLgISS”   \n2                                                                     @Mourinholic Hmmm.   \n\n                   id                      pid      userid  emoji_count  \\\n0  521410632953131008 521369179392581632.00000   159811191            2   \n1  521373142347153409 521369179392581632.00000  2338265452            0   \n2  521369380249432064 521369179392581632.00000  1042012837            0   \n\n   has_media  URLcount  Skepticism  MentionCount  \\\n0          1         0           2             1   \n1          0         1           5             1   \n2          0         0           1             1   \n\n                                           token_for_POS  Noun  Verb  \\\n0                                                     []     0     0   \n1  [micheal, essien, denying, the, ebola, rumours, like]     2     2   \n2                                                 [hmmm]     1     0   \n\n   Adjective  Pronoun  FirstPersonPronoun  SecondPersonPronoun  \\\n0          0        0                   0                    0   \n1          1        0                   0                    0   \n2          0        0                   0                    0   \n\n   ThirdPersonPronoun  Adverb  Numeral  Conjunction_inj  Particle  Determiner  \\\n0                   0       0        0                0         0           0   \n1                   0       0        0                1         0           1   \n2                   0       0        0                0         0           0   \n\n   Modal  Whs  test_auxiliary  test_tentat  test_certain  char_count  \\\n0      0    0               0            0             0          38   \n1      0    0               0            0             0          85   \n2      0    0               0            0             0          18   \n\n   word_count  HashTag  has_question  has_exclaim  has_period  retweet_count  \\\n0           3        0             0            0           1              0   \n1           9        0             0            0           1              0   \n2           2        0             0            0           1              0   \n\n  isRT  statuses_count  listed_count  friends_count  followers_count  \\\n0    0           78030       1.20412           1374             3636   \n1    0            3875       0.90309           1261             1278   \n2    0           33334       1.17609             78             1394   \n\n          location           name  followers/friend  favourites_count  \\\n0         Dortmund       #Jinxed            2.64629              1088   \n1  Stamford Bridge  Diegooooooooo           1.01348                62   \n2            Cairo    Ahmed Wagih          17.87179              2651   \n\n   account_age_days    tweet_created  capital_ratio  verified         Event  \\\n0              1569 1413148956.00000        0.10526         0  ebola-essien   \n1               242 1413140018.00000        0.10588         0  ebola-essien   \n2               653 1413139121.00000        0.11111         0  ebola-essien   \n\n   isSrcTweet  target  \n0           0       1  \n1           0       1  \n2           0       1  "
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../PHEME/all-rnr-annotated-threads\"\n",
    "events = ['ebola-essien', 'prince-toronto', 'putinmissing']\n",
    "# events = ['ebola-essien']\n",
    "tweetType = '*'\n",
    "\n",
    "all_ext = fetchRawText_all(path, events, tweetType)\n",
    "all_ext.isRT = all_ext.isRT.replace({True: 1, False: 0}) \n",
    "all_ext.verified = all_ext.verified.replace({True: 1, False: 0}) \n",
    "all_ext.has_question = all_ext.has_question.replace({True: 1, False: 0}) \n",
    "all_ext.has_exclaim = all_ext.has_exclaim.replace({True: 1, False: 0}) \n",
    "all_ext.has_period = all_ext.has_period.replace({True: 1, False: 0}) \n",
    "all_ext = all_ext.replace(-np.inf, 0)\n",
    "\n",
    "print(all_ext.shape)\n",
    "all_ext.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data looking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-186-33b1d2d62580>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-186-33b1d2d62580>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    mentionsum = np.sum([np.sum( df.loc[ df.loc[(df['id'] == int(childid))]['location'].values == ] ) for childid in structure.loc[index,:].dropna()])\u001b[0m\n\u001b[0m                                                                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "mentionsum = np.sum([np.sum( df.loc[ df.loc[(df['id'] == int(childid))]['location'].values == ] ) for childid in structure.loc[index,:].dropna()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "159811191"
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_userid = all_ext.loc[(all_ext['id'] == int(521410632953131008))].userid.sum()\n",
    "p_userid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "16"
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(([np.sum(all_ext.loc[(all_ext['id'] == int(childid))]\n",
    "        ['userid'].values) for childid in structure_ext.loc[0, :].dropna()]))\n",
    "# len([np.sum(df.loc[(df['id'] == int(childid))]\n",
    "#         ['userid'].values) for childid in structure.loc[0, :].dropna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "16"
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([childid for childid in structure_ext.loc[0, :].dropna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.0625"
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 루트 트윗 작성자가 쓰레드에서 차지하는 비율\n",
    "np.sum([np.any(all_ext.loc[(all_ext['id'] == int(childid)) & (all_ext['userid'] == p_userid)]['userid'].values) for childid in structure_ext.loc[0, :].dropna()]) / len([childid for childid in structure_ext.loc[0, :].dropna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "13"
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 해당 쓰레드의 unique한 작성자 수\n",
    "len(np.unique([np.sum(all_ext.loc[(all_ext['id'] == int(childid))]['userid'].values) for childid in structure_ext.loc[0, :].dropna()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Root     521369179392581632\n0        521410632953131008\n1        521373142347153409\n2        521369380249432064\n3        521370496928337920\n4        521370224256614400\n5        521370771793670144\n6        521378607231279104\n7        521370530134626307\n8        521373433654157312\n9        521369485144387584\n10       521370061550809088\n11       521369671975858176\n12       521372372927266817\n13       521373960509079552\n14                     None\n15                     None\n16                     None\n17                     None\n18                     None\n19                     None\n20                     None\n21                     None\n22                     None\n23                     None\n24                     None\n25                     None\ndepth                     4\nName: 0, dtype: object"
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structure_ext.loc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0        159811191\n1       2338265452\n2       1042012837\n3         96820406\n4        159412087\n           ...    \n1958     563061700\n1959     267736380\n1960     512529194\n1961      34792486\n1962     218264459\nName: userid, Length: 1963, dtype: int64"
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ext['userid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>id</th>\n      <th>pid</th>\n      <th>userid</th>\n      <th>emoji_count</th>\n      <th>has_media</th>\n      <th>URLcount</th>\n      <th>Skepticism</th>\n      <th>MentionCount</th>\n      <th>token_for_POS</th>\n      <th>Noun</th>\n      <th>Verb</th>\n      <th>Adjective</th>\n      <th>Pronoun</th>\n      <th>FirstPersonPronoun</th>\n      <th>SecondPersonPronoun</th>\n      <th>ThirdPersonPronoun</th>\n      <th>Adverb</th>\n      <th>Numeral</th>\n      <th>Conjunction_inj</th>\n      <th>Particle</th>\n      <th>Determiner</th>\n      <th>Modal</th>\n      <th>Whs</th>\n      <th>test_auxiliary</th>\n      <th>test_tentat</th>\n      <th>test_certain</th>\n      <th>char_count</th>\n      <th>word_count</th>\n      <th>HashTag</th>\n      <th>has_question</th>\n      <th>has_exclaim</th>\n      <th>has_period</th>\n      <th>retweet_count</th>\n      <th>isRT</th>\n      <th>statuses_count</th>\n      <th>listed_count</th>\n      <th>friends_count</th>\n      <th>followers_count</th>\n      <th>location</th>\n      <th>name</th>\n      <th>followers/friend</th>\n      <th>favourites_count</th>\n      <th>account_age_days</th>\n      <th>tweet_created</th>\n      <th>capital_ratio</th>\n      <th>verified</th>\n      <th>Event</th>\n      <th>isSrcTweet</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>@Mourinholic 😕😕 http://t.co/sFoV1v8uDo</td>\n      <td>521410632953131008</td>\n      <td>521369179392581632.00000</td>\n      <td>159811191</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>38</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>78030</td>\n      <td>1.20412</td>\n      <td>1374</td>\n      <td>3636</td>\n      <td>Dortmund</td>\n      <td>#Jinxed</td>\n      <td>2.64629</td>\n      <td>1088</td>\n      <td>1569</td>\n      <td>1413148956.00000</td>\n      <td>0.10526</td>\n      <td>0</td>\n      <td>ebola-essien</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>“@Mourinholic: Micheal Essien denying the Ebola rumours like https://t.co/8Yo8iLgISS”</td>\n      <td>521373142347153409</td>\n      <td>521369179392581632.00000</td>\n      <td>2338265452</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>5</td>\n      <td>1</td>\n      <td>[micheal, essien, denying, the, ebola, rumours, like]</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>85</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3875</td>\n      <td>0.90309</td>\n      <td>1261</td>\n      <td>1278</td>\n      <td>Stamford Bridge</td>\n      <td>Diegooooooooo</td>\n      <td>1.01348</td>\n      <td>62</td>\n      <td>242</td>\n      <td>1413140018.00000</td>\n      <td>0.10588</td>\n      <td>0</td>\n      <td>ebola-essien</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@Mourinholic Hmmm.</td>\n      <td>521369380249432064</td>\n      <td>521369179392581632.00000</td>\n      <td>1042012837</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>[hmmm]</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>18</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>33334</td>\n      <td>1.17609</td>\n      <td>78</td>\n      <td>1394</td>\n      <td>Cairo</td>\n      <td>Ahmed Wagih</td>\n      <td>17.87179</td>\n      <td>2651</td>\n      <td>653</td>\n      <td>1413139121.00000</td>\n      <td>0.11111</td>\n      <td>0</td>\n      <td>ebola-essien</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>@Mourinholic Even though it was against us, it was a bloody amazing goal.</td>\n      <td>521370496928337920</td>\n      <td>521369179392581632.00000</td>\n      <td>96820406</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>[even, though, it, was, against, us, it, was, a, bloody, amazing, goal]</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>73</td>\n      <td>13</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>928</td>\n      <td>0.00000</td>\n      <td>224</td>\n      <td>57</td>\n      <td></td>\n      <td>Matthew Terzian</td>\n      <td>0.25446</td>\n      <td>2255</td>\n      <td>1762</td>\n      <td>1413139387.00000</td>\n      <td>0.02740</td>\n      <td>0</td>\n      <td>ebola-essien</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>@CdtChoco1er thanks bro.</td>\n      <td>521370224256614400</td>\n      <td>521370061550809088.00000</td>\n      <td>159412087</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>[thanks, bro]</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>24</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>42054</td>\n      <td>2.20140</td>\n      <td>670</td>\n      <td>22699</td>\n      <td></td>\n      <td>Rashad</td>\n      <td>33.87910</td>\n      <td>10074</td>\n      <td>1570</td>\n      <td>1413139322.00000</td>\n      <td>0.08333</td>\n      <td>0</td>\n      <td>ebola-essien</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1958</th>\n      <td>@AndreaChalupa Yes the fact that he (if still with us) has 'allowed' these rumours to continue is...interesting.</td>\n      <td>576444037437198336</td>\n      <td>576443643680178176.00000</td>\n      <td>563061700</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>1</td>\n      <td>[yes, the, fact, that, he, if, still, with, us, has, allowed, these, rumours, to, continue, isinteresting]</td>\n      <td>2</td>\n      <td>4</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>112</td>\n      <td>17</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>10799</td>\n      <td>1.30103</td>\n      <td>354</td>\n      <td>610</td>\n      <td></td>\n      <td>Andrew Stuttaford</td>\n      <td>1.72316</td>\n      <td>107</td>\n      <td>1052</td>\n      <td>1426269942.00000</td>\n      <td>0.02679</td>\n      <td>0</td>\n      <td>putinmissing</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1959</th>\n      <td>@AndreaChalupa ...that's the plan, confuse your opponents: Judo 101</td>\n      <td>576446450856435713</td>\n      <td>576443643680178176.00000</td>\n      <td>267736380</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>[that, is, the, plan, confuse, your, opponents, judo, 101]</td>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>67</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9929</td>\n      <td>0.77815</td>\n      <td>317</td>\n      <td>170</td>\n      <td>Idaho</td>\n      <td>Jon Muench</td>\n      <td>0.53628</td>\n      <td>5027</td>\n      <td>1457</td>\n      <td>1426270518.00000</td>\n      <td>0.04478</td>\n      <td>0</td>\n      <td>putinmissing</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1960</th>\n      <td>@AndreaChalupa he's probably deep underground finalising the targets before launch.</td>\n      <td>576462402864177153</td>\n      <td>576443643680178176.00000</td>\n      <td>512529194</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>1</td>\n      <td>[he, is, probably, deep, underground, finalising, the, targets, before, launch]</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>83</td>\n      <td>10</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>382</td>\n      <td>0.47712</td>\n      <td>201</td>\n      <td>31</td>\n      <td></td>\n      <td>DigoriePiper</td>\n      <td>0.15423</td>\n      <td>10</td>\n      <td>1105</td>\n      <td>1426274321.00000</td>\n      <td>0.02410</td>\n      <td>0</td>\n      <td>putinmissing</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1961</th>\n      <td>Putin juggling enough instability. He would make a live appearance by now to squash death/coup jitters.</td>\n      <td>576443643680178176</td>\n      <td>NaN</td>\n      <td>34792486</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>[putin, juggling, enough, instability, he, would, make, a, live, appearance, by, now, to, squash, deathcoup, jitters]</td>\n      <td>5</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>103</td>\n      <td>16</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>7</td>\n      <td>0</td>\n      <td>8878</td>\n      <td>2.16435</td>\n      <td>878</td>\n      <td>3244</td>\n      <td>NYC</td>\n      <td>Andrea Chalupa</td>\n      <td>3.69476</td>\n      <td>5100</td>\n      <td>2149</td>\n      <td>1426269849.00000</td>\n      <td>0.01942</td>\n      <td>0</td>\n      <td>putinmissing</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1962</th>\n      <td>Vladimir #Putin #reappears on #television amidst all wild speculations\\nhttp://t.co/Is6dpF5WIp</td>\n      <td>576715243948118016</td>\n      <td>NaN</td>\n      <td>218264459</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>[vladimir, on, amidst, all, wild, speculations]</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>93</td>\n      <td>10</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>194988</td>\n      <td>2.31806</td>\n      <td>6287</td>\n      <td>7542</td>\n      <td>la terra firma</td>\n      <td>°•.༺•way❇seer•༻*°•.*</td>\n      <td>1.19962</td>\n      <td>47229</td>\n      <td>1573</td>\n      <td>1426334603.00000</td>\n      <td>0.06452</td>\n      <td>0</td>\n      <td>putinmissing</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1963 rows × 50 columns</p>\n</div>",
      "text/plain": "                                                                                                                  text  \\\n0                                                                               @Mourinholic 😕😕 http://t.co/sFoV1v8uDo   \n1                                “@Mourinholic: Micheal Essien denying the Ebola rumours like https://t.co/8Yo8iLgISS”   \n2                                                                                                   @Mourinholic Hmmm.   \n3                                            @Mourinholic Even though it was against us, it was a bloody amazing goal.   \n4                                                                                             @CdtChoco1er thanks bro.   \n...                                                                                                                ...   \n1958  @AndreaChalupa Yes the fact that he (if still with us) has 'allowed' these rumours to continue is...interesting.   \n1959                                               @AndreaChalupa ...that's the plan, confuse your opponents: Judo 101   \n1960                               @AndreaChalupa he's probably deep underground finalising the targets before launch.   \n1961           Putin juggling enough instability. He would make a live appearance by now to squash death/coup jitters.   \n1962                    Vladimir #Putin #reappears on #television amidst all wild speculations\\nhttp://t.co/Is6dpF5WIp   \n\n                      id                      pid      userid  emoji_count  \\\n0     521410632953131008 521369179392581632.00000   159811191            2   \n1     521373142347153409 521369179392581632.00000  2338265452            0   \n2     521369380249432064 521369179392581632.00000  1042012837            0   \n3     521370496928337920 521369179392581632.00000    96820406            0   \n4     521370224256614400 521370061550809088.00000   159412087            0   \n...                  ...                      ...         ...          ...   \n1958  576444037437198336 576443643680178176.00000   563061700            0   \n1959  576446450856435713 576443643680178176.00000   267736380            0   \n1960  576462402864177153 576443643680178176.00000   512529194            0   \n1961  576443643680178176                      NaN    34792486            0   \n1962  576715243948118016                      NaN   218264459            0   \n\n      has_media  URLcount  Skepticism  MentionCount  \\\n0             1         0           2             1   \n1             0         1           5             1   \n2             0         0           1             1   \n3             0         0           3             1   \n4             0         0           2             1   \n...         ...       ...         ...           ...   \n1958          0         0           9             1   \n1959          0         0           4             1   \n1960          0         0           5             1   \n1961          0         0           3             0   \n1962          0         1           2             0   \n\n                                                                                                              token_for_POS  \\\n0                                                                                                                        []   \n1                                                                     [micheal, essien, denying, the, ebola, rumours, like]   \n2                                                                                                                    [hmmm]   \n3                                                   [even, though, it, was, against, us, it, was, a, bloody, amazing, goal]   \n4                                                                                                             [thanks, bro]   \n...                                                                                                                     ...   \n1958             [yes, the, fact, that, he, if, still, with, us, has, allowed, these, rumours, to, continue, isinteresting]   \n1959                                                             [that, is, the, plan, confuse, your, opponents, judo, 101]   \n1960                                        [he, is, probably, deep, underground, finalising, the, targets, before, launch]   \n1961  [putin, juggling, enough, instability, he, would, make, a, live, appearance, by, now, to, squash, deathcoup, jitters]   \n1962                                                                        [vladimir, on, amidst, all, wild, speculations]   \n\n      Noun  Verb  Adjective  Pronoun  FirstPersonPronoun  SecondPersonPronoun  \\\n0        0     0          0        0                   0                    0   \n1        2     2          1        0                   0                    0   \n2        1     0          0        0                   0                    0   \n3        1     2          2        3                   1                    0   \n4        1     1          0        0                   0                    0   \n...    ...   ...        ...      ...                 ...                  ...   \n1958     2     4          0        2                   1                    0   \n1959     2     3          0        1                   0                    1   \n1960     2     2          1        1                   0                    0   \n1961     5     3          2        1                   0                    0   \n1962     3     0          1        0                   0                    0   \n\n      ThirdPersonPronoun  Adverb  Numeral  Conjunction_inj  Particle  \\\n0                      0       0        0                0         0   \n1                      0       0        0                1         0   \n2                      0       0        0                0         0   \n3                      2       1        0                2         0   \n4                      0       0        0                0         0   \n...                  ...     ...      ...              ...       ...   \n1958                   1       2        0                3         0   \n1959                   0       0        1                0         0   \n1960                   1       1        0                2         0   \n1961                   1       1        0                1         0   \n1962                   0       0        0                1         0   \n\n      Determiner  Modal  Whs  test_auxiliary  test_tentat  test_certain  \\\n0              0      0    0               0            0             0   \n1              1      0    0               0            0             0   \n2              0      0    0               0            0             0   \n3              1      0    0               2            0             0   \n4              0      0    0               0            0             0   \n...          ...    ...  ...             ...          ...           ...   \n1958           2      0    0               0            0             0   \n1959           2      0    0               1            0             0   \n1960           1      0    0               1            1             0   \n1961           1      1    0               1            0             0   \n1962           1      0    0               0            0             0   \n\n      char_count  word_count  HashTag  has_question  has_exclaim  has_period  \\\n0             38           3        0             0            0           1   \n1             85           9        0             0            0           1   \n2             18           2        0             0            0           1   \n3             73          13        0             0            0           1   \n4             24           3        0             0            0           1   \n...          ...         ...      ...           ...          ...         ...   \n1958         112          17        0             0            0           1   \n1959          67           9        0             0            0           1   \n1960          83          10        0             0            0           1   \n1961         103          16        0             0            0           1   \n1962          93          10        3             0            0           1   \n\n      retweet_count isRT  statuses_count  listed_count  friends_count  \\\n0                 0    0           78030       1.20412           1374   \n1                 0    0            3875       0.90309           1261   \n2                 0    0           33334       1.17609             78   \n3                 0    0             928       0.00000            224   \n4                 0    0           42054       2.20140            670   \n...             ...  ...             ...           ...            ...   \n1958              1    0           10799       1.30103            354   \n1959              0    0            9929       0.77815            317   \n1960              0    0             382       0.47712            201   \n1961              7    0            8878       2.16435            878   \n1962              2    0          194988       2.31806           6287   \n\n      followers_count         location                  name  \\\n0                3636         Dortmund              #Jinxed    \n1                1278  Stamford Bridge         Diegooooooooo   \n2                1394            Cairo           Ahmed Wagih   \n3                  57                        Matthew Terzian   \n4               22699                                 Rashad   \n...               ...              ...                   ...   \n1958              610                      Andrew Stuttaford   \n1959              170            Idaho            Jon Muench   \n1960               31                           DigoriePiper   \n1961             3244              NYC        Andrea Chalupa   \n1962             7542   la terra firma  °•.༺•way❇seer•༻*°•.*   \n\n      followers/friend  favourites_count  account_age_days    tweet_created  \\\n0              2.64629              1088              1569 1413148956.00000   \n1              1.01348                62               242 1413140018.00000   \n2             17.87179              2651               653 1413139121.00000   \n3              0.25446              2255              1762 1413139387.00000   \n4             33.87910             10074              1570 1413139322.00000   \n...                ...               ...               ...              ...   \n1958           1.72316               107              1052 1426269942.00000   \n1959           0.53628              5027              1457 1426270518.00000   \n1960           0.15423                10              1105 1426274321.00000   \n1961           3.69476              5100              2149 1426269849.00000   \n1962           1.19962             47229              1573 1426334603.00000   \n\n      capital_ratio  verified         Event  isSrcTweet  target  \n0           0.10526         0  ebola-essien           0       1  \n1           0.10588         0  ebola-essien           0       1  \n2           0.11111         0  ebola-essien           0       1  \n3           0.02740         0  ebola-essien           0       1  \n4           0.08333         0  ebola-essien           0       1  \n...             ...       ...           ...         ...     ...  \n1958        0.02679         0  putinmissing           0       0  \n1959        0.04478         0  putinmissing           0       0  \n1960        0.02410         0  putinmissing           0       0  \n1961        0.01942         0  putinmissing           1       0  \n1962        0.06452         0  putinmissing           1       0  \n\n[1963 rows x 50 columns]"
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for &: 'str' and 'bool'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mna_logical_op\u001b[0;34m(x, y, op)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;31m#  (xint or xbool) and (yint or bool)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for &: 'str' and 'bool'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-4d695894545e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_ext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_ext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'location'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m521369179392581632\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mall_ext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/pandas/core/arraylike.py\u001b[0m in \u001b[0;36m__and__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__and__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__and__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logical_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mand_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__rand__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_logical_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   4984\u001b[0m         \u001b[0mrvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4986\u001b[0;31m         \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4987\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mlogical_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0mfiller\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill_int\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_self_int_dtype\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_other_int_dtype\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfill_bool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mna_logical_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;31m# error: Cannot call function of unknown type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_values\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[operator]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mna_logical_op\u001b[0;34m(x, y, op)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_binop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0;31m# let null fall thru\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/ops.pyx\u001b[0m in \u001b[0;36mpandas._libs.ops.vec_binop\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/ops.pyx\u001b[0m in \u001b[0;36mpandas._libs.ops.vec_binop\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for &: 'str' and 'bool'"
     ]
    }
   ],
   "source": [
    "all_ext.loc[(all_ext['location'] and (521369179392581632 == all_ext.id))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-154a418ce4d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m all_ext.loc[(all_ext['retweet_count'] > 0) and \n\u001b[0m\u001b[1;32m      2\u001b[0m     (all_ext.pid == 521369179392581632)][['verified', 'HashTag', 'URLcount',\n\u001b[1;32m      3\u001b[0m     'MentionCount', 'retweet_count', 'isSrcTweet', 'target']].sample(18)\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1441\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   1442\u001b[0m             \u001b[0;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m             \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "all_ext.loc[(all_ext['location'] == and \n",
    "    (all_ext.pid == 521369179392581632)][['verified', 'HashTag', 'URLcount',\n",
    "    'MentionCount', 'retweet_count', 'isSrcTweet', 'target']].sample(18)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>location</th>\n      <th>name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Dortmund</td>\n      <td>#Jinxed</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Stamford Bridge</td>\n      <td>Diegooooooooo</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Cairo</td>\n      <td>Ahmed Wagih</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>Matthew Terzian</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td>Rashad</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1958</th>\n      <td></td>\n      <td>Andrew Stuttaford</td>\n    </tr>\n    <tr>\n      <th>1959</th>\n      <td>Idaho</td>\n      <td>Jon Muench</td>\n    </tr>\n    <tr>\n      <th>1960</th>\n      <td></td>\n      <td>DigoriePiper</td>\n    </tr>\n    <tr>\n      <th>1961</th>\n      <td>NYC</td>\n      <td>Andrea Chalupa</td>\n    </tr>\n    <tr>\n      <th>1962</th>\n      <td>la terra firma</td>\n      <td>°•.༺•way❇seer•༻*°•.*</td>\n    </tr>\n  </tbody>\n</table>\n<p>1963 rows × 2 columns</p>\n</div>",
      "text/plain": "             location                  name\n0            Dortmund              #Jinxed \n1     Stamford Bridge         Diegooooooooo\n2               Cairo           Ahmed Wagih\n3                           Matthew Terzian\n4                                    Rashad\n...               ...                   ...\n1958                      Andrew Stuttaford\n1959            Idaho            Jon Muench\n1960                           DigoriePiper\n1961              NYC        Andrea Chalupa\n1962   la terra firma  °•.༺•way❇seer•༻*°•.*\n\n[1963 rows x 2 columns]"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all_ext[['test_auxiliary','test_tentat','test_certain']].value_counts()\n",
    "# final_ext[['test_auxiliary','test_tentat','test_certain']].value_counts()\n",
    "all_ext[['location', 'name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>test_auxiliary</th>\n      <th>test_tentat</th>\n      <th>test_certain</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>No truth in internet rumours that I have contracted Ebola.i m very well &amp;amp; I'm doing very gud &amp;amp; will be training as usual tomorrow.#falsenews</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Milan have stated that the reports about Essien having Ebola are completely false.\\nhttp://t.co/Sb9v9ulfTX\\n@MichaelEssien</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>I'm very fit and very healthy,No truth in the internet rumours that I have contracted Ebola.im well &amp;amp;… http://t.co/TGidyI5JVG</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>AC Milan have denied reports that midfielder Michael Essien has contracted Ebola while on national duty with Ghana #SSFootball</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>AC Milan have confirmed that the reports about Michael Essien having Ebola are completely false.</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>471</th>\n      <td>Why do I see tanks in front of Moscow Mayor's office? #putinmissing</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>477</th>\n      <td>Stauffenberg meant well, but killing Hitler in July 1944 would have left Germany @ war, under control of Generals &amp;amp; NSDAP types. #PutinDead</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>478</th>\n      <td>We've sussed it. The Kremlin's getting ready for St Patrick's Day ;) #putinmissing #putindead http://t.co/J4aOEUv4gl</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>479</th>\n      <td>There was no coup in #Ukraine, #Putin now admits he was the one who urged Yanukovych to flee the country. http://t.co/Zx6ZaC5osy</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>483</th>\n      <td>Putin juggling enough instability. He would make a live appearance by now to squash death/coup jitters.</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>301 rows × 4 columns</p>\n</div>",
      "text/plain": "                                                                                                                                                     text  \\\n1    No truth in internet rumours that I have contracted Ebola.i m very well &amp; I'm doing very gud &amp; will be training as usual tomorrow.#falsenews   \n4                              Milan have stated that the reports about Essien having Ebola are completely false.\\nhttp://t.co/Sb9v9ulfTX\\n@MichaelEssien   \n5                       I'm very fit and very healthy,No truth in the internet rumours that I have contracted Ebola.im well &amp;… http://t.co/TGidyI5JVG   \n9                          AC Milan have denied reports that midfielder Michael Essien has contracted Ebola while on national duty with Ghana #SSFootball   \n13                                                       AC Milan have confirmed that the reports about Michael Essien having Ebola are completely false.   \n..                                                                                                                                                    ...   \n471                                                                                   Why do I see tanks in front of Moscow Mayor's office? #putinmissing   \n477       Stauffenberg meant well, but killing Hitler in July 1944 would have left Germany @ war, under control of Generals &amp; NSDAP types. #PutinDead   \n478                                  We've sussed it. The Kremlin's getting ready for St Patrick's Day ;) #putinmissing #putindead http://t.co/J4aOEUv4gl   \n479                      There was no coup in #Ukraine, #Putin now admits he was the one who urged Yanukovych to flee the country. http://t.co/Zx6ZaC5osy   \n483                                               Putin juggling enough instability. He would make a live appearance by now to squash death/coup jitters.   \n\n     test_auxiliary  test_tentat  test_certain  \n1                 4            0             0  \n4                 1            0             0  \n5                 2            0             0  \n9                 1            0             0  \n13                1            0             0  \n..              ...          ...           ...  \n471               1            0             0  \n477               2            0             0  \n478               3            0             0  \n479               2            0             0  \n483               1            0             0  \n\n[301 rows x 4 columns]"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all_ext[['text','test_auxiliary','test_tentat','test_certain']].loc[(all_ext.test_auxiliary > 0)|(all_ext.test_tentat > 0)]\n",
    "final_ext[['text','test_auxiliary','test_tentat','test_certain']].loc[(final_ext.test_auxiliary > 0)|(final_ext.test_tentat > 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_ext.to_csv('./data/all/_PHEMEextall.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ebola-essien's structure.json number is 14\n",
      "prince-toronto's structure.json number is 233\n",
      "putinmissing's structure.json number is 238\n",
      "ebola-essien's annotated.json number is 14\n",
      "prince-toronto's annotated.json number is 233\n",
      "putinmissing's annotated.json number is 238\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# ext_structure = getThreadData(path, events)\n",
    "structure_ext, annotation_ext = getThreadData(path, events)\n",
    "annotation_ext = annotation_ext.replace({'0': 0}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": " 1    245\n 0    124\n-1    116\nName: misinformation, dtype: int64"
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation_ext.misinformation.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "# structure_ext.to_csv('./data/all/_PHEMEext_structure.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PHEMEext Thread data PROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1963, 50)\n",
      "(485, 28)\n"
     ]
    }
   ],
   "source": [
    "# all_ext = pd.read_csv(\"./data/all/_PHEMEextall.csv\")\n",
    "structure_ext = pd.read_csv(\"./data/all/_PHEMEext_structure.csv\")\n",
    "ext_y = pd.read_csv('./data/_PHEMEext_target.csv')\n",
    "print(all_ext.shape)\n",
    "print(structure_ext.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_thread_avg = getThreadInfo_AVG(structure_ext, all_ext)\n",
    "# ext_thread_std = getThreadInfo_noAVG(structure_ext, all_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_thread_avg.to_csv('./data/_PHEMEext_thread_avg.csv', index = False)\n",
    "# ext_thread_std.to_csv('./data/_PHEMEext_thread_std.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>depth</th>\n      <th>SUM FriendsCount</th>\n      <th>AVG FriendsCount</th>\n      <th>AVG WordCount</th>\n      <th>SUM WordCount</th>\n      <th>AVG CharCount</th>\n      <th>AVG HashTag</th>\n      <th>SUM HashTag</th>\n      <th>Ratio HashTag</th>\n      <th>SUM Url</th>\n      <th>AVG Url</th>\n      <th>RATIO Url</th>\n      <th>SUM Mention</th>\n      <th>AVG Mention</th>\n      <th>Ratio Mention</th>\n      <th>AVG Statues</th>\n      <th>AVG Listed</th>\n      <th>AVG Follower</th>\n      <th>AVG followers/friend</th>\n      <th>AVG favorite</th>\n      <th>Tweets Count</th>\n      <th>Ratio Verified</th>\n      <th>SUM Verified</th>\n      <th>SUM RT</th>\n      <th>AVG RT</th>\n      <th>AVG AccAge</th>\n      <th>thread_time</th>\n      <th>AVG Emoji</th>\n      <th>RATIO Emoji</th>\n      <th>Ratio Media</th>\n      <th>RATIO Question</th>\n      <th>RATIO Exclaim</th>\n      <th>RATIO Period</th>\n      <th>AVG FPP</th>\n      <th>AVG SPP</th>\n      <th>AVG TPP</th>\n      <th>AVG Skepticism</th>\n      <th>Ratio Skepticism</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2.19794</td>\n      <td>3528.28247</td>\n      <td>1064.99130</td>\n      <td>10.01375</td>\n      <td>36.95670</td>\n      <td>69.41844</td>\n      <td>0.59794</td>\n      <td>1.25361</td>\n      <td>0.29762</td>\n      <td>0.51340</td>\n      <td>0.22614</td>\n      <td>0.22078</td>\n      <td>3.59381</td>\n      <td>0.60497</td>\n      <td>0.40513</td>\n      <td>17399.96588</td>\n      <td>0.97821</td>\n      <td>10285.87114</td>\n      <td>19.31136</td>\n      <td>2479.83766</td>\n      <td>4.04742</td>\n      <td>0.06684</td>\n      <td>0.15258</td>\n      <td>40.95258</td>\n      <td>4.41943</td>\n      <td>986.42153</td>\n      <td>15581.70722</td>\n      <td>0.03985</td>\n      <td>0.02008</td>\n      <td>0.13214</td>\n      <td>0.15139</td>\n      <td>0.10150</td>\n      <td>0.52345</td>\n      <td>0.18014</td>\n      <td>0.06492</td>\n      <td>0.24703</td>\n      <td>2.26836</td>\n      <td>0.65777</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.70257</td>\n      <td>8927.90066</td>\n      <td>2597.42952</td>\n      <td>6.36584</td>\n      <td>45.48508</td>\n      <td>42.83633</td>\n      <td>0.96245</td>\n      <td>1.75798</td>\n      <td>0.39206</td>\n      <td>0.78620</td>\n      <td>0.37453</td>\n      <td>0.35968</td>\n      <td>6.05126</td>\n      <td>0.66793</td>\n      <td>0.35595</td>\n      <td>31337.17039</td>\n      <td>0.81168</td>\n      <td>43573.90867</td>\n      <td>94.98489</td>\n      <td>6815.82271</td>\n      <td>4.83785</td>\n      <td>0.21699</td>\n      <td>0.38759</td>\n      <td>482.16712</td>\n      <td>25.62266</td>\n      <td>709.21957</td>\n      <td>51235.86482</td>\n      <td>0.20250</td>\n      <td>0.08366</td>\n      <td>0.29372</td>\n      <td>0.28140</td>\n      <td>0.21562</td>\n      <td>0.38458</td>\n      <td>0.33362</td>\n      <td>0.22990</td>\n      <td>0.40823</td>\n      <td>1.75281</td>\n      <td>0.35917</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.00000</td>\n      <td>287.00000</td>\n      <td>143.00000</td>\n      <td>5.50000</td>\n      <td>11.00000</td>\n      <td>39.40000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1534.45455</td>\n      <td>0.31808</td>\n      <td>163.00000</td>\n      <td>0.42067</td>\n      <td>28.25000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>475.66667</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.16667</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0.50000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>2.00000</td>\n      <td>1141.00000</td>\n      <td>413.00000</td>\n      <td>10.00000</td>\n      <td>20.00000</td>\n      <td>69.53333</td>\n      <td>0.04167</td>\n      <td>1.00000</td>\n      <td>0.04167</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0.50000</td>\n      <td>0.50000</td>\n      <td>6435.00000</td>\n      <td>0.86850</td>\n      <td>923.00000</td>\n      <td>1.02649</td>\n      <td>483.00000</td>\n      <td>2.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>3.00000</td>\n      <td>2.00000</td>\n      <td>938.46154</td>\n      <td>561.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.50000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>2.00000</td>\n      <td>0.71429</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>3.00000</td>\n      <td>3033.00000</td>\n      <td>964.00000</td>\n      <td>15.00000</td>\n      <td>46.00000</td>\n      <td>104.00000</td>\n      <td>1.00000</td>\n      <td>2.00000</td>\n      <td>0.50000</td>\n      <td>1.00000</td>\n      <td>0.33333</td>\n      <td>0.33333</td>\n      <td>4.00000</td>\n      <td>1.00000</td>\n      <td>0.66667</td>\n      <td>19238.50000</td>\n      <td>1.44936</td>\n      <td>3652.22222</td>\n      <td>4.41576</td>\n      <td>2298.50000</td>\n      <td>5.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>8.00000</td>\n      <td>4.00000</td>\n      <td>1443.00000</td>\n      <td>6964.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.05556</td>\n      <td>0.16667</td>\n      <td>0.11111</td>\n      <td>1.00000</td>\n      <td>0.25000</td>\n      <td>0.00000</td>\n      <td>0.40000</td>\n      <td>3.00000</td>\n      <td>1.00000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>16.00000</td>\n      <td>142166.00000</td>\n      <td>24369.00000</td>\n      <td>29.00000</td>\n      <td>326.00000</td>\n      <td>143.00000</td>\n      <td>6.00000</td>\n      <td>12.00000</td>\n      <td>1.00000</td>\n      <td>5.00000</td>\n      <td>2.00000</td>\n      <td>1.00000</td>\n      <td>38.00000</td>\n      <td>6.50000</td>\n      <td>1.00000</td>\n      <td>251318.00000</td>\n      <td>4.02987</td>\n      <td>562282.00000</td>\n      <td>1348.39808</td>\n      <td>96201.00000</td>\n      <td>27.00000</td>\n      <td>1.00000</td>\n      <td>3.00000</td>\n      <td>10415.00000</td>\n      <td>548.15789</td>\n      <td>3021.00000</td>\n      <td>753999.00000</td>\n      <td>3.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>2.00000</td>\n      <td>2.00000</td>\n      <td>2.00000</td>\n      <td>9.00000</td>\n      <td>1.00000</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "          depth  SUM FriendsCount  AVG FriendsCount  AVG WordCount  \\\ncount 485.00000         485.00000         485.00000      485.00000   \nmean    2.19794        3528.28247        1064.99130       10.01375   \nstd     1.70257        8927.90066        2597.42952        6.36584   \nmin     1.00000           0.00000           0.00000        0.00000   \n25%     1.00000         287.00000         143.00000        5.50000   \n50%     2.00000        1141.00000         413.00000       10.00000   \n75%     3.00000        3033.00000         964.00000       15.00000   \nmax    16.00000      142166.00000       24369.00000       29.00000   \n\n       SUM WordCount  AVG CharCount  AVG HashTag  SUM HashTag  Ratio HashTag  \\\ncount      485.00000      485.00000    485.00000    485.00000      485.00000   \nmean        36.95670       69.41844      0.59794      1.25361        0.29762   \nstd         45.48508       42.83633      0.96245      1.75798        0.39206   \nmin          0.00000        0.00000      0.00000      0.00000        0.00000   \n25%         11.00000       39.40000      0.00000      0.00000        0.00000   \n50%         20.00000       69.53333      0.04167      1.00000        0.04167   \n75%         46.00000      104.00000      1.00000      2.00000        0.50000   \nmax        326.00000      143.00000      6.00000     12.00000        1.00000   \n\n        SUM Url   AVG Url  RATIO Url  SUM Mention  AVG Mention  Ratio Mention  \\\ncount 485.00000 485.00000  485.00000    485.00000    485.00000      485.00000   \nmean    0.51340   0.22614    0.22078      3.59381      0.60497        0.40513   \nstd     0.78620   0.37453    0.35968      6.05126      0.66793        0.35595   \nmin     0.00000   0.00000    0.00000      0.00000      0.00000        0.00000   \n25%     0.00000   0.00000    0.00000      0.00000      0.00000        0.00000   \n50%     0.00000   0.00000    0.00000      1.00000      0.50000        0.50000   \n75%     1.00000   0.33333    0.33333      4.00000      1.00000        0.66667   \nmax     5.00000   2.00000    1.00000     38.00000      6.50000        1.00000   \n\n       AVG Statues  AVG Listed  AVG Follower  AVG followers/friend  \\\ncount    485.00000   485.00000     485.00000             485.00000   \nmean   17399.96588     0.97821   10285.87114              19.31136   \nstd    31337.17039     0.81168   43573.90867              94.98489   \nmin        0.00000     0.00000       0.00000               0.00000   \n25%     1534.45455     0.31808     163.00000               0.42067   \n50%     6435.00000     0.86850     923.00000               1.02649   \n75%    19238.50000     1.44936    3652.22222               4.41576   \nmax   251318.00000     4.02987  562282.00000            1348.39808   \n\n       AVG favorite  Tweets Count  Ratio Verified  SUM Verified      SUM RT  \\\ncount     485.00000     485.00000       485.00000     485.00000   485.00000   \nmean     2479.83766       4.04742         0.06684       0.15258    40.95258   \nstd      6815.82271       4.83785         0.21699       0.38759   482.16712   \nmin         0.00000       1.00000         0.00000       0.00000     0.00000   \n25%        28.25000       1.00000         0.00000       0.00000     0.00000   \n50%       483.00000       2.00000         0.00000       0.00000     3.00000   \n75%      2298.50000       5.00000         0.00000       0.00000     8.00000   \nmax     96201.00000      27.00000         1.00000       3.00000 10415.00000   \n\n         AVG RT  AVG AccAge  thread_time  AVG Emoji  RATIO Emoji  Ratio Media  \\\ncount 485.00000   485.00000    485.00000  485.00000    485.00000    485.00000   \nmean    4.41943   986.42153  15581.70722    0.03985      0.02008      0.13214   \nstd    25.62266   709.21957  51235.86482    0.20250      0.08366      0.29372   \nmin     0.00000     0.00000      0.00000    0.00000      0.00000      0.00000   \n25%     0.00000   475.66667      0.00000    0.00000      0.00000      0.00000   \n50%     2.00000   938.46154    561.00000    0.00000      0.00000      0.00000   \n75%     4.00000  1443.00000   6964.00000    0.00000      0.00000      0.05556   \nmax   548.15789  3021.00000 753999.00000    3.00000      1.00000      1.00000   \n\n       RATIO Question  RATIO Exclaim  RATIO Period   AVG FPP   AVG SPP  \\\ncount       485.00000      485.00000     485.00000 485.00000 485.00000   \nmean          0.15139        0.10150       0.52345   0.18014   0.06492   \nstd           0.28140        0.21562       0.38458   0.33362   0.22990   \nmin           0.00000        0.00000       0.00000   0.00000   0.00000   \n25%           0.00000        0.00000       0.16667   0.00000   0.00000   \n50%           0.00000        0.00000       0.50000   0.00000   0.00000   \n75%           0.16667        0.11111       1.00000   0.25000   0.00000   \nmax           1.00000        1.00000       1.00000   2.00000   2.00000   \n\n        AVG TPP  AVG Skepticism  Ratio Skepticism  \ncount 485.00000       485.00000         485.00000  \nmean    0.24703         2.26836           0.65777  \nstd     0.40823         1.75281           0.35917  \nmin     0.00000         0.00000           0.00000  \n25%     0.00000         1.00000           0.50000  \n50%     0.00000         2.00000           0.71429  \n75%     0.40000         3.00000           1.00000  \nmax     2.00000         9.00000           1.00000  "
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ext_thread_avg.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logify the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 👇 Thread 정보만을 추출한 결과\n",
    "아래의 Features들은 모두 한 Root 트윗에 달린 Thread의 정보를 포함한다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheme_thread = pd.read_csv(\"./data/_PHEME_thread.csv\")\n",
    "pheme_all = pd.read_csv(\"./data/all/_PHEMEall.csv\")\n",
    "ext_thread = pd.read_csv(\"./data/_PHEMEext_thread.csv\")\n",
    "pheme_thread_avg = pd.read_csv(\"./data/_PHEME_thread_avg.csv\")\n",
    "ext_thread_avg = pd.read_csv(\"./data/_PHEMEext_thread_avg.csv\")\n",
    "# pheme_thread.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>id</th>\n      <th>pid</th>\n      <th>emoji_count</th>\n      <th>has_media</th>\n      <th>URLcount</th>\n      <th>Skepticism</th>\n      <th>MentionCount</th>\n      <th>token_for_POS</th>\n      <th>Noun</th>\n      <th>Verb</th>\n      <th>Adjective</th>\n      <th>Pronoun</th>\n      <th>FirstPersonPronoun</th>\n      <th>SecondPersonPronoun</th>\n      <th>ThirdPersonPronoun</th>\n      <th>Adverb</th>\n      <th>Numeral</th>\n      <th>Conjunction_inj</th>\n      <th>Particle</th>\n      <th>Determiner</th>\n      <th>Modal</th>\n      <th>Whs</th>\n      <th>test_auxiliary</th>\n      <th>test_tentat</th>\n      <th>test_certain</th>\n      <th>char_count</th>\n      <th>word_count</th>\n      <th>HashTag</th>\n      <th>has_question</th>\n      <th>has_exclaim</th>\n      <th>has_period</th>\n      <th>retweet_count</th>\n      <th>isRT</th>\n      <th>statuses_count</th>\n      <th>listed_count</th>\n      <th>friends_count</th>\n      <th>followers_count</th>\n      <th>followers/friend</th>\n      <th>favourites_count</th>\n      <th>account_age_days</th>\n      <th>tweet_created</th>\n      <th>capital_ratio</th>\n      <th>verified</th>\n      <th>Event</th>\n      <th>isSrcTweet</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>BREAKING: Armed man takes hostage in kosher grocery east of Paris http://t.co/PBs3sMwhLt</td>\n      <td>553529101659566080.00000</td>\n      <td>NaN</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>4.00000</td>\n      <td>0.00000</td>\n      <td>['breaking', 'armed', 'man', 'takes', 'hostage', 'in', 'kosher', 'grocery', 'east', 'of', 'paris']</td>\n      <td>6.00000</td>\n      <td>3.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>2.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>88.00000</td>\n      <td>12.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>177.00000</td>\n      <td>0.00000</td>\n      <td>63575.00000</td>\n      <td>3.85594</td>\n      <td>614.00000</td>\n      <td>193798.00000</td>\n      <td>315.63192</td>\n      <td>77.00000</td>\n      <td>2126.00000</td>\n      <td>1420806596.00000</td>\n      <td>0.15909</td>\n      <td>1.00000</td>\n      <td>charliehebdo</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>“@haaretzcom: BREAKING: Armed man takes hostage in kosher grocery east of Paris http://t.co/SvpMxBoLsn” @andreinetto</td>\n      <td>553530890908098560.00000</td>\n      <td>553529101659566080.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>4.00000</td>\n      <td>2.00000</td>\n      <td>['breaking', 'armed', 'man', 'takes', 'hostage', 'in', 'kosher', 'grocery', 'east', 'of', 'paris']</td>\n      <td>6.00000</td>\n      <td>3.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>2.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>116.00000</td>\n      <td>14.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>102425.00000</td>\n      <td>1.51851</td>\n      <td>1997.00000</td>\n      <td>1296.00000</td>\n      <td>0.64897</td>\n      <td>4608.00000</td>\n      <td>1391.00000</td>\n      <td>1420807023.00000</td>\n      <td>0.12069</td>\n      <td>0.00000</td>\n      <td>charliehebdo</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@haaretzcom @AhmetHez to kill is right? How dare you you are not soldier how dare you turn children into killers how dare you do that</td>\n      <td>553547184000339968.00000</td>\n      <td>553529101659566080.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>7.00000</td>\n      <td>2.00000</td>\n      <td>['to', 'kill', 'is', 'right', 'how', 'dare', 'you', 'you', 'are', 'not', 'soldier', 'how', 'dare', 'you', 'turn', 'children', 'into', 'killers', 'how', 'dare', 'you', 'do', 'that']</td>\n      <td>5.00000</td>\n      <td>5.00000</td>\n      <td>2.00000</td>\n      <td>4.00000</td>\n      <td>0.00000</td>\n      <td>4.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>2.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>3.00000</td>\n      <td>4.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>133.00000</td>\n      <td>25.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>2297.00000</td>\n      <td>0.00000</td>\n      <td>1998.00000</td>\n      <td>163.00000</td>\n      <td>0.08158</td>\n      <td>23.00000</td>\n      <td>2.00000</td>\n      <td>1420810907.00000</td>\n      <td>0.02256</td>\n      <td>0.00000</td>\n      <td>charliehebdo</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>@haaretzcom @AhmetHez play back infront of ur kids so they can laugh at you what kind of nonsense you feed their mind what kind of bad words</td>\n      <td>553546643941761024.00000</td>\n      <td>553529101659566080.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>7.00000</td>\n      <td>2.00000</td>\n      <td>['play', 'back', 'infront', 'of', 'ur', 'kids', 'so', 'they', 'can', 'laugh', 'at', 'you', 'what', 'kind', 'of', 'nonsense', 'you', 'feed', 'their', 'mind', 'what', 'kind', 'of', 'bad', 'words']</td>\n      <td>7.00000</td>\n      <td>3.00000</td>\n      <td>2.00000</td>\n      <td>4.00000</td>\n      <td>0.00000</td>\n      <td>2.00000</td>\n      <td>2.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>5.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>2.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>140.00000</td>\n      <td>27.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>2297.00000</td>\n      <td>0.00000</td>\n      <td>1998.00000</td>\n      <td>163.00000</td>\n      <td>0.08158</td>\n      <td>23.00000</td>\n      <td>2.00000</td>\n      <td>1420810778.00000</td>\n      <td>0.01429</td>\n      <td>0.00000</td>\n      <td>charliehebdo</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>@ohohyesyesnono @haaretzcom Bots will conquest all the world.</td>\n      <td>553530583583047680.00000</td>\n      <td>553529101659566080.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>4.00000</td>\n      <td>2.00000</td>\n      <td>['bots', 'will', 'conquest', 'all', 'the', 'world']</td>\n      <td>2.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>61.00000</td>\n      <td>8.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>113848.00000</td>\n      <td>0.95424</td>\n      <td>3.00000</td>\n      <td>339.00000</td>\n      <td>113.00000</td>\n      <td>0.00000</td>\n      <td>68.00000</td>\n      <td>1420806949.00000</td>\n      <td>0.01639</td>\n      <td>0.00000</td>\n      <td>charliehebdo</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>125203</th>\n      <td>@ABCReligion Gotta love the Aussies.  Gorgeous.</td>\n      <td>544427788745592832.00000</td>\n      <td>544419008615702528.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>['gotta', 'love', 'the', 'aussies', 'gorgeous']</td>\n      <td>2.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>47.00000</td>\n      <td>6.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>8968.00000</td>\n      <td>1.57978</td>\n      <td>540.00000</td>\n      <td>1832.00000</td>\n      <td>3.39259</td>\n      <td>1797.00000</td>\n      <td>830.00000</td>\n      <td>1418636674.00000</td>\n      <td>0.14894</td>\n      <td>0.00000</td>\n      <td>sydneysiege</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>125204</th>\n      <td>@effeminate_guy @ABCReligion not this time around!</td>\n      <td>544440722129031168.00000</td>\n      <td>544439684655378432.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>2.00000</td>\n      <td>['not', 'this', 'time', 'around']</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>50.00000</td>\n      <td>6.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>7382.00000</td>\n      <td>1.04139</td>\n      <td>697.00000</td>\n      <td>867.00000</td>\n      <td>1.24390</td>\n      <td>9633.00000</td>\n      <td>657.00000</td>\n      <td>1418639758.00000</td>\n      <td>0.08000</td>\n      <td>0.00000</td>\n      <td>sydneysiege</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>125205</th>\n      <td>.@ABCReligion racism or anti-religious? Muslim or Arab? Conflicting words.</td>\n      <td>544421326664896512.00000</td>\n      <td>544419008615702528.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>['racism', 'or', 'antireligious', 'muslim', 'or', 'arab', 'conflicting', 'words']</td>\n      <td>4.00000</td>\n      <td>0.00000</td>\n      <td>2.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>2.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>74.00000</td>\n      <td>9.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>105060.00000</td>\n      <td>1.74036</td>\n      <td>299.00000</td>\n      <td>640.00000</td>\n      <td>2.14047</td>\n      <td>303.00000</td>\n      <td>1286.00000</td>\n      <td>1418635133.00000</td>\n      <td>0.09459</td>\n      <td>0.00000</td>\n      <td>sydneysiege</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>125206</th>\n      <td>@JezNews  via @ABCReligion Australians respond to racism by telling #Muslim community #illridewithyou. #sydneysiege #MartinPlace</td>\n      <td>544425604188090368.00000</td>\n      <td>544419008615702528.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>2.00000</td>\n      <td>['via', 'australians', 'respond', 'to', 'racism', 'by', 'telling', 'community']</td>\n      <td>2.00000</td>\n      <td>3.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>2.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>128.00000</td>\n      <td>14.00000</td>\n      <td>4.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>6088.00000</td>\n      <td>1.47712</td>\n      <td>575.00000</td>\n      <td>609.00000</td>\n      <td>1.05913</td>\n      <td>244.00000</td>\n      <td>1126.00000</td>\n      <td>1418636153.00000</td>\n      <td>0.07812</td>\n      <td>0.00000</td>\n      <td>sydneysiege</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>125207</th>\n      <td>@ABCReligion @melkirem But is there a risk of Cronulla-riots kind of incident soon, you think ?</td>\n      <td>544439684655378432.00000</td>\n      <td>544419008615702528.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>2.00000</td>\n      <td>2.00000</td>\n      <td>['but', 'is', 'there', 'a', 'risk', 'of', 'cronullariots', 'kind', 'of', 'incident', 'soon', 'you', 'think']</td>\n      <td>4.00000</td>\n      <td>2.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>2.00000</td>\n      <td>0.00000</td>\n      <td>3.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>95.00000</td>\n      <td>16.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>75395.00000</td>\n      <td>0.69897</td>\n      <td>784.00000</td>\n      <td>783.00000</td>\n      <td>0.99872</td>\n      <td>732.00000</td>\n      <td>1257.00000</td>\n      <td>1418639510.00000</td>\n      <td>0.06316</td>\n      <td>0.00000</td>\n      <td>sydneysiege</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n    </tr>\n  </tbody>\n</table>\n<p>125208 rows × 47 columns</p>\n</div>",
      "text/plain": "                                                                                                                                                text  \\\n0                                                           BREAKING: Armed man takes hostage in kosher grocery east of Paris http://t.co/PBs3sMwhLt   \n1                               “@haaretzcom: BREAKING: Armed man takes hostage in kosher grocery east of Paris http://t.co/SvpMxBoLsn” @andreinetto   \n2              @haaretzcom @AhmetHez to kill is right? How dare you you are not soldier how dare you turn children into killers how dare you do that   \n3       @haaretzcom @AhmetHez play back infront of ur kids so they can laugh at you what kind of nonsense you feed their mind what kind of bad words   \n4                                                                                      @ohohyesyesnono @haaretzcom Bots will conquest all the world.   \n...                                                                                                                                              ...   \n125203                                                                                               @ABCReligion Gotta love the Aussies.  Gorgeous.   \n125204                                                                                            @effeminate_guy @ABCReligion not this time around!   \n125205                                                                    .@ABCReligion racism or anti-religious? Muslim or Arab? Conflicting words.   \n125206              @JezNews  via @ABCReligion Australians respond to racism by telling #Muslim community #illridewithyou. #sydneysiege #MartinPlace   \n125207                                               @ABCReligion @melkirem But is there a risk of Cronulla-riots kind of incident soon, you think ?   \n\n                             id                      pid  emoji_count  \\\n0      553529101659566080.00000                      NaN      0.00000   \n1      553530890908098560.00000 553529101659566080.00000      0.00000   \n2      553547184000339968.00000 553529101659566080.00000      0.00000   \n3      553546643941761024.00000 553529101659566080.00000      0.00000   \n4      553530583583047680.00000 553529101659566080.00000      0.00000   \n...                         ...                      ...          ...   \n125203 544427788745592832.00000 544419008615702528.00000      0.00000   \n125204 544440722129031168.00000 544439684655378432.00000      0.00000   \n125205 544421326664896512.00000 544419008615702528.00000      0.00000   \n125206 544425604188090368.00000 544419008615702528.00000      0.00000   \n125207 544439684655378432.00000 544419008615702528.00000      0.00000   \n\n        has_media  URLcount  Skepticism  MentionCount  \\\n0         0.00000   1.00000     4.00000       0.00000   \n1         0.00000   1.00000     4.00000       2.00000   \n2         0.00000   0.00000     7.00000       2.00000   \n3         0.00000   0.00000     7.00000       2.00000   \n4         0.00000   0.00000     4.00000       2.00000   \n...           ...       ...         ...           ...   \n125203    0.00000   0.00000     1.00000       1.00000   \n125204    0.00000   0.00000     1.00000       2.00000   \n125205    0.00000   0.00000     0.00000       1.00000   \n125206    0.00000   0.00000     1.00000       2.00000   \n125207    0.00000   0.00000     2.00000       2.00000   \n\n                                                                                                                                                                                             token_for_POS  \\\n0                                                                                                       ['breaking', 'armed', 'man', 'takes', 'hostage', 'in', 'kosher', 'grocery', 'east', 'of', 'paris']   \n1                                                                                                       ['breaking', 'armed', 'man', 'takes', 'hostage', 'in', 'kosher', 'grocery', 'east', 'of', 'paris']   \n2                     ['to', 'kill', 'is', 'right', 'how', 'dare', 'you', 'you', 'are', 'not', 'soldier', 'how', 'dare', 'you', 'turn', 'children', 'into', 'killers', 'how', 'dare', 'you', 'do', 'that']   \n3       ['play', 'back', 'infront', 'of', 'ur', 'kids', 'so', 'they', 'can', 'laugh', 'at', 'you', 'what', 'kind', 'of', 'nonsense', 'you', 'feed', 'their', 'mind', 'what', 'kind', 'of', 'bad', 'words']   \n4                                                                                                                                                      ['bots', 'will', 'conquest', 'all', 'the', 'world']   \n...                                                                                                                                                                                                    ...   \n125203                                                                                                                                                     ['gotta', 'love', 'the', 'aussies', 'gorgeous']   \n125204                                                                                                                                                                   ['not', 'this', 'time', 'around']   \n125205                                                                                                                   ['racism', 'or', 'antireligious', 'muslim', 'or', 'arab', 'conflicting', 'words']   \n125206                                                                                                                     ['via', 'australians', 'respond', 'to', 'racism', 'by', 'telling', 'community']   \n125207                                                                                        ['but', 'is', 'there', 'a', 'risk', 'of', 'cronullariots', 'kind', 'of', 'incident', 'soon', 'you', 'think']   \n\n          Noun    Verb  Adjective  Pronoun  FirstPersonPronoun  \\\n0      6.00000 3.00000    0.00000  0.00000             0.00000   \n1      6.00000 3.00000    0.00000  0.00000             0.00000   \n2      5.00000 5.00000    2.00000  4.00000             0.00000   \n3      7.00000 3.00000    2.00000  4.00000             0.00000   \n4      2.00000 1.00000    0.00000  0.00000             0.00000   \n...        ...     ...        ...      ...                 ...   \n125203 2.00000 1.00000    1.00000  0.00000             0.00000   \n125204 1.00000 0.00000    0.00000  0.00000             0.00000   \n125205 4.00000 0.00000    2.00000  0.00000             0.00000   \n125206 2.00000 3.00000    0.00000  0.00000             0.00000   \n125207 4.00000 2.00000    0.00000  1.00000             0.00000   \n\n        SecondPersonPronoun  ThirdPersonPronoun  Adverb  Numeral  \\\n0                   0.00000             0.00000 0.00000  0.00000   \n1                   0.00000             0.00000 0.00000  0.00000   \n2                   4.00000             0.00000 1.00000  0.00000   \n3                   2.00000             2.00000 1.00000  0.00000   \n4                   0.00000             0.00000 0.00000  0.00000   \n...                     ...                 ...     ...      ...   \n125203              0.00000             0.00000 0.00000  0.00000   \n125204              0.00000             0.00000 1.00000  0.00000   \n125205              0.00000             0.00000 0.00000  0.00000   \n125206              0.00000             0.00000 0.00000  0.00000   \n125207              1.00000             0.00000 2.00000  0.00000   \n\n        Conjunction_inj  Particle  Determiner   Modal     Whs  test_auxiliary  \\\n0               2.00000   0.00000     0.00000 0.00000 0.00000         0.00000   \n1               2.00000   0.00000     0.00000 0.00000 0.00000         0.00000   \n2               2.00000   0.00000     0.00000 0.00000 3.00000         4.00000   \n3               5.00000   0.00000     0.00000 1.00000 2.00000         1.00000   \n4               0.00000   0.00000     1.00000 1.00000 0.00000         1.00000   \n...                 ...       ...         ...     ...     ...             ...   \n125203          0.00000   0.00000     1.00000 0.00000 0.00000         0.00000   \n125204          0.00000   1.00000     1.00000 0.00000 0.00000         0.00000   \n125205          2.00000   0.00000     0.00000 0.00000 0.00000         0.00000   \n125206          2.00000   0.00000     0.00000 0.00000 0.00000         0.00000   \n125207          3.00000   0.00000     1.00000 0.00000 0.00000         1.00000   \n\n        test_tentat  test_certain  char_count  word_count  HashTag  \\\n0           0.00000       0.00000    88.00000    12.00000  0.00000   \n1           0.00000       0.00000   116.00000    14.00000  0.00000   \n2           0.00000       0.00000   133.00000    25.00000  0.00000   \n3           0.00000       0.00000   140.00000    27.00000  0.00000   \n4           0.00000       0.00000    61.00000     8.00000  0.00000   \n...             ...           ...         ...         ...      ...   \n125203      0.00000       0.00000    47.00000     6.00000  0.00000   \n125204      0.00000       0.00000    50.00000     6.00000  0.00000   \n125205      0.00000       0.00000    74.00000     9.00000  0.00000   \n125206      0.00000       0.00000   128.00000    14.00000  4.00000   \n125207      0.00000       0.00000    95.00000    16.00000  0.00000   \n\n        has_question  has_exclaim  has_period  retweet_count    isRT  \\\n0            0.00000      0.00000     1.00000      177.00000 0.00000   \n1            0.00000      0.00000     1.00000        0.00000 0.00000   \n2            1.00000      0.00000     0.00000        0.00000 0.00000   \n3            0.00000      0.00000     0.00000        0.00000 0.00000   \n4            0.00000      0.00000     1.00000        0.00000 0.00000   \n...              ...          ...         ...            ...     ...   \n125203       0.00000      0.00000     1.00000        0.00000 0.00000   \n125204       0.00000      1.00000     0.00000        0.00000 0.00000   \n125205       1.00000      0.00000     1.00000        1.00000 0.00000   \n125206       0.00000      0.00000     1.00000        1.00000 0.00000   \n125207       1.00000      0.00000     0.00000        0.00000 0.00000   \n\n        statuses_count  listed_count  friends_count  followers_count  \\\n0          63575.00000       3.85594      614.00000     193798.00000   \n1         102425.00000       1.51851     1997.00000       1296.00000   \n2           2297.00000       0.00000     1998.00000        163.00000   \n3           2297.00000       0.00000     1998.00000        163.00000   \n4         113848.00000       0.95424        3.00000        339.00000   \n...                ...           ...            ...              ...   \n125203      8968.00000       1.57978      540.00000       1832.00000   \n125204      7382.00000       1.04139      697.00000        867.00000   \n125205    105060.00000       1.74036      299.00000        640.00000   \n125206      6088.00000       1.47712      575.00000        609.00000   \n125207     75395.00000       0.69897      784.00000        783.00000   \n\n        followers/friend  favourites_count  account_age_days    tweet_created  \\\n0              315.63192          77.00000        2126.00000 1420806596.00000   \n1                0.64897        4608.00000        1391.00000 1420807023.00000   \n2                0.08158          23.00000           2.00000 1420810907.00000   \n3                0.08158          23.00000           2.00000 1420810778.00000   \n4              113.00000           0.00000          68.00000 1420806949.00000   \n...                  ...               ...               ...              ...   \n125203           3.39259        1797.00000         830.00000 1418636674.00000   \n125204           1.24390        9633.00000         657.00000 1418639758.00000   \n125205           2.14047         303.00000        1286.00000 1418635133.00000   \n125206           1.05913         244.00000        1126.00000 1418636153.00000   \n125207           0.99872         732.00000        1257.00000 1418639510.00000   \n\n        capital_ratio  verified         Event  isSrcTweet  target  \n0             0.15909   1.00000  charliehebdo     1.00000 1.00000  \n1             0.12069   0.00000  charliehebdo     0.00000 1.00000  \n2             0.02256   0.00000  charliehebdo     0.00000 1.00000  \n3             0.01429   0.00000  charliehebdo     0.00000 1.00000  \n4             0.01639   0.00000  charliehebdo     0.00000 1.00000  \n...               ...       ...           ...         ...     ...  \n125203        0.14894   0.00000   sydneysiege     0.00000 0.00000  \n125204        0.08000   0.00000   sydneysiege     0.00000 0.00000  \n125205        0.09459   0.00000   sydneysiege     0.00000 0.00000  \n125206        0.07812   0.00000   sydneysiege     0.00000 0.00000  \n125207        0.06316   0.00000   sydneysiege     0.00000 0.00000  \n\n[125208 rows x 47 columns]"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pheme_all.loc[pheme_all['id'] != pheme_all['pid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_auxiliary : -0.012822407893744774\n",
      "test_tentat : -0.014681441112108085\n",
      "test_certain : -0.04242708788415191\n",
      "\n",
      "test_auxiliary : 0.017699890028851934\n",
      "test_tentat : -0.0037352373472128203\n",
      "test_certain : -0.024703870567063895\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['SUM Emoji'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-fced87e95ffd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\":\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfinal_ext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_auxiliary'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'test_tentat'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'test_certain'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_ext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mext_thread_avg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_auxiliary'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'test_tentat'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'test_certain'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'SUM Emoji'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Ratio Verified'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\":\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mext_thread_avg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_auxiliary'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'test_tentat'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'test_certain'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'SUM Emoji'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Ratio Verified'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_ext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3028\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3029\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3030\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3032\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1264\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1266\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1314\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1316\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['SUM Emoji'] not in index\""
     ]
    }
   ],
   "source": [
    "# for data in ext_thread.columns:\n",
    "#     print(data,\":\",ext_thread[data].corr(ext_y))\n",
    "# for data in pheme_thread_avg.columns:\n",
    "#     print(data,\":\",pheme_thread_avg[data].corr(pheme_y))\n",
    "for data in all_ext[['test_auxiliary','test_tentat','test_certain']].columns:\n",
    "    print(data,\":\",all_ext[['test_auxiliary','test_tentat','test_certain']][data].corr(all_ext.target))\n",
    "print()\n",
    "for data in final_ext[['test_auxiliary','test_tentat','test_certain']].columns:\n",
    "    print(data,\":\",final_ext[['test_auxiliary','test_tentat','test_certain']][data].corr(final_ext.target))\n",
    "print()\n",
    "for data in ext_thread_avg[['test_auxiliary','test_tentat','test_certain','SUM Emoji','Ratio Verified']].columns:\n",
    "    print(data,\":\",ext_thread_avg[['test_auxiliary','test_tentat','test_certain','SUM Emoji','Ratio Verified']][data].corr(final_ext.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>depth</th>\n      <th>SUM FriendsCount</th>\n      <th>AVG FriendsCount</th>\n      <th>AVG WordCount</th>\n      <th>SUM WordCount</th>\n      <th>AVG CharCount</th>\n      <th>AVG HashTag</th>\n      <th>SUM HashTag</th>\n      <th>Ratio HashTag</th>\n      <th>SUM Url</th>\n      <th>AVG Url</th>\n      <th>RATIO Url</th>\n      <th>SUM Mention</th>\n      <th>AVG Mention</th>\n      <th>Ratio Mention</th>\n      <th>AVG Statues</th>\n      <th>AVG Listed</th>\n      <th>AVG Follower</th>\n      <th>AVG followers/friend</th>\n      <th>AVG favorite</th>\n      <th>Tweets Count</th>\n      <th>Ratio Verified</th>\n      <th>SUM Verified</th>\n      <th>SUM RT</th>\n      <th>AVG RT</th>\n      <th>AVG AccAge</th>\n      <th>thread_time</th>\n      <th>AVG Emoji</th>\n      <th>RATIO Emoji</th>\n      <th>Ratio Media</th>\n      <th>RATIO Question</th>\n      <th>RATIO Exclaim</th>\n      <th>RATIO Period</th>\n      <th>AVG FPP</th>\n      <th>AVG SPP</th>\n      <th>AVG TPP</th>\n      <th>AVG Skepticism</th>\n      <th>Ratio Skepticism</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2.19794</td>\n      <td>2.71752</td>\n      <td>2.33266</td>\n      <td>10.01375</td>\n      <td>1.27193</td>\n      <td>1.60452</td>\n      <td>0.59794</td>\n      <td>1.25361</td>\n      <td>0.29762</td>\n      <td>0.51340</td>\n      <td>0.22614</td>\n      <td>0.22078</td>\n      <td>3.59381</td>\n      <td>0.60497</td>\n      <td>0.40513</td>\n      <td>3.36478</td>\n      <td>1.34006</td>\n      <td>2.71131</td>\n      <td>0.55145</td>\n      <td>2.34798</td>\n      <td>0.39030</td>\n      <td>0.06684</td>\n      <td>0.15258</td>\n      <td>0.67103</td>\n      <td>0.44146</td>\n      <td>2.55391</td>\n      <td>2.17879</td>\n      <td>0.03985</td>\n      <td>0.02008</td>\n      <td>0.13214</td>\n      <td>0.15139</td>\n      <td>0.10150</td>\n      <td>0.52345</td>\n      <td>0.18014</td>\n      <td>0.06492</td>\n      <td>0.24703</td>\n      <td>2.26836</td>\n      <td>0.65777</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.70257</td>\n      <td>1.25022</td>\n      <td>1.06547</td>\n      <td>6.36584</td>\n      <td>0.61126</td>\n      <td>0.67452</td>\n      <td>0.96245</td>\n      <td>1.75798</td>\n      <td>0.39206</td>\n      <td>0.78620</td>\n      <td>0.37453</td>\n      <td>0.35968</td>\n      <td>6.05126</td>\n      <td>0.66793</td>\n      <td>0.35595</td>\n      <td>1.48228</td>\n      <td>0.92251</td>\n      <td>1.36753</td>\n      <td>0.61120</td>\n      <td>1.31856</td>\n      <td>0.40859</td>\n      <td>0.21699</td>\n      <td>0.38759</td>\n      <td>0.60637</td>\n      <td>0.39141</td>\n      <td>1.07148</td>\n      <td>1.93851</td>\n      <td>0.20250</td>\n      <td>0.08366</td>\n      <td>0.29372</td>\n      <td>0.28140</td>\n      <td>0.21562</td>\n      <td>0.38458</td>\n      <td>0.33362</td>\n      <td>0.22990</td>\n      <td>0.40823</td>\n      <td>1.75281</td>\n      <td>0.35917</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.00000</td>\n      <td>2.45939</td>\n      <td>2.15836</td>\n      <td>5.50000</td>\n      <td>1.07918</td>\n      <td>1.60638</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>3.18624</td>\n      <td>0.60206</td>\n      <td>2.21484</td>\n      <td>0.15249</td>\n      <td>1.46613</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>2.67821</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.16667</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0.50000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>2.00000</td>\n      <td>3.05767</td>\n      <td>2.61700</td>\n      <td>10.00000</td>\n      <td>1.32222</td>\n      <td>1.84839</td>\n      <td>0.04167</td>\n      <td>1.00000</td>\n      <td>0.04167</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0.50000</td>\n      <td>0.50000</td>\n      <td>3.80862</td>\n      <td>1.33297</td>\n      <td>2.96567</td>\n      <td>0.30674</td>\n      <td>2.68485</td>\n      <td>0.30103</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.60206</td>\n      <td>0.47712</td>\n      <td>2.97288</td>\n      <td>2.74974</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.50000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>2.00000</td>\n      <td>0.71429</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>3.00000</td>\n      <td>3.48202</td>\n      <td>2.98453</td>\n      <td>15.00000</td>\n      <td>1.67210</td>\n      <td>2.02119</td>\n      <td>1.00000</td>\n      <td>2.00000</td>\n      <td>0.50000</td>\n      <td>1.00000</td>\n      <td>0.33333</td>\n      <td>0.33333</td>\n      <td>4.00000</td>\n      <td>1.00000</td>\n      <td>0.66667</td>\n      <td>4.28419</td>\n      <td>1.96047</td>\n      <td>3.56268</td>\n      <td>0.73366</td>\n      <td>3.36163</td>\n      <td>0.69897</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.95424</td>\n      <td>0.69897</td>\n      <td>3.15957</td>\n      <td>3.84292</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.05556</td>\n      <td>0.16667</td>\n      <td>0.11111</td>\n      <td>1.00000</td>\n      <td>0.25000</td>\n      <td>0.00000</td>\n      <td>0.40000</td>\n      <td>3.00000</td>\n      <td>1.00000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>16.00000</td>\n      <td>5.15280</td>\n      <td>4.38686</td>\n      <td>29.00000</td>\n      <td>2.51455</td>\n      <td>2.15836</td>\n      <td>6.00000</td>\n      <td>12.00000</td>\n      <td>1.00000</td>\n      <td>5.00000</td>\n      <td>2.00000</td>\n      <td>1.00000</td>\n      <td>38.00000</td>\n      <td>6.50000</td>\n      <td>1.00000</td>\n      <td>5.40023</td>\n      <td>4.02991</td>\n      <td>5.74995</td>\n      <td>3.13014</td>\n      <td>4.98318</td>\n      <td>1.43136</td>\n      <td>1.00000</td>\n      <td>3.00000</td>\n      <td>4.01770</td>\n      <td>2.73970</td>\n      <td>3.48029</td>\n      <td>5.87737</td>\n      <td>3.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>2.00000</td>\n      <td>2.00000</td>\n      <td>2.00000</td>\n      <td>9.00000</td>\n      <td>1.00000</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "          depth  SUM FriendsCount  AVG FriendsCount  AVG WordCount  \\\ncount 485.00000         485.00000         485.00000      485.00000   \nmean    2.19794           2.71752           2.33266       10.01375   \nstd     1.70257           1.25022           1.06547        6.36584   \nmin     1.00000           0.00000           0.00000        0.00000   \n25%     1.00000           2.45939           2.15836        5.50000   \n50%     2.00000           3.05767           2.61700       10.00000   \n75%     3.00000           3.48202           2.98453       15.00000   \nmax    16.00000           5.15280           4.38686       29.00000   \n\n       SUM WordCount  AVG CharCount  AVG HashTag  SUM HashTag  Ratio HashTag  \\\ncount      485.00000      485.00000    485.00000    485.00000      485.00000   \nmean         1.27193        1.60452      0.59794      1.25361        0.29762   \nstd          0.61126        0.67452      0.96245      1.75798        0.39206   \nmin          0.00000        0.00000      0.00000      0.00000        0.00000   \n25%          1.07918        1.60638      0.00000      0.00000        0.00000   \n50%          1.32222        1.84839      0.04167      1.00000        0.04167   \n75%          1.67210        2.02119      1.00000      2.00000        0.50000   \nmax          2.51455        2.15836      6.00000     12.00000        1.00000   \n\n        SUM Url   AVG Url  RATIO Url  SUM Mention  AVG Mention  Ratio Mention  \\\ncount 485.00000 485.00000  485.00000    485.00000    485.00000      485.00000   \nmean    0.51340   0.22614    0.22078      3.59381      0.60497        0.40513   \nstd     0.78620   0.37453    0.35968      6.05126      0.66793        0.35595   \nmin     0.00000   0.00000    0.00000      0.00000      0.00000        0.00000   \n25%     0.00000   0.00000    0.00000      0.00000      0.00000        0.00000   \n50%     0.00000   0.00000    0.00000      1.00000      0.50000        0.50000   \n75%     1.00000   0.33333    0.33333      4.00000      1.00000        0.66667   \nmax     5.00000   2.00000    1.00000     38.00000      6.50000        1.00000   \n\n       AVG Statues  AVG Listed  AVG Follower  AVG followers/friend  \\\ncount    485.00000   485.00000     485.00000             485.00000   \nmean       3.36478     1.34006       2.71131               0.55145   \nstd        1.48228     0.92251       1.36753               0.61120   \nmin        0.00000     0.00000       0.00000               0.00000   \n25%        3.18624     0.60206       2.21484               0.15249   \n50%        3.80862     1.33297       2.96567               0.30674   \n75%        4.28419     1.96047       3.56268               0.73366   \nmax        5.40023     4.02991       5.74995               3.13014   \n\n       AVG favorite  Tweets Count  Ratio Verified  SUM Verified    SUM RT  \\\ncount     485.00000     485.00000       485.00000     485.00000 485.00000   \nmean        2.34798       0.39030         0.06684       0.15258   0.67103   \nstd         1.31856       0.40859         0.21699       0.38759   0.60637   \nmin         0.00000       0.00000         0.00000       0.00000   0.00000   \n25%         1.46613       0.00000         0.00000       0.00000   0.00000   \n50%         2.68485       0.30103         0.00000       0.00000   0.60206   \n75%         3.36163       0.69897         0.00000       0.00000   0.95424   \nmax         4.98318       1.43136         1.00000       3.00000   4.01770   \n\n         AVG RT  AVG AccAge  thread_time  AVG Emoji  RATIO Emoji  Ratio Media  \\\ncount 485.00000   485.00000    485.00000  485.00000    485.00000    485.00000   \nmean    0.44146     2.55391      2.17879    0.03985      0.02008      0.13214   \nstd     0.39141     1.07148      1.93851    0.20250      0.08366      0.29372   \nmin     0.00000     0.00000      0.00000    0.00000      0.00000      0.00000   \n25%     0.00000     2.67821      0.00000    0.00000      0.00000      0.00000   \n50%     0.47712     2.97288      2.74974    0.00000      0.00000      0.00000   \n75%     0.69897     3.15957      3.84292    0.00000      0.00000      0.05556   \nmax     2.73970     3.48029      5.87737    3.00000      1.00000      1.00000   \n\n       RATIO Question  RATIO Exclaim  RATIO Period   AVG FPP   AVG SPP  \\\ncount       485.00000      485.00000     485.00000 485.00000 485.00000   \nmean          0.15139        0.10150       0.52345   0.18014   0.06492   \nstd           0.28140        0.21562       0.38458   0.33362   0.22990   \nmin           0.00000        0.00000       0.00000   0.00000   0.00000   \n25%           0.00000        0.00000       0.16667   0.00000   0.00000   \n50%           0.00000        0.00000       0.50000   0.00000   0.00000   \n75%           0.16667        0.11111       1.00000   0.25000   0.00000   \nmax           1.00000        1.00000       1.00000   2.00000   2.00000   \n\n        AVG TPP  AVG Skepticism  Ratio Skepticism  \ncount 485.00000       485.00000         485.00000  \nmean    0.24703         2.26836           0.65777  \nstd     0.40823         1.75281           0.35917  \nmin     0.00000         0.00000           0.00000  \n25%     0.00000         1.00000           0.50000  \n50%     0.00000         2.00000           0.71429  \n75%     0.40000         3.00000           1.00000  \nmax     2.00000         9.00000           1.00000  "
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ext_thread_avg.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BERT & EMOJI 이모지 다루는 차이 😂😂😂😂😂\n",
    "\n",
    "> Before applying fastBPE to the pre-training corpus of 850M English Tweets, we tokenized these Tweets using TweetTokenizer from the NLTK toolkit and used the emoji package to translate emotion icons into text strings (here, each icon is referred to as a word token). We also normalized the Tweets by converting user mentions and web/url links into special tokens @USER and HTTPURL, respectively. Thus it is recommended to also apply the same pre-processing step for BERTweet-based downstream applications w.r.t. the raw input Tweets. BERTweet provides this pre-processing step by enabling the normalization argument.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer \n",
    "bertweet = AutoModel.from_pretrained(\"vinai/bertweet-base\", )\n",
    "\n",
    "# For transformers v4.x+: \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=False, normalization=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[array(['2014-10-12 21:22:36+00:00'], dtype=object),\n array([], dtype=object),\n array(['2014-10-12 18:38:41+00:00'], dtype=object),\n array(['2014-10-12 18:43:07+00:00'], dtype=object),\n array(['2014-10-12 18:42:02+00:00'], dtype=object),\n array(['2014-10-12 18:44:13+00:00'], dtype=object),\n array(['2014-10-12 19:15:21+00:00'], dtype=object),\n array([], dtype=object),\n array(['2014-10-12 18:54:47+00:00'], dtype=object),\n array(['2014-10-12 18:39:06+00:00'], dtype=object),\n array(['2014-10-12 18:41:23+00:00'], dtype=object),\n array(['2014-10-12 18:39:51+00:00'], dtype=object),\n array([], dtype=object),\n array(['2014-10-12 18:56:53+00:00'], dtype=object)]"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ext_thread.thread_time[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT TWEET IS ALREADY NORMALIZED!\n",
    "line = \"@MichaelEssien that's a shame wanted to Invest in you😔\"\n",
    "print(line)\n",
    "print(tokenizer.encode(line),\"\\n\")\n",
    "input_ids = torch.tensor([tokenizer.encode(line)])\n",
    "# print(input_ids)\n",
    "\n",
    "line = \"HTTPURL @MichaelEssien that's a shame wanted to Invest INVEST in you😔😂😂 http://www.google.com\"\n",
    "input_ids = torch.tensor([tokenizer.encode(line)])\n",
    "print(line)\n",
    "print(tokenizer.encode(line),\"\\n\")\n",
    "\n",
    "line = \"HTTPURL @USER that's a shame wanted to Invest INVEST in you:pensive_face::face_with_tears_of_joy::face_with_tears_of_joy: HTTPURL\"\n",
    "input_ids = torch.tensor([tokenizer.encode(line)])\n",
    "print(line)\n",
    "print(tokenizer.encode(line),\"\\n\")\n",
    "\n",
    "line = \"HTTPURL @USER that's a shame wanted to Invest INVEST in you pensive_face face_with_tears_of_joy face_with_tears_of_joy :grinning_face_with_big_eyes: HTTPURL  \"\n",
    "input_ids = torch.tensor([tokenizer.encode(line)])\n",
    "print(line)\n",
    "print(tokenizer.encode(line))\n",
    "\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     features = bertweet(input_ids)  # Models outputs are now tuples\n",
    "# print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"HTTPURL @MichaelEssien that's a shame wanted to Invest INVEST in you😔😂😂😃 http://www.google.com\"\n",
    "print(emoji.emoji_count(text),\"\\n\")\n",
    "print(text)\n",
    "text = emoji.demojize(text)\n",
    "# print(emoji.get_emoji_regexp(),\"\\n\")\n",
    "# text=text.strip(':')\n",
    "# text = re.sub(r'(@.*?)[\\s]', '@USER ', text)\n",
    "text = re.sub(r\"@\\S+\", \"@USER\", text)   # mention -> '@'\n",
    "text = re.sub(r\"http\\S+\", \"HTTPURL\", text)  # http link -> '*'\n",
    "emojis = re.findall(r'(::)', text)\n",
    "print(emojis)\n",
    "# print(text,\"\\n\")\n",
    "text = re.sub(r':[^:]*:', r' \\g<0>', text)  # http link -> '*'\n",
    "print(text,\"\\n\")\n",
    "\n",
    "text=text.split()\n",
    "# text= re.sub(r'(:[!_\\-\\w]+:)', '', text)\n",
    "print(text,\"\\n\")\n",
    "# emojis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 추가 데이터들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ext.loc[(all_ext['id'] == int(529657433866915840))].HashTag.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ext.loc[(all_ext['pid'] == int(521367917322338304))][['text','token_for_POS','HashTag','Pronoun','FirstPersonPronoun','SecondPersonPronoun','ThirdPersonPronoun','Numeral','Modal','Whs', 'Noun', 'Verb','Adjective','has_question',\t'has_exclaim',\t'has_period']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_ext.loc[((all_ext['Skepticism'] >-1))].groupby('target').mean()  #[['text','URLcount','token_for_POS','id','pid','HashTag','Pronoun','FirstPersonPronoun','SecondPersonPronoun','ThirdPersonPronoun']]\n",
    "all_ext.loc[((all_ext['Skepticism'] >-1))].groupby('target').mean()  #[['text','URLcount','token_for_POS','id','pid','HashTag','Pronoun','FirstPersonPronoun','SecondPersonPronoun','ThirdPersonPronoun']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([ext_thread, ext_y], axis=1).groupby('target').mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ext[['id','text','token_for_POS','HashTag','URLcount','target','Skepticism']].loc[all_ext.HashTag > 4]\n",
    "# all_ext['HashTag'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.max([np.sum(all_ext.loc[(all_ext['id'] == int(childid))]['tweet_created'].values) for childid in structure_ext.loc[0,'0':].dropna()])\n",
    "# np.max([np.sum(all_ext.loc[(all_ext['id'] == childid)]['tweet_created']) for childid in structure_ext.loc[0,'0':'13'].dropna()] - all_ext.loc[(all_ext['id'] == int(521369179392581632))].tweet_created.sum())\n",
    "[np.sum(all_ext.loc[(all_ext['id'] == childid)]['urls_dicts_len']) for childid in structure_ext.loc[11,:].dropna().drop(['depth'],axis=0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thread()를 만드는데 필요한 정보들\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>pid</th>\n      <th>emoji_count</th>\n      <th>has_media</th>\n      <th>URLcount</th>\n      <th>Skepticism</th>\n      <th>MentionCount</th>\n      <th>Noun</th>\n      <th>Verb</th>\n      <th>Adjective</th>\n      <th>Pronoun</th>\n      <th>FirstPersonPronoun</th>\n      <th>SecondPersonPronoun</th>\n      <th>ThirdPersonPronoun</th>\n      <th>Adverb</th>\n      <th>Numeral</th>\n      <th>Conjunction_inj</th>\n      <th>Particle</th>\n      <th>Determiner</th>\n      <th>Modal</th>\n      <th>Whs</th>\n      <th>char_count</th>\n      <th>word_count</th>\n      <th>HashTag</th>\n      <th>has_question</th>\n      <th>has_exclaim</th>\n      <th>has_period</th>\n      <th>retweet_count</th>\n      <th>tweet_count</th>\n      <th>listed_count</th>\n      <th>friends_count</th>\n      <th>follow_ratio</th>\n      <th>account_age_days</th>\n      <th>tweet_created</th>\n      <th>capital_ratio</th>\n      <th>verified</th>\n      <th>isSrcTweet</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1963.00000</td>\n      <td>1478.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>548748486071387968.00000</td>\n      <td>547483663616841984.00000</td>\n      <td>0.08304</td>\n      <td>0.11768</td>\n      <td>0.19511</td>\n      <td>3.03311</td>\n      <td>1.26490</td>\n      <td>3.49465</td>\n      <td>2.37341</td>\n      <td>0.89812</td>\n      <td>0.65869</td>\n      <td>0.33724</td>\n      <td>0.11258</td>\n      <td>0.39226</td>\n      <td>0.72033</td>\n      <td>0.12124</td>\n      <td>1.29954</td>\n      <td>0.06928</td>\n      <td>0.78859</td>\n      <td>0.20122</td>\n      <td>0.18136</td>\n      <td>88.74325</td>\n      <td>13.01528</td>\n      <td>0.44320</td>\n      <td>0.18747</td>\n      <td>0.17728</td>\n      <td>0.63169</td>\n      <td>13.43301</td>\n      <td>3.85033</td>\n      <td>1.18417</td>\n      <td>2.67871</td>\n      <td>2.86539</td>\n      <td>1296.51605</td>\n      <td>1419666808.49159</td>\n      <td>0.08952</td>\n      <td>0.06470</td>\n      <td>0.24707</td>\n      <td>0.81915</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>24197288222753516.00000</td>\n      <td>24194908479467996.00000</td>\n      <td>0.52533</td>\n      <td>0.32231</td>\n      <td>0.40779</td>\n      <td>2.08666</td>\n      <td>0.92597</td>\n      <td>2.55108</td>\n      <td>1.83844</td>\n      <td>0.99326</td>\n      <td>0.92956</td>\n      <td>0.72692</td>\n      <td>0.36411</td>\n      <td>0.68698</td>\n      <td>0.98238</td>\n      <td>0.37989</td>\n      <td>1.26827</td>\n      <td>0.26190</td>\n      <td>0.91239</td>\n      <td>0.46241</td>\n      <td>0.44552</td>\n      <td>39.00655</td>\n      <td>6.42202</td>\n      <td>0.98470</td>\n      <td>0.39039</td>\n      <td>0.38200</td>\n      <td>0.48247</td>\n      <td>254.08308</td>\n      <td>0.81881</td>\n      <td>0.92393</td>\n      <td>0.59617</td>\n      <td>0.93745</td>\n      <td>737.28048</td>\n      <td>5769083.07608</td>\n      <td>0.07571</td>\n      <td>0.24605</td>\n      <td>0.43142</td>\n      <td>0.38499</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>521310417696858112.00000</td>\n      <td>521310417696858112.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>8.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.30103</td>\n      <td>3.00000</td>\n      <td>1413125063.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>529676680548595712.00000</td>\n      <td>529654768249354240.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>55.00000</td>\n      <td>8.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>3.39872</td>\n      <td>0.47712</td>\n      <td>2.32118</td>\n      <td>2.24674</td>\n      <td>652.00000</td>\n      <td>1415119735.50000</td>\n      <td>0.04167</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>529753935545118720.00000</td>\n      <td>529735657531656192.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>3.00000</td>\n      <td>1.00000</td>\n      <td>3.00000</td>\n      <td>2.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>90.00000</td>\n      <td>13.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>3.94161</td>\n      <td>1.11394</td>\n      <td>2.73957</td>\n      <td>2.82478</td>\n      <td>1313.00000</td>\n      <td>1415138155.00000</td>\n      <td>0.07246</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>576560832456267776.00000</td>\n      <td>576504635738951680.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>4.00000</td>\n      <td>2.00000</td>\n      <td>5.00000</td>\n      <td>4.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>2.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>128.00000</td>\n      <td>18.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>2.00000</td>\n      <td>4.43603</td>\n      <td>1.78174</td>\n      <td>3.04513</td>\n      <td>3.39436</td>\n      <td>2031.00000</td>\n      <td>1426297788.50000</td>\n      <td>0.11611</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>579479145828257792.00000</td>\n      <td>577453947599777792.00000</td>\n      <td>10.00000</td>\n      <td>1.00000</td>\n      <td>2.00000</td>\n      <td>12.00000</td>\n      <td>7.00000</td>\n      <td>21.00000</td>\n      <td>10.00000</td>\n      <td>6.00000</td>\n      <td>5.00000</td>\n      <td>7.00000</td>\n      <td>3.00000</td>\n      <td>5.00000</td>\n      <td>6.00000</td>\n      <td>3.00000</td>\n      <td>7.00000</td>\n      <td>2.00000</td>\n      <td>5.00000</td>\n      <td>3.00000</td>\n      <td>3.00000</td>\n      <td>148.00000</td>\n      <td>29.00000</td>\n      <td>7.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>10402.00000</td>\n      <td>5.73594</td>\n      <td>4.15927</td>\n      <td>4.83829</td>\n      <td>6.31487</td>\n      <td>3021.00000</td>\n      <td>1426993569.00000</td>\n      <td>0.76471</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                            id                      pid  emoji_count  \\\ncount               1963.00000               1478.00000   1963.00000   \nmean  548748486071387968.00000 547483663616841984.00000      0.08304   \nstd    24197288222753516.00000  24194908479467996.00000      0.52533   \nmin   521310417696858112.00000 521310417696858112.00000      0.00000   \n25%   529676680548595712.00000 529654768249354240.00000      0.00000   \n50%   529753935545118720.00000 529735657531656192.00000      0.00000   \n75%   576560832456267776.00000 576504635738951680.00000      0.00000   \nmax   579479145828257792.00000 577453947599777792.00000     10.00000   \n\n       has_media   URLcount  Skepticism  MentionCount       Noun       Verb  \\\ncount 1963.00000 1963.00000  1963.00000    1963.00000 1963.00000 1963.00000   \nmean     0.11768    0.19511     3.03311       1.26490    3.49465    2.37341   \nstd      0.32231    0.40779     2.08666       0.92597    2.55108    1.83844   \nmin      0.00000    0.00000     0.00000       0.00000    0.00000    0.00000   \n25%      0.00000    0.00000     1.00000       1.00000    1.00000    1.00000   \n50%      0.00000    0.00000     3.00000       1.00000    3.00000    2.00000   \n75%      0.00000    0.00000     4.00000       2.00000    5.00000    4.00000   \nmax      1.00000    2.00000    12.00000       7.00000   21.00000   10.00000   \n\n       Adjective    Pronoun  FirstPersonPronoun  SecondPersonPronoun  \\\ncount 1963.00000 1963.00000          1963.00000           1963.00000   \nmean     0.89812    0.65869             0.33724              0.11258   \nstd      0.99326    0.92956             0.72692              0.36411   \nmin      0.00000    0.00000             0.00000              0.00000   \n25%      0.00000    0.00000             0.00000              0.00000   \n50%      1.00000    0.00000             0.00000              0.00000   \n75%      1.00000    1.00000             0.00000              0.00000   \nmax      6.00000    5.00000             7.00000              3.00000   \n\n       ThirdPersonPronoun     Adverb    Numeral  Conjunction_inj   Particle  \\\ncount          1963.00000 1963.00000 1963.00000       1963.00000 1963.00000   \nmean              0.39226    0.72033    0.12124          1.29954    0.06928   \nstd               0.68698    0.98238    0.37989          1.26827    0.26190   \nmin               0.00000    0.00000    0.00000          0.00000    0.00000   \n25%               0.00000    0.00000    0.00000          0.00000    0.00000   \n50%               0.00000    0.00000    0.00000          1.00000    0.00000   \n75%               1.00000    1.00000    0.00000          2.00000    0.00000   \nmax               5.00000    6.00000    3.00000          7.00000    2.00000   \n\n       Determiner      Modal        Whs  char_count  word_count    HashTag  \\\ncount  1963.00000 1963.00000 1963.00000  1963.00000  1963.00000 1963.00000   \nmean      0.78859    0.20122    0.18136    88.74325    13.01528    0.44320   \nstd       0.91239    0.46241    0.44552    39.00655     6.42202    0.98470   \nmin       0.00000    0.00000    0.00000     8.00000     1.00000    0.00000   \n25%       0.00000    0.00000    0.00000    55.00000     8.00000    0.00000   \n50%       1.00000    0.00000    0.00000    90.00000    13.00000    0.00000   \n75%       1.00000    0.00000    0.00000   128.00000    18.00000    0.00000   \nmax       5.00000    3.00000    3.00000   148.00000    29.00000    7.00000   \n\n       has_question  has_exclaim  has_period  retweet_count  tweet_count  \\\ncount    1963.00000   1963.00000  1963.00000     1963.00000   1963.00000   \nmean        0.18747      0.17728     0.63169       13.43301      3.85033   \nstd         0.39039      0.38200     0.48247      254.08308      0.81881   \nmin         0.00000      0.00000     0.00000        0.00000      0.00000   \n25%         0.00000      0.00000     0.00000        0.00000      3.39872   \n50%         0.00000      0.00000     1.00000        0.00000      3.94161   \n75%         0.00000      0.00000     1.00000        2.00000      4.43603   \nmax         1.00000      1.00000     1.00000    10402.00000      5.73594   \n\n       listed_count  friends_count  follow_ratio  account_age_days  \\\ncount    1963.00000     1963.00000    1963.00000        1963.00000   \nmean        1.18417        2.67871       2.86539        1296.51605   \nstd         0.92393        0.59617       0.93745         737.28048   \nmin         0.00000        0.00000       0.30103           3.00000   \n25%         0.47712        2.32118       2.24674         652.00000   \n50%         1.11394        2.73957       2.82478        1313.00000   \n75%         1.78174        3.04513       3.39436        2031.00000   \nmax         4.15927        4.83829       6.31487        3021.00000   \n\n         tweet_created  capital_ratio   verified  isSrcTweet     target  \ncount       1963.00000     1963.00000 1963.00000  1963.00000 1963.00000  \nmean  1419666808.49159        0.08952    0.06470     0.24707    0.81915  \nstd      5769083.07608        0.07571    0.24605     0.43142    0.38499  \nmin   1413125063.00000        0.00000    0.00000     0.00000    0.00000  \n25%   1415119735.50000        0.04167    0.00000     0.00000    1.00000  \n50%   1415138155.00000        0.07246    0.00000     0.00000    1.00000  \n75%   1426297788.50000        0.11611    0.00000     0.00000    1.00000  \nmax   1426993569.00000        0.76471    1.00000     1.00000    1.00000  "
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ext.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "target\n1    71\n0    26\ndtype: int64"
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ext.loc[all_ext['account_age_days']<100][['account_age_days','verified', 'HashTag', 'URLcount',\n",
    "                                           'MentionCount', 'retweet_count', 'isSrcTweet', 'target']].value_counts('target')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-240-4b19871eb0f9>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-240-4b19871eb0f9>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    all_ext.loc[all_ext['depth']<5][['account_age_days','verified', 'HashTag', 'URLcount',\u001b[0m\n\u001b[0m                                                                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "all_ext.loc[all_ext['depth']<10][['account_age_days','verified', 'HashTag', 'URLcount',\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>verified</th>\n      <th>HashTag</th>\n      <th>URLcount</th>\n      <th>MentionCount</th>\n      <th>retweet_count</th>\n      <th>isSrcTweet</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>320</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>272</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>442</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1860</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1657</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>8</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1177</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>915</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1873</th>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1712</th>\n      <td>0</td>\n      <td>5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>15</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>603</th>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1779</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1528</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>11</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>574</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>280</th>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>10</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>13</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>659</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>22</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>666</th>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>562</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "      verified  HashTag  URLcount  MentionCount  retweet_count  isSrcTweet  \\\n320          0        1         0             2              1           0   \n272          0        0         0             0              2           1   \n442          1        1         1             0              2           1   \n1860         0        0         0             1              1           0   \n1657         0        0         0             1              8           0   \n1177         0        1         1             1              5           1   \n915          0        0         0             1              1           0   \n1873         0        2         0             1              1           0   \n1712         0        5         1             0             15           1   \n603          0        0         2             0              3           1   \n1779         0        1         2             0              4           1   \n1528         0        0         1             0             11           1   \n574          0        1         1             2              2           1   \n280          0        2         0             0             10           1   \n198          0        0         0             1             13           0   \n659          1        0         0             0             22           1   \n666          0        3         1             2              1           0   \n562          0        0         0             0              2           1   \n\n      target  \n320        1  \n272        1  \n442        1  \n1860       0  \n1657       0  \n1177       1  \n915        1  \n1873       0  \n1712       0  \n603        1  \n1779       0  \n1528       1  \n574        1  \n280        1  \n198        1  \n659        1  \n666        1  \n562        1  "
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ext.loc[(all_ext['retweet_count'] > 0) and (all_ext.pid==521369179392581632)][['verified', 'HashTag', 'URLcount',\n",
    "                                           'MentionCount', 'retweet_count', 'isSrcTweet', 'target']].sample(18)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>verified</th>\n      <th>HashTag</th>\n      <th>URLcount</th>\n      <th>MentionCount</th>\n      <th>retweet_count</th>\n    </tr>\n    <tr>\n      <th>target</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.03356</td>\n      <td>1.77852</td>\n      <td>0.65772</td>\n      <td>0.44966</td>\n      <td>12.28859</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.19880</td>\n      <td>0.73695</td>\n      <td>0.73695</td>\n      <td>0.68273</td>\n      <td>49.27309</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "        verified  HashTag  URLcount  MentionCount  retweet_count\ntarget                                                          \n0        0.03356  1.77852   0.65772       0.44966       12.28859\n1        0.19880  0.73695   0.73695       0.68273       49.27309"
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ext.loc[all_ext['retweet_count']>0][['text', 'verified', 'HashTag', 'URLcount', 'MentionCount','retweet_count','target']].groupby('target').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0    521410632953131008.00000\n1    521373142347153408.00000\n2    521369380249432064.00000\n3    521370496928337920.00000\n4    521370224256614400.00000\n5    521370771793670144.00000\n6    521378607231279104.00000\n7    521370530134626304.00000\n8    521373433654157312.00000\n9    521369485144387584.00000\n10   521370061550809088.00000\n11   521369671975858176.00000\n12   521372372927266816.00000\n13   521373960509079552.00000\nName: 0, dtype: float64"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structure_ext.loc[0,'0':].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "15"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# friends_count = [np.sum(all_ext.loc[(all_ext['id'] == int(childid))]['friends_count'].values) for childid in structure_ext.loc[0,'0':].dropna()]\n",
    "len([childid for childid in structure_ext.loc[0,:].dropna()]) \n",
    "\n",
    "# # '''print where 'Sum Friends Count' is 0'''\n",
    "# ext_thread.loc[ext_thread['Sum Friends Count'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Root   521369179392581632.00000\n0      521410632953131008.00000\n1      521373142347153408.00000\n2      521369380249432064.00000\n3      521370496928337920.00000\n4      521370224256614400.00000\n5      521370771793670144.00000\n6      521378607231279104.00000\n7      521370530134626304.00000\n8      521373433654157312.00000\n9      521369485144387584.00000\n10     521370061550809088.00000\n11     521369671975858176.00000\n12     521372372927266816.00000\n13     521373960509079552.00000\nName: 0, dtype: float64"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structure_ext.loc[0].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (all_ext.loc[(all_ext['pid'] == 521369179392581632)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_imp(X, y):\n",
    "    forest = ExtraTreesClassifier(n_estimators=250,\n",
    "                                random_state=3)\n",
    "\n",
    "    forest.fit(X, y)\n",
    "    importances = forest.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "                axis=0)\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    # Print the feature ranking\n",
    "    print(\"Feature ranking:\")\n",
    "\n",
    "    for f in range(X.shape[1]):\n",
    "        print(\"%d. feature %d: %s (%f)\" % (f + 1, indices[f], X.columns[indices[f]], importances[indices[f]]))\n",
    "\n",
    "    # Plot the impurity-based feature importances of the forest\n",
    "    # plt.figure()\n",
    "    # plt.title(\"Feature importances\")\n",
    "    # plt.bar(range(X.shape[1]), importances[indices],\n",
    "    #         color=\"r\", yerr=std[indices], align=\"center\")\n",
    "    # plt.xticks(range(X.shape[1]), indices)\n",
    "    # plt.xlim([-1, X.shape[1]])\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 33: AVG FPP (0.040009)\n",
      "2. feature 17: AVG Follower (0.035032)\n",
      "3. feature 34: AVG SPP (0.034403)\n",
      "4. feature 18: AVG followers/friend (0.032619)\n",
      "5. feature 29: Ratio Media (0.031679)\n",
      "6. feature 36: AVG Skepticism (0.031342)\n",
      "7. feature 26: thread_time (0.031308)\n",
      "8. feature 35: AVG TPP (0.030130)\n",
      "9. feature 8: Ratio HashTag (0.028389)\n",
      "10. feature 25: AVG AccAge (0.028336)\n",
      "11. feature 3: AVG WordCount (0.028235)\n",
      "12. feature 5: AVG CharCount (0.028209)\n",
      "13. feature 15: AVG Statues (0.027946)\n",
      "14. feature 16: AVG Listed (0.027543)\n",
      "15. feature 19: AVG favorite (0.027381)\n",
      "16. feature 32: RATIO Period (0.027200)\n",
      "17. feature 24: AVG RT (0.027073)\n",
      "18. feature 23: SUM RT (0.026441)\n",
      "19. feature 6: AVG HashTag (0.026324)\n",
      "20. feature 13: AVG Mention (0.026262)\n",
      "21. feature 7: SUM HashTag (0.025630)\n",
      "22. feature 2: AVG FriendsCount (0.025273)\n",
      "23. feature 4: SUM WordCount (0.025108)\n",
      "24. feature 30: RATIO Question (0.024994)\n",
      "25. feature 21: Ratio Verified (0.024990)\n",
      "26. feature 1: SUM FriendsCount (0.024865)\n",
      "27. feature 31: RATIO Exclaim (0.024014)\n",
      "28. feature 14: Ratio Mention (0.023600)\n",
      "29. feature 11: RATIO Url (0.023300)\n",
      "30. feature 12: SUM Mention (0.023062)\n",
      "31. feature 37: Ratio Skepticism (0.022847)\n",
      "32. feature 0: depth (0.022279)\n",
      "33. feature 20: Tweets Count (0.022072)\n",
      "34. feature 10: AVG Url (0.021595)\n",
      "35. feature 22: SUM Verified (0.019999)\n",
      "36. feature 9: SUM Url (0.019547)\n",
      "37. feature 28: RATIO Emoji (0.015994)\n",
      "38. feature 27: AVG Emoji (0.014969)\n"
     ]
    }
   ],
   "source": [
    "f_imp(pheme_thread_avg, pheme_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 19: AVG RT (0.039630)\n",
      "2. feature 18: SUM RT (0.039513)\n",
      "3. feature 28: AVG FPP (0.038684)\n",
      "4. feature 1: SUM FriendsCount (0.037558)\n",
      "5. feature 4: SUM WordCount (0.037424)\n",
      "6. feature 24: Ratio Media (0.035976)\n",
      "7. feature 29: AVG SPP (0.035525)\n",
      "8. feature 21: thread_time (0.034321)\n",
      "9. feature 31: AVG Skepticism (0.033293)\n",
      "10. feature 8: Ratio HashTag (0.032947)\n",
      "11. feature 7: SUM HashTag (0.032868)\n",
      "12. feature 30: AVG TPP (0.032501)\n",
      "13. feature 2: AVG FriendsCount (0.032004)\n",
      "14. feature 27: RATIO Period (0.031865)\n",
      "15. feature 20: AVG AccAge (0.030882)\n",
      "16. feature 5: AVG CharCount (0.030646)\n",
      "17. feature 3: AVG WordCount (0.030422)\n",
      "18. feature 13: AVG Mention (0.029672)\n",
      "19. feature 25: RATIO Question (0.029629)\n",
      "20. feature 16: Ratio Verified (0.029464)\n",
      "21. feature 26: RATIO Exclaim (0.029002)\n",
      "22. feature 6: AVG HashTag (0.028951)\n",
      "23. feature 12: SUM Mention (0.028561)\n",
      "24. feature 14: Ratio Mention (0.027891)\n",
      "25. feature 11: RATIO Url (0.027080)\n",
      "26. feature 32: Ratio Skepticism (0.027008)\n",
      "27. feature 0: depth (0.025802)\n",
      "28. feature 15: Tweets Count (0.025466)\n",
      "29. feature 10: AVG Url (0.023567)\n",
      "30. feature 17: SUM Verified (0.022930)\n",
      "31. feature 9: SUM Url (0.022718)\n",
      "32. feature 23: RATIO Emoji (0.018563)\n",
      "33. feature 22: AVG Emoji (0.017636)\n"
     ]
    }
   ],
   "source": [
    "f_imp(pheme_thread_std, pheme_y)\n",
    "\n",
    "'''\n",
    "Feature ranking:\n",
    "1. feature 19: AVG RT (0.039630)\n",
    "2. feature 18: SUM RT (0.039513)\n",
    "3. feature 28: AVG FPP (0.038684)\n",
    "4. feature 1: SUM FriendsCount (0.037558)\n",
    "5. feature 4: SUM WordCount (0.037424)\n",
    "6. feature 24: Ratio Media (0.035976)\n",
    "7. feature 29: AVG SPP (0.035525)\n",
    "8. feature 21: thread_time (0.034321)\n",
    "9. feature 31: AVG Skepticism (0.033293)\n",
    "10. feature 8: Ratio HashTag (0.032947)\n",
    "11. feature 7: SUM HashTag (0.032868)\n",
    "12. feature 30: AVG TPP (0.032501)\n",
    "13. feature 2: AVG FriendsCount (0.032004)\n",
    "14. feature 27: RATIO Period (0.031865)\n",
    "15. feature 20: AVG AccAge (0.030882)\n",
    "16. feature 5: AVG CharCount (0.030646)\n",
    "17. feature 3: AVG WordCount (0.030422)\n",
    "18. feature 13: AVG Mention (0.029672)\n",
    "19. feature 25: RATIO Question (0.029629)\n",
    "20. feature 16: Ratio Verified (0.029464)\n",
    "21. feature 26: RATIO Exclaim (0.029002)\n",
    "22. feature 6: AVG HashTag (0.028951)\n",
    "23. feature 12: SUM Mention (0.028561)\n",
    "24. feature 14: Ratio Mention (0.027891)\n",
    "25. feature 11: RATIO Url (0.027080)\n",
    "26. feature 32: Ratio Skepticism (0.027008)\n",
    "27. feature 0: depth (0.025802)\n",
    "28. feature 15: Tweets Count (0.025466)\n",
    "29. feature 10: AVG Url (0.023567)\n",
    "30. feature 17: SUM Verified (0.022930)\n",
    "31. feature 9: SUM Url (0.022718)\n",
    "32. feature 23: RATIO Emoji (0.018563)\n",
    "33. feature 22: AVG Emoji (0.017636)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 8: Ratio HashTag (0.049742)\n",
      "2. feature 29: Ratio Media (0.044968)\n",
      "3. feature 6: AVG HashTag (0.043019)\n",
      "4. feature 26: thread_time (0.041468)\n",
      "5. feature 25: AVG AccAge (0.037100)\n",
      "6. feature 7: SUM HashTag (0.033560)\n",
      "7. feature 19: AVG favorite (0.032574)\n",
      "8. feature 18: AVG followers/friend (0.031930)\n",
      "9. feature 4: SUM WordCount (0.030859)\n",
      "10. feature 5: AVG CharCount (0.030410)\n",
      "11. feature 3: AVG WordCount (0.030394)\n",
      "12. feature 36: AVG Skepticism (0.029637)\n",
      "13. feature 16: AVG Listed (0.029517)\n",
      "14. feature 24: AVG RT (0.029280)\n",
      "15. feature 17: AVG Follower (0.028177)\n",
      "16. feature 15: AVG Statues (0.027288)\n",
      "17. feature 33: AVG FPP (0.025404)\n",
      "18. feature 23: SUM RT (0.025367)\n",
      "19. feature 38: test_auxiliary (0.025030)\n",
      "20. feature 14: Ratio Mention (0.024896)\n",
      "21. feature 2: AVG FriendsCount (0.024288)\n",
      "22. feature 32: RATIO Period (0.024002)\n",
      "23. feature 1: SUM FriendsCount (0.022976)\n",
      "24. feature 20: Tweets Count (0.022059)\n",
      "25. feature 13: AVG Mention (0.020815)\n",
      "26. feature 12: SUM Mention (0.020213)\n",
      "27. feature 35: AVG TPP (0.020142)\n",
      "28. feature 37: Ratio Skepticism (0.019880)\n",
      "29. feature 0: depth (0.018869)\n",
      "30. feature 30: RATIO Question (0.018580)\n",
      "31. feature 22: SUM Verified (0.016823)\n",
      "32. feature 11: RATIO Url (0.015920)\n",
      "33. feature 9: SUM Url (0.015901)\n",
      "34. feature 31: RATIO Exclaim (0.014906)\n",
      "35. feature 10: AVG Url (0.014899)\n",
      "36. feature 21: Ratio Verified (0.013503)\n",
      "37. feature 39: test_tentat (0.011325)\n",
      "38. feature 34: AVG SPP (0.011113)\n",
      "39. feature 40: test_certain (0.011106)\n",
      "40. feature 28: RATIO Emoji (0.006216)\n",
      "41. feature 27: AVG Emoji (0.005840)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-ab6af1219c62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Plot the impurity-based feature importances of the forest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Feature importances\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m plt.bar(range(ext_thread_avg.shape[1]), importances[indices],\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "scaler = StandardScaler()\n",
    "# X = scaler.fit_transform(pheme_sparse)\n",
    "# X2 = scaler.fit_transform(pheme_thread)\n",
    "\n",
    "# X = pd.concat([pheme_sparse, pheme_thread], axis=1)\n",
    "\n",
    "forest = ExtraTreesClassifier(n_estimators=250,\n",
    "                            random_state=3)\n",
    "\n",
    "forest.fit(ext_thread_avg, ext_y)\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "            axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(ext_thread_avg.shape[1]):\n",
    "    print(\"%d. feature %d: %s (%f)\" % (f + 1, indices[f], ext_thread_avg.columns[indices[f]], importances[indices[f]]))\n",
    "\n",
    "# Plot the impurity-based feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(ext_thread_avg.shape[1]), importances[indices],\n",
    "        color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(ext_thread_avg.shape[1]), indices)\n",
    "plt.xlim([-1, ext_thread_avg.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/x.notebook.stream": "(125208, 42)\n(5802, 347)\n"
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "all_pheme = pd.read_csv(\"./data/all/_PHEMEall.csv\")\n",
    "structure_pheme = pd.read_csv(\"./data/all/_PHEME_structure.csv\")\n",
    "print(all_pheme.shape)\n",
    "print(structure_pheme.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "for:\n",
    "    pheme_thread_log_1 = np.log10(pheme_thread[['depth','Tweets Count','AVG CharCount', 'SUM RT', 'AVG RT', 'AVG AccAge','thread_time','AVG Skepticism']])\n",
    "    ext_thread_log_1 = np.log10(ext_thread[['depth','Tweets Count','AVG CharCount', 'SUM RT', 'AVG RT', 'AVG AccAge','thread_time','AVG Skepticism']])\n",
    "    pheme_thread_log_1 = pheme_thread_log_1.replace(-np.inf, 0)\n",
    "    ext_thread_log_1 = ext_thread_log_1.replace(-np.inf, 0)\n",
    "\n",
    "    pheme_thread_log_2 = np.log10(pheme_thread)\n",
    "    ext_thread_log_2 = np.log10(ext_thread)\n",
    "    pheme_thread_log_2 = pheme_thread_log_2.replace(-np.inf, 0)\n",
    "    ext_thread_log_2 = ext_thread_log_2.replace(-np.inf, 0)\n",
    "\n",
    "    pheme_thread_log_3 = np.log10(pheme_thread[['depth','Tweets Count','AVG CharCount', 'SUM RT', 'AVG RT', 'AVG AccAge','thread_time','AVG Skepticism']])\n",
    "    ext_thread_log_3 = np.log10(ext_thread[['depth','Tweets Count','AVG CharCount', 'SUM RT', 'AVG RT', 'AVG AccAge','thread_time','AVG Skepticism']])\n",
    "    pheme_temp = pheme_thread.drop(['depth','Tweets Count','AVG CharCount', 'SUM RT', 'AVG RT', 'AVG AccAge','thread_time','AVG Skepticism'],axis=1)\n",
    "    ext_temp = ext_thread.drop(['depth','Tweets Count','AVG CharCount', 'SUM RT', 'AVG RT', 'AVG AccAge','thread_time','AVG Skepticism'],axis=1)\n",
    "    pheme_thread_log_3 = pd.concat([pheme_thread_log_3, pheme_temp], axis=1)\n",
    "    ext_thread_log_3 = pd.concat([ext_thread_log_3, ext_temp], axis=1)\n",
    "    pheme_thread_log_3 = pheme_thread_log_3.replace(-np.inf, 0)\n",
    "    ext_thread_log_3 = ext_thread_log_3.replace(-np.inf, 0)\n",
    "\n",
    "    pheme_thread_log_4 = np.log10(pheme_thread+1)\n",
    "    ext_thread_log_4 = np.log10(ext_thread+1)\n",
    "    pheme_thread_log_4 = pheme_thread_log_4.replace(-np.inf, 0)\n",
    "    ext_thread_log_4 = ext_thread_log_4.replace(-np.inf, 0)\n",
    "\n",
    "    pheme_thread_log_5 = np.log10(pheme_thread-pheme_thread.min()+1)\n",
    "    ext_thread_log_5 = np.log10(ext_thread-ext_thread.min()+1)\n",
    "    pheme_thread_log_5 = pheme_thread_log_5.replace(-np.inf, 0)\n",
    "    ext_thread_log_5 = ext_thread_log_5.replace(-np.inf, 0)\n",
    "\n",
    "    # pheme_thread_log_6 = np.log10(pheme_thread-pheme_thread.min()+1)\n",
    "    ext_thread_log_6 = np.log10(ext_thread_nostd-ext_thread_nostd.min()+1)\n",
    "    # pheme_thread_log_6 = pheme_thread_log_5.replace(-np.inf, 0)\n",
    "    ext_thread_log_6 = ext_thread_log_6.replace(-np.inf, 0)\n",
    "\n",
    "    ext_thread_log_7 = np.log10(ext_thread_noavg-ext_thread_noavg.min()+1)\n",
    "    # pheme_thread_log_7 = pheme_thread_log_5.replace(-np.inf, 0)\n",
    "    ext_thread_log_7 = ext_thread_log_7.replace(-np.inf, 0)\n",
    "\n",
    "    oheme_temp = pheme_thread_std.drop(['depth','SUM FriendsCount', 'SUM HashTag','SUM Mention', 'Tweets Count','AVG CharCount','AVG WordCount', 'SUM RT', 'AVG RT', 'AVG AccAge','thread_time','AVG Skepticism'],axis=1)\n",
    "    pheme_thread_log_8 = pheme_thread_std[['depth','SUM FriendsCount', 'SUM HashTag','SUM Mention', 'Tweets Count','AVG CharCount','AVG WordCount', 'SUM RT', 'AVG RT', 'AVG AccAge','thread_time','AVG Skepticism']]\n",
    "    pheme_thread_log_8 = np.log10(pheme_thread_log_8-pheme_thread_log_8.min()+1)\n",
    "    pheme_thread_log_8 = pd.concat([pheme_thread_log_8, oheme_temp], axis=1)\n",
    "    pheme_thread_log_8 = pheme_thread_log_8.replace(-np.inf, 0)\n",
    "\n",
    "    ext_temp = ext_thread_std.drop(['depth','SUM FriendsCount', 'SUM HashTag','SUM Mention', 'Tweets Count','AVG CharCount','AVG WordCount', 'SUM RT', 'AVG RT', 'AVG AccAge','thread_time','AVG Skepticism'],axis=1)\n",
    "    ext_thread_log_8 = ext_thread_std[['depth','SUM FriendsCount', 'SUM HashTag','SUM Mention', 'Tweets Count','AVG CharCount','AVG WordCount', 'SUM RT', 'AVG RT', 'AVG AccAge','thread_time','AVG Skepticism']]\n",
    "    ext_thread_log_8 = np.log10(ext_thread_log_8-ext_thread_log_8.min()+1)\n",
    "    ext_thread_log_8 = pd.concat([ext_thread_log_8, ext_temp], axis=1)\n",
    "    ext_thread_log_8 = ext_thread_log_8.replace(-np.inf, 0)\n",
    "\n",
    "\n",
    "    pheme_thread_log_9 = np.log10(pheme_thread_std-pheme_thread_std.min()+1)\n",
    "    ext_thread_log_9 = np.log10(ext_thread_std-ext_thread_std.min()+1)\n",
    "    pheme_thread_log_9 = pheme_thread_log_9.replace(-np.inf, 0)\n",
    "    ext_thread_log_9 = ext_thread_log_9.replace(-np.inf, 0)\n",
    "\n",
    "\n",
    "    # pheme_thread_log_7 = pheme_thread_log_5.replace(-np.inf, 0)\n",
    "\n",
    "    # pheme_structure.to_csv('./data/all/_PHEME_structure.csv', index = False)\n",
    "\n",
    "    # pheme_thread_log_5.to_csv('./data/_PHEME_thread_log.csv', index = False)\n",
    "    # ext_thread_log_5.to_csv('./data/_PHEMEext_thread_log.csv', index = False)\n",
    "\n",
    "    # np.isinf(pheme_thread_log).sum()\n",
    "    # ext_thread_log = np.log10(ext_thread)\n",
    "    # np.isinf(ext_thread_log).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(X_train, X_test, y_train, y_test, clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    result = clf.predict(X_test)\n",
    "    print(\"Accuracy:\\t\\t\",accuracy_score(y_test,result))\n",
    "    print('Precision Score:\\t', str(precision_score(y_test,result)))\n",
    "    print('Recall Score:\\t\\t' + str(recall_score(y_test,result)))\n",
    "    print(\"F1 Score:\\t\\t\",f1_score(y_test, result, average='macro', zero_division=True))\n",
    "    print(classification_report(y_test, result))\n",
    "    \n",
    "pheme_all = pd.read_csv(\"./data/all/_PHEMEall.csv\")\n",
    "pheme_thread = pd.read_csv(\"./data/_PHEME_thread.csv\")\n",
    "pheme_thread_std = pd.read_csv(\"./data/_PHEME_thread_std.csv\")\n",
    "pheme_thread_avg = pd.read_csv(\"./data/_PHEME_thread_avg.csv\")\n",
    "pheme_y = pd.read_csv('./data/_PHEME_text.csv').target\n",
    "ext_all = pd.read_csv(\"./data/all/_PHEMEextall.csv\")\n",
    "ext_thread = pd.read_csv(\"./data/_PHEMEext_thread.csv\")\n",
    "ext_thread_std = pd.read_csv(\"./data/_PHEMEext_thread_std.csv\")\n",
    "# ext_thread_avg = pd.read_csv(\"./data/_PHEMEext_thread_avg.csv\")\n",
    "ext_y = pd.read_csv('./data/_PHEMEext_text.csv').target\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# ext_thread = ext_thread.replace(-np.inf, 0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(ext_thread_avg.iloc[:,:], ext_y, test_size=0.12, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.5918367346938775\n",
      "Precision Score:\t 0.8\n",
      "Recall Score:\t\t0.5\n",
      "F1 Score:\t\t 0.5903010033444817\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.76      0.57        17\n",
      "           1       0.80      0.50      0.62        32\n",
      "\n",
      "    accuracy                           0.59        49\n",
      "   macro avg       0.62      0.63      0.59        49\n",
      "weighted avg       0.68      0.59      0.60        49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# All X_ext\n",
    "X_train, X_test, y_train, y_test = train_test_split(ext_thread_avg.iloc[:,:], ext_y, test_size=0.1, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "clf = GaussianNB()\n",
    "train_test(X_train, X_test, y_train, y_test, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.673469387755102\n",
      "Precision Score:\t 0.7666666666666667\n",
      "Recall Score:\t\t0.71875\n",
      "F1 Score:\t\t 0.6487455197132617\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.59      0.56        17\n",
      "           1       0.77      0.72      0.74        32\n",
      "\n",
      "    accuracy                           0.67        49\n",
      "   macro avg       0.65      0.65      0.65        49\n",
      "weighted avg       0.68      0.67      0.68        49\n",
      "\n",
      "Accuracy:\t\t 0.5714285714285714\n",
      "Precision Score:\t 0.7391304347826086\n",
      "Recall Score:\t\t0.53125\n",
      "F1 Score:\t\t 0.5649048625792812\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.65      0.51        17\n",
      "           1       0.74      0.53      0.62        32\n",
      "\n",
      "    accuracy                           0.57        49\n",
      "   macro avg       0.58      0.59      0.56        49\n",
      "weighted avg       0.63      0.57      0.58        49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# All X_ext\n",
    "X_train, X_test, y_train, y_test = train_test_split(ext_thread_avg.iloc[:,:], ext_y, test_size=0.1, random_state=42)\n",
    "clf = GaussianNB()\n",
    "train_test(X_train, X_test, y_train, y_test, clf)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(ext_thread_std.iloc[:,:], ext_y, test_size=0.1, random_state=42)\n",
    "clf = GaussianNB()\n",
    "train_test(X_train, X_test, y_train, y_test, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.5443298969072164\n",
      "Precision Score:\t 0.8189655172413793\n",
      "Recall Score:\t\t0.5149051490514905\n",
      "F1 Score:\t\t 0.5166817724749626\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.64      0.40       116\n",
      "           1       0.82      0.51      0.63       369\n",
      "\n",
      "    accuracy                           0.54       485\n",
      "   macro avg       0.56      0.58      0.52       485\n",
      "weighted avg       0.69      0.54      0.58       485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# All X_ext\n",
    "# X_train, X_test, y_train, y_test = train_test_split(pheme_thread_avg, pheme_y, test_size=0.1, random_state=42)\n",
    "clf = RandomForestClassifier()\n",
    "train_test(pheme_thread_avg,ext_thread_avg, pheme_y, ext_y, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DL\n",
    "\n",
    "Training data: pheme_thread_scaled\n",
    "\n",
    "Testing data: ext_thread_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fetchData import fetchdata \n",
    "import __MLP\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ext_thread_noavg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-212-480ccafd250d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# ext_y = pd.read_csv('./data/_PHEMEext_target.csv')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# # pd.read_csv('./data/_PHEME_text.csv').target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mext_thread_noavg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mext_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpheme_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mext_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ext_thread_noavg' is not defined"
     ]
    }
   ],
   "source": [
    "# pheme_thread = pd.read_csv(\"./data/all/_PHEME_thread.csv\")\n",
    "# ext_thread = pd.read_csv(\"./data/all/_PHEMEext_thread.csv\")\n",
    "# pheme_y = pd.read_csv('./data/_PHEME_target.csv')\n",
    "# ext_y = pd.read_csv('./data/_PHEMEext_target.csv')\n",
    "# # pd.read_csv('./data/_PHEME_text.csv').target\n",
    "X_train, X_test, y_train, y_test = train_test_split(ext_thread_noavg, ext_y, test_size=0.10, random_state=42)\n",
    "print(torch.Tensor(pheme_thread.values).shape,torch.Tensor(ext_thread.values).shape)\n",
    "print(torch.Tensor(X_train.values).shape,torch.Tensor(X_test.values).shape)\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# pheme_thread_scaled = scaler.fit_transform(X_train)\n",
    "# ext_thread_scaled = scaler.transform(X_test)\n",
    "# print(torch.Tensor(pheme_thread_scaled).shape,torch.Tensor(ext_thread_scaled).shape)\n",
    "\n",
    "# pheme_thread_scaled = scaler.fit_transform(pheme_thread)\n",
    "# ext_thread_scaled = scaler.transform(ext_thread)\n",
    "# print(torch.Tensor(pheme_thread_scaled).shape,torch.Tensor(ext_thread_scaled).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(5802, 38)"
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pheme_thread_avg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "pheme_thread_scaled = scaler.fit_transform(pheme_thread_avg)\n",
    "ext_thread_scaled = scaler.transform(ext_thread_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 38) (59, 38)\n",
      "(426,) (59,)\n",
      "(5802, 36) (485, 36)\n",
      "(5802, 38) (485, 38)\n",
      "(5802,) (485,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)\n",
    "print(pheme_thread.shape, ext_thread.shape)\n",
    "print(pheme_thread_avg.shape, ext_thread_avg.shape)\n",
    "# print(pheme_thread_scaled.shape, ext_thread_scaled.shape)\n",
    "print(pheme_y.shape, ext_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X Size: torch.Size([5802, 1, 38]) / Train y Size: torch.Size([5802, 1])\n",
      "Test X Size: torch.Size([485, 1, 38]) / Test y Size: torch.Size([485, 1])\n",
      "Train Size 5802 Test Size 485\n"
     ]
    }
   ],
   "source": [
    "tensor_x1 = torch.Tensor(pheme_thread_scaled).unsqueeze(1)\n",
    "tensor_y1 = torch.Tensor(pheme_y.values).unsqueeze(1)\n",
    "tensor_x2 = torch.Tensor(ext_thread_scaled).unsqueeze(1)\n",
    "tensor_y2 = torch.Tensor(ext_y.values).unsqueeze(1)\n",
    "# tensor_y1 = torch.Tensor(pheme_y.values).unsqueeze(1)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(ext_thread_avg, ext_y, test_size=0.1, random_state=42)\n",
    "\n",
    "# tensor_x1 = torch.Tensor(X_train.values).unsqueeze(1)\n",
    "# tensor_y1 = torch.Tensor(y_train.values).unsqueeze(1)\n",
    "# tensor_x2 = torch.Tensor(X_test.values).unsqueeze(1)\n",
    "# tensor_y2 = torch.Tensor(y_test.values).unsqueeze(1)\n",
    "\n",
    "train_dataset = TensorDataset(tensor_x1,tensor_y1)\n",
    "test_dataset = TensorDataset(tensor_x2,tensor_y2)\n",
    "\n",
    "batch_size = 8\n",
    "counts = np.bincount(y_train.values)\n",
    "labels_weights = 1. / counts\n",
    "weights = labels_weights[y_train.values]\n",
    "train_sampler = WeightedRandomSampler(weights, len(weights))\n",
    "test_sampler = SequentialSampler(tensor_x2)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler, num_workers=2)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "train_size = int(tensor_y1.size(0))\n",
    "test_size = int(tensor_y2.size(0))\n",
    "print(\"Train X Size:\", tensor_x1.shape, \"/ Train y Size:\", tensor_y1.shape)\n",
    "print(\"Test X Size:\", tensor_x2.shape, \"/ Test y Size:\", tensor_y2.shape)\n",
    "print(\"Train Size\",train_size,\"Test Size\",test_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5802, 1, 38])\n",
      "torch.Size([5802, 1])\n"
     ]
    }
   ],
   "source": [
    "print(tensor_x1.size())\n",
    "print(tensor_y1.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sparse_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(sparse_model, self).__init__() # 1*20\n",
    "        self.fc1 = nn.Linear(38, 12, bias=True) # 420\n",
    "        self.fc3 = nn.Linear(12, 1)\n",
    "\n",
    "        self.drop_3 = nn.Dropout(0.3)\n",
    "        self.drop_4 = nn.Dropout(0.4)\n",
    "        self.drop_2 = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.drop_4(F.elu(self.fc1(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sparse = sparse_model()\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# optimizer = optim.SGD(model_sparse.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizer = optim.Adam(model_sparse.parameters(), lr=5e-5, eps=1e-8, weight_decay=1e-6)\n",
    "# scheduler = lr_scheduler.ExponentialLR(optimizer, gamma= 0.99)  \n",
    "\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps=0,  # Default value\n",
    "                                            num_training_steps=total_steps)\n",
    "\n",
    "PATH = \"./Model/state_dict_sparse_model.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf_report(train_loss, train_acc, val_loss, val_acc):\n",
    "    fig, ax = plt.subplots(4, 1, figsize=(12,8))\n",
    "    ax[0].plot(train_loss[:])\n",
    "    ax[0].set_ylabel('Loss')\n",
    "    ax[0].set_title('Training Loss')\n",
    "\n",
    "    ax[1].plot(train_acc[:])\n",
    "    ax[1].set_ylabel('Classification Accuracy')\n",
    "    ax[1].set_title('Training Accuracy')\n",
    "\n",
    "    ax[2].plot(val_loss[:])\n",
    "    ax[2].set_ylabel('Classification Accuracy')\n",
    "    ax[2].set_title('Testing Loss')\n",
    "\n",
    "    ax[3].plot(val_acc[:])\n",
    "    ax[3].set_ylabel('Classification Accuracy')\n",
    "    ax[3].set_title('Testing Accuracy')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Min of Training Loss: %4f\"%(np.min(train_loss)))\n",
    "    print(\"Max of Training Accuracy: %4f\"%(np.max(train_acc)))\n",
    "    print(\"Mean of Training Loss: %4f\"%(np.mean(train_loss)))\n",
    "    print(\"Mean of Training Accuracy: %4f\"%(np.mean(train_acc)))\n",
    "    print(\"----\")\n",
    "    print(\"Max of Testing Accuracy: %4f\"%(np.max(val_acc)))\n",
    "    print(\"Mean of Testing Loss: %4f\"%(np.mean(val_loss)))\n",
    "    print(\"Mean of Testing Accuracy: %4f\"%(np.mean(val_acc)))\n",
    "\n",
    "def set_seed(seed_value=42):\n",
    "    \"\"\"Set seed for reproducibility.\n",
    "    \"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "def train1(model, num_epochs, criterion, optimizer, scheduler, train_loader, train_size, test_loader=None, test_size=None, patience=5, PATH='./state_dict_model.pt'):\n",
    "    set_seed(42)\n",
    "    train_loss = []\n",
    "    patience_count = 0\n",
    "    train_accuracy = []\n",
    "    prev_loss = 10\n",
    "    best_loss = 10.0\n",
    "    val_corrects_list = []\n",
    "    val_loss_list = []\n",
    "    val_acc_list = []\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        # print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        # print('-' * 10)\n",
    "        running_corrects = 0.0\n",
    "        running_loss = 0.0\n",
    "        model.train()  # Set model to training mode\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.float(), labels.float()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            #  _, predictions = torch.max(outputs.data, 1) won’t work if your output only contains a single output unit.\n",
    "            # _, preds = torch.max(outputs, 1)\n",
    "            # print(outputs.flatten().size())\n",
    "            preds = outputs.squeeze(1) > 0.0\n",
    "\n",
    "            loss = criterion(outputs, labels.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # step function\n",
    "            scheduler.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / train_size\n",
    "        # print(running_loss)\n",
    "        # print(train_size)\n",
    "        epoch_acc = running_corrects.double() / train_size\n",
    "        train_loss.append(epoch_loss)\n",
    "        train_accuracy.append(epoch_acc)\n",
    "\n",
    "        if (epoch % 2 == 0):\n",
    "            print('Epoch {}/{}\\tTrain) Acc: {:.4f}, Loss: {:.4f}'.format(epoch,\n",
    "                                                                         num_epochs - 1, epoch_acc, epoch_loss))\n",
    "\n",
    "        if (test_loader != None):\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_loss = 0.0\n",
    "                val_corrects = 0\n",
    "                val_preds_list = []\n",
    "                val_label_list = []\n",
    "                for j, val in enumerate(test_loader, 0):\n",
    "                    val_x, val_label = val\n",
    "                    val_x, val_label = val_x.float(), val_label.float()\n",
    "                    val_outputs = model(val_x)\n",
    "                    # _, val_preds = torch.max(val_outputs, 1)\n",
    "                    val_preds = val_outputs.squeeze(1) > 0.0\n",
    "                    # print(\"val_preds:\\n\", val_preds)\n",
    "                    # print(\"val_labels:\\n\", val_label)\n",
    "\n",
    "                    val_preds_list.append(val_preds)\n",
    "                    val_label_list.append(val_label)\n",
    "                    v_loss = criterion(val_outputs, val_label.unsqueeze(1))\n",
    "                    val_loss += (v_loss.item() * val_x.size(0))\n",
    "                    val_corrects += torch.sum(val_preds == val_label)\n",
    "                    # print(\"val_corrects:\\n\", val_corrects)\n",
    "                    # accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
    "\n",
    "                if (epoch % 2 == 0):\n",
    "                    val_preds_list = torch.cat(val_preds_list, 0)\n",
    "                    val_label_list = torch.cat(val_label_list, 0)\n",
    "                    # print(\"\\t\\tValidation) Acc: {:.4f} Loss:{:.4f} F1 score: {:4f}\".format(val_corrects/test_size, val_loss/test_size, f1_score(val_label_list,val_preds_list,average='macro')))\n",
    "                    print(\"\\t\\tValidation) Acc: {:.4f} Loss:{:.4f}\".format(\n",
    "                        val_corrects/test_size, val_loss/test_size))\n",
    "            # print(\"val_corrects:\\n\", val_corrects)\n",
    "\n",
    "            val_corrects_list.append(val_corrects/test_size)\n",
    "            val_loss_list.append(val_loss/test_size)\n",
    "            val_acc = val_corrects.double() / test_size\n",
    "            val_acc_list.append(val_acc)\n",
    "\n",
    "        if epoch_loss < best_loss:\n",
    "            # print(\"prev_loss: {:.5f}\".format(prev_loss))\n",
    "            # print(\"loss: {:.5f}\".format(loss))\n",
    "            print(\n",
    "                \"\\t\\tSaving the best model w/ loss {:.4f}\".format(epoch_loss))\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "            best_loss = epoch_loss\n",
    "            patience_count = 0\n",
    "        elif best_loss < epoch_loss:\n",
    "            patience_count += 1\n",
    "        if patience_count >= patience:\n",
    "            print(\"Finishing the Model: Loss is not decreasing...\")\n",
    "            print(train_loss[-6:-1])\n",
    "            return train_accuracy, train_loss, val_acc_list, val_loss_list\n",
    "    return train_accuracy, train_loss, val_acc_list, val_loss_list\n",
    "\n",
    "def train2(model, num_epochs, criterion, optimizer, train_loader, train_size, test_loader=None, test_size=None, patience=5, PATH='./state_dict_model.pt'):\n",
    "    set_seed(42)\n",
    "    train_loss = []\n",
    "    patience_count = 0\n",
    "    train_accuracy = []\n",
    "    prev_loss = 10\n",
    "    best_loss = 10.0\n",
    "    val_corrects_list = []\n",
    "    val_loss_list = []\n",
    "    val_acc_list = []\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        # print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        # print('-' * 10)\n",
    "        running_corrects = 0.0\n",
    "        running_loss = 0.0\n",
    "        model.train()  # Set model to training mode\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.float(), labels.float()\n",
    "            print(inputs.size())\n",
    "            print(labels.size())\n",
    "            print(inputs.flatten())\n",
    "            print(labels.flatten())\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            print(\"outputs:\",outputs.size())\n",
    "            print(\"outputs:\",outputs)\n",
    "            print(\"labels:\",labels.size())\n",
    "            print(\"labels:\",labels.unsqueeze(1).size())\n",
    "\n",
    "            #  _, predictions = torch.max(outputs.data, 1) won’t work if your output only contains a single output unit.\n",
    "            # _, preds = torch.max(outputs, 1)\n",
    "            preds = torch.argmax(outputs, dim=1).flatten()\n",
    "            # print(outputs.flatten().size())\n",
    "            # preds = outputs > 0.0\n",
    "            # labels = labels.view(-1)\n",
    "            loss = criterion(outputs, labels.long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # step function\n",
    "            scheduler.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            # print('running correct')\n",
    "            # print(running_corrects)\n",
    "\n",
    "        epoch_loss = running_loss / train_size\n",
    "        # print(running_loss)\n",
    "        # print(train_size)\n",
    "        epoch_acc = running_corrects.double() / train_size\n",
    "        train_loss.append(epoch_loss)\n",
    "        train_accuracy.append(epoch_acc)\n",
    "\n",
    "        if (epoch % 2 == 0):\n",
    "            print('Epoch {}/{}\\tTrain) Acc: {:.4f}, Loss: {:.4f}'.format(epoch,\n",
    "                                                                         num_epochs - 1, epoch_acc, epoch_loss))\n",
    "\n",
    "        if (test_loader != None):\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_loss = 0.0\n",
    "                val_corrects = 0\n",
    "                val_preds_list = []\n",
    "                val_label_list = []\n",
    "                for j, val in enumerate(test_loader, 0):\n",
    "                    val_x, val_label = val\n",
    "                    val_x, val_label = val_x.float(), val_label.float()\n",
    "                    val_outputs = model(val_x)\n",
    "                    val_preds = torch.argmax(val_outputs, dim=1).flatten()\n",
    "                    # _, val_preds = torch.max(val_outputs, 1)\n",
    "                    # print(\"val_outputs:\",val_outputs.flatten())\n",
    "                    # val_preds = val_outputs > 0.0\n",
    "                    # print(\"val_preds:\",val_preds)\n",
    "                    val_preds_list.append(val_preds)\n",
    "                    val_label_list.append(val_label)\n",
    "                    v_loss = criterion(val_outputs, val_label.unsqueeze(1))\n",
    "                    val_loss += (v_loss.item() * val_x.size(0))\n",
    "                    val_corrects += torch.sum(val_preds ==\n",
    "                                              val_label.data).double()\n",
    "                if (epoch % 2 == 0):\n",
    "                    val_preds_list = torch.cat(val_preds_list, 0)\n",
    "                    val_label_list = torch.cat(val_label_list, 0)\n",
    "                    # print(\"\\t\\tValidation) Acc: {:.4f} Loss:{:.4f} F1 score: {:4f}\".format(val_corrects/test_size, val_loss/test_size, f1_score(val_label_list,val_preds_list,average='macro')))\n",
    "                    print(\"\\t\\tValidation) Acc: {:.4f} Loss:{:.4f}\".format(\n",
    "                        val_corrects/test_size, val_loss/test_size))\n",
    "            val_corrects_list.append(val_corrects/test_size)\n",
    "            val_loss_list.append(val_loss/test_size)\n",
    "            val_acc = val_corrects.double() / test_size\n",
    "            val_acc_list.append(val_acc)\n",
    "\n",
    "        if epoch_loss < best_loss:\n",
    "            # print(\"prev_loss: {:.5f}\".format(prev_loss))\n",
    "            # print(\"loss: {:.5f}\".format(loss))\n",
    "            print(\n",
    "                \"\\t\\tSaving the best model w/ loss {:.4f}\".format(epoch_loss))\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "            best_loss = epoch_loss\n",
    "            patience_count = 0\n",
    "        elif best_loss < epoch_loss:\n",
    "            patience_count += 1\n",
    "        if patience_count >= patience:\n",
    "            print(\"Finishing the Model: Loss is not decreasing...\")\n",
    "            print(train_loss[-6:-1])\n",
    "            return train_accuracy, train_loss, val_acc_list, val_loss_list\n",
    "    return train_accuracy, train_loss, val_acc_list, val_loss_list\n",
    "\n",
    "def predict(model, criterion, val_dataloader, val_size):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "        for j, val in enumerate(val_dataloader, 0):\n",
    "            val_x, val_label = val\n",
    "            val_x, val_label = val_x.float(), val_label.float()\n",
    "            val_outputs = model(val_x)\n",
    "            val_preds = val_outputs.squeeze(1) > 0.0\n",
    "\n",
    "            val_preds_list.append(val_preds)\n",
    "            val_label_list.append(val_label)\n",
    "            v_loss = criterion(val_outputs, val_label.unsqueeze(1))\n",
    "            val_loss += (v_loss.item() * val_x.size(0))\n",
    "            val_corrects += torch.sum(val_preds == val_label)\n",
    "\n",
    "    val_preds_list = torch.cat(val_preds_list, 0)\n",
    "    val_label_list = torch.cat(val_label_list, 0)\n",
    "    val_corrects = val_corrects/val_size\n",
    "    val_loss/test_size\n",
    "    val_acc = val_corrects.double() / val_size\n",
    "    print(\"\\t\\tValidation) Acc: {:.4f} Loss:{:.4f}\".format(\n",
    "        val_corrects/val_size, val_loss/test_size))\n",
    "    # print(\"\\t\\tValidation) Acc: {:.4f} Loss:{:.4f} F1 score: {:4f}\".format(val_corrects/val_size, val_loss/test_size, f1_score(val_label_list,val_preds_list,average='macro')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/99\tTrain) Acc: 0.0357, Loss: 0.0515\n",
      "\t\tValidation) Acc: 0.5979 Loss:0.6834\n",
      "\t\tSaving the best model w/ loss 0.0515\n",
      "\t\tSaving the best model w/ loss 0.0510\n",
      "Epoch 2/99\tTrain) Acc: 0.0474, Loss: 0.0496\n",
      "\t\tValidation) Acc: 0.6247 Loss:0.6726\n",
      "\t\tSaving the best model w/ loss 0.0496\n",
      "\t\tSaving the best model w/ loss 0.0486\n",
      "Epoch 4/99\tTrain) Acc: 0.0483, Loss: 0.0481\n",
      "\t\tValidation) Acc: 0.6351 Loss:0.6619\n",
      "\t\tSaving the best model w/ loss 0.0481\n",
      "Epoch 6/99\tTrain) Acc: 0.0510, Loss: 0.0471\n",
      "\t\tValidation) Acc: 0.6474 Loss:0.6523\n",
      "\t\tSaving the best model w/ loss 0.0471\n",
      "\t\tSaving the best model w/ loss 0.0463\n",
      "Epoch 8/99\tTrain) Acc: 0.0524, Loss: 0.0471\n",
      "\t\tValidation) Acc: 0.6660 Loss:0.6440\n",
      "\t\tSaving the best model w/ loss 0.0458\n",
      "Epoch 10/99\tTrain) Acc: 0.0562, Loss: 0.0457\n",
      "\t\tValidation) Acc: 0.6763 Loss:0.6367\n",
      "\t\tSaving the best model w/ loss 0.0457\n",
      "\t\tSaving the best model w/ loss 0.0446\n",
      "Epoch 12/99\tTrain) Acc: 0.0593, Loss: 0.0442\n",
      "\t\tValidation) Acc: 0.6784 Loss:0.6286\n",
      "\t\tSaving the best model w/ loss 0.0442\n",
      "Epoch 14/99\tTrain) Acc: 0.0610, Loss: 0.0439\n",
      "\t\tValidation) Acc: 0.6887 Loss:0.6214\n",
      "\t\tSaving the best model w/ loss 0.0439\n",
      "\t\tSaving the best model w/ loss 0.0437\n",
      "Epoch 16/99\tTrain) Acc: 0.0617, Loss: 0.0423\n",
      "\t\tValidation) Acc: 0.6928 Loss:0.6145\n",
      "\t\tSaving the best model w/ loss 0.0423\n",
      "Epoch 18/99\tTrain) Acc: 0.0605, Loss: 0.0428\n",
      "\t\tValidation) Acc: 0.6928 Loss:0.6086\n",
      "\t\tSaving the best model w/ loss 0.0410\n",
      "Epoch 20/99\tTrain) Acc: 0.0650, Loss: 0.0401\n",
      "\t\tValidation) Acc: 0.6907 Loss:0.6022\n",
      "\t\tSaving the best model w/ loss 0.0401\n",
      "Epoch 22/99\tTrain) Acc: 0.0646, Loss: 0.0400\n",
      "\t\tValidation) Acc: 0.6969 Loss:0.5970\n",
      "\t\tSaving the best model w/ loss 0.0400\n",
      "\t\tSaving the best model w/ loss 0.0393\n",
      "Epoch 24/99\tTrain) Acc: 0.0657, Loss: 0.0387\n",
      "\t\tValidation) Acc: 0.6990 Loss:0.5919\n",
      "\t\tSaving the best model w/ loss 0.0387\n",
      "Epoch 26/99\tTrain) Acc: 0.0646, Loss: 0.0382\n",
      "\t\tValidation) Acc: 0.6969 Loss:0.5880\n",
      "\t\tSaving the best model w/ loss 0.0382\n",
      "Epoch 28/99\tTrain) Acc: 0.0657, Loss: 0.0379\n",
      "\t\tValidation) Acc: 0.7113 Loss:0.5839\n",
      "\t\tSaving the best model w/ loss 0.0379\n",
      "Epoch 30/99\tTrain) Acc: 0.0657, Loss: 0.0373\n",
      "\t\tValidation) Acc: 0.7093 Loss:0.5809\n",
      "\t\tSaving the best model w/ loss 0.0373\n",
      "\t\tSaving the best model w/ loss 0.0369\n",
      "Epoch 32/99\tTrain) Acc: 0.0655, Loss: 0.0376\n",
      "\t\tValidation) Acc: 0.7093 Loss:0.5788\n",
      "\t\tSaving the best model w/ loss 0.0364\n",
      "Epoch 34/99\tTrain) Acc: 0.0676, Loss: 0.0351\n",
      "\t\tValidation) Acc: 0.7093 Loss:0.5760\n",
      "\t\tSaving the best model w/ loss 0.0351\n",
      "Epoch 36/99\tTrain) Acc: 0.0674, Loss: 0.0348\n",
      "\t\tValidation) Acc: 0.7113 Loss:0.5736\n",
      "\t\tSaving the best model w/ loss 0.0348\n",
      "\t\tSaving the best model w/ loss 0.0344\n",
      "Epoch 38/99\tTrain) Acc: 0.0681, Loss: 0.0337\n",
      "\t\tValidation) Acc: 0.7093 Loss:0.5715\n",
      "\t\tSaving the best model w/ loss 0.0337\n",
      "Epoch 40/99\tTrain) Acc: 0.0693, Loss: 0.0328\n",
      "\t\tValidation) Acc: 0.7072 Loss:0.5699\n",
      "\t\tSaving the best model w/ loss 0.0328\n",
      "Epoch 42/99\tTrain) Acc: 0.0677, Loss: 0.0338\n",
      "\t\tValidation) Acc: 0.7072 Loss:0.5681\n",
      "\t\tSaving the best model w/ loss 0.0322\n",
      "Epoch 44/99\tTrain) Acc: 0.0674, Loss: 0.0332\n",
      "\t\tValidation) Acc: 0.7093 Loss:0.5666\n",
      "Epoch 46/99\tTrain) Acc: 0.0689, Loss: 0.0322\n",
      "\t\tValidation) Acc: 0.7093 Loss:0.5653\n",
      "\t\tSaving the best model w/ loss 0.0320\n",
      "Epoch 48/99\tTrain) Acc: 0.0691, Loss: 0.0312\n",
      "\t\tValidation) Acc: 0.7093 Loss:0.5644\n",
      "\t\tSaving the best model w/ loss 0.0312\n",
      "Epoch 50/99\tTrain) Acc: 0.0684, Loss: 0.0305\n",
      "\t\tValidation) Acc: 0.7134 Loss:0.5635\n",
      "\t\tSaving the best model w/ loss 0.0305\n",
      "Epoch 52/99\tTrain) Acc: 0.0686, Loss: 0.0319\n",
      "\t\tValidation) Acc: 0.7134 Loss:0.5629\n",
      "Epoch 54/99\tTrain) Acc: 0.0653, Loss: 0.0323\n",
      "\t\tValidation) Acc: 0.7155 Loss:0.5623\n",
      "\t\tSaving the best model w/ loss 0.0293\n",
      "Epoch 56/99\tTrain) Acc: 0.0683, Loss: 0.0304\n",
      "\t\tValidation) Acc: 0.7155 Loss:0.5621\n",
      "Epoch 58/99\tTrain) Acc: 0.0686, Loss: 0.0301\n",
      "\t\tValidation) Acc: 0.7155 Loss:0.5619\n",
      "\t\tSaving the best model w/ loss 0.0292\n",
      "Epoch 60/99\tTrain) Acc: 0.0705, Loss: 0.0284\n",
      "\t\tValidation) Acc: 0.7155 Loss:0.5618\n",
      "\t\tSaving the best model w/ loss 0.0284\n",
      "Epoch 62/99\tTrain) Acc: 0.0681, Loss: 0.0299\n",
      "\t\tValidation) Acc: 0.7196 Loss:0.5615\n",
      "Epoch 64/99\tTrain) Acc: 0.0700, Loss: 0.0281\n",
      "\t\tValidation) Acc: 0.7237 Loss:0.5612\n",
      "\t\tSaving the best model w/ loss 0.0281\n",
      "Epoch 66/99\tTrain) Acc: 0.0679, Loss: 0.0292\n",
      "\t\tValidation) Acc: 0.7237 Loss:0.5611\n",
      "\t\tSaving the best model w/ loss 0.0279\n",
      "Epoch 68/99\tTrain) Acc: 0.0689, Loss: 0.0288\n",
      "\t\tValidation) Acc: 0.7237 Loss:0.5610\n",
      "Epoch 70/99\tTrain) Acc: 0.0681, Loss: 0.0291\n",
      "\t\tValidation) Acc: 0.7237 Loss:0.5608\n",
      "Epoch 72/99\tTrain) Acc: 0.0698, Loss: 0.0285\n",
      "\t\tValidation) Acc: 0.7258 Loss:0.5607\n",
      "Finishing the Model: Loss is not decreasing...\n",
      "[0.027912357610819546, 0.028848437924337403, 0.02844981610343523, 0.029122860040881642, 0.02875080471489192]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "train_acc, train_loss, val_acc, val_loss_list = train1(model=model_sparse, num_epochs=epochs,patience=5, criterion=criterion, optimizer=optimizer, scheduler=scheduler, train_loader=train_dataloader, train_size=train_size, test_loader=test_dataloader, test_size=test_size, PATH=PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 864x576 with 4 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min of Training Loss: 0.033228\n",
      "Max of Training Accuracy: 0.065495\n",
      "Mean of Training Loss: 0.043980\n",
      "Mean of Training Accuracy: 0.049195\n",
      "----\n",
      "Max of Testing Accuracy: 0.738144\n",
      "Mean of Testing Loss: 0.625475\n",
      "Mean of Testing Accuracy: 0.628689\n"
     ]
    }
   ],
   "source": [
    "__MLP.clf_report(train_loss, train_acc, val_loss_list, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. log_lists 1\n",
    "# - Min of Training Loss: 0.676791\n",
    "# - Max of Training Accuracy: 0.580834\n",
    "# - Mean of Training Loss: 0.930833\n",
    "# - Mean of Training Accuracy: 0.549138\n",
    "\n",
    "# - Max of Testing Accuracy: 0.758763\n",
    "# - Mean of Testing Loss: 0.639751\n",
    "# - Mean of Testing Accuracy: 0.741991\n",
    "\n",
    "# 2. log_lists 2\n",
    "# Min of Training Loss: 0.661804\n",
    "# Max of Training Accuracy: 0.623923\n",
    "# Mean of Training Loss: 0.675339\n",
    "# Mean of Training Accuracy: 0.579164\n",
    "# ----\n",
    "# Max of Testing Accuracy: 0.754639\n",
    "# Mean of Testing Loss: 0.647825\n",
    "# Mean of Testing Accuracy: 0.663184\n",
    "\n",
    "# 3. log_lists 3\n",
    "# Min of Training Loss: 0.689231\n",
    "# Max of Training Accuracy: 0.551534\n",
    "# Mean of Training Loss: 0.691886\n",
    "# Mean of Training Accuracy: 0.529895\n",
    "# ----\n",
    "# Max of Testing Accuracy: 0.769072\n",
    "# Mean of Testing Loss: 0.672092\n",
    "# Mean of Testing Accuracy: 0.727753\n",
    "\n",
    "# 4. log_lists 4\n",
    "# Min of Training Loss: 0.655381\n",
    "# Max of Training Accuracy: 0.615822\n",
    "# Mean of Training Loss: 0.668167\n",
    "# Mean of Training Accuracy: 0.590891\n",
    "# ----\n",
    "# Max of Testing Accuracy: 0.760825\n",
    "# Mean of Testing Loss: 0.602897\n",
    "# Mean of Testing Accuracy: 0.751031\n",
    "\n",
    "# 5. log_lists 5\n",
    "# Min of Training Loss: 0.645203\n",
    "# Max of Training Accuracy: 0.638573\n",
    "# Mean of Training Loss: 0.664737\n",
    "# Mean of Training Accuracy: 0.602872\n",
    "# ----\n",
    "# Max of Testing Accuracy: 0.773196\n",
    "# Mean of Testing Loss: 0.595279\n",
    "# Mean of Testing Accuracy: 0.755809"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(5802, 33)"
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pheme_thread_log_9.shape\n",
    "pheme_thread_log_9.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pheme_thread_log_8' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-43ed68abceb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# pheme_thread_log_9\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtensor_x1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpheme_thread_log_8\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtensor_y1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpheme_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_x1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtensor_y1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pheme_thread_log_8' is not defined"
     ]
    }
   ],
   "source": [
    "# pheme_thread_log_9\n",
    "\n",
    "tensor_x1 = torch.Tensor(pheme_thread_log_8.values).unsqueeze(1)\n",
    "tensor_y1 = torch.Tensor(pheme_y.values).unsqueeze(1)\n",
    "train_dataset = TensorDataset(tensor_x1,tensor_y1)\n",
    "\n",
    "tensor_x2 = torch.Tensor(ext_thread_log_8.values).unsqueeze(1)\n",
    "tensor_y2 = torch.Tensor(ext_y.values).unsqueeze(1)\n",
    "test_dataset = TensorDataset(tensor_x2,tensor_y2)\n",
    "\n",
    "batch_size = 8\n",
    "counts = np.bincount(pheme_y.values)\n",
    "labels_weights = 1. / counts\n",
    "weights = labels_weights[pheme_y.values]\n",
    "train_sampler = WeightedRandomSampler(weights, len(weights))\n",
    "test_sampler = SequentialSampler(tensor_x2)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler, num_workers=2)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "train_size = int(tensor_y1.size(0))\n",
    "test_size = int(tensor_y2.size(0))\n",
    "print(\"Train X Size:\", tensor_x1.shape, \"/ Train y Size:\", tensor_y1.shape)\n",
    "print(\"Test X Size:\", tensor_x2.shape, \"/ Test y Size:\", tensor_y2.shape)\n",
    "print(\"Train Size\",train_size,\"Test Size\",test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sparse = sparse_model()\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# optimizer = optim.SGD(model_sparse.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizer = optim.Adam(model_sparse.parameters(), lr=5e-5, eps=1e-8, weight_decay=1e-6)\n",
    "# scheduler = lr_scheduler.ExponentialLR(optimizer, gamma= 0.99)  \n",
    "\n",
    "epochs = 100\n",
    "\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps=0,  # Default value\n",
    "                                            num_training_steps=total_steps)\n",
    "# PATH = \"./Model/state_dict_sparse_model.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/99\tTrain) Acc: 0.0596, Loss: 0.0318\n",
      "\t\tValidation) Acc: 0.7546 Loss:0.5863\n",
      "\t\tSaving the best model w/ loss 0.0318\n",
      "\t\tSaving the best model w/ loss 0.0271\n",
      "Epoch 2/99\tTrain) Acc: 0.0684, Loss: 0.0185\n",
      "\t\tValidation) Acc: 0.7588 Loss:0.5567\n",
      "\t\tSaving the best model w/ loss 0.0185\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid 65620) is killed by signal: Interrupt: 2. ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-103-16d706f7b80b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_sparse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPATH\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-92-cb49b67d9e17>\u001b[0m in \u001b[0;36mtrain1\u001b[0;34m(model, num_epochs, criterion, optimizer, scheduler, train_loader, train_size, test_loader, test_size, patience, PATH)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Set model to training mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0;31m# get the inputs; data is a list of [inputs, labels]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1181\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1147\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1149\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    106\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2060\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2061\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2062\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2061\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2062\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2063\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2064\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1082\u001b[0m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m         \u001b[0mformatted_exception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_records\u001b[0;34m(self, records, last_unique, recursion_repeat)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0mskipped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m             \u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mskipped\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_record\u001b[0;34m(self, frame, file, lnum, func, lines, index)\u001b[0m\n\u001b[1;32m   1021\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1023\u001b[0;31m             \u001b[0m_line_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPyColorize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcol_scheme\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1024\u001b[0m             return '%s%s' % (level, ''.join(\n\u001b[1;32m   1025\u001b[0m                 _format_traceback_lines(lnum, index, lines, Colors, lvals,\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/IPython/utils/PyColorize.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, color_table, out, parent, style)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolor_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolor_table\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcolor_table\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mANSICodeColors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/traitlets/config/configurable.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;31m# making that a class attribute.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;31m# self.config = deepcopy(config)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0;31m# allow _config_default to return something\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/traitlets/traitlets.py\u001b[0m in \u001b[0;36m__set__\u001b[0;34m(self, obj, value)\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTraitError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The \"%s\" trait is read-only.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/traitlets/traitlets.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, obj, value)\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0;31m# we explicitly compare silent to True just in case the equality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m             \u001b[0;31m# comparison above returns something other than True/False\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_notify_trait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__set__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/traitlets/traitlets.py\u001b[0m in \u001b[0;36m_notify_trait\u001b[0;34m(self, name, old_value, new_value)\u001b[0m\n\u001b[1;32m   1215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_notify_trait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         self.notify_change(Bunch(\n\u001b[0m\u001b[1;32m   1218\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m             \u001b[0mold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mold_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/traitlets/traitlets.py\u001b[0m in \u001b[0;36mnotify_change\u001b[0;34m(self, change)\u001b[0m\n\u001b[1;32m   1225\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnotify_change\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m         \u001b[0;34m\"\"\"Notify observers of a change event\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1227\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_notify_observers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1229\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_notify_observers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/traitlets/traitlets.py\u001b[0m in \u001b[0;36m_notify_observers\u001b[0;34m(self, event)\u001b[0m\n\u001b[1;32m   1262\u001b[0m                 \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1264\u001b[0;31m             \u001b[0mc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_add_notifiers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/traitlets/traitlets.py\u001b[0m in \u001b[0;36mcompatible_observer\u001b[0;34m(self, change_or_name, old, new)\u001b[0m\n\u001b[1;32m    886\u001b[0m                 \u001b[0mowner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m             )\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcompatible_observer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/traitlets/config/configurable.py\u001b[0m in \u001b[0;36m_config_changed\u001b[0;34m(self, change)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \"\"\"\n\u001b[1;32m    201\u001b[0m         \u001b[0;31m# Get all traits with a config metadata entry that is True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mtraits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;31m# We auto-load config section for this class as well as any parent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/traitlets/traitlets.py\u001b[0m in \u001b[0;36mtraits\u001b[0;34m(self, **metadata)\u001b[0m\n\u001b[1;32m   1604\u001b[0m         \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1605\u001b[0m         \"\"\"\n\u001b[0;32m-> 1606\u001b[0;31m         traits = dict([memb for memb in getmembers(self.__class__) if\n\u001b[0m\u001b[1;32m   1607\u001b[0m                      isinstance(memb[1], TraitType)])\n\u001b[1;32m   1608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/traitlets/traitlets.py\u001b[0m in \u001b[0;36mgetmembers\u001b[0;34m(object, predicate)\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpredicate\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpredicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m                 \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/torch/utils/data/_utils/signal_handling.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m# Python can still get and update the process status successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0m_error_if_any_worker_fails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprevious_handler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprevious_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 65620) is killed by signal: Interrupt: 2. "
     ]
    }
   ],
   "source": [
    "train_acc, train_loss, val_acc, val_loss_list = train1(model=model_sparse, num_epochs=epochs,patience=5, criterion=criterion, optimizer=optimizer, scheduler=scheduler, train_loader=train_dataloader, train_size=train_size, test_loader=test_dataloader, test_size=test_size, PATH=PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 864x576 with 4 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min of Training Loss: 0.661521\n",
      "Max of Training Accuracy: 0.616684\n",
      "Mean of Training Loss: 0.676972\n",
      "Mean of Training Accuracy: 0.578032\n",
      "----\n",
      "Max of Testing Accuracy: 0.414433\n",
      "Mean of Testing Loss: 0.752124\n",
      "Mean of Testing Accuracy: 0.320928\n"
     ]
    }
   ],
   "source": [
    "__MLP.clf_report(train_loss, train_acc, val_loss_list, val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rosetta",
   "language": "python",
   "name": "rosetta"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}