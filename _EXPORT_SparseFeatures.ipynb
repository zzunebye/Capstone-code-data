{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행시 등장하는 URL을 클릭하여 허용해주면 인증KEY가 나타난다. 복사하여 URL아래 빈칸에 붙여넣으면 마운트에 성공하게된다.\n",
    "from google.colab import drive\n",
    "drive.mount('./MyDrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd MyDrive/MyDrive/Capstone/code_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/june/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/june/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob2 import glob\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "import gensim\n",
    "import gensim.models.word2vec as w2v\n",
    "from gensim.test.utils import common_texts\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "\n",
    "from nltk import SnowballStemmer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import emoji\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', 400)\n",
    "# pd.set_option('display.max_rowwidth', 100)\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmt = WordNetLemmatizer()\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "freqdist = nltk.FreqDist()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tweet_tokenizer = TweetTokenizer()\n",
    "\n",
    "\"\"\" Replaces contractions from a string to their equivalents \"\"\"\n",
    "contraction_patterns = [ (r'won\\'t', 'will not'), (r'can\\'t', 'cannot'), (r'i\\'m', 'i am'), (r'ain\\'t', 'is not'), (r'(\\w+)\\'ll', '\\g<1> will'), (r'(\\w+)n\\'t', '\\g<1> not'),\n",
    "                         (r'(\\w+)\\'ve', '\\g<1> have'), (r'(\\w+)\\'s', '\\g<1> is'), (r'(\\w+)\\'re', '\\g<1> are'), (r'(\\w+)\\'d', '\\g<1> would'), (r'&', 'and'), (r'dammit', 'damn it'), (r'dont', 'do not'), (r'wont', 'will not'), \n",
    "                         (r'i\\'d', 'i would'), (r'I\\'d', 'I would'), (r'he\\'d', 'he would'), (r'she\\'d', 'she would'), (r'they\\'d', 'they would'), (r'we\\'d', 'we would')]\n",
    "def replaceContraction(text):\n",
    "    patterns = [(re.compile(regex), repl) for (regex, repl) in contraction_patterns]\n",
    "    for (pattern, repl) in patterns:\n",
    "        (text, count) = re.subn(pattern, repl, text)\n",
    "    return text\n",
    "\n",
    "def capitalratio(tweet_text):\n",
    "    uppers = [l for l in tweet_text if l.isupper()]\n",
    "    capitalratio = len(uppers) / len(tweet_text)\n",
    "    return capitalratio \n",
    "\n",
    "def getTokenization(sent):\n",
    "    tweet_tokens = []\n",
    "    sent = sent.lower()\n",
    "    sent = replaceContraction(sent)\n",
    "\n",
    "    sent = re.sub(r\"http\\S+\", \"*\", sent) # http link -> '*'\n",
    "    # sent = re.sub(r\"@\\S+\", \"@\", sent)   # mention -> '@'\n",
    "    sent = re.sub(r\"@[^\\s]+\", \"@\", sent)   # mention -> '@'\n",
    "    sent = re.sub(r\"(#)(\\S+)\", r'\\1 \\2', sent) \n",
    "\n",
    "    sent = re.sub(r'([^\\s\\w@#\\*]|_)+', '', sent) # Erasing Special Characters\n",
    "    # sent = re.sub('@[^\\s]+','atUser',sent)\n",
    "    # sent = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','url',sent)\n",
    "    # sent = re.sub(r'#([^\\s]+)', r'\\1', sent)\n",
    "\n",
    "\n",
    "    # sent = re.sub('', '', sent.lower())\n",
    "    # sent = [tweet_tokenizer.tokenize(sent)]\n",
    "    sent = tweet_tokenizer.tokenize(sent)\n",
    "    sent = [stemmer.stem(token) for token in sent]\n",
    "    sent = [lmt.lemmatize(token) for token in sent]\n",
    "\n",
    "    temp = [token for token in sent if not token in stop_words]\n",
    "    url=0\n",
    "    for token in temp:\n",
    "        if token.startswith('*'):\n",
    "            url+=1\n",
    "    # tweet_tokens.append([temp])\n",
    "    # tweet_tokens.append(tweet_tokenizer.tokenize(sent))\n",
    "    # df_tokens = pd.DataFrame(tweet_tokens, columns=['token'])\n",
    "    return temp, url\n",
    "\n",
    "def extract_urls(entities_dicts):\n",
    "    if len(entities_dicts) < 1:\n",
    "        return 0\n",
    "    if len(entities_dicts) == 1:\n",
    "        return 1\n",
    "    if len(entities_dicts) == 2:\n",
    "        return 2\n",
    "\n",
    "    # urls = []\n",
    "    # urls_expanded = []\n",
    "\n",
    "    # key = 'url'\n",
    "    # key2 = 'expanded_url'\n",
    "    # # print(len(entities_dict))\n",
    "    # for i in entities_dicts:\n",
    "    #     urls.append(i[key])\n",
    "    #     urls_expanded.append(i[key2])\n",
    "    # return 1, urls, urls_expanded\n",
    "\n",
    "def getposcount(tokens):\n",
    "    postag = []\n",
    "    poscount = {}\n",
    "    poscount['Noun']=0\n",
    "    poscount['Verb']=0\n",
    "    poscount['Adjective'] = 0\n",
    "    poscount['Pronoun']=0\n",
    "    poscount['FirstPersonPronoun']=0\n",
    "    poscount['SecondPersonPronoun']=0\n",
    "    poscount['ThirdPersonPronoun']=0\n",
    "    poscount['Adverb']=0\n",
    "    poscount['Numeral']=0\n",
    "    poscount['Conjunction_inj']=0\n",
    "    poscount['Particle']=0\n",
    "    poscount['Determiner']=0\n",
    "    poscount['Modal']=0\n",
    "    poscount['Whs']=0\n",
    "    Nouns = {'NN','NNS','NNP','NNPS'}\n",
    "    Adverbs = {'RB','RBR','RBS'}\n",
    "    Whs = {'WDT','WP','WRB'} # Composition of wh-determiner(that,what), wh-pronoun(who), wh-adverb(how)\n",
    "    Verbs={'VB','VBP','VBZ','VBN','VBG','VBD','To'}\n",
    "    first_person_pronouns=['i','I','me','my','mine','we','us','our','ours'] #'i',\n",
    "    second_person_pronouns=['you','your','yours', 'ya']\n",
    "    third_person_pronouns=['he','she','it','him','her','it','his','hers','its','they','them','their','theirs']\n",
    "\n",
    "    for word in tokens:\n",
    "        w_lower=word.lower()\n",
    "        if w_lower in first_person_pronouns:\n",
    "            poscount['FirstPersonPronoun']+=1\n",
    "        elif w_lower in second_person_pronouns:\n",
    "            poscount['SecondPersonPronoun']+=1\n",
    "        elif w_lower in third_person_pronouns:\n",
    "            poscount['ThirdPersonPronoun']+=1\n",
    "    \n",
    "    postag = nltk.pos_tag(tokens)\n",
    "    for g1 in postag:\n",
    "        if g1[1] in Nouns:\n",
    "            poscount['Noun'] += 1\n",
    "        elif g1[1] in Verbs:\n",
    "            poscount['Verb']+= 1\n",
    "        elif g1[1]=='ADJ'or g1[1]=='JJ':\n",
    "            poscount['Adjective']+=1\n",
    "        elif g1[1]=='PRP' or g1[1]=='PRON' or g1[1]=='PRP$':\n",
    "            poscount['Pronoun']+=1\n",
    "        elif g1[1] in Adverbs or g1[1]=='ADV':\n",
    "            poscount['Adverb']+=1\n",
    "        elif g1[1]=='CD':\n",
    "            poscount['Numeral']+=1\n",
    "        elif g1[1]=='CC' or g1[1]=='IN':\n",
    "            poscount['Conjunction_inj']+=1\n",
    "        elif g1[1]=='RP':\n",
    "            poscount['Particle']+=1\n",
    "        elif g1[1]=='MD':\n",
    "            poscount['Modal']+=1\n",
    "        elif g1[1]=='DT':\n",
    "            poscount['Determiner']+=1\n",
    "        elif g1[1] in Whs:\n",
    "            poscount['Whs']+=1\n",
    "    return poscount\n",
    "\n",
    "def fetchRawText(path, events, tweetType):\n",
    "    jsons = []\n",
    "    for i, event in enumerate(events):\n",
    "        jsons.append(glob('%s/%s/**/%s/*.json' % (path, event,tweetType)))\n",
    "    for i,d in enumerate(jsons): print(\"%s's length is %d\" %(events[i], len(d)))\n",
    "\n",
    "    targets = []\n",
    "    features = []\n",
    "    for index, dataset in enumerate(jsons):\n",
    "        targetEvent = []\n",
    "        dataEvent = []\n",
    "        count = 0  # help var\n",
    "        for jsonFile in dataset:\n",
    "            count += 1\n",
    "            if jsonFile.find(\"non-rumours\") == -1:\n",
    "                targetEvent.append(1)\n",
    "            else:\n",
    "                targetEvent.append(0)\n",
    "\n",
    "            with open(jsonFile, 'r') as f:\n",
    "                for l in f.readlines():\n",
    "                    if not l.strip():  # skip empty lines\n",
    "                        continue\n",
    "                    try:\n",
    "                        json_data = json.loads(l)\n",
    "                    except:\n",
    "                        print (l,\"\\n\\n\")\n",
    "                        break\n",
    "                    dataEvent.append(json_data)\n",
    "        print(index, events[index], len(targetEvent), len(dataEvent))\n",
    "        targets.append(targetEvent)\n",
    "        features.append(dataEvent)\n",
    "\n",
    "    # print(\"\\nNumber of Events:\", len(targets))\n",
    "    # print(\"Number of tweets in the first event:\", len(targets[0]))\n",
    "\n",
    "    # targets은 targetEvent들을 리스트에 담은 것\n",
    "    target_list = []\n",
    "    for event in targets:\n",
    "        for elem in event:\n",
    "            target_list.append(elem)\n",
    "    target = pd.DataFrame(target_list, columns=[\"target\"])\n",
    "\n",
    "    extracted_features = []\n",
    "\n",
    "    extracted = []\n",
    "\n",
    "    for obj_list in features:\n",
    "        extracted_event = []\n",
    "        for obj in obj_list:\n",
    "            output_f = dict()\n",
    "            output_f['text'] = obj['text']\n",
    "            urls_dicts = obj['entities']['urls']\n",
    "            output_f['URLcount'] = extract_urls(urls_dicts)\n",
    "        \n",
    "            # print(type(obj['user']))\n",
    "            # print(obj['user'].contains_key('entities'))\n",
    "            # if ('url' in obj['user']):\n",
    "            #     output_f['hasUserURL'] = 1\n",
    "            #     output_f['user_url'] = 1 if (obj['user']['url'] != None) else 0\n",
    "            # elif ('entities' in obj['user']):\n",
    "            #     output_f['user_entity'] = obj['user']['entities']['url']['urls']\n",
    "            #     # print(obj['user']['entities']['url']['urls'])\n",
    "            #     output_f['user_url'] = obj['user']['entities']['expanded_url']\n",
    "            #     output_f['hasUserURL'] , _ , output_f['user_url'] = extract_urls(obj['user']['entities']['url']['urls'])\n",
    "            # else:\n",
    "            #     # output_f['user_entity'] = None\n",
    "            #     output_f['user_url'] = 0\n",
    "            #     output_f['hasUserURL'] = 0\n",
    "            \n",
    "\n",
    "            output_f['text_token'], output_f['URLcount'] = getTokenization(obj['text'])\n",
    "\n",
    "\n",
    "            '''POS Tagging and text cleansing for POS'''\n",
    "            temp = output_f['text']\n",
    "            temp=  emoji.demojize(temp)\n",
    "            temp = re.sub(r\"(#)(\\S+)\", r'\\1 \\2', temp)\n",
    "            temp = re.sub(r\"http\\S+\", \"\", temp)\n",
    "            temp = replaceContraction(temp.lower())\n",
    "            temp = temp.split()\n",
    "            pos_dict=getposcount(temp)\n",
    "            output_f.update(pos_dict)\n",
    "\n",
    "            output_f['emoji_count'] = emoji.emoji_count(obj['text'])\n",
    "\n",
    "\n",
    "            output_f['char_count'] = len(output_f['text'])\n",
    "            output_f['word_count'] = len(output_f['text'].split())\n",
    "\n",
    "            output_f['has_question'] = \"?\" in output_f[\"text\"]\n",
    "            output_f['has_exclaim'] = \"!\" in output_f[\"text\"]\n",
    "            output_f['has_period'] = \".\" in output_f[\"text\"]\n",
    "\n",
    "            output_f['capital_ratio']=(capitalratio(obj['text']))\n",
    "            output_f['retweet_count'] = obj['retweet_count']\n",
    "            output_f['tweet_count'] = np.log10(obj['user']['statuses_count'])\n",
    "            output_f['listed_count'] = np.log10(obj['user']['listed_count'])\n",
    "            output_f['friends_count'] = np.log10(obj['user']['friends_count'])\n",
    "            output_f['follow_ratio'] = np.log10(obj['user']['followers_count'])\n",
    "\n",
    "            acc_created = datetime.strptime(obj['user']['created_at'], '%a %b %d %H:%M:%S %z %Y')\n",
    "            tweet_created = datetime.strptime(obj['created_at'], '%a %b %d %H:%M:%S %z %Y')\n",
    "            age = (tweet_created - acc_created)\n",
    "            output_f['account_age_days'] = age.days\n",
    "            \n",
    "            output_f['capital_ratio']=(capitalratio(obj['text']))\n",
    "            output_f['verified'] = obj['user']['verified']\n",
    "\n",
    "            extracted_event.append(output_f)\n",
    "        extracted_features.append(extracted_event)\n",
    "\n",
    "    extracted_df = []\n",
    "    for i, data in enumerate(extracted_features):\n",
    "        temp = pd.DataFrame(data)\n",
    "        temp[\"Event\"] = events[i]\n",
    "        extracted_df.append(pd.DataFrame(temp))\n",
    "\n",
    "    final = pd.concat(extracted_df, ignore_index=True)\n",
    "    final = pd.concat([final, target], axis=1)\n",
    "    return final\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHEME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "charliehebdo's length is 2079\n",
      "ferguson's length is 1143\n",
      "germanwings-crash's length is 469\n",
      "ottawashooting's length is 890\n",
      "sydneysiege's length is 1221\n",
      "0 charliehebdo 2079 2079\n",
      "1 ferguson 1143 1143\n",
      "2 germanwings-crash 469 469\n",
      "3 ottawashooting 890 890\n",
      "4 sydneysiege 1221 1221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-03eea0864855>:228: RuntimeWarning: divide by zero encountered in log10\n",
      "  output_f['friends_count'] = np.log10(obj['user']['friends_count'])\n",
      "<ipython-input-4-03eea0864855>:227: RuntimeWarning: divide by zero encountered in log10\n",
      "  output_f['listed_count'] = np.log10(obj['user']['listed_count'])\n"
     ]
    }
   ],
   "source": [
    "path = \"../pheme-rnr-dataset\"\n",
    "events = ['charliehebdo', 'ferguson',\n",
    "          'germanwings-crash', 'ottawashooting', 'sydneysiege']\n",
    "tweetType = 'source-tweet'\n",
    "jsons = []\n",
    "final = fetchRawText(path, events, tweetType)\n",
    "target = final.target\n",
    "final.verified = final.verified.replace({True: 1, False: 0}) \n",
    "final.has_question = final.has_question.replace({True: 1, False: 0}) \n",
    "final.has_exclaim = final.has_exclaim.replace({True: 1, False: 0}) \n",
    "final.has_period = final.has_period.replace({True: 1, False: 0}) \n",
    "final = final.replace(-np.inf, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>URLcount</th>\n      <th>Noun</th>\n      <th>Verb</th>\n      <th>Adjective</th>\n      <th>Pronoun</th>\n      <th>FirstPersonPronoun</th>\n      <th>SecondPersonPronoun</th>\n      <th>ThirdPersonPronoun</th>\n      <th>Adverb</th>\n      <th>Numeral</th>\n      <th>Conjunction_inj</th>\n      <th>Particle</th>\n      <th>Determiner</th>\n      <th>Modal</th>\n      <th>Whs</th>\n      <th>HashTag</th>\n      <th>char_count</th>\n      <th>word_count</th>\n      <th>has_question</th>\n      <th>has_exclaim</th>\n      <th>has_period</th>\n      <th>capital_ratio</th>\n      <th>tweet_count</th>\n      <th>listed_count</th>\n      <th>friends_count</th>\n      <th>follow_ratio</th>\n      <th>verified</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>7</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>88</td>\n      <td>12</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.159091</td>\n      <td>4.803286</td>\n      <td>3.855943</td>\n      <td>2.788168</td>\n      <td>5.287349</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>53</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.037736</td>\n      <td>3.031812</td>\n      <td>2.146128</td>\n      <td>2.574031</td>\n      <td>3.672929</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>4</td>\n      <td>4</td>\n      <td>7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>136</td>\n      <td>18</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.073529</td>\n      <td>3.856245</td>\n      <td>2.879669</td>\n      <td>2.772322</td>\n      <td>4.309651</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>4</td>\n      <td>5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>138</td>\n      <td>16</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.101449</td>\n      <td>4.735814</td>\n      <td>5.009820</td>\n      <td>3.016197</td>\n      <td>7.187664</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>7</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>117</td>\n      <td>13</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.145299</td>\n      <td>5.021181</td>\n      <td>4.132996</td>\n      <td>2.662758</td>\n      <td>5.925434</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   URLcount  Noun  Verb  Adjective  Pronoun  FirstPersonPronoun  \\\n0         1     7     2          0        0                   0   \n1         0     3     2          0        0                   0   \n2         0     4     4          7        0                   0   \n3         2     4     5          1        0                   0   \n4         2     7     2          0        0                   0   \n\n   SecondPersonPronoun  ThirdPersonPronoun  Adverb  Numeral  Conjunction_inj  \\\n0                    0                   0       0        0                2   \n1                    0                   0       0        0                1   \n2                    0                   0       1        0                2   \n3                    0                   0       0        0                0   \n4                    0                   0       0        0                2   \n\n   Particle  Determiner  Modal  Whs  HashTag  char_count  word_count  \\\n0         0           0      0    0        0          88          12   \n1         0           0      0    0        1          53           6   \n2         0           0      0    0        2         136          18   \n3         0           2      0    1        1         138          16   \n4         0           0      0    0        1         117          13   \n\n   has_question  has_exclaim  has_period  capital_ratio  tweet_count  \\\n0             0            0           1       0.159091     4.803286   \n1             0            0           1       0.037736     3.031812   \n2             0            0           1       0.073529     3.856245   \n3             0            0           1       0.101449     4.735814   \n4             0            0           1       0.145299     5.021181   \n\n   listed_count  friends_count  follow_ratio  verified  \n0      3.855943       2.788168      5.287349         1  \n1      2.146128       2.574031      3.672929         0  \n2      2.879669       2.772322      4.309651         0  \n3      5.009820       3.016197      7.187664         1  \n4      4.132996       2.662758      5.925434         1  "
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.drop(['text_token','text','Event','target'], axis=1, inplace=True)\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv('./data/_PHEME_sparse.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHEME (Extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ebola-essien's length is 14\n",
      "prince-toronto's length is 233\n",
      "putinmissing's length is 238\n",
      "0 ebola-essien 14 14\n",
      "1 prince-toronto 233 233\n",
      "2 putinmissing 238 238\n"
     ]
    }
   ],
   "source": [
    "path = \"../PHEME/all-rnr-annotated-threads\"\n",
    "events = ['ebola-essien', 'prince-toronto', 'putinmissing']\n",
    "tweetType = 'source-tweets'\n",
    "jsons = []\n",
    "final_ext = fetchRawText(path,events,tweetType)\n",
    "ext_target = final_ext.target\n",
    "final_ext.verified = final_ext.verified.replace({True: 1, False: 0}) \n",
    "final_ext.has_question = final_ext.has_question.replace({True: 1, False: 0}) \n",
    "final_ext.has_exclaim = final_ext.has_exclaim.replace({True: 1, False: 0}) \n",
    "final_ext.has_period = final_ext.has_period.replace({True: 1, False: 0}) \n",
    "final_ext = final_ext.replace(-np.inf, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>URLcount</th>\n      <th>Noun</th>\n      <th>Verb</th>\n      <th>Adjective</th>\n      <th>Pronoun</th>\n      <th>FirstPersonPronoun</th>\n      <th>SecondPersonPronoun</th>\n      <th>ThirdPersonPronoun</th>\n      <th>Adverb</th>\n      <th>Numeral</th>\n      <th>Conjunction_inj</th>\n      <th>Particle</th>\n      <th>Determiner</th>\n      <th>Modal</th>\n      <th>Whs</th>\n      <th>emoji_count</th>\n      <th>char_count</th>\n      <th>word_count</th>\n      <th>has_question</th>\n      <th>has_exclaim</th>\n      <th>has_period</th>\n      <th>capital_ratio</th>\n      <th>retweet_count</th>\n      <th>tweet_count</th>\n      <th>listed_count</th>\n      <th>friends_count</th>\n      <th>follow_ratio</th>\n      <th>account_age_days</th>\n      <th>verified</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>69</td>\n      <td>8</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.10145</td>\n      <td>117</td>\n      <td>4.60934</td>\n      <td>2.17026</td>\n      <td>2.81425</td>\n      <td>4.33911</td>\n      <td>1570</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>9</td>\n      <td>6</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>148</td>\n      <td>25</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.02703</td>\n      <td>10402</td>\n      <td>2.70672</td>\n      <td>3.21032</td>\n      <td>2.24551</td>\n      <td>5.68886</td>\n      <td>579</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>7</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>119</td>\n      <td>20</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.02521</td>\n      <td>126</td>\n      <td>4.92029</td>\n      <td>3.33546</td>\n      <td>2.15836</td>\n      <td>5.36614</td>\n      <td>2042</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>5</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>130</td>\n      <td>16</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.10769</td>\n      <td>192</td>\n      <td>4.18887</td>\n      <td>2.78390</td>\n      <td>2.85491</td>\n      <td>4.86657</td>\n      <td>468</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>120</td>\n      <td>15</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.06667</td>\n      <td>196</td>\n      <td>4.92029</td>\n      <td>3.33546</td>\n      <td>2.15836</td>\n      <td>5.36614</td>\n      <td>2039</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   URLcount  Noun  Verb  Adjective  Pronoun  FirstPersonPronoun  \\\n0         1     2     2          1        0                   0   \n1         0     9     6          3        0                   2   \n2         0     7     4          1        1                   0   \n3         2     5     3          2        0                   0   \n4         1     4     4          2        0                   0   \n\n   SecondPersonPronoun  ThirdPersonPronoun  Adverb  Numeral  Conjunction_inj  \\\n0                    0                   0       0        0                1   \n1                    0                   0       3        0                4   \n2                    0                   1       0        0                2   \n3                    0                   0       0        0                1   \n4                    0                   0       1        0                2   \n\n   Particle  Determiner  Modal  Whs  emoji_count  char_count  word_count  \\\n0         0           1      0    0            0          69           8   \n1         0           1      1    0            0         148          25   \n2         0           3      0    1            0         119          20   \n3         0           2      0    0            0         130          16   \n4         0           1      0    0            0         120          15   \n\n   has_question  has_exclaim  has_period  capital_ratio  retweet_count  \\\n0             0            0           1        0.10145            117   \n1             0            0           1        0.02703          10402   \n2             0            0           1        0.02521            126   \n3             0            0           1        0.10769            192   \n4             0            0           1        0.06667            196   \n\n   tweet_count  listed_count  friends_count  follow_ratio  account_age_days  \\\n0      4.60934       2.17026        2.81425       4.33911              1570   \n1      2.70672       3.21032        2.24551       5.68886               579   \n2      4.92029       3.33546        2.15836       5.36614              2042   \n3      4.18887       2.78390        2.85491       4.86657               468   \n4      4.92029       3.33546        2.15836       5.36614              2039   \n\n   verified  \n0         0  \n1         1  \n2         0  \n3         1  \n4         0  "
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_ext.drop(['text_token','text','Event','target'], axis=1, inplace=True)\n",
    "final_ext.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ext.to_csv('./data/_PHEMEext_sparse.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHEME ALL (Reactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from glob2 import glob\n",
    "import json\n",
    "\n",
    "pd.options.display.float_format = '{:.5f}'.format\n",
    "\n",
    "def fetchRawText_all(path, events, tweetType):\n",
    "    jsons = []\n",
    "    for i, event in enumerate(events):\n",
    "        jsons.append(glob('%s/%s/**/%s/[0-9]*.json' % (path, event, tweetType)))\n",
    "    for i,d in enumerate(jsons): print(\"%s's length is %d\" %(events[i], len(d)))\n",
    "\n",
    "    targets = []\n",
    "    features = []\n",
    "    isSrcTweet = []\n",
    "    for index, dataset in enumerate(jsons):\n",
    "        targetEvent = []\n",
    "        dataEvent = []\n",
    "        count = 0  # help var\n",
    "        for jsonFile in dataset:\n",
    "            count += 1\n",
    "            if jsonFile.find(\"non-rumours\") == -1:\n",
    "                targetEvent.append(1)\n",
    "            else:\n",
    "                targetEvent.append(0)\n",
    "            if jsonFile.find(\"source-tweet\") == -1:\n",
    "                isSrcTweet.append(0)\n",
    "            else: #if jsonFile.find(\"reactions\") == 1:\n",
    "                isSrcTweet.append(1)\n",
    "                \n",
    "\n",
    "            with open(jsonFile, 'r') as f:\n",
    "                for l in f.readlines():\n",
    "                    if not l.strip():  # skip empty lines\n",
    "                        continue\n",
    "                    json_data = json.loads(l)\n",
    "                    dataEvent.append(json_data)\n",
    "        targets.append(targetEvent)\n",
    "        features.append(dataEvent)\n",
    "        # isSrcTweet.append(isSrcTweet)\n",
    "\n",
    "    # print(\"\\nNumber of Events:\", len(targets))\n",
    "    # print(\"Number of tweets in the first event:\", len(targets[0]))\n",
    "\n",
    "    # targets은 targetEvent들을 리스트에 담은 것\n",
    "    target_list = []\n",
    "    for event in targets:\n",
    "        for elem in event:\n",
    "            target_list.append(elem)\n",
    "    target = pd.DataFrame(target_list, columns=[\"target\"])\n",
    "    isSrcTweet = pd.DataFrame(isSrcTweet, columns=[\"isSrcTweet\"])\n",
    "\n",
    "    extracted_features = []\n",
    "\n",
    "    extracted = []\n",
    "\n",
    "    for obj_list in features:\n",
    "        extracted_event = []\n",
    "        for obj in obj_list:\n",
    "            output_f = dict()\n",
    "\n",
    "            if ('text' in obj):\n",
    "                output_f['text'] = obj['text']\n",
    "            else:\n",
    "                output_f['text'] = None\n",
    "            if ('id' in obj):\n",
    "                output_f['id'] = obj['id']\n",
    "            else:\n",
    "                output_f['id'] = None\n",
    "            if ('in_reply_to_status_id' in obj):\n",
    "                output_f['pid'] = obj['in_reply_to_status_id']\n",
    "            else: \n",
    "                output_f['pid'] = None\n",
    "       \n",
    "            \n",
    "            output_f['emoji_count'] = emoji.emoji_count(obj['text'])\n",
    "            urls_dicts = obj['entities']['urls']\n",
    "            if \"media\" in obj['entities']:\n",
    "                output_f['has_media'] = len(obj['entities']['media'])\n",
    "                # output_f['media_type'] = obj['entities']['media'][0]['type']\n",
    "            else:\n",
    "                output_f['has_media'] = 0\n",
    "                # output_f['media_type'] = 0\n",
    "            output_f['URLcount'] = len(urls_dicts)\n",
    "            # output_f['URLcount'] = extract_urls(urls_dicts)\n",
    "            # temp = obj['text'].lower()\n",
    "            temp = re.sub(r\"http\\S+\", \"HTTPURL\", obj['text'])\n",
    "\n",
    "            verification = 0\n",
    "            verification += len(re.findall(r'is(that|this|it) true', obj['text']))\n",
    "            verification += len(re.findall(r'wh[a]*t[?!|!?][?!|!?]*', obj['text']))\n",
    "            verification += len(re.findall(r'(rumour|rumor|debunk)', obj['text']))\n",
    "            verification += len(re.findall(r'(real?|really?|uncomfirmed)', obj['text']))\n",
    "            verification += len(re.findall(r'(that|this|it) is not true', obj['text']))\n",
    "            verification += len(re.findall(r'(that|this|it) is false', obj['text']))\n",
    "            verification += len(re.findall(r'(h[m]*)', obj['text']))\n",
    "            output_f['Skepticism'] = verification\n",
    "\n",
    "            url, mention = 0, 0\n",
    "            for token in temp:\n",
    "                if token.startswith('HTTPURL'):\n",
    "                # if token.startswith (r\"http\\S+\"):\n",
    "                    url+=1\n",
    "                if token.startswith('@'):\n",
    "                    mention+=1 \n",
    "            # output_f['URLcount'] = url\n",
    "            output_f['MentionCount'] = mention\n",
    "\n",
    "            '''POS Tagging'''\n",
    "            temp = output_f['text']\n",
    "            temp = replaceContraction(temp.lower())\n",
    "            temp = re.sub(r\"(#)(\\S+)\", '', temp)\n",
    "            temp = re.sub(r\"(@)(\\S+)\", '', temp)\n",
    "            temp = re.sub(r\"http\\S+\", \"\", temp)\n",
    "            temp = re.sub(r'([^\\s\\w#\\*]|_)+', '', temp) # Erasing Special Characters\n",
    "\n",
    "            temp = temp.split()\n",
    "            pos_dict=getposcount(temp)\n",
    "            output_f['token_for_POS'] = temp\n",
    "            output_f.update(pos_dict)\n",
    "\n",
    "            output_f['char_count'] = len(output_f['text'])\n",
    "            output_f['word_count'] = len(output_f['text'].split())\n",
    "\n",
    "            # output_f['HashTag'] = len(obj['entities'][0]['hashtags'])\n",
    "            output_f['HashTag'] = len(obj['entities']['hashtags'])\n",
    "            \n",
    "            output_f['has_question'] = \"?\" in output_f[\"text\"]\n",
    "            output_f['has_exclaim'] = \"!\" in output_f[\"text\"]\n",
    "            output_f['has_period'] = \".\" in output_f[\"text\"]\n",
    "\n",
    "            output_f['retweet_count'] = obj['retweet_count']\n",
    "            output_f['isRT'] = obj['retweeted']\n",
    "\n",
    "            output_f['tweet_count'] = np.log10(obj['user']['statuses_count'])\n",
    "            output_f['listed_count'] = np.log10(obj['user']['listed_count'])\n",
    "            output_f['friends_count'] = np.log10(obj['user']['friends_count'])\n",
    "            output_f['follow_ratio'] = np.log10(obj['user']['followers_count'])\n",
    "            \n",
    "            acc_created = datetime.strptime(obj['user']['created_at'], '%a %b %d %H:%M:%S %z %Y')\n",
    "            tweet_created = datetime.strptime(obj['created_at'], '%a %b %d %H:%M:%S %z %Y')\n",
    "            age = (tweet_created - acc_created)\n",
    "            output_f['account_age_days'] = age.days\n",
    "            output_f['tweet_created'] = datetime.timestamp(tweet_created)\n",
    "            # output_f['tweet_created2'] = tweet_created\n",
    "            \n",
    "\n",
    "\n",
    "            output_f['capital_ratio']=(capitalratio(obj['text']))\n",
    "            output_f['verified'] = obj['user']['verified']\n",
    "\n",
    "            extracted_event.append(output_f)\n",
    "        extracted_features.append(extracted_event)\n",
    "\n",
    "    extracted_df = []\n",
    "    # print(events)\n",
    "    # print(len(extracted_features))\n",
    "    for i, data in enumerate(extracted_features):\n",
    "        temp = pd.DataFrame(data)\n",
    "        temp[\"Event\"] = events[i]\n",
    "        extracted_df.append(pd.DataFrame(temp))\n",
    "\n",
    "    final = pd.concat(extracted_df, ignore_index=True)\n",
    "    final = pd.concat([final, isSrcTweet ,target], axis=1)\n",
    "    final.pid = final.pid\n",
    "    return final\n",
    "\n",
    "def depth(x):\n",
    "    if type(x) is dict and x:\n",
    "        return 1 + max(depth(x[a]) for a in x)\n",
    "    if type(x) is list and x:\n",
    "        return 1 + max(depth(a) for a in x)\n",
    "    return 0\n",
    "\n",
    "def getThreadData(path, events):\n",
    "    import re\n",
    "\n",
    "    sources = []\n",
    "    for i, event in enumerate(events):\n",
    "        sources.append(glob('%s/%s/*/*' % (path, event)))\n",
    "    roots = []\n",
    "    children = []\n",
    "    features = []\n",
    "    isSrcTweet = []\n",
    "    for num, event in enumerate(sources):\n",
    "        for index, dataset in enumerate(event):\n",
    "            # print(dataset)\n",
    "            # children.append(glob('%s/reactions/*/*' % (dataset)))\n",
    "            childs = [os.path.basename(x) for x in glob('%s/reactions/*.json' % (dataset))]\n",
    "            reext = re.compile(r'(.*?)\\.json')\n",
    "            childs = (reext.match(child) for child in childs)\n",
    "            children.append([match.group(1) for match in childs if match])\n",
    "            # print(dataset)\n",
    "            roots.append(os.path.basename(dataset))\n",
    "\n",
    "    df = pd.DataFrame(roots, columns=['Root'])\n",
    "    df = pd.concat([df,pd.DataFrame(children)],axis=1)\n",
    "    \n",
    "    structfile = []\n",
    "    for i, event in enumerate(events):\n",
    "        structfile.append(glob('%s/%s/**/[0-9]*/structure.json' % (path, event)))\n",
    "\n",
    "    for i,d in enumerate(structfile): print(\"%s's structure.json number is %d\" %(events[i], len(d)))\n",
    "    # print(structfile)\n",
    "\n",
    "    thread_depths = []\n",
    "    thread_roots = []\n",
    "    for index, dataset in enumerate(structfile):\n",
    "        targetEvent = []\n",
    "        dataEvent = []\n",
    "        count = 0  # help var\n",
    "        for jsonFile in dataset:\n",
    "            # print(jsonFile)\n",
    "            match = re.search(\"/([0-9]*)/\", jsonFile)\n",
    "            # p.match(\"lalalaI want this partlalala\").group(1)\n",
    "            rootname = match.group(1) if match else None\n",
    "            # print(rootname)\n",
    "            with open(jsonFile, 'r') as f:\n",
    "                for l in f.readlines():\n",
    "                    if not l.strip():  # skip empty lines\n",
    "                        continue\n",
    "                json_data = json.loads(l)\n",
    "                # print(json_data)\n",
    "                thread_depth = depth(json_data)\n",
    "                thread_depths.append([rootname,thread_depth])\n",
    "                # thread_roots.append(rootname)\n",
    "    df_depth = pd.DataFrame(thread_depths, columns=['Root', 'depth'])\n",
    "    df = pd.merge(df, df_depth, on=\"Root\")\n",
    "                \n",
    "    \n",
    "    # return pd.DataFrame(thread_depths)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def getThreadInfo(structure, df):\n",
    "    threadInfo = []\n",
    "    thread_depth = structure[['Root', 'depth']]\n",
    "    structure = structure.drop('depth', axis=1)\n",
    "    for index, data in enumerate(structure.Root):\n",
    "        tweetInfo = []\n",
    "        # print(\"data: %s\\n\" %(data))\n",
    "        # print(\"data: %s\\n%s\\n\" %(data, structure.loc[index,0:].values))\n",
    "        # print(\"root: %s\\tFirst reaction: %s\\n\" %(data, structure.loc[index,0]))\n",
    "\n",
    "        \n",
    "        pid = int(data)\n",
    "        thread = structure.loc[structure['Root']==pid].dropna(axis=1)\n",
    "        # threadRange = structure.loc[structure['Root']==data].any().sum()-1\n",
    "        # print(structure)\n",
    "        threadRange = len(structure.iloc[index,:].dropna())\n",
    "\n",
    "        # 아래로는 성공적인 Features\n",
    "        friends_count = np.sum([np.sum(df.loc[(df['id'] == int(childid))]['friends_count'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        friends_countavg = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['friends_count'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        words_count = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['word_count'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        char_count = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['char_count'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        hashtagavg = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['HashTag'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        hashtagsum = np.sum([np.sum(df.loc[(df['id'] == int(childid))]['HashTag'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        hashtagpercentage = np.sum([np.any(df.loc[(df['id'] == int(childid))]['HashTag']) for childid in structure.loc[index,:].dropna()])/threadRange\n",
    "        urlavg = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['URLcount'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        urlstd = np.std([np.sum(df.loc[(df['id'] == int(childid))]['URLcount'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        urlratio = np.mean([np.any(df.loc[(df['id'] == int(childid))]['URLcount'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        mentionsum = np.sum([np.sum(df.loc[(df['id'] == int(childid))]['MentionCount'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        mentionavg = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['MentionCount'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        mentionpercentage = np.sum([np.any(df.loc[(df['id'] == int(childid))]['MentionCount'].values) for childid in structure.loc[index,:].dropna()])/threadRange\n",
    "        verifiedratio = np.mean([np.any(df.loc[(df['id'] == int(childid))]['verified'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        verifiedsum = np.sum([np.sum(df.loc[(df['id'] == int(childid))]['verified'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        retweetsum = np.sum([np.sum(df.loc[(df['id'] == int(childid))]['retweet_count'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        retweetavg = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['retweet_count'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        retweetstd = np.std([np.sum(df.loc[(df['id'] == int(childid))]['retweet_count'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        accageavg = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['account_age_days'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        accagestd = np.std([np.sum(df.loc[(df['id'] == int(childid))]['account_age_days'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        emojistd = np.std([np.sum(df.loc[(df['id'] == int(childid))]['emoji_count'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        emojimean = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['emoji_count'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        mediaratio = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['has_media'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        questionratio = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['has_question'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        exclamationratio = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['has_exclaim'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        periodratio = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['has_period'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        FPPmean = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['FirstPersonPronoun'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        FPPstd = np.std([np.sum(df.loc[(df['id'] == int(childid))]['FirstPersonPronoun'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        SPPmean = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['SecondPersonPronoun'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        SPPstd = np.std([np.sum(df.loc[(df['id'] == int(childid))]['SecondPersonPronoun'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        TPPmean = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['ThirdPersonPronoun'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        TPPstd = np.std([np.sum(df.loc[(df['id'] == int(childid))]['ThirdPersonPronoun'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        Skepticismmean = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['Skepticism'].values) for childid in structure.loc[index,:].dropna()])\n",
    "# FirstPersonPronoun\tSecondPersonPronoun\tThirdPersonPronoun\n",
    "\n",
    "        # Get the lifetime of thread\n",
    "        # root_created = df.loc[(df['id'] == int(pid))].tweet_created.sum()\n",
    "        # try:\n",
    "        #     thread_latest = np.max([np.sum(df.loc[(df['id'] == childid)]['tweet_created'].values) for childid in structure.loc[index,'0':].dropna()])\n",
    "        # except:\n",
    "        # #     print([df.loc[(df['id'] == int(childid))]['tweet_created'].values for childid in structure.loc[index,'0':].dropna()])\n",
    "        #     print(\"error\")\n",
    "\n",
    "        # thread_life = thread_latest - root_created\n",
    "        try:\n",
    "            thread_life = np.max([np.sum(df.loc[(df['id'] == childid)]['tweet_created']) for childid in structure.loc[index,:].dropna()] - df.loc[(df['id'] == pid)].tweet_created.sum())\n",
    "        except:\n",
    "            print(\"index:\", index)\n",
    "\n",
    "        # 해당 스레드의 트윗 개수\n",
    "        thread_node_count = len([childid for childid in structure.loc[index,:].dropna()]) \n",
    "        # print(\"thread_node_count:\",thread_node_count,\", threadRange:\",threadRange, \"lastest Thread:\", thread_latest )\n",
    "        # print(structure.loc[structure.Root == data])\n",
    "\n",
    "        tweetInfo.append(data)\n",
    "        tweetInfo.append(friends_count)\n",
    "        tweetInfo.append(friends_countavg)\n",
    "        tweetInfo.append(words_count)\n",
    "        tweetInfo.append(char_count)\n",
    "        tweetInfo.append(hashtagavg)\n",
    "        tweetInfo.append(hashtagsum)\n",
    "        tweetInfo.append(hashtagpercentage)\n",
    "        tweetInfo.append(urlavg)\n",
    "        tweetInfo.append(urlstd)\n",
    "        tweetInfo.append(urlratio)\n",
    "        tweetInfo.append(mentionsum)\n",
    "        tweetInfo.append(mentionavg)\n",
    "        tweetInfo.append(mentionpercentage)\n",
    "        tweetInfo.append(thread_node_count)\n",
    "        tweetInfo.append(verifiedratio)\n",
    "        tweetInfo.append(verifiedsum)\n",
    "        tweetInfo.append(retweetsum)\n",
    "        tweetInfo.append(retweetavg)\n",
    "        tweetInfo.append(retweetstd)\n",
    "        tweetInfo.append(accageavg)\n",
    "        tweetInfo.append(accagestd)\n",
    "        tweetInfo.append(thread_life)\n",
    "        tweetInfo.append(emojistd)\n",
    "        tweetInfo.append(emojimean)\n",
    "        tweetInfo.append(mediaratio)\n",
    "        tweetInfo.append(questionratio)\n",
    "        tweetInfo.append(exclamationratio)\n",
    "        tweetInfo.append(periodratio)\n",
    "        tweetInfo.append(FPPmean)\n",
    "        tweetInfo.append(FPPstd)\n",
    "        tweetInfo.append(SPPmean)\n",
    "        tweetInfo.append(SPPstd)\n",
    "        tweetInfo.append(TPPmean)\n",
    "        tweetInfo.append(TPPstd)\n",
    "        tweetInfo.append(Skepticismmean)\n",
    "\n",
    "        threadInfo.append(tweetInfo)\n",
    "\n",
    "        result = pd.DataFrame(threadInfo, columns=['Root', 'SUM FriendsCount','AVG FriendsCount', 'AVG WordCount', 'AVG CharCount', 'AVG HashTag', 'SUM HashTag', 'Ratio HashTag', 'AVG Url','STD Url','RATIO Url','SUM Mention', 'AVG Mention', 'Ratio Mention', 'Tweets Count', 'Ratio Verified','SUM Verified','SUM RT', 'AVG RT','STD RT', 'AVG AccAge', 'STD AccAge', 'thread_time', \"STD Emoji\",\"AVG Emoji\",\"Ratio Media\",'RATIO Question', 'RATIO Exclaim','RATIO Period', 'AVG FPP','STD FPP','AVG SPP','STD SPP','AVG TPP','STD TPP','AVG Skepticism'])\n",
    "        # result = pd.merge(thread_depth, result, on=\"Root\").drop(['Root'], axis=1)\n",
    "    # print(threadInfo)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'structure_ext' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-adb077c51d3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure_ext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'structure_ext' is not defined"
     ]
    }
   ],
   "source": [
    "len(structure_ext.loc[0,'0':].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": "3"
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threadRange = len(structure_ext.loc[9,'0':].dropna())\n",
    "print(threadRange)\n",
    "print(np.sum([np.sum(all_ext.loc[(all_ext['id'] == int(childid))]['HashTag'].values) for childid in structure_ext.loc[9,'0':].dropna()]))\n",
    "np.sum([np.any(all_ext.loc[(all_ext['id'] == int(childid))]['HashTag'].values) for childid in structure_ext.loc[9,'0':].dropna()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PHEME ALL Create\n",
    "\n",
    "420120 Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pheme_all.shape)\n",
    "# pheme_all.loc[pheme_all['Event']=='charliehebdo'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ottawashooting's length is 12284\n"
     ]
    }
   ],
   "source": [
    "path = \"../pheme-rnr-dataset\"\n",
    "# events = ['charliehebdo', 'ferguson',\n",
    "#           'germanwings-crash', 'ottawashooting', 'sydneysiege']\n",
    "events = ['ottawashooting']\n",
    "# events = [ 'sydneysiege']\n",
    "\n",
    "tweetType = '*'\n",
    "final = fetchRawText_all(path, events, tweetType)\n",
    "final.verified = final.verified.replace({True: 1, False: 0}) \n",
    "final.has_question = final.has_question.replace({True: 1, False: 0}) \n",
    "final.has_exclaim = final.has_exclaim.replace({True: 1, False: 0}) \n",
    "final.has_period = final.has_period.replace({True: 1, False: 0}) \n",
    "final = final.replace(-np.inf, 0)\n",
    "\n",
    "pheme_all = final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheme_all.to_csv('./data/all/_PHEMEall.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ottawashooting's structure.json number is 0\n"
     ]
    }
   ],
   "source": [
    "pheme_structure = getThreadData(path, events)\n",
    "pheme_structure.to_csv('./data/all/_PHEME_structure.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PHEME ALL Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125208, 34)\n",
      "(5802, 346)\n"
     ]
    }
   ],
   "source": [
    "all_pheme = pd.read_csv(\"./data/all/_PHEMEall.csv\")\n",
    "structure_pheme = pd.read_csv(\"./data/all/_PHEME_structure.csv\")\n",
    "print(all_pheme.shape)\n",
    "print(structure_pheme.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'structure_pheme' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-581-5ee696568091>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpheme_thread\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetThreadInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure_pheme\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_pheme\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpheme_thread\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpheme_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpheme_thread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'structure_pheme' is not defined"
     ]
    }
   ],
   "source": [
    "pheme_thread = getThreadInfo(structure_pheme, all_pheme)\n",
    "pheme_thread = pheme_thread.fillna(0)\n",
    "pheme_thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheme_thread.to_csv('./data/all/_PHEME_thread.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "photo    942\nName: media_type, dtype: int64"
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pheme_all.loc[(pheme_all['media_type'] != 0)]['media_type'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PHEMEext Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ebola-essien's length is 226\n",
      "prince-toronto's length is 902\n",
      "putinmissing's length is 835\n",
      "(1963, 42)\n"
     ]
    },
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>id</th>\n      <th>pid</th>\n      <th>emoji_count</th>\n      <th>has_media</th>\n      <th>URLcount</th>\n      <th>Skepticism</th>\n      <th>MentionCount</th>\n      <th>token_for_POS</th>\n      <th>Noun</th>\n      <th>Verb</th>\n      <th>Adjective</th>\n      <th>Pronoun</th>\n      <th>FirstPersonPronoun</th>\n      <th>SecondPersonPronoun</th>\n      <th>ThirdPersonPronoun</th>\n      <th>Adverb</th>\n      <th>Numeral</th>\n      <th>Conjunction_inj</th>\n      <th>Particle</th>\n      <th>Determiner</th>\n      <th>Modal</th>\n      <th>Whs</th>\n      <th>char_count</th>\n      <th>word_count</th>\n      <th>HashTag</th>\n      <th>has_question</th>\n      <th>has_exclaim</th>\n      <th>has_period</th>\n      <th>retweet_count</th>\n      <th>isRT</th>\n      <th>tweet_count</th>\n      <th>listed_count</th>\n      <th>friends_count</th>\n      <th>follow_ratio</th>\n      <th>account_age_days</th>\n      <th>tweet_created</th>\n      <th>capital_ratio</th>\n      <th>verified</th>\n      <th>Event</th>\n      <th>isSrcTweet</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>@Mourinholic 😕😕 http://t.co/sFoV1v8uDo</td>\n      <td>521410632953131008</td>\n      <td>521369179392581632.00000</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>38</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4.89226</td>\n      <td>1.20412</td>\n      <td>3.13799</td>\n      <td>3.56062</td>\n      <td>1569</td>\n      <td>1413148956.00000</td>\n      <td>0.10526</td>\n      <td>0</td>\n      <td>ebola-essien</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>“@Mourinholic: Micheal Essien denying the Ebola rumours like https://t.co/8Yo8iLgISS”</td>\n      <td>521373142347153409</td>\n      <td>521369179392581632.00000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>5</td>\n      <td>1</td>\n      <td>[micheal, essien, denying, the, ebola, rumours, like]</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>85</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3.58827</td>\n      <td>0.90309</td>\n      <td>3.10072</td>\n      <td>3.10653</td>\n      <td>242</td>\n      <td>1413140018.00000</td>\n      <td>0.10588</td>\n      <td>0</td>\n      <td>ebola-essien</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@Mourinholic Hmmm.</td>\n      <td>521369380249432064</td>\n      <td>521369179392581632.00000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>[hmmm]</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>18</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4.52289</td>\n      <td>1.17609</td>\n      <td>1.89209</td>\n      <td>3.14426</td>\n      <td>653</td>\n      <td>1413139121.00000</td>\n      <td>0.11111</td>\n      <td>0</td>\n      <td>ebola-essien</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>@Mourinholic Even though it was against us, it was a bloody amazing goal.</td>\n      <td>521370496928337920</td>\n      <td>521369179392581632.00000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>[even, though, it, was, against, us, it, was, a, bloody, amazing, goal]</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>73</td>\n      <td>13</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.96755</td>\n      <td>0.00000</td>\n      <td>2.35025</td>\n      <td>1.75587</td>\n      <td>1762</td>\n      <td>1413139387.00000</td>\n      <td>0.02740</td>\n      <td>0</td>\n      <td>ebola-essien</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>@CdtChoco1er thanks bro.</td>\n      <td>521370224256614400</td>\n      <td>521370061550809088.00000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>[thanks, bro]</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>24</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4.62381</td>\n      <td>2.20140</td>\n      <td>2.82607</td>\n      <td>4.35601</td>\n      <td>1570</td>\n      <td>1413139322.00000</td>\n      <td>0.08333</td>\n      <td>0</td>\n      <td>ebola-essien</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                                                                    text  \\\n0                                                 @Mourinholic 😕😕 http://t.co/sFoV1v8uDo   \n1  “@Mourinholic: Micheal Essien denying the Ebola rumours like https://t.co/8Yo8iLgISS”   \n2                                                                     @Mourinholic Hmmm.   \n3              @Mourinholic Even though it was against us, it was a bloody amazing goal.   \n4                                                               @CdtChoco1er thanks bro.   \n\n                   id                      pid  emoji_count  has_media  \\\n0  521410632953131008 521369179392581632.00000            2          1   \n1  521373142347153409 521369179392581632.00000            0          0   \n2  521369380249432064 521369179392581632.00000            0          0   \n3  521370496928337920 521369179392581632.00000            0          0   \n4  521370224256614400 521370061550809088.00000            0          0   \n\n   URLcount  Skepticism  MentionCount  \\\n0         0           2             1   \n1         1           5             1   \n2         0           1             1   \n3         0           3             1   \n4         0           2             1   \n\n                                                             token_for_POS  \\\n0                                                                       []   \n1                    [micheal, essien, denying, the, ebola, rumours, like]   \n2                                                                   [hmmm]   \n3  [even, though, it, was, against, us, it, was, a, bloody, amazing, goal]   \n4                                                            [thanks, bro]   \n\n   Noun  Verb  Adjective  Pronoun  FirstPersonPronoun  SecondPersonPronoun  \\\n0     0     0          0        0                   0                    0   \n1     2     2          1        0                   0                    0   \n2     1     0          0        0                   0                    0   \n3     1     2          2        3                   1                    0   \n4     1     1          0        0                   0                    0   \n\n   ThirdPersonPronoun  Adverb  Numeral  Conjunction_inj  Particle  Determiner  \\\n0                   0       0        0                0         0           0   \n1                   0       0        0                1         0           1   \n2                   0       0        0                0         0           0   \n3                   2       1        0                2         0           1   \n4                   0       0        0                0         0           0   \n\n   Modal  Whs  char_count  word_count  HashTag  has_question  has_exclaim  \\\n0      0    0          38           3        0             0            0   \n1      0    0          85           9        0             0            0   \n2      0    0          18           2        0             0            0   \n3      0    0          73          13        0             0            0   \n4      0    0          24           3        0             0            0   \n\n   has_period  retweet_count isRT  tweet_count  listed_count  friends_count  \\\n0           1              0    0      4.89226       1.20412        3.13799   \n1           1              0    0      3.58827       0.90309        3.10072   \n2           1              0    0      4.52289       1.17609        1.89209   \n3           1              0    0      2.96755       0.00000        2.35025   \n4           1              0    0      4.62381       2.20140        2.82607   \n\n   follow_ratio  account_age_days    tweet_created  capital_ratio  verified  \\\n0       3.56062              1569 1413148956.00000        0.10526         0   \n1       3.10653               242 1413140018.00000        0.10588         0   \n2       3.14426               653 1413139121.00000        0.11111         0   \n3       1.75587              1762 1413139387.00000        0.02740         0   \n4       4.35601              1570 1413139322.00000        0.08333         0   \n\n          Event  isSrcTweet  target  \n0  ebola-essien           0       1  \n1  ebola-essien           0       1  \n2  ebola-essien           0       1  \n3  ebola-essien           0       1  \n4  ebola-essien           0       1  "
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../PHEME/all-rnr-annotated-threads\"\n",
    "events = ['ebola-essien', 'prince-toronto', 'putinmissing']\n",
    "# events = ['ebola-essien']\n",
    "tweetType = '*'\n",
    "\n",
    "all_ext = fetchRawText_all(path, events, tweetType)\n",
    "all_ext.isRT = all_ext.isRT.replace({True: 1, False: 0}) \n",
    "all_ext.verified = all_ext.verified.replace({True: 1, False: 0}) \n",
    "all_ext.has_question = all_ext.has_question.replace({True: 1, False: 0}) \n",
    "all_ext.has_exclaim = all_ext.has_exclaim.replace({True: 1, False: 0}) \n",
    "all_ext.has_period = all_ext.has_period.replace({True: 1, False: 0}) \n",
    "all_ext = all_ext.replace(-np.inf, 0)\n",
    "\n",
    "print(all_ext.shape)\n",
    "all_ext.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ext.to_csv('./data/all/_PHEMEextall.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ebola-essien's structure.json number is 14\n",
      "prince-toronto's structure.json number is 233\n",
      "putinmissing's structure.json number is 238\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# ext_structure = getThreadData(path, events)\n",
    "structure_ext = getThreadData(path, events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure_ext.to_csv('./data/all/_PHEMEext_structure.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PHEME EXT PROCESS\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1963, 43)\n",
      "(485, 28)\n"
     ]
    }
   ],
   "source": [
    "all_ext = pd.read_csv(\"./data/all/_PHEMEextall.csv\")\n",
    "structure_ext = pd.read_csv(\"./data/all/_PHEMEext_structure.csv\")\n",
    "ext_y = pd.read_csv('./data/_PHEMEext_target.csv')\n",
    "print(all_ext.shape)\n",
    "print(structure_ext.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 👇 Thread 정보만을 추출한 결과\n",
    "아래의 Features들은 모두 한 Root 트윗에 달린 Thread의 정보를 포함한다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUM FriendsCount\tAVG FriendsCount 들이 -inf 값 포함\n",
    "ext_thread = getThreadInfo(structure_ext, all_ext)\n",
    "# ext_thread = ext_thread.replace(-np.inf, 0)\n",
    "ext_thread = ext_thread.fillna(0)\n",
    "ext_thread = ext_thread.replace(-np.inf, 0)\n",
    "ext_thread.head(15)\n",
    "ext_thread.to_csv('./data/_PHEMEext_thread.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Root</th>\n      <th>SUM FriendsCount</th>\n      <th>AVG FriendsCount</th>\n      <th>AVG WordCount</th>\n      <th>AVG CharCount</th>\n      <th>AVG HashTag</th>\n      <th>SUM HashTag</th>\n      <th>Ratio HashTag</th>\n      <th>AVG Url</th>\n      <th>STD Url</th>\n      <th>RATIO Url</th>\n      <th>SUM Mention</th>\n      <th>AVG Mention</th>\n      <th>Ratio Mention</th>\n      <th>Tweets Count</th>\n      <th>Ratio Verified</th>\n      <th>SUM Verified</th>\n      <th>SUM RT</th>\n      <th>AVG RT</th>\n      <th>STD RT</th>\n      <th>AVG AccAge</th>\n      <th>STD AccAge</th>\n      <th>thread_time</th>\n      <th>STD Emoji</th>\n      <th>AVG Emoji</th>\n      <th>Ratio Media</th>\n      <th>RATIO Question</th>\n      <th>RATIO Exclaim</th>\n      <th>RATIO Period</th>\n      <th>AVG FPP</th>\n      <th>STD FPP</th>\n      <th>AVG SPP</th>\n      <th>STD SPP</th>\n      <th>AVG TPP</th>\n      <th>STD TPP</th>\n      <th>AVG Skepticism</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>552503400071557312.00000</td>\n      <td>7.61952</td>\n      <td>1.91587</td>\n      <td>10.01375</td>\n      <td>69.41844</td>\n      <td>0.59794</td>\n      <td>1.25361</td>\n      <td>0.29762</td>\n      <td>0.22614</td>\n      <td>0.10124</td>\n      <td>0.22078</td>\n      <td>3.59381</td>\n      <td>0.60497</td>\n      <td>0.40513</td>\n      <td>4.04742</td>\n      <td>0.06684</td>\n      <td>0.15258</td>\n      <td>40.95258</td>\n      <td>4.41943</td>\n      <td>9.69219</td>\n      <td>986.42153</td>\n      <td>370.60815</td>\n      <td>15581.70722</td>\n      <td>0.06312</td>\n      <td>0.03985</td>\n      <td>0.13214</td>\n      <td>0.15139</td>\n      <td>0.10150</td>\n      <td>0.52345</td>\n      <td>0.18014</td>\n      <td>0.19884</td>\n      <td>0.06492</td>\n      <td>0.06322</td>\n      <td>0.24703</td>\n      <td>0.20441</td>\n      <td>2.26836</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>23774883756088644.00000</td>\n      <td>9.62440</td>\n      <td>1.05029</td>\n      <td>6.36584</td>\n      <td>42.83633</td>\n      <td>0.96245</td>\n      <td>1.75798</td>\n      <td>0.39206</td>\n      <td>0.37453</td>\n      <td>0.18859</td>\n      <td>0.35968</td>\n      <td>6.05126</td>\n      <td>0.66793</td>\n      <td>0.35595</td>\n      <td>4.83785</td>\n      <td>0.21699</td>\n      <td>0.38759</td>\n      <td>482.16712</td>\n      <td>25.62266</td>\n      <td>107.48288</td>\n      <td>709.21957</td>\n      <td>392.53652</td>\n      <td>51235.86482</td>\n      <td>0.25042</td>\n      <td>0.20250</td>\n      <td>0.29372</td>\n      <td>0.28140</td>\n      <td>0.21562</td>\n      <td>0.38458</td>\n      <td>0.33362</td>\n      <td>0.35683</td>\n      <td>0.22990</td>\n      <td>0.16169</td>\n      <td>0.40823</td>\n      <td>0.32968</td>\n      <td>1.75281</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>521310417696858112.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>529697032659673088.00000</td>\n      <td>2.48855</td>\n      <td>1.31377</td>\n      <td>5.50000</td>\n      <td>39.40000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>475.66667</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.16667</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>529778109290012672.00000</td>\n      <td>3.79844</td>\n      <td>2.07485</td>\n      <td>10.00000</td>\n      <td>69.53333</td>\n      <td>0.04167</td>\n      <td>1.00000</td>\n      <td>0.04167</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0.50000</td>\n      <td>0.50000</td>\n      <td>2.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>3.00000</td>\n      <td>2.00000</td>\n      <td>0.00000</td>\n      <td>938.46154</td>\n      <td>209.00000</td>\n      <td>561.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.50000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>2.00000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>576641067317096448.00000</td>\n      <td>9.19258</td>\n      <td>2.70672</td>\n      <td>15.00000</td>\n      <td>104.00000</td>\n      <td>1.00000</td>\n      <td>2.00000</td>\n      <td>0.50000</td>\n      <td>0.33333</td>\n      <td>0.00000</td>\n      <td>0.33333</td>\n      <td>4.00000</td>\n      <td>1.00000</td>\n      <td>0.66667</td>\n      <td>5.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>8.00000</td>\n      <td>4.00000</td>\n      <td>2.49444</td>\n      <td>1443.00000</td>\n      <td>726.71193</td>\n      <td>6964.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.05556</td>\n      <td>0.16667</td>\n      <td>0.11111</td>\n      <td>1.00000</td>\n      <td>0.25000</td>\n      <td>0.40000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.40000</td>\n      <td>0.43301</td>\n      <td>3.00000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>577342598592901120.00000</td>\n      <td>57.40306</td>\n      <td>4.38684</td>\n      <td>29.00000</td>\n      <td>143.00000</td>\n      <td>6.00000</td>\n      <td>12.00000</td>\n      <td>1.00000</td>\n      <td>2.00000</td>\n      <td>0.94281</td>\n      <td>1.00000</td>\n      <td>38.00000</td>\n      <td>6.50000</td>\n      <td>1.00000</td>\n      <td>27.00000</td>\n      <td>1.00000</td>\n      <td>3.00000</td>\n      <td>10415.00000</td>\n      <td>548.15789</td>\n      <td>2322.57324</td>\n      <td>3021.00000</td>\n      <td>1432.00000</td>\n      <td>753999.00000</td>\n      <td>2.76385</td>\n      <td>3.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>2.00000</td>\n      <td>2.00000</td>\n      <td>2.00000</td>\n      <td>1.00000</td>\n      <td>2.00000</td>\n      <td>2.00000</td>\n      <td>9.00000</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                          Root  SUM FriendsCount  AVG FriendsCount  \\\ncount                485.00000         485.00000         485.00000   \nmean  552503400071557312.00000           7.61952           1.91587   \nstd    23774883756088644.00000           9.62440           1.05029   \nmin   521310417696858112.00000           0.00000           0.00000   \n25%   529697032659673088.00000           2.48855           1.31377   \n50%   529778109290012672.00000           3.79844           2.07485   \n75%   576641067317096448.00000           9.19258           2.70672   \nmax   577342598592901120.00000          57.40306           4.38684   \n\n       AVG WordCount  AVG CharCount  AVG HashTag  SUM HashTag  Ratio HashTag  \\\ncount      485.00000      485.00000    485.00000    485.00000      485.00000   \nmean        10.01375       69.41844      0.59794      1.25361        0.29762   \nstd          6.36584       42.83633      0.96245      1.75798        0.39206   \nmin          0.00000        0.00000      0.00000      0.00000        0.00000   \n25%          5.50000       39.40000      0.00000      0.00000        0.00000   \n50%         10.00000       69.53333      0.04167      1.00000        0.04167   \n75%         15.00000      104.00000      1.00000      2.00000        0.50000   \nmax         29.00000      143.00000      6.00000     12.00000        1.00000   \n\n        AVG Url   STD Url  RATIO Url  SUM Mention  AVG Mention  Ratio Mention  \\\ncount 485.00000 485.00000  485.00000    485.00000    485.00000      485.00000   \nmean    0.22614   0.10124    0.22078      3.59381      0.60497        0.40513   \nstd     0.37453   0.18859    0.35968      6.05126      0.66793        0.35595   \nmin     0.00000   0.00000    0.00000      0.00000      0.00000        0.00000   \n25%     0.00000   0.00000    0.00000      0.00000      0.00000        0.00000   \n50%     0.00000   0.00000    0.00000      1.00000      0.50000        0.50000   \n75%     0.33333   0.00000    0.33333      4.00000      1.00000        0.66667   \nmax     2.00000   0.94281    1.00000     38.00000      6.50000        1.00000   \n\n       Tweets Count  Ratio Verified  SUM Verified      SUM RT    AVG RT  \\\ncount     485.00000       485.00000     485.00000   485.00000 485.00000   \nmean        4.04742         0.06684       0.15258    40.95258   4.41943   \nstd         4.83785         0.21699       0.38759   482.16712  25.62266   \nmin         1.00000         0.00000       0.00000     0.00000   0.00000   \n25%         1.00000         0.00000       0.00000     0.00000   0.00000   \n50%         2.00000         0.00000       0.00000     3.00000   2.00000   \n75%         5.00000         0.00000       0.00000     8.00000   4.00000   \nmax        27.00000         1.00000       3.00000 10415.00000 548.15789   \n\n          STD RT  AVG AccAge  STD AccAge  thread_time  STD Emoji  AVG Emoji  \\\ncount  485.00000   485.00000   485.00000    485.00000  485.00000  485.00000   \nmean     9.69219   986.42153   370.60815  15581.70722    0.06312    0.03985   \nstd    107.48288   709.21957   392.53652  51235.86482    0.25042    0.20250   \nmin      0.00000     0.00000     0.00000      0.00000    0.00000    0.00000   \n25%      0.00000   475.66667     0.00000      0.00000    0.00000    0.00000   \n50%      0.00000   938.46154   209.00000    561.00000    0.00000    0.00000   \n75%      2.49444  1443.00000   726.71193   6964.00000    0.00000    0.00000   \nmax   2322.57324  3021.00000  1432.00000 753999.00000    2.76385    3.00000   \n\n       Ratio Media  RATIO Question  RATIO Exclaim  RATIO Period   AVG FPP  \\\ncount    485.00000       485.00000      485.00000     485.00000 485.00000   \nmean       0.13214         0.15139        0.10150       0.52345   0.18014   \nstd        0.29372         0.28140        0.21562       0.38458   0.33362   \nmin        0.00000         0.00000        0.00000       0.00000   0.00000   \n25%        0.00000         0.00000        0.00000       0.16667   0.00000   \n50%        0.00000         0.00000        0.00000       0.50000   0.00000   \n75%        0.05556         0.16667        0.11111       1.00000   0.25000   \nmax        1.00000         1.00000        1.00000       1.00000   2.00000   \n\n        STD FPP   AVG SPP   STD SPP   AVG TPP   STD TPP  AVG Skepticism  \ncount 485.00000 485.00000 485.00000 485.00000 485.00000       485.00000  \nmean    0.19884   0.06492   0.06322   0.24703   0.20441         2.26836  \nstd     0.35683   0.22990   0.16169   0.40823   0.32968         1.75281  \nmin     0.00000   0.00000   0.00000   0.00000   0.00000         0.00000  \n25%     0.00000   0.00000   0.00000   0.00000   0.00000         1.00000  \n50%     0.00000   0.00000   0.00000   0.00000   0.00000         2.00000  \n75%     0.40000   0.00000   0.00000   0.40000   0.43301         3.00000  \nmax     2.00000   2.00000   1.00000   2.00000   2.00000         9.00000  "
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ext_thread.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_ext.loc[(all_ext['pid'] == 521369179392581632) | (all_ext['id'] == 521369179392581632)]#[['tweet_created', 'pid', 'id']]\n",
    "# 521369179392581632"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>id</th>\n      <th>pid</th>\n      <th>emoji_count</th>\n      <th>has_media</th>\n      <th>URLcount</th>\n      <th>Skepticism</th>\n      <th>MentionCount</th>\n      <th>token_for_POS</th>\n      <th>Noun</th>\n      <th>Verb</th>\n      <th>Adjective</th>\n      <th>Pronoun</th>\n      <th>FirstPersonPronoun</th>\n      <th>SecondPersonPronoun</th>\n      <th>ThirdPersonPronoun</th>\n      <th>Adverb</th>\n      <th>Numeral</th>\n      <th>Conjunction_inj</th>\n      <th>Particle</th>\n      <th>Determiner</th>\n      <th>Modal</th>\n      <th>Whs</th>\n      <th>char_count</th>\n      <th>word_count</th>\n      <th>HashTag</th>\n      <th>has_question</th>\n      <th>has_exclaim</th>\n      <th>has_period</th>\n      <th>retweet_count</th>\n      <th>isRT</th>\n      <th>tweet_count</th>\n      <th>listed_count</th>\n      <th>friends_count</th>\n      <th>follow_ratio</th>\n      <th>account_age_days</th>\n      <th>tweet_created</th>\n      <th>capital_ratio</th>\n      <th>verified</th>\n      <th>Event</th>\n      <th>isSrcTweet</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>15</th>\n      <td>@MichaelEssien Glad you are healthy and well! #ForzaMilan</td>\n      <td>521368486053150721</td>\n      <td>521367917322338304.00000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>[glad, you, are, healthy, and, well]</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>57</td>\n      <td>8</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4.59222</td>\n      <td>2.09342</td>\n      <td>2.99782</td>\n      <td>3.52840</td>\n      <td>2118</td>\n      <td>1413138908.00000</td>\n      <td>0.08772</td>\n      <td>0</td>\n      <td>ebola-essien</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>@MichaelEssien that's a shame wanted to Invest in you😔</td>\n      <td>521368752135610368</td>\n      <td>521367917322338304.00000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>[that, is, a, shame, wanted, to, invest, in, you]</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>54</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>4.86344</td>\n      <td>0.69897</td>\n      <td>2.75282</td>\n      <td>4.02057</td>\n      <td>342</td>\n      <td>1413138971.00000</td>\n      <td>0.05556</td>\n      <td>0</td>\n      <td>ebola-essien</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>@MichaelEssien u got kik?</td>\n      <td>521368597734912000</td>\n      <td>521367917322338304.00000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>[u, got, kik]</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>25</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4.66114</td>\n      <td>0.47712</td>\n      <td>1.99123</td>\n      <td>3.22968</td>\n      <td>512</td>\n      <td>1413138934.00000</td>\n      <td>0.08000</td>\n      <td>0</td>\n      <td>ebola-essien</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>@MichaelEssien love you mikey</td>\n      <td>521368183358648321</td>\n      <td>521367917322338304.00000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>[love, you, mikey]</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>29</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4.30604</td>\n      <td>0.77815</td>\n      <td>2.91698</td>\n      <td>3.28488</td>\n      <td>489</td>\n      <td>1413138836.00000</td>\n      <td>0.06897</td>\n      <td>0</td>\n      <td>ebola-essien</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>@MichaelEssien pleased to hear it. Nasty rumour</td>\n      <td>521368281526321152</td>\n      <td>521367917322338304.00000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>[pleased, to, hear, it, nasty, rumour]</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>47</td>\n      <td>7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4.27240</td>\n      <td>0.60206</td>\n      <td>2.64836</td>\n      <td>2.42325</td>\n      <td>866</td>\n      <td>1413138859.00000</td>\n      <td>0.06383</td>\n      <td>0</td>\n      <td>ebola-essien</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                                         text  \\\n15  @MichaelEssien Glad you are healthy and well! #ForzaMilan   \n16     @MichaelEssien that's a shame wanted to Invest in you😔   \n18                                  @MichaelEssien u got kik?   \n20                              @MichaelEssien love you mikey   \n21            @MichaelEssien pleased to hear it. Nasty rumour   \n\n                    id                      pid  emoji_count  has_media  \\\n15  521368486053150721 521367917322338304.00000            0          0   \n16  521368752135610368 521367917322338304.00000            1          0   \n18  521368597734912000 521367917322338304.00000            0          0   \n20  521368183358648321 521367917322338304.00000            0          0   \n21  521368281526321152 521367917322338304.00000            0          0   \n\n    URLcount  Skepticism  MentionCount  \\\n15         0           3             1   \n16         0           3             1   \n18         0           1             1   \n20         0           1             1   \n21         0           3             1   \n\n                                        token_for_POS  Noun  Verb  Adjective  \\\n15               [glad, you, are, healthy, and, well]     1     1          1   \n16  [that, is, a, shame, wanted, to, invest, in, you]     1     3          0   \n18                                      [u, got, kik]     1     1          1   \n20                                 [love, you, mikey]     1     1          0   \n21             [pleased, to, hear, it, nasty, rumour]     1     1          2   \n\n    Pronoun  FirstPersonPronoun  SecondPersonPronoun  ThirdPersonPronoun  \\\n15        1                   0                    1                   0   \n16        1                   0                    1                   0   \n18        0                   0                    0                   0   \n20        1                   0                    1                   0   \n21        1                   0                    0                   1   \n\n    Adverb  Numeral  Conjunction_inj  Particle  Determiner  Modal  Whs  \\\n15       1        0                1         0           0      0    0   \n16       0        0                1         0           2      0    0   \n18       0        0                0         0           0      0    0   \n20       0        0                0         0           0      0    0   \n21       0        0                0         0           0      0    0   \n\n    char_count  word_count  HashTag  has_question  has_exclaim  has_period  \\\n15          57           8        1             0            1           0   \n16          54           9        0             0            0           0   \n18          25           4        0             1            0           0   \n20          29           4        0             0            0           0   \n21          47           7        0             0            0           1   \n\n    retweet_count isRT  tweet_count  listed_count  friends_count  \\\n15              0    0      4.59222       2.09342        2.99782   \n16              2    0      4.86344       0.69897        2.75282   \n18              1    0      4.66114       0.47712        1.99123   \n20              1    0      4.30604       0.77815        2.91698   \n21              0    0      4.27240       0.60206        2.64836   \n\n    follow_ratio  account_age_days    tweet_created  capital_ratio  verified  \\\n15       3.52840              2118 1413138908.00000        0.08772         0   \n16       4.02057               342 1413138971.00000        0.05556         0   \n18       3.22968               512 1413138934.00000        0.08000         0   \n20       3.28488               489 1413138836.00000        0.06897         0   \n21       2.42325               866 1413138859.00000        0.06383         0   \n\n           Event  isSrcTweet  target  \n15  ebola-essien           0       1  \n16  ebola-essien           0       1  \n18  ebola-essien           0       1  \n20  ebola-essien           0       1  \n21  ebola-essien           0       1  "
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ext.loc[(all_ext['pid'] == int(521367917322338304))].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BERT & EMOJI 이모지 다루는 차이 😂😂😂😂😂\n",
    "\n",
    "> Before applying fastBPE to the pre-training corpus of 850M English Tweets, we tokenized these Tweets using TweetTokenizer from the NLTK toolkit and used the emoji package to translate emotion icons into text strings (here, each icon is referred to as a word token). We also normalized the Tweets by converting user mentions and web/url links into special tokens @USER and HTTPURL, respectively. Thus it is recommended to also apply the same pre-processing step for BERTweet-based downstream applications w.r.t. the raw input Tweets. BERTweet provides this pre-processing step by enabling the normalization argument.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer \n",
    "bertweet = AutoModel.from_pretrained(\"vinai/bertweet-base\", )\n",
    "\n",
    "# For transformers v4.x+: \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=False, normalization=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@MichaelEssien that's a shame wanted to Invest in you😔\n",
      "[0, 5238, 55508, 471, 10424, 818, 6139, 20, 11, 2536, 588, 9, 22630, 16, 3805, 3, 2] \n",
      "\n",
      "HTTPURL @MichaelEssien that's a shame wanted to Invest INVEST in you😔😂😂 http://www.google.com\n",
      "[0, 10, 5238, 55508, 471, 10424, 818, 6139, 20, 11, 2536, 588, 9, 22630, 27227, 3969, 16, 3805, 3, 3, 3, 45565, 36110, 9485, 17048, 6354, 2] \n",
      "\n",
      "HTTPURL @USER that's a shame wanted to Invest INVEST in you:pensive_face::face_with_tears_of_joy::face_with_tears_of_joy: HTTPURL\n",
      "[0, 10, 5, 6139, 20, 11, 2536, 588, 9, 22630, 27227, 3969, 16, 3805, 3, 524, 9859, 1043, 3, 3, 16517, 1043, 88, 10, 2] \n",
      "\n",
      "HTTPURL @USER that's a shame wanted to Invest INVEST in you pensive_face face_with_tears_of_joy face_with_tears_of_joy :grinning_face_with_big_eyes: HTTPURL  \n",
      "[0, 10, 5, 6139, 20, 11, 2536, 588, 9, 22630, 27227, 3969, 16, 14, 581, 62983, 524, 363, 3, 3, 3194, 3, 3, 3194, 3475, 10, 2]\n"
     ]
    }
   ],
   "source": [
    "# INPUT TWEET IS ALREADY NORMALIZED!\n",
    "line = \"@MichaelEssien that's a shame wanted to Invest in you😔\"\n",
    "print(line)\n",
    "print(tokenizer.encode(line),\"\\n\")\n",
    "input_ids = torch.tensor([tokenizer.encode(line)])\n",
    "# print(input_ids)\n",
    "\n",
    "line = \"HTTPURL @MichaelEssien that's a shame wanted to Invest INVEST in you😔😂😂 http://www.google.com\"\n",
    "input_ids = torch.tensor([tokenizer.encode(line)])\n",
    "print(line)\n",
    "print(tokenizer.encode(line),\"\\n\")\n",
    "\n",
    "line = \"HTTPURL @USER that's a shame wanted to Invest INVEST in you:pensive_face::face_with_tears_of_joy::face_with_tears_of_joy: HTTPURL\"\n",
    "input_ids = torch.tensor([tokenizer.encode(line)])\n",
    "print(line)\n",
    "print(tokenizer.encode(line),\"\\n\")\n",
    "\n",
    "line = \"HTTPURL @USER that's a shame wanted to Invest INVEST in you pensive_face face_with_tears_of_joy face_with_tears_of_joy :grinning_face_with_big_eyes: HTTPURL  \"\n",
    "input_ids = torch.tensor([tokenizer.encode(line)])\n",
    "print(line)\n",
    "print(tokenizer.encode(line))\n",
    "\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     features = bertweet(input_ids)  # Models outputs are now tuples\n",
    "# print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 \n",
      "\n",
      "HTTPURL @MichaelEssien that's a shame wanted to Invest INVEST in you😔😂😂😃 http://www.google.com\n",
      "['::', '::', '::']\n",
      "HTTPURL @USER that's a shame wanted to Invest INVEST in you :pensive_face: :face_with_tears_of_joy: :face_with_tears_of_joy: :grinning_face_with_big_eyes: HTTPURL \n",
      "\n",
      "['HTTPURL', '@USER', \"that's\", 'a', 'shame', 'wanted', 'to', 'Invest', 'INVEST', 'in', 'you', ':pensive_face:', ':face_with_tears_of_joy:', ':face_with_tears_of_joy:', ':grinning_face_with_big_eyes:', 'HTTPURL'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = \"HTTPURL @MichaelEssien that's a shame wanted to Invest INVEST in you😔😂😂😃 http://www.google.com\"\n",
    "print(emoji.emoji_count(text),\"\\n\")\n",
    "print(text)\n",
    "text = emoji.demojize(text)\n",
    "# print(emoji.get_emoji_regexp(),\"\\n\")\n",
    "# text=text.strip(':')\n",
    "# text = re.sub(r'(@.*?)[\\s]', '@USER ', text)\n",
    "text = re.sub(r\"@\\S+\", \"@USER\", text)   # mention -> '@'\n",
    "text = re.sub(r\"http\\S+\", \"HTTPURL\", text)  # http link -> '*'\n",
    "emojis = re.findall(r'(::)', text)\n",
    "print(emojis)\n",
    "# print(text,\"\\n\")\n",
    "text = re.sub(r':[^:]*:', r' \\g<0>', text)  # http link -> '*'\n",
    "print(text,\"\\n\")\n",
    "\n",
    "text=text.split()\n",
    "# text= re.sub(r'(:[!_\\-\\w]+:)', '', text)\n",
    "print(text,\"\\n\")\n",
    "# emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 추가 데이터들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_ext.loc[(all_ext['Whs'] > 1)][['text','token_for_POS','Pronoun','FirstPersonPronoun','SecondPersonPronoun','ThirdPersonPronoun','Numeral','Modal','Whs', 'Noun', 'Verb','Adjective','has_question',\t'has_exclaim',\t'has_period','target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "2"
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ext.loc[(all_ext['id'] == int(529657433866915840))].HashTag.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>token_for_POS</th>\n      <th>HashTag</th>\n      <th>Pronoun</th>\n      <th>FirstPersonPronoun</th>\n      <th>SecondPersonPronoun</th>\n      <th>ThirdPersonPronoun</th>\n      <th>Numeral</th>\n      <th>Modal</th>\n      <th>Whs</th>\n      <th>Noun</th>\n      <th>Verb</th>\n      <th>Adjective</th>\n      <th>has_question</th>\n      <th>has_exclaim</th>\n      <th>has_period</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>15</th>\n      <td>@MichaelEssien Glad you are healthy and well! #ForzaMilan</td>\n      <td>[glad, you, are, healthy, and, well]</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>@MichaelEssien that's a shame wanted to Invest in you😔</td>\n      <td>[that, is, a, shame, wanted, to, invest, in, you]</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>@MichaelEssien u got kik?</td>\n      <td>[u, got, kik]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>@MichaelEssien love you mikey</td>\n      <td>[love, you, mikey]</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>@MichaelEssien pleased to hear it. Nasty rumour</td>\n      <td>[pleased, to, hear, it, nasty, rumour]</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>@MichaelEssien we love you Michael</td>\n      <td>[we, love, you, michael]</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>@MichaelEssien Great to hear Essien !</td>\n      <td>[great, to, hear, essien]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>@MichaelEssien sue the journalist Michael.</td>\n      <td>[sue, the, journalist, michael]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>@MichaelEssien @Mourinholic very good to hear bison :) all the best and keep well! 😃</td>\n      <td>[very, good, to, hear, bison, all, the, best, and, keep, well]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>@MichaelEssien great to hear!</td>\n      <td>[great, to, hear]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>@MichaelEssien That's great, Just ignore the racist cunt.</td>\n      <td>[that, is, great, just, ignore, the, racist, cunt]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>@MichaelEssien @JamesChelsea16 Told ya</td>\n      <td>[told, ya]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>@MichaelEssien MENTEUUUUUUUUR</td>\n      <td>[menteuuuuuuuur]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>@MichaelEssien Sue him!</td>\n      <td>[sue, him]</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>@MichaelEssien I'm so happy that you're doing well!!!! I can't believe that anyone would make up such a rumor.... God bless you Michael! :)</td>\n      <td>[i, am, so, happy, that, you, are, doing, well, i, cannot, believe, that, anyone, would, make, up, such, a, rumor, god, bless, you, michael]</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>5</td>\n      <td>7</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                                                                                                                           text  \\\n15                                                                                    @MichaelEssien Glad you are healthy and well! #ForzaMilan   \n16                                                                                       @MichaelEssien that's a shame wanted to Invest in you😔   \n18                                                                                                                    @MichaelEssien u got kik?   \n20                                                                                                                @MichaelEssien love you mikey   \n21                                                                                              @MichaelEssien pleased to hear it. Nasty rumour   \n22                                                                                                           @MichaelEssien we love you Michael   \n23                                                                                                        @MichaelEssien Great to hear Essien !   \n24                                                                                                   @MichaelEssien sue the journalist Michael.   \n25                                                         @MichaelEssien @Mourinholic very good to hear bison :) all the best and keep well! 😃   \n27                                                                                                                @MichaelEssien great to hear!   \n28                                                                                    @MichaelEssien That's great, Just ignore the racist cunt.   \n29                                                                                                       @MichaelEssien @JamesChelsea16 Told ya   \n30                                                                                                                @MichaelEssien MENTEUUUUUUUUR   \n31                                                                                                                      @MichaelEssien Sue him!   \n32  @MichaelEssien I'm so happy that you're doing well!!!! I can't believe that anyone would make up such a rumor.... God bless you Michael! :)   \n\n                                                                                                                                   token_for_POS  \\\n15                                                                                                          [glad, you, are, healthy, and, well]   \n16                                                                                             [that, is, a, shame, wanted, to, invest, in, you]   \n18                                                                                                                                 [u, got, kik]   \n20                                                                                                                            [love, you, mikey]   \n21                                                                                                        [pleased, to, hear, it, nasty, rumour]   \n22                                                                                                                      [we, love, you, michael]   \n23                                                                                                                     [great, to, hear, essien]   \n24                                                                                                               [sue, the, journalist, michael]   \n25                                                                                [very, good, to, hear, bison, all, the, best, and, keep, well]   \n27                                                                                                                             [great, to, hear]   \n28                                                                                            [that, is, great, just, ignore, the, racist, cunt]   \n29                                                                                                                                    [told, ya]   \n30                                                                                                                              [menteuuuuuuuur]   \n31                                                                                                                                    [sue, him]   \n32  [i, am, so, happy, that, you, are, doing, well, i, cannot, believe, that, anyone, would, make, up, such, a, rumor, god, bless, you, michael]   \n\n    HashTag  Pronoun  FirstPersonPronoun  SecondPersonPronoun  \\\n15        1        1                   0                    1   \n16        0        1                   0                    1   \n18        0        0                   0                    0   \n20        0        1                   0                    1   \n21        0        1                   0                    0   \n22        0        2                   1                    1   \n23        0        0                   0                    0   \n24        0        0                   0                    0   \n25        0        0                   0                    0   \n27        0        0                   0                    0   \n28        0        0                   0                    0   \n29        0        0                   0                    1   \n30        0        0                   0                    0   \n31        0        1                   0                    0   \n32        0        2                   2                    2   \n\n    ThirdPersonPronoun  Numeral  Modal  Whs  Noun  Verb  Adjective  \\\n15                   0        0      0    0     1     1          1   \n16                   0        0      0    0     1     3          0   \n18                   0        0      0    0     1     1          1   \n20                   0        0      0    0     1     1          0   \n21                   1        0      0    0     1     1          2   \n22                   0        0      0    0     0     2          0   \n23                   0        0      0    0     1     1          1   \n24                   0        0      0    0     2     1          0   \n25                   0        0      0    0     2     2          1   \n27                   0        0      0    0     0     1          1   \n28                   0        0      0    0     2     2          1   \n29                   0        0      0    0     1     1          0   \n30                   0        0      0    0     1     0          0   \n31                   1        0      0    0     1     0          0   \n32                   0        0      1    0     5     7          2   \n\n    has_question  has_exclaim  has_period  \n15             0            1           0  \n16             0            0           0  \n18             1            0           0  \n20             0            0           0  \n21             0            0           1  \n22             0            0           0  \n23             0            1           0  \n24             0            0           1  \n25             0            1           0  \n27             0            1           0  \n28             0            0           1  \n29             0            0           0  \n30             0            0           0  \n31             0            1           0  \n32             0            1           1  "
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ext.loc[(all_ext['pid'] == int(521367917322338304))][['text','token_for_POS','HashTag','Pronoun','FirstPersonPronoun','SecondPersonPronoun','ThirdPersonPronoun','Numeral','Modal','Whs', 'Noun', 'Verb','Adjective','has_question',\t'has_exclaim',\t'has_period']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>pid</th>\n      <th>emoji_count</th>\n      <th>has_media</th>\n      <th>URLcount</th>\n      <th>Skepticism</th>\n      <th>MentionCount</th>\n      <th>Noun</th>\n      <th>Verb</th>\n      <th>Adjective</th>\n      <th>Pronoun</th>\n      <th>FirstPersonPronoun</th>\n      <th>SecondPersonPronoun</th>\n      <th>ThirdPersonPronoun</th>\n      <th>Adverb</th>\n      <th>Numeral</th>\n      <th>Conjunction_inj</th>\n      <th>Particle</th>\n      <th>Determiner</th>\n      <th>Modal</th>\n      <th>Whs</th>\n      <th>HashTag</th>\n      <th>char_count</th>\n      <th>word_count</th>\n      <th>has_question</th>\n      <th>has_exclaim</th>\n      <th>has_period</th>\n      <th>retweet_count</th>\n      <th>tweet_count</th>\n      <th>listed_count</th>\n      <th>friends_count</th>\n      <th>follow_ratio</th>\n      <th>account_age_days</th>\n      <th>tweet_created</th>\n      <th>capital_ratio</th>\n      <th>verified</th>\n      <th>isSrcTweet</th>\n    </tr>\n    <tr>\n      <th>target</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>575843532725041152.00000</td>\n      <td>576128013291619328.00000</td>\n      <td>0.03099</td>\n      <td>0.19155</td>\n      <td>0.13521</td>\n      <td>0.02254</td>\n      <td>1.07606</td>\n      <td>3.14930</td>\n      <td>2.40845</td>\n      <td>0.98873</td>\n      <td>0.71549</td>\n      <td>0.27887</td>\n      <td>0.12958</td>\n      <td>0.45352</td>\n      <td>0.78310</td>\n      <td>0.11549</td>\n      <td>1.39155</td>\n      <td>0.05352</td>\n      <td>0.80845</td>\n      <td>0.19155</td>\n      <td>0.20563</td>\n      <td>0.00000</td>\n      <td>90.39155</td>\n      <td>13.25915</td>\n      <td>0.14648</td>\n      <td>0.14648</td>\n      <td>0.65634</td>\n      <td>5.15775</td>\n      <td>3.80007</td>\n      <td>1.22078</td>\n      <td>2.65681</td>\n      <td>2.73380</td>\n      <td>1220.76901</td>\n      <td>1426126771.01972</td>\n      <td>0.07439</td>\n      <td>0.01690</td>\n      <td>0.32676</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>542766681617367296.00000</td>\n      <td>541958240233241280.00000</td>\n      <td>0.09453</td>\n      <td>0.10137</td>\n      <td>0.20833</td>\n      <td>0.07090</td>\n      <td>1.30659</td>\n      <td>3.57090</td>\n      <td>2.36567</td>\n      <td>0.87811</td>\n      <td>0.64614</td>\n      <td>0.35012</td>\n      <td>0.10883</td>\n      <td>0.37873</td>\n      <td>0.70647</td>\n      <td>0.12251</td>\n      <td>1.27923</td>\n      <td>0.07276</td>\n      <td>0.78420</td>\n      <td>0.20336</td>\n      <td>0.17600</td>\n      <td>0.00062</td>\n      <td>88.37935</td>\n      <td>12.96144</td>\n      <td>0.19652</td>\n      <td>0.18408</td>\n      <td>0.62624</td>\n      <td>15.25995</td>\n      <td>3.86143</td>\n      <td>1.17609</td>\n      <td>2.68354</td>\n      <td>2.89444</td>\n      <td>1313.23881</td>\n      <td>1418240635.17226</td>\n      <td>0.09286</td>\n      <td>0.07525</td>\n      <td>0.22948</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                             id                      pid  emoji_count  \\\ntarget                                                                  \n0      575843532725041152.00000 576128013291619328.00000      0.03099   \n1      542766681617367296.00000 541958240233241280.00000      0.09453   \n\n        has_media  URLcount  Skepticism  MentionCount    Noun    Verb  \\\ntarget                                                                  \n0         0.19155   0.13521     0.02254       1.07606 3.14930 2.40845   \n1         0.10137   0.20833     0.07090       1.30659 3.57090 2.36567   \n\n        Adjective  Pronoun  FirstPersonPronoun  SecondPersonPronoun  \\\ntarget                                                                \n0         0.98873  0.71549             0.27887              0.12958   \n1         0.87811  0.64614             0.35012              0.10883   \n\n        ThirdPersonPronoun  Adverb  Numeral  Conjunction_inj  Particle  \\\ntarget                                                                   \n0                  0.45352 0.78310  0.11549          1.39155   0.05352   \n1                  0.37873 0.70647  0.12251          1.27923   0.07276   \n\n        Determiner   Modal     Whs  HashTag  char_count  word_count  \\\ntarget                                                                \n0          0.80845 0.19155 0.20563  0.00000    90.39155    13.25915   \n1          0.78420 0.20336 0.17600  0.00062    88.37935    12.96144   \n\n        has_question  has_exclaim  has_period  retweet_count  tweet_count  \\\ntarget                                                                      \n0            0.14648      0.14648     0.65634        5.15775      3.80007   \n1            0.19652      0.18408     0.62624       15.25995      3.86143   \n\n        listed_count  friends_count  follow_ratio  account_age_days  \\\ntarget                                                                \n0            1.22078        2.65681       2.73380        1220.76901   \n1            1.17609        2.68354       2.89444        1313.23881   \n\n          tweet_created  capital_ratio  verified  isSrcTweet  \ntarget                                                        \n0      1426126771.01972        0.07439   0.01690     0.32676  \n1      1418240635.17226        0.09286   0.07525     0.22948  "
     },
     "execution_count": 888,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all_ext.loc[((all_ext['Skepticism'] >-1))].groupby('target').mean()  #[['text','URLcount','token_for_POS','id','pid','HashTag','Pronoun','FirstPersonPronoun','SecondPersonPronoun','ThirdPersonPronoun']]\n",
    "all_ext.loc[((all_ext['Skepticism'] >-1))].groupby('target').mean()  #[['text','URLcount','token_for_POS','id','pid','HashTag','Pronoun','FirstPersonPronoun','SecondPersonPronoun','ThirdPersonPronoun']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Root</th>\n      <th>SUM FriendsCount</th>\n      <th>AVG FriendsCount</th>\n      <th>AVG WordCount</th>\n      <th>AVG CharCount</th>\n      <th>AVG HashTag</th>\n      <th>SUM HashTag</th>\n      <th>Ratio HashTag</th>\n      <th>AVG Url</th>\n      <th>STD Url</th>\n      <th>RATIO Url</th>\n      <th>SUM Mention</th>\n      <th>AVG Mention</th>\n      <th>Ratio Mention</th>\n      <th>Tweets Count</th>\n      <th>Ratio Verified</th>\n      <th>SUM Verified</th>\n      <th>SUM RT</th>\n      <th>AVG RT</th>\n      <th>STD RT</th>\n      <th>AVG AccAge</th>\n      <th>STD AccAge</th>\n      <th>thread_time</th>\n      <th>STD Emoji</th>\n      <th>AVG Emoji</th>\n      <th>Ratio Media</th>\n      <th>RATIO Question</th>\n      <th>RATIO Exclaim</th>\n      <th>RATIO Period</th>\n      <th>AVG FPP</th>\n      <th>STD FPP</th>\n    </tr>\n    <tr>\n      <th>target</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>575085752669624256.00000</td>\n      <td>6.27038</td>\n      <td>2.10176</td>\n      <td>10.91659</td>\n      <td>77.15702</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.17880</td>\n      <td>0.06735</td>\n      <td>0.17757</td>\n      <td>2.50862</td>\n      <td>0.48479</td>\n      <td>0.35553</td>\n      <td>3.06034</td>\n      <td>0.01466</td>\n      <td>0.02586</td>\n      <td>10.97414</td>\n      <td>3.75976</td>\n      <td>3.26869</td>\n      <td>1049.38342</td>\n      <td>293.74990</td>\n      <td>28447.69828</td>\n      <td>0.02483</td>\n      <td>0.04061</td>\n      <td>0.25582</td>\n      <td>0.15440</td>\n      <td>0.11342</td>\n      <td>0.61356</td>\n      <td>0.24153</td>\n      <td>0.16274</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>545404340718235008.00000</td>\n      <td>8.04364</td>\n      <td>1.85743</td>\n      <td>9.72992</td>\n      <td>66.98572</td>\n      <td>0.00271</td>\n      <td>0.00271</td>\n      <td>0.00271</td>\n      <td>0.24102</td>\n      <td>0.11189</td>\n      <td>0.23436</td>\n      <td>3.93496</td>\n      <td>0.64275</td>\n      <td>0.42072</td>\n      <td>4.35772</td>\n      <td>0.08324</td>\n      <td>0.19241</td>\n      <td>50.37669</td>\n      <td>4.62681</td>\n      <td>11.71150</td>\n      <td>966.62864</td>\n      <td>394.76956</td>\n      <td>11537.11382</td>\n      <td>0.07516</td>\n      <td>0.03961</td>\n      <td>0.09326</td>\n      <td>0.15044</td>\n      <td>0.09776</td>\n      <td>0.49512</td>\n      <td>0.16084</td>\n      <td>0.21020</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                           Root  SUM FriendsCount  AVG FriendsCount  \\\ntarget                                                                \n0      575085752669624256.00000           6.27038           2.10176   \n1      545404340718235008.00000           8.04364           1.85743   \n\n        AVG WordCount  AVG CharCount  AVG HashTag  SUM HashTag  Ratio HashTag  \\\ntarget                                                                          \n0            10.91659       77.15702      0.00000      0.00000        0.00000   \n1             9.72992       66.98572      0.00271      0.00271        0.00271   \n\n        AVG Url  STD Url  RATIO Url  SUM Mention  AVG Mention  Ratio Mention  \\\ntarget                                                                         \n0       0.17880  0.06735    0.17757      2.50862      0.48479        0.35553   \n1       0.24102  0.11189    0.23436      3.93496      0.64275        0.42072   \n\n        Tweets Count  Ratio Verified  SUM Verified   SUM RT  AVG RT   STD RT  \\\ntarget                                                                         \n0            3.06034         0.01466       0.02586 10.97414 3.75976  3.26869   \n1            4.35772         0.08324       0.19241 50.37669 4.62681 11.71150   \n\n        AVG AccAge  STD AccAge  thread_time  STD Emoji  AVG Emoji  \\\ntarget                                                              \n0       1049.38342   293.74990  28447.69828    0.02483    0.04061   \n1        966.62864   394.76956  11537.11382    0.07516    0.03961   \n\n        Ratio Media  RATIO Question  RATIO Exclaim  RATIO Period  AVG FPP  \\\ntarget                                                                      \n0           0.25582         0.15440        0.11342       0.61356  0.24153   \n1           0.09326         0.15044        0.09776       0.49512  0.16084   \n\n        STD FPP  \ntarget           \n0       0.16274  \n1       0.21020  "
     },
     "execution_count": 895,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([ext_thread, ext_y], axis=1).groupby('target').mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>token_for_POS</th>\n      <th>HashTag</th>\n      <th>URLcount</th>\n      <th>target</th>\n      <th>Skepticism</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>381</th>\n      <td>529775890767437825</td>\n      <td>This is what it sounds like when fans cry. #Prince #Toronto #PRINCEWATCH #princeTOrumours #masseyhall</td>\n      <td>[this, is, what, it, sounds, like, when, fans, cry]</td>\n      <td>5</td>\n      <td>0</td>\n      <td>1</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>588</th>\n      <td>529649691630514176</td>\n      <td>@blogTO OMG #justsaying #PRINCE #TORONTO #otnorot #MasseyHall #LOVE #PurpleRain</td>\n      <td>[omg]</td>\n      <td>7</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>956</th>\n      <td>529695483661664257</td>\n      <td>Clearly prince is having a show in #toronto @TorontoComms #tdot #gta #prince #concert http://t.co/e7oktlGd1v</td>\n      <td>[clearly, prince, is, having, a, show, in]</td>\n      <td>5</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1156</th>\n      <td>576860819322880000</td>\n      <td>Expert: #Vladimir #Putin’s #Disappearance Could Mean #Russia’s Undergoing a #Coup http://t.co/rzLhZFdnwy</td>\n      <td>[expert, could, mean, undergoing, a]</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1212</th>\n      <td>577300721449771008</td>\n      <td>@PatDollard @jasian12345 Another Confirmation my readers #SecurityConcerns #Nemstov #Putin Next #Assassination #DrEd https://t.co/n7DQyio1Ej</td>\n      <td>[another, confirmation, my, readers, next]</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1334</th>\n      <td>577287176288776192</td>\n      <td>Why the Russian oil crash could threaten Putin with a palace coup - http://t.co/uZIOIWHe4I #WhereIsPutin #putindead #Putin #Kremlin #Moscow</td>\n      <td>[why, the, russian, oil, crash, could, threaten, putin, with, a, palace, coup]</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>1341</th>\n      <td>576890955955113985</td>\n      <td>@jasian12345 Another Confirmation my readers #SecurityConcerns #Nemstov #Putin Next #Assassination #DrEd https://t.co/n7DQyio1Ej</td>\n      <td>[another, confirmation, my, readers, next]</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1593</th>\n      <td>577284294051123201</td>\n      <td>@patondabak Maybe, just maybe… he's huddling with best minds/top advisors about how to prevent #USA #UK #NATO #EU #Canada threat of WWIII ?</td>\n      <td>[maybe, just, maybe, he, is, huddling, with, best, mindstop, advisors, about, how, to, prevent, threat, of, wwiii]</td>\n      <td>5</td>\n      <td>0</td>\n      <td>1</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1614</th>\n      <td>576175612336992257</td>\n      <td>#Putin/s \"death\" or another #maskirovka? Military helo's flying over #Moscow &amp;gt;  http://t.co/Spj2VTdlAt #Reddit #Russia #Putindead #NATO</td>\n      <td>[death, or, another, military, helo, is, flying, over, andgt]</td>\n      <td>7</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1650</th>\n      <td>577301613502722050</td>\n      <td>@RT_com #FalseFlag #BlackOps #Ukraine #Flight #MH17 Off Course Flying In #Restricted #Airspace; More https://t.co/9U32Jsfolf</td>\n      <td>[off, course, flying, in, more]</td>\n      <td>7</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1655</th>\n      <td>577301727193477120</td>\n      <td>@RT_com Another Confirmation my readers #SecurityConcerns #Nemstov #Putin Next #Assassination #DrEd https://t.co/n7DQyio1Ej</td>\n      <td>[another, confirmation, my, readers, next]</td>\n      <td>5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1691</th>\n      <td>576524931409772544</td>\n      <td>#whyileft \\n\\n#Snowden was thinking about leaving and they have pizza. @DiGiornoPizza\\n\\n#WhereIsPutin \\n#Putin \\n#FridayThe13th \\n#putindead</td>\n      <td>[was, thinking, about, leaving, and, they, have, pizza]</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>1707</th>\n      <td>576848770136174594</td>\n      <td>You know strange things are happening in the #Kremlin when #Russia trolls start worrying #Putindead #Putin #Ukraine http://t.co/ScvTRE7zOw</td>\n      <td>[you, know, strange, things, are, happening, in, the, when, trolls, start, worrying]</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1712</th>\n      <td>576811711652450304</td>\n      <td>#BREAKING #Russia #Moscow today #Putin #Putindead http://t.co/Wg6KyvUgJ3</td>\n      <td>[today]</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1718</th>\n      <td>576497758862987265</td>\n      <td>VIDEO #Russia(n) Armored Vehicles,Tanks in #Donetsk #Ukraine https://t.co/wvwVYUjm3V #Luhansk #Mariupol #Putindead http://t.co/jU5RD8a1Sr</td>\n      <td>[video, armored, vehiclestanks, in]</td>\n      <td>6</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1740</th>\n      <td>576617856919465984</td>\n      <td>I think President #Putin decided to die in order to divert attention from Nemtsov's death #WhereIsPutin #ПутинУмер #putindead #RIP</td>\n      <td>[i, think, president, decided, to, die, in, order, to, divert, attention, from, nemtsov, is, death]</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1797</th>\n      <td>576777317474652160</td>\n      <td>#Russia #Moscow #Kremlin today #Putin #Putindead http://t.co/rubjKPxgcN</td>\n      <td>[today]</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1825</th>\n      <td>577301582917816321</td>\n      <td>#Putinmissing - just found him! #SundayFunday #VladimirPutin #Putin #putinnotdead http://t.co/FI9k9cKq7I http://t.co/HseiwTft5J</td>\n      <td>[just, found, him]</td>\n      <td>5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                      id  \\\n381   529775890767437825   \n588   529649691630514176   \n956   529695483661664257   \n1156  576860819322880000   \n1212  577300721449771008   \n1334  577287176288776192   \n1341  576890955955113985   \n1593  577284294051123201   \n1614  576175612336992257   \n1650  577301613502722050   \n1655  577301727193477120   \n1691  576524931409772544   \n1707  576848770136174594   \n1712  576811711652450304   \n1718  576497758862987265   \n1740  576617856919465984   \n1797  576777317474652160   \n1825  577301582917816321   \n\n                                                                                                                                               text  \\\n381                                           This is what it sounds like when fans cry. #Prince #Toronto #PRINCEWATCH #princeTOrumours #masseyhall   \n588                                                                 @blogTO OMG #justsaying #PRINCE #TORONTO #otnorot #MasseyHall #LOVE #PurpleRain   \n956                                    Clearly prince is having a show in #toronto @TorontoComms #tdot #gta #prince #concert http://t.co/e7oktlGd1v   \n1156                                       Expert: #Vladimir #Putin’s #Disappearance Could Mean #Russia’s Undergoing a #Coup http://t.co/rzLhZFdnwy   \n1212   @PatDollard @jasian12345 Another Confirmation my readers #SecurityConcerns #Nemstov #Putin Next #Assassination #DrEd https://t.co/n7DQyio1Ej   \n1334    Why the Russian oil crash could threaten Putin with a palace coup - http://t.co/uZIOIWHe4I #WhereIsPutin #putindead #Putin #Kremlin #Moscow   \n1341               @jasian12345 Another Confirmation my readers #SecurityConcerns #Nemstov #Putin Next #Assassination #DrEd https://t.co/n7DQyio1Ej   \n1593    @patondabak Maybe, just maybe… he's huddling with best minds/top advisors about how to prevent #USA #UK #NATO #EU #Canada threat of WWIII ?   \n1614     #Putin/s \"death\" or another #maskirovka? Military helo's flying over #Moscow &gt;  http://t.co/Spj2VTdlAt #Reddit #Russia #Putindead #NATO   \n1650                   @RT_com #FalseFlag #BlackOps #Ukraine #Flight #MH17 Off Course Flying In #Restricted #Airspace; More https://t.co/9U32Jsfolf   \n1655                    @RT_com Another Confirmation my readers #SecurityConcerns #Nemstov #Putin Next #Assassination #DrEd https://t.co/n7DQyio1Ej   \n1691  #whyileft \\n\\n#Snowden was thinking about leaving and they have pizza. @DiGiornoPizza\\n\\n#WhereIsPutin \\n#Putin \\n#FridayThe13th \\n#putindead   \n1707     You know strange things are happening in the #Kremlin when #Russia trolls start worrying #Putindead #Putin #Ukraine http://t.co/ScvTRE7zOw   \n1712                                                                       #BREAKING #Russia #Moscow today #Putin #Putindead http://t.co/Wg6KyvUgJ3   \n1718      VIDEO #Russia(n) Armored Vehicles,Tanks in #Donetsk #Ukraine https://t.co/wvwVYUjm3V #Luhansk #Mariupol #Putindead http://t.co/jU5RD8a1Sr   \n1740             I think President #Putin decided to die in order to divert attention from Nemtsov's death #WhereIsPutin #ПутинУмер #putindead #RIP   \n1797                                                                        #Russia #Moscow #Kremlin today #Putin #Putindead http://t.co/rubjKPxgcN   \n1825                #Putinmissing - just found him! #SundayFunday #VladimirPutin #Putin #putinnotdead http://t.co/FI9k9cKq7I http://t.co/HseiwTft5J   \n\n                                                                                                           token_for_POS  \\\n381                                                                  [this, is, what, it, sounds, like, when, fans, cry]   \n588                                                                                                                [omg]   \n956                                                                           [clearly, prince, is, having, a, show, in]   \n1156                                                                                [expert, could, mean, undergoing, a]   \n1212                                                                          [another, confirmation, my, readers, next]   \n1334                                      [why, the, russian, oil, crash, could, threaten, putin, with, a, palace, coup]   \n1341                                                                          [another, confirmation, my, readers, next]   \n1593  [maybe, just, maybe, he, is, huddling, with, best, mindstop, advisors, about, how, to, prevent, threat, of, wwiii]   \n1614                                                       [death, or, another, military, helo, is, flying, over, andgt]   \n1650                                                                                     [off, course, flying, in, more]   \n1655                                                                          [another, confirmation, my, readers, next]   \n1691                                                             [was, thinking, about, leaving, and, they, have, pizza]   \n1707                                [you, know, strange, things, are, happening, in, the, when, trolls, start, worrying]   \n1712                                                                                                             [today]   \n1718                                                                                 [video, armored, vehiclestanks, in]   \n1740                 [i, think, president, decided, to, die, in, order, to, divert, attention, from, nemtsov, is, death]   \n1797                                                                                                             [today]   \n1825                                                                                                  [just, found, him]   \n\n      HashTag  URLcount  target  Skepticism  \n381         5         0       1           5  \n588         7         0       1           0  \n956         5         0       1           3  \n1156        5         1       1           2  \n1212        5         1       1           3  \n1334        5         1       1           8  \n1341        5         1       1           3  \n1593        5         0       1           6  \n1614        7         1       1           4  \n1650        7         1       0           2  \n1655        5         1       0           3  \n1691        6         0       0           7  \n1707        5         0       0           5  \n1712        5         0       0           1  \n1718        6         1       0           4  \n1740        5         0       0           3  \n1797        5         0       0           1  \n1825        5         1       0           3  "
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ext[['id','text','token_for_POS','HashTag','URLcount','target','Skepticism']].loc[all_ext.HashTag > 4]\n",
    "# all_ext['HashTag'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
     },
     "execution_count": 625,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.max([np.sum(all_ext.loc[(all_ext['id'] == int(childid))]['tweet_created'].values) for childid in structure_ext.loc[0,'0':].dropna()])\n",
    "# np.max([np.sum(all_ext.loc[(all_ext['id'] == childid)]['tweet_created']) for childid in structure_ext.loc[0,'0':'13'].dropna()] - all_ext.loc[(all_ext['id'] == int(521369179392581632))].tweet_created.sum())\n",
    "[np.sum(all_ext.loc[(all_ext['id'] == childid)]['urls_dicts_len']) for childid in structure_ext.loc[11,:].dropna().drop(['depth'],axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [all_ext.loc[(all_ext['id'] == int(childid))]['URLcount'].values for childid in structure_ext.loc[int(521369179392581632),:].dropna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-627-1add269d7274>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-627-1add269d7274>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    structure_ext.loc[.Root == 529723023591743488]\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "structure_ext.loc[structure_ext.Root == 529723023591743488]\n",
    "structure_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[array(['2014-10-12 21:22:36+00:00'], dtype=object),\n array([], dtype=object),\n array(['2014-10-12 18:38:41+00:00'], dtype=object),\n array(['2014-10-12 18:43:07+00:00'], dtype=object),\n array(['2014-10-12 18:42:02+00:00'], dtype=object),\n array(['2014-10-12 18:44:13+00:00'], dtype=object),\n array(['2014-10-12 19:15:21+00:00'], dtype=object),\n array([], dtype=object),\n array(['2014-10-12 18:54:47+00:00'], dtype=object),\n array(['2014-10-12 18:39:06+00:00'], dtype=object),\n array(['2014-10-12 18:41:23+00:00'], dtype=object),\n array(['2014-10-12 18:39:51+00:00'], dtype=object),\n array([], dtype=object),\n array(['2014-10-12 18:56:53+00:00'], dtype=object)]"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ext_thread.thread_time[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thread()를 만드는데 필요한 정보들\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>pid</th>\n      <th>emoji_count</th>\n      <th>has_media</th>\n      <th>URLcount</th>\n      <th>Skepticism</th>\n      <th>MentionCount</th>\n      <th>Noun</th>\n      <th>Verb</th>\n      <th>Adjective</th>\n      <th>Pronoun</th>\n      <th>FirstPersonPronoun</th>\n      <th>SecondPersonPronoun</th>\n      <th>ThirdPersonPronoun</th>\n      <th>Adverb</th>\n      <th>Numeral</th>\n      <th>Conjunction_inj</th>\n      <th>Particle</th>\n      <th>Determiner</th>\n      <th>Modal</th>\n      <th>Whs</th>\n      <th>char_count</th>\n      <th>word_count</th>\n      <th>HashTag</th>\n      <th>has_question</th>\n      <th>has_exclaim</th>\n      <th>has_period</th>\n      <th>retweet_count</th>\n      <th>tweet_count</th>\n      <th>listed_count</th>\n      <th>friends_count</th>\n      <th>follow_ratio</th>\n      <th>account_age_days</th>\n      <th>tweet_created</th>\n      <th>capital_ratio</th>\n      <th>verified</th>\n      <th>isSrcTweet</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1963.00000</td>\n      <td>1478.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>548748486071387968.00000</td>\n      <td>547483663616841984.00000</td>\n      <td>0.08304</td>\n      <td>0.11768</td>\n      <td>0.19511</td>\n      <td>3.03311</td>\n      <td>1.26490</td>\n      <td>3.49465</td>\n      <td>2.37341</td>\n      <td>0.89812</td>\n      <td>0.65869</td>\n      <td>0.33724</td>\n      <td>0.11258</td>\n      <td>0.39226</td>\n      <td>0.72033</td>\n      <td>0.12124</td>\n      <td>1.29954</td>\n      <td>0.06928</td>\n      <td>0.78859</td>\n      <td>0.20122</td>\n      <td>0.18136</td>\n      <td>88.74325</td>\n      <td>13.01528</td>\n      <td>0.44320</td>\n      <td>0.18747</td>\n      <td>0.17728</td>\n      <td>0.63169</td>\n      <td>13.43301</td>\n      <td>3.85033</td>\n      <td>1.18417</td>\n      <td>2.67871</td>\n      <td>2.86539</td>\n      <td>1296.51605</td>\n      <td>1419666808.49159</td>\n      <td>0.08952</td>\n      <td>0.06470</td>\n      <td>0.24707</td>\n      <td>0.81915</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>24197288222753516.00000</td>\n      <td>24194908479467996.00000</td>\n      <td>0.52533</td>\n      <td>0.32231</td>\n      <td>0.40779</td>\n      <td>2.08666</td>\n      <td>0.92597</td>\n      <td>2.55108</td>\n      <td>1.83844</td>\n      <td>0.99326</td>\n      <td>0.92956</td>\n      <td>0.72692</td>\n      <td>0.36411</td>\n      <td>0.68698</td>\n      <td>0.98238</td>\n      <td>0.37989</td>\n      <td>1.26827</td>\n      <td>0.26190</td>\n      <td>0.91239</td>\n      <td>0.46241</td>\n      <td>0.44552</td>\n      <td>39.00655</td>\n      <td>6.42202</td>\n      <td>0.98470</td>\n      <td>0.39039</td>\n      <td>0.38200</td>\n      <td>0.48247</td>\n      <td>254.08308</td>\n      <td>0.81881</td>\n      <td>0.92393</td>\n      <td>0.59617</td>\n      <td>0.93745</td>\n      <td>737.28048</td>\n      <td>5769083.07608</td>\n      <td>0.07571</td>\n      <td>0.24605</td>\n      <td>0.43142</td>\n      <td>0.38499</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>521310417696858112.00000</td>\n      <td>521310417696858112.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>8.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.30103</td>\n      <td>3.00000</td>\n      <td>1413125063.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>529676680548595712.00000</td>\n      <td>529654768249354240.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>55.00000</td>\n      <td>8.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>3.39872</td>\n      <td>0.47712</td>\n      <td>2.32118</td>\n      <td>2.24674</td>\n      <td>652.00000</td>\n      <td>1415119735.50000</td>\n      <td>0.04167</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>529753935545118720.00000</td>\n      <td>529735657531656192.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>3.00000</td>\n      <td>1.00000</td>\n      <td>3.00000</td>\n      <td>2.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>90.00000</td>\n      <td>13.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>3.94161</td>\n      <td>1.11394</td>\n      <td>2.73957</td>\n      <td>2.82478</td>\n      <td>1313.00000</td>\n      <td>1415138155.00000</td>\n      <td>0.07246</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>576560832456267776.00000</td>\n      <td>576504635738951680.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>4.00000</td>\n      <td>2.00000</td>\n      <td>5.00000</td>\n      <td>4.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>2.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>128.00000</td>\n      <td>18.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>2.00000</td>\n      <td>4.43603</td>\n      <td>1.78174</td>\n      <td>3.04513</td>\n      <td>3.39436</td>\n      <td>2031.00000</td>\n      <td>1426297788.50000</td>\n      <td>0.11611</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>579479145828257792.00000</td>\n      <td>577453947599777792.00000</td>\n      <td>10.00000</td>\n      <td>1.00000</td>\n      <td>2.00000</td>\n      <td>12.00000</td>\n      <td>7.00000</td>\n      <td>21.00000</td>\n      <td>10.00000</td>\n      <td>6.00000</td>\n      <td>5.00000</td>\n      <td>7.00000</td>\n      <td>3.00000</td>\n      <td>5.00000</td>\n      <td>6.00000</td>\n      <td>3.00000</td>\n      <td>7.00000</td>\n      <td>2.00000</td>\n      <td>5.00000</td>\n      <td>3.00000</td>\n      <td>3.00000</td>\n      <td>148.00000</td>\n      <td>29.00000</td>\n      <td>7.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>10402.00000</td>\n      <td>5.73594</td>\n      <td>4.15927</td>\n      <td>4.83829</td>\n      <td>6.31487</td>\n      <td>3021.00000</td>\n      <td>1426993569.00000</td>\n      <td>0.76471</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                            id                      pid  emoji_count  \\\ncount               1963.00000               1478.00000   1963.00000   \nmean  548748486071387968.00000 547483663616841984.00000      0.08304   \nstd    24197288222753516.00000  24194908479467996.00000      0.52533   \nmin   521310417696858112.00000 521310417696858112.00000      0.00000   \n25%   529676680548595712.00000 529654768249354240.00000      0.00000   \n50%   529753935545118720.00000 529735657531656192.00000      0.00000   \n75%   576560832456267776.00000 576504635738951680.00000      0.00000   \nmax   579479145828257792.00000 577453947599777792.00000     10.00000   \n\n       has_media   URLcount  Skepticism  MentionCount       Noun       Verb  \\\ncount 1963.00000 1963.00000  1963.00000    1963.00000 1963.00000 1963.00000   \nmean     0.11768    0.19511     3.03311       1.26490    3.49465    2.37341   \nstd      0.32231    0.40779     2.08666       0.92597    2.55108    1.83844   \nmin      0.00000    0.00000     0.00000       0.00000    0.00000    0.00000   \n25%      0.00000    0.00000     1.00000       1.00000    1.00000    1.00000   \n50%      0.00000    0.00000     3.00000       1.00000    3.00000    2.00000   \n75%      0.00000    0.00000     4.00000       2.00000    5.00000    4.00000   \nmax      1.00000    2.00000    12.00000       7.00000   21.00000   10.00000   \n\n       Adjective    Pronoun  FirstPersonPronoun  SecondPersonPronoun  \\\ncount 1963.00000 1963.00000          1963.00000           1963.00000   \nmean     0.89812    0.65869             0.33724              0.11258   \nstd      0.99326    0.92956             0.72692              0.36411   \nmin      0.00000    0.00000             0.00000              0.00000   \n25%      0.00000    0.00000             0.00000              0.00000   \n50%      1.00000    0.00000             0.00000              0.00000   \n75%      1.00000    1.00000             0.00000              0.00000   \nmax      6.00000    5.00000             7.00000              3.00000   \n\n       ThirdPersonPronoun     Adverb    Numeral  Conjunction_inj   Particle  \\\ncount          1963.00000 1963.00000 1963.00000       1963.00000 1963.00000   \nmean              0.39226    0.72033    0.12124          1.29954    0.06928   \nstd               0.68698    0.98238    0.37989          1.26827    0.26190   \nmin               0.00000    0.00000    0.00000          0.00000    0.00000   \n25%               0.00000    0.00000    0.00000          0.00000    0.00000   \n50%               0.00000    0.00000    0.00000          1.00000    0.00000   \n75%               1.00000    1.00000    0.00000          2.00000    0.00000   \nmax               5.00000    6.00000    3.00000          7.00000    2.00000   \n\n       Determiner      Modal        Whs  char_count  word_count    HashTag  \\\ncount  1963.00000 1963.00000 1963.00000  1963.00000  1963.00000 1963.00000   \nmean      0.78859    0.20122    0.18136    88.74325    13.01528    0.44320   \nstd       0.91239    0.46241    0.44552    39.00655     6.42202    0.98470   \nmin       0.00000    0.00000    0.00000     8.00000     1.00000    0.00000   \n25%       0.00000    0.00000    0.00000    55.00000     8.00000    0.00000   \n50%       1.00000    0.00000    0.00000    90.00000    13.00000    0.00000   \n75%       1.00000    0.00000    0.00000   128.00000    18.00000    0.00000   \nmax       5.00000    3.00000    3.00000   148.00000    29.00000    7.00000   \n\n       has_question  has_exclaim  has_period  retweet_count  tweet_count  \\\ncount    1963.00000   1963.00000  1963.00000     1963.00000   1963.00000   \nmean        0.18747      0.17728     0.63169       13.43301      3.85033   \nstd         0.39039      0.38200     0.48247      254.08308      0.81881   \nmin         0.00000      0.00000     0.00000        0.00000      0.00000   \n25%         0.00000      0.00000     0.00000        0.00000      3.39872   \n50%         0.00000      0.00000     1.00000        0.00000      3.94161   \n75%         0.00000      0.00000     1.00000        2.00000      4.43603   \nmax         1.00000      1.00000     1.00000    10402.00000      5.73594   \n\n       listed_count  friends_count  follow_ratio  account_age_days  \\\ncount    1963.00000     1963.00000    1963.00000        1963.00000   \nmean        1.18417        2.67871       2.86539        1296.51605   \nstd         0.92393        0.59617       0.93745         737.28048   \nmin         0.00000        0.00000       0.30103           3.00000   \n25%         0.47712        2.32118       2.24674         652.00000   \n50%         1.11394        2.73957       2.82478        1313.00000   \n75%         1.78174        3.04513       3.39436        2031.00000   \nmax         4.15927        4.83829       6.31487        3021.00000   \n\n         tweet_created  capital_ratio   verified  isSrcTweet     target  \ncount       1963.00000     1963.00000 1963.00000  1963.00000 1963.00000  \nmean  1419666808.49159        0.08952    0.06470     0.24707    0.81915  \nstd      5769083.07608        0.07571    0.24605     0.43142    0.38499  \nmin   1413125063.00000        0.00000    0.00000     0.00000    0.00000  \n25%   1415119735.50000        0.04167    0.00000     0.00000    1.00000  \n50%   1415138155.00000        0.07246    0.00000     0.00000    1.00000  \n75%   1426297788.50000        0.11611    0.00000     0.00000    1.00000  \nmax   1426993569.00000        0.76471    1.00000     1.00000    1.00000  "
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ext.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "target\n1    71\n0    26\ndtype: int64"
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ext.loc[all_ext['account_age_days']<100][['account_age_days','verified', 'HashTag', 'URLcount',\n",
    "                                           'MentionCount', 'retweet_count', 'isSrcTweet', 'target']].value_counts('target')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-4b5709a94d49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m all_ext.loc[(all_ext['retweet_count'] > 0) and (all_ext.pid==521369179392581632)][['verified', 'HashTag', 'URLcount',\n\u001b[0m\u001b[1;32m      2\u001b[0m                                            'MentionCount', 'retweet_count', 'isSrcTweet', 'target']].sample(18)\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1441\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   1442\u001b[0m             \u001b[0;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m             \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "all_ext.loc[(all_ext['retweet_count'] > 0) and (all_ext.pid==521369179392581632)][['verified', 'HashTag', 'URLcount',\n",
    "                                           'MentionCount', 'retweet_count', 'isSrcTweet', 'target']].sample(18)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>verified</th>\n      <th>HashTag</th>\n      <th>URLcount</th>\n      <th>MentionCount</th>\n      <th>retweet_count</th>\n    </tr>\n    <tr>\n      <th>target</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.03356</td>\n      <td>1.77852</td>\n      <td>0.65772</td>\n      <td>0.44966</td>\n      <td>12.28859</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.19880</td>\n      <td>0.73695</td>\n      <td>0.73695</td>\n      <td>0.68273</td>\n      <td>49.27309</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "        verified  HashTag  URLcount  MentionCount  retweet_count\ntarget                                                          \n0        0.03356  1.77852   0.65772       0.44966       12.28859\n1        0.19880  0.73695   0.73695       0.68273       49.27309"
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ext.loc[all_ext['retweet_count']>0][['text', 'verified', 'HashTag', 'URLcount', 'MentionCount','retweet_count','target']].groupby('target').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [],
   "source": [
    "# High degree: If the coefficient value lies between ± 0.50 and ± 1, then it is said to be a strong correlation. \n",
    "# Moderate degree: If the value lies between ± 0.30 and ± 0.49, then it is said to be a medium correlation. \n",
    "# Low degree: When the value lies below + . 29, then it is said to be a small correlation.\n",
    "\n",
    "# ext_thread.corr(ext_y,method='pearson')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 907,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 485 and the array at index 1 has size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-907-15a6098fe44f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mext_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\":\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mext_thread\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mext_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mcorr\u001b[0;34m(self, other, method, min_periods)\u001b[0m\n\u001b[1;32m   2323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2324\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"pearson\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"spearman\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"kendall\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2325\u001b[0;31m             return nanops.nancorr(\n\u001b[0m\u001b[1;32m   2326\u001b[0m                 \u001b[0mthis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_periods\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_periods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2327\u001b[0m             )\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36m_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0;31m# we want to transform an object array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mnancorr\u001b[0;34m(a, b, method, min_periods)\u001b[0m\n\u001b[1;32m   1457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1458\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_corr_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1459\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mfunc\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m   1478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1480\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorrcoef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mcorrcoef\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mcorrcoef\u001b[0;34m(x, y, rowvar, bias, ddof, dtype)\u001b[0m\n\u001b[1;32m   2632\u001b[0m         warnings.warn('bias and ddof have no effect and are deprecated',\n\u001b[1;32m   2633\u001b[0m                       DeprecationWarning, stacklevel=3)\n\u001b[0;32m-> 2634\u001b[0;31m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrowvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2635\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2636\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mcov\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mcov\u001b[0;34m(m, y, rowvar, bias, ddof, fweights, aweights, dtype)\u001b[0m\n\u001b[1;32m   2426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrowvar\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2427\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2428\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2430\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mddof\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 485 and the array at index 1 has size 1"
     ]
    }
   ],
   "source": [
    "for data in ext_thread.columns:\n",
    "    print(data,\":\",ext_thread[data].corr(ext_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Root</th>\n      <th>SUM FriendsCount</th>\n      <th>AVG FriendsCount</th>\n      <th>AVG WordCount</th>\n      <th>AVG CharCount</th>\n      <th>AVG HashTag</th>\n      <th>SUM HashTag</th>\n      <th>Ratio HashTag</th>\n      <th>AVG Url</th>\n      <th>SUM Mention</th>\n      <th>AVG Mention</th>\n      <th>Ratio Mention</th>\n      <th>Tweets Count</th>\n      <th>Ratio Verified</th>\n      <th>SUM Verified</th>\n      <th>SUM RT</th>\n      <th>AVG RT</th>\n      <th>STD RT</th>\n      <th>AVG AccAge</th>\n      <th>STD AccAge</th>\n      <th>thread_time</th>\n      <th>STD Emoji</th>\n      <th>AVG Emoji</th>\n      <th>Ratio Media</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>",
      "text/plain": "Empty DataFrame\nColumns: [Root, SUM FriendsCount, AVG FriendsCount, AVG WordCount, AVG CharCount, AVG HashTag, SUM HashTag, Ratio HashTag, AVG Url, SUM Mention, AVG Mention, Ratio Mention, Tweets Count, Ratio Verified, SUM Verified, SUM RT, AVG RT, STD RT, AVG AccAge, STD AccAge, thread_time, STD Emoji, AVG Emoji, Ratio Media]\nIndex: []"
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ext_thread.loc[ext_thread['AVG Url']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (all_ext.loc[(all_ext['pid'] == 521369179392581632)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_thread.to_csv('./data/all/_PHEMEext_thread.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheme_all = pd.read_csv(\"./data/all/_PHEMEall.csv\")\n",
    "pheme_thread = pd.read_csv(\"./data/all/_PHEME_thread.csv\")\n",
    "ext_all = pd.read_csv(\"./data/all/_PHEMEextall.csv\")\n",
    "ext_thread = pd.read_csv(\"./data/all/_PHEMEext_thread.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(485, 36)\n"
     ]
    }
   ],
   "source": [
    "# print(pheme_all.shape)\n",
    "# print(pheme_thread.shape)\n",
    "# print(ext_all.shape)\n",
    "print(ext_thread.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(X_train, X_test, y_train, y_test, clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    result = clf.predict(X_test)\n",
    "    print(\"Accuracy:\\t\\t\",accuracy_score(y_test,result))\n",
    "    print('Precision Score:\\t', str(precision_score(y_test,result)))\n",
    "    print('Recall Score:\\t\\t' + str(recall_score(y_test,result)))\n",
    "    print(\"F1 Score:\\t\\t\",f1_score(y_test, result, average='macro', zero_division=True))\n",
    "    print(classification_report(y_test, result))\n",
    "    \n",
    "ext_y = pd.read_csv('./data/_PHEMEext_text.csv').target\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "ext_thread = ext_thread.replace(-np.inf, 0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(ext_thread.iloc[:,:], ext_y, test_size=0.15, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ext_thread.isna().sum()\n",
    "# ext_thread.iloc[:].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.684931506849315\n",
      "Precision Score:\t 0.684931506849315\n",
      "Recall Score:\t\t1.0\n",
      "F1 Score:\t\t 0.40650406504065034\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        23\n",
      "           1       0.68      1.00      0.81        50\n",
      "\n",
      "    accuracy                           0.68        73\n",
      "   macro avg       0.34      0.50      0.41        73\n",
      "weighted avg       0.47      0.68      0.56        73\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 12\n",
    "clf = SVC()\n",
    "train_test(X_train[:,0:2], X_test[:,0:2], y_train, y_test, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.6986301369863014\n",
      "Precision Score:\t 0.868421052631579\n",
      "Recall Score:\t\t0.66\n",
      "F1 Score:\t\t 0.685344827586207\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.78      0.62        23\n",
      "           1       0.87      0.66      0.75        50\n",
      "\n",
      "    accuracy                           0.70        73\n",
      "   macro avg       0.69      0.72      0.69        73\n",
      "weighted avg       0.76      0.70      0.71        73\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#AVG\n",
    "clf = GaussianNB()\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "train_test(X_train, X_test, y_train, y_test, clf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.8493150684931506\n",
      "Precision Score:\t 0.8421052631578947\n",
      "Recall Score:\t\t0.96\n",
      "F1 Score:\t\t 0.8075724898154804\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.61      0.72        23\n",
      "           1       0.84      0.96      0.90        50\n",
      "\n",
      "    accuracy                           0.85        73\n",
      "   macro avg       0.86      0.78      0.81        73\n",
      "weighted avg       0.85      0.85      0.84        73\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#STD\n",
    "clf = LogisticRegression()\n",
    "# scaler = StandardScaler()\n",
    "# X_train2 = scaler.fit_transform(X_train.iloc[:,-3:-1:1])\n",
    "# X_test2 = scaler.transform(X_test.iloc[:,-3:-1:1])\n",
    "train_test(X_train, X_test, y_train, y_test, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.7671232876712328\n",
      "Precision Score:\t 0.7619047619047619\n",
      "Recall Score:\t\t0.96\n",
      "F1 Score:\t\t 0.6672030034861893\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.35      0.48        23\n",
      "           1       0.76      0.96      0.85        50\n",
      "\n",
      "    accuracy                           0.77        73\n",
      "   macro avg       0.78      0.65      0.67        73\n",
      "weighted avg       0.77      0.77      0.73        73\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#STD\n",
    "clf = RandomForestClassifier()\n",
    "# scaler = StandardScaler()\n",
    "# X_train2 = scaler.fit_transform(X_train.iloc[:,-3:-1:1])\n",
    "# X_test2 = scaler.transform(X_test.iloc[:,-3:-1:1])\n",
    "train_test(X_train, X_test, y_train, y_test, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'principalComponents' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-136-23f3c9f7ee4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# X_train2 = scaler.fit_transform(X_train.iloc[:,-3:-1:1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# X_test2 = scaler.transform(X_test.iloc[:,-3:-1:1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrain_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprincipalComponents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprincipalComponents_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'principalComponents' is not defined"
     ]
    }
   ],
   "source": [
    "#STD\n",
    "# clf = RandomForestClassifier()\n",
    "# clf = GaussianNB()\n",
    "# clf = SVC()\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_train2 = scaler.fit_transform(X_train.iloc[:,-3:-1:1])\n",
    "# X_test2 = scaler.transform(X_test.iloc[:,-3:-1:1])\n",
    "train_test(principalComponents, principalComponents_test, y_train, y_test, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=8)\n",
    "principalComponents = pca.fit_transform(X_train)\n",
    "principalDf = pd.DataFrame(data = principalComponents)\n",
    "y_train2 = y_train.reset_index().drop(['index'], axis=1)\n",
    "finalDf = pd.concat([principalDf, y_train2], axis = 1)\n",
    "principalComponents_test = pca.fit_transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>principal component 1</th>\n      <th>principal component 2</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-4.14978</td>\n      <td>-0.97230</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-1.67788</td>\n      <td>-1.34834</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.41252</td>\n      <td>1.13753</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-1.23750</td>\n      <td>1.80490</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-4.14436</td>\n      <td>1.09175</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>421</th>\n      <td>1.53700</td>\n      <td>0.56607</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>422</th>\n      <td>2.24347</td>\n      <td>-3.39819</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>423</th>\n      <td>2.19976</td>\n      <td>0.22078</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>424</th>\n      <td>-2.89820</td>\n      <td>-1.27488</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>425</th>\n      <td>-4.76315</td>\n      <td>0.13712</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>426 rows × 3 columns</p>\n</div>",
      "text/plain": "     principal component 1  principal component 2  target\n0                 -4.14978               -0.97230       1\n1                 -1.67788               -1.34834       1\n2                  1.41252                1.13753       0\n3                 -1.23750                1.80490       1\n4                 -4.14436                1.09175       0\n..                     ...                    ...     ...\n421                1.53700                0.56607       1\n422                2.24347               -3.39819       1\n423                2.19976                0.22078       1\n424               -2.89820               -1.27488       0\n425               -4.76315                0.13712       1\n\n[426 rows x 3 columns]"
     },
     "execution_count": 734,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 576x576 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "ax.set_title('2 component PCA', fontsize = 20)\n",
    "targets = ['0','1']\n",
    "colors = ['r',  'b']\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = (finalDf['target'] == target)\n",
    "    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1']\n",
    "               , finalDf.loc[indicesToKeep, 'principal component 2']\n",
    "               , c = color\n",
    "               , s = 50)\n",
    "ax.legend(targets)\n",
    "ax.grid()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fetchData import fetchdata \n",
    "import __MLP\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "((412, 36), (73, 36))"
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([412, 1, 36])\n",
      "torch.Size([412, 1])\n",
      "Train Size 412 Test Size 73\n"
     ]
    }
   ],
   "source": [
    "# tensor_x1 = torch.Tensor(pheme_sparse.values).unsqueeze(1)\n",
    "# tensor_x1 = torch.Tensor(X_train.values).unsqueeze(1)\n",
    "tensor_y1 = torch.Tensor(y_train.values).unsqueeze(1)\n",
    "tensor_x1 = torch.Tensor(X_train).unsqueeze(1)\n",
    "train_dataset = TensorDataset(tensor_x1,tensor_y1)\n",
    "\n",
    "# tensor_x2 = torch.Tensor(ext_sparse.values).unsqueeze(1)\n",
    "# tensor_x2 = torch.Tensor(X_test.values).unsqueeze(1)\n",
    "tensor_y2 = torch.Tensor(y_test.values).unsqueeze(1)\n",
    "tensor_x2 = torch.Tensor(X_test).unsqueeze(1)\n",
    "test_dataset = TensorDataset(tensor_x2,tensor_y2)\n",
    "\n",
    "\n",
    "# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
    "batch_size = 16\n",
    "\n",
    "# Initialize WeightedRandomSampler to deal with the unbalanced dataset\n",
    "counts = np.bincount(y_train.values)\n",
    "labels_weights = 1. / counts\n",
    "weights = labels_weights[y_train.values]\n",
    "train_sampler = WeightedRandomSampler(weights, len(weights))\n",
    "test_sampler = SequentialSampler(tensor_x2)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler, num_workers=2)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "train_size = int(tensor_y1.size(0))\n",
    "test_size = int(tensor_y2.size(0))\n",
    "print(tensor_x1.shape)\n",
    "print(tensor_y1.shape)\n",
    "print(\"Train Size\",train_size,\"Test Size\",test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sparse_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(sparse_model, self).__init__() # 1*20\n",
    "        self.fc1 = nn.Linear(36, 10, bias=True) # 420\n",
    "        self.fc3 = nn.Linear(10, 1)\n",
    "\n",
    "        self.drop_3 = nn.Dropout(0.3)\n",
    "        self.drop_4 = nn.Dropout(0.4)\n",
    "        self.drop_2 = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.drop_3(F.elu(self.fc1(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sparse = sparse_model()\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# optimizer = optim.SGD(model_sparse.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizer = optim.Adam(model_sparse.parameters(), lr=5e-4, eps=1e-8, weight_decay=1e-6)\n",
    "# scheduler = lr_scheduler.ExponentialLR(optimizer, gamma= 0.99)  \n",
    "\n",
    "epochs = 100\n",
    "\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps=0,  # Default value\n",
    "                                            num_training_steps=total_steps)\n",
    "\n",
    "PATH = \"./Model/state_dict_sparse_model.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf_report(train_loss, train_acc, val_loss, val_acc):\n",
    "    fig, ax = plt.subplots(4, 1, figsize=(12,8))\n",
    "    ax[0].plot(train_loss[:])\n",
    "    ax[0].set_ylabel('Loss')\n",
    "    ax[0].set_title('Training Loss')\n",
    "\n",
    "    ax[1].plot(train_acc[:])\n",
    "    ax[1].set_ylabel('Classification Accuracy')\n",
    "    ax[1].set_title('Training Accuracy')\n",
    "\n",
    "    ax[2].plot(val_loss[:])\n",
    "    ax[2].set_ylabel('Classification Accuracy')\n",
    "    ax[2].set_title('Testing Loss')\n",
    "\n",
    "    ax[3].plot(val_acc[:])\n",
    "    ax[3].set_ylabel('Classification Accuracy')\n",
    "    ax[3].set_title('Testing Accuracy')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Min of Training Loss: %4f\"%(np.min(train_loss)))\n",
    "    print(\"Max of Training Accuracy: %4f\"%(np.max(train_acc)))\n",
    "    print(\"Mean of Training Loss: %4f\"%(np.mean(train_loss)))\n",
    "    print(\"Mean of Training Accuracy: %4f\"%(np.mean(train_acc)))\n",
    "    print(\"----\")\n",
    "    print(\"Max of Testing Accuracy: %4f\"%(np.max(val_acc)))\n",
    "    print(\"Mean of Testing Loss: %4f\"%(np.mean(val_loss_list)))\n",
    "    print(\"Mean of Testing Accuracy: %4f\"%(np.mean(val_acc)))\n",
    "\n",
    "def set_seed(seed_value=42):\n",
    "    \"\"\"Set seed for reproducibility.\n",
    "    \"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "def train1(model, num_epochs, criterion, optimizer, scheduler, train_loader, train_size, test_loader=None, test_size=None, patience=5, PATH='./state_dict_model.pt'):\n",
    "    set_seed(42)\n",
    "    train_loss = []\n",
    "    patience_count = 0\n",
    "    train_accuracy = []\n",
    "    prev_loss = 10\n",
    "    best_loss = 10.0\n",
    "    val_corrects_list = []\n",
    "    val_loss_list = []\n",
    "    val_acc_list = []\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        # print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        # print('-' * 10)\n",
    "        running_corrects = 0.0\n",
    "        running_loss = 0.0\n",
    "        model.train()  # Set model to training mode\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.float(), labels.float()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            #  _, predictions = torch.max(outputs.data, 1) won’t work if your output only contains a single output unit.\n",
    "            # _, preds = torch.max(outputs, 1)\n",
    "            # print(outputs.flatten().size())\n",
    "            preds = outputs.squeeze(1) > 0.0\n",
    "\n",
    "            loss = criterion(outputs, labels.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # step function\n",
    "            scheduler.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / train_size\n",
    "        # print(running_loss)\n",
    "        # print(train_size)\n",
    "        epoch_acc = running_corrects.double() / train_size\n",
    "        train_loss.append(epoch_loss)\n",
    "        train_accuracy.append(epoch_acc)\n",
    "\n",
    "        if (epoch % 2 == 0):\n",
    "            print('Epoch {}/{}\\tTrain) Acc: {:.4f}, Loss: {:.4f}'.format(epoch,\n",
    "                                                                         num_epochs - 1, epoch_acc, epoch_loss))\n",
    "\n",
    "        if (test_loader != None):\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_loss = 0.0\n",
    "                val_corrects = 0\n",
    "                val_preds_list = []\n",
    "                val_label_list = []\n",
    "                for j, val in enumerate(test_loader, 0):\n",
    "                    val_x, val_label = val\n",
    "                    val_x, val_label = val_x.float(), val_label.float()\n",
    "                    val_outputs = model(val_x)\n",
    "                    # _, val_preds = torch.max(val_outputs, 1)\n",
    "                    val_preds = val_outputs.squeeze(1) > 0.0\n",
    "\n",
    "                    val_preds_list.append(val_preds)\n",
    "                    val_label_list.append(val_label)\n",
    "                    v_loss = criterion(val_outputs, val_label.unsqueeze(1))\n",
    "                    val_loss += (v_loss.item() * val_x.size(0))\n",
    "                    val_corrects += torch.sum(val_preds == val_label)\n",
    "                    # accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
    "\n",
    "                if (epoch % 2 == 0):\n",
    "                    val_preds_list = torch.cat(val_preds_list, 0)\n",
    "                    val_label_list = torch.cat(val_label_list, 0)\n",
    "                    # print(\"\\t\\tValidation) Acc: {:.4f} Loss:{:.4f} F1 score: {:4f}\".format(val_corrects/test_size, val_loss/test_size, f1_score(val_label_list,val_preds_list,average='macro')))\n",
    "                    print(\"\\t\\tValidation) Acc: {:.4f} Loss:{:.4f}\".format(\n",
    "                        val_corrects/test_size, val_loss/test_size))\n",
    "            val_corrects_list.append(val_corrects/test_size)\n",
    "            val_loss_list.append(val_loss/test_size)\n",
    "            val_acc = val_corrects.double() / test_size\n",
    "            val_acc_list.append(val_acc)\n",
    "\n",
    "        if epoch_loss < best_loss:\n",
    "            # print(\"prev_loss: {:.5f}\".format(prev_loss))\n",
    "            # print(\"loss: {:.5f}\".format(loss))\n",
    "            print(\n",
    "                \"\\t\\tSaving the best model w/ loss {:.4f}\".format(epoch_loss))\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "            best_loss = epoch_loss\n",
    "            patience_count = 0\n",
    "        elif best_loss < epoch_loss:\n",
    "            patience_count += 1\n",
    "        if patience_count >= patience:\n",
    "            print(\"Finishing the Model: Loss is not decreasing...\")\n",
    "            print(train_loss[-6:-1])\n",
    "            return train_accuracy, train_loss, val_acc_list, val_loss_list\n",
    "    return train_accuracy, train_loss, val_acc_list, val_loss_list\n",
    "\n",
    "def train2(model, num_epochs, criterion, optimizer, train_loader, train_size, test_loader=None, test_size=None, patience=5, PATH='./state_dict_model.pt'):\n",
    "    set_seed(42)\n",
    "    train_loss = []\n",
    "    patience_count = 0\n",
    "    train_accuracy = []\n",
    "    prev_loss = 10\n",
    "    best_loss = 10.0\n",
    "    val_corrects_list = []\n",
    "    val_loss_list = []\n",
    "    val_acc_list = []\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        # print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        # print('-' * 10)\n",
    "        running_corrects = 0.0\n",
    "        running_loss = 0.0\n",
    "        model.train()  # Set model to training mode\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.float(), labels.float()\n",
    "            print(inputs.size())\n",
    "            print(labels.size())\n",
    "            print(inputs.flatten())\n",
    "            print(labels.flatten())\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            print(\"outputs:\",outputs.size())\n",
    "            print(\"outputs:\",outputs)\n",
    "            print(\"labels:\",labels.size())\n",
    "            print(\"labels:\",labels.unsqueeze(1).size())\n",
    "\n",
    "            #  _, predictions = torch.max(outputs.data, 1) won’t work if your output only contains a single output unit.\n",
    "            # _, preds = torch.max(outputs, 1)\n",
    "            preds = torch.argmax(outputs, dim=1).flatten()\n",
    "            # print(outputs.flatten().size())\n",
    "            # preds = outputs > 0.0\n",
    "            # labels = labels.view(-1)\n",
    "            loss = criterion(outputs, labels.long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # step function\n",
    "            scheduler.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            # print('running correct')\n",
    "            # print(running_corrects)\n",
    "\n",
    "        epoch_loss = running_loss / train_size\n",
    "        # print(running_loss)\n",
    "        # print(train_size)\n",
    "        epoch_acc = running_corrects.double() / train_size\n",
    "        train_loss.append(epoch_loss)\n",
    "        train_accuracy.append(epoch_acc)\n",
    "\n",
    "        if (epoch % 2 == 0):\n",
    "            print('Epoch {}/{}\\tTrain) Acc: {:.4f}, Loss: {:.4f}'.format(epoch,\n",
    "                                                                         num_epochs - 1, epoch_acc, epoch_loss))\n",
    "\n",
    "        if (test_loader != None):\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_loss = 0.0\n",
    "                val_corrects = 0\n",
    "                val_preds_list = []\n",
    "                val_label_list = []\n",
    "                for j, val in enumerate(test_loader, 0):\n",
    "                    val_x, val_label = val\n",
    "                    val_x, val_label = val_x.float(), val_label.float()\n",
    "                    val_outputs = model(val_x)\n",
    "                    val_preds = torch.argmax(val_outputs, dim=1).flatten()\n",
    "                    # _, val_preds = torch.max(val_outputs, 1)\n",
    "                    # print(\"val_outputs:\",val_outputs.flatten())\n",
    "                    # val_preds = val_outputs > 0.0\n",
    "                    # print(\"val_preds:\",val_preds)\n",
    "                    val_preds_list.append(val_preds)\n",
    "                    val_label_list.append(val_label)\n",
    "                    v_loss = criterion(val_outputs, val_label.unsqueeze(1))\n",
    "                    val_loss += (v_loss.item() * val_x.size(0))\n",
    "                    val_corrects += torch.sum(val_preds ==\n",
    "                                              val_label.data).double()\n",
    "                if (epoch % 2 == 0):\n",
    "                    val_preds_list = torch.cat(val_preds_list, 0)\n",
    "                    val_label_list = torch.cat(val_label_list, 0)\n",
    "                    # print(\"\\t\\tValidation) Acc: {:.4f} Loss:{:.4f} F1 score: {:4f}\".format(val_corrects/test_size, val_loss/test_size, f1_score(val_label_list,val_preds_list,average='macro')))\n",
    "                    print(\"\\t\\tValidation) Acc: {:.4f} Loss:{:.4f}\".format(\n",
    "                        val_corrects/test_size, val_loss/test_size))\n",
    "            val_corrects_list.append(val_corrects/test_size)\n",
    "            val_loss_list.append(val_loss/test_size)\n",
    "            val_acc = val_corrects.double() / test_size\n",
    "            val_acc_list.append(val_acc)\n",
    "\n",
    "        if epoch_loss < best_loss:\n",
    "            # print(\"prev_loss: {:.5f}\".format(prev_loss))\n",
    "            # print(\"loss: {:.5f}\".format(loss))\n",
    "            print(\n",
    "                \"\\t\\tSaving the best model w/ loss {:.4f}\".format(epoch_loss))\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "            best_loss = epoch_loss\n",
    "            patience_count = 0\n",
    "        elif best_loss < epoch_loss:\n",
    "            patience_count += 1\n",
    "        if patience_count >= patience:\n",
    "            print(\"Finishing the Model: Loss is not decreasing...\")\n",
    "            print(train_loss[-6:-1])\n",
    "            return train_accuracy, train_loss, val_acc_list, val_loss_list\n",
    "    return train_accuracy, train_loss, val_acc_list, val_loss_list\n",
    "\n",
    "def predict(model, criterion, val_dataloader, val_size):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "        for j, val in enumerate(val_dataloader, 0):\n",
    "            val_x, val_label = val\n",
    "            val_x, val_label = val_x.float(), val_label.float()\n",
    "            val_outputs = model(val_x)\n",
    "            val_preds = val_outputs.squeeze(1) > 0.0\n",
    "\n",
    "            val_preds_list.append(val_preds)\n",
    "            val_label_list.append(val_label)\n",
    "            v_loss = criterion(val_outputs, val_label.unsqueeze(1))\n",
    "            val_loss += (v_loss.item() * val_x.size(0))\n",
    "            val_corrects += torch.sum(val_preds == val_label)\n",
    "\n",
    "    val_preds_list = torch.cat(val_preds_list, 0)\n",
    "    val_label_list = torch.cat(val_label_list, 0)\n",
    "    val_corrects = val_corrects/val_size\n",
    "    val_loss/test_size\n",
    "    val_acc = val_corrects.double() / val_size\n",
    "    print(\"\\t\\tValidation) Acc: {:.4f} Loss:{:.4f}\".format(\n",
    "        val_corrects/val_size, val_loss/test_size))\n",
    "    # print(\"\\t\\tValidation) Acc: {:.4f} Loss:{:.4f} F1 score: {:4f}\".format(val_corrects/val_size, val_loss/test_size, f1_score(val_label_list,val_preds_list,average='macro')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/99\tTrain) Acc: 0.5461, Loss: 0.6817\n",
      "\t\tValidation) Acc: 0.6438 Loss:0.6576\n",
      "\t\tSaving the best model w/ loss 0.6817\n",
      "\t\tSaving the best model w/ loss 0.6529\n",
      "Epoch 2/99\tTrain) Acc: 0.6893, Loss: 0.6344\n",
      "\t\tValidation) Acc: 0.6712 Loss:0.6370\n",
      "\t\tSaving the best model w/ loss 0.6344\n",
      "\t\tSaving the best model w/ loss 0.6104\n",
      "Epoch 4/99\tTrain) Acc: 0.7476, Loss: 0.5902\n",
      "\t\tValidation) Acc: 0.6301 Loss:0.6215\n",
      "\t\tSaving the best model w/ loss 0.5902\n",
      "Epoch 6/99\tTrain) Acc: 0.7816, Loss: 0.5631\n",
      "\t\tValidation) Acc: 0.6849 Loss:0.6047\n",
      "\t\tSaving the best model w/ loss 0.5631\n",
      "Epoch 8/99\tTrain) Acc: 0.7743, Loss: 0.5493\n",
      "\t\tValidation) Acc: 0.6849 Loss:0.5905\n",
      "\t\tSaving the best model w/ loss 0.5493\n",
      "Epoch 10/99\tTrain) Acc: 0.7597, Loss: 0.5421\n",
      "\t\tValidation) Acc: 0.6986 Loss:0.5717\n",
      "\t\tSaving the best model w/ loss 0.5421\n",
      "\t\tSaving the best model w/ loss 0.5282\n",
      "Epoch 12/99\tTrain) Acc: 0.7718, Loss: 0.5323\n",
      "\t\tValidation) Acc: 0.7260 Loss:0.5587\n",
      "Epoch 14/99\tTrain) Acc: 0.7816, Loss: 0.5158\n",
      "\t\tValidation) Acc: 0.7397 Loss:0.5441\n",
      "\t\tSaving the best model w/ loss 0.5158\n",
      "\t\tSaving the best model w/ loss 0.4838\n",
      "Epoch 16/99\tTrain) Acc: 0.7524, Loss: 0.5174\n",
      "\t\tValidation) Acc: 0.7671 Loss:0.5281\n",
      "Epoch 18/99\tTrain) Acc: 0.7549, Loss: 0.5112\n",
      "\t\tValidation) Acc: 0.8082 Loss:0.5106\n",
      "\t\tSaving the best model w/ loss 0.4636\n",
      "Epoch 20/99\tTrain) Acc: 0.7937, Loss: 0.4889\n",
      "\t\tValidation) Acc: 0.8219 Loss:0.4971\n",
      "Epoch 22/99\tTrain) Acc: 0.7913, Loss: 0.4792\n",
      "\t\tValidation) Acc: 0.8356 Loss:0.4840\n",
      "\t\tSaving the best model w/ loss 0.4223\n",
      "Epoch 24/99\tTrain) Acc: 0.8058, Loss: 0.4452\n",
      "\t\tValidation) Acc: 0.8219 Loss:0.4717\n",
      "Epoch 26/99\tTrain) Acc: 0.8252, Loss: 0.4277\n",
      "\t\tValidation) Acc: 0.8219 Loss:0.4639\n",
      "Epoch 28/99\tTrain) Acc: 0.8107, Loss: 0.4658\n",
      "\t\tValidation) Acc: 0.8219 Loss:0.4472\n",
      "Finishing the Model: Loss is not decreasing...\n",
      "[0.422334314260668, 0.4451988524603612, 0.44099618161766274, 0.427662959955271, 0.4354493134808772]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "train_acc, train_loss, val_acc, val_loss_list = train1(model=model_sparse, num_epochs=epochs,patience=5, criterion=criterion, optimizer=optimizer, scheduler=scheduler, train_loader=train_dataloader, train_size=train_size, test_loader=test_dataloader, test_size=test_size, PATH=PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 864x576 with 4 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min of Training Loss: 0.436889\n",
      "Max of Training Accuracy: 0.840376\n",
      "Mean of Training Loss: 0.540100\n",
      "Mean of Training Accuracy: 0.753521\n",
      "----\n",
      "Max of Testing Accuracy: 0.796610\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'val_loss_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-829-4f5d2641781e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m__MLP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclf_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Code/FYP/code_data/__MLP.py\u001b[0m in \u001b[0;36mclf_report\u001b[0;34m(train_loss, train_acc, val_loss, val_acc)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"----\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Max of Testing Accuracy: %4f\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mean of Testing Loss: %4f\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mean of Testing Accuracy: %4f\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val_loss_list' is not defined"
     ]
    }
   ],
   "source": [
    "__MLP.clf_report(train_loss, train_acc, val_loss_list, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rosetta",
   "language": "python",
   "name": "rosetta"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}