{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행시 등장하는 URL을 클릭하여 허용해주면 인증KEY가 나타난다. 복사하여 URL아래 빈칸에 붙여넣으면 마운트에 성공하게된다.\n",
    "from google.colab import drive\n",
    "drive.mount('./MyDrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd MyDrive/MyDrive/Capstone/code_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/june/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/june/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob2 import glob\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "import gensim\n",
    "import gensim.models.word2vec as w2v\n",
    "from gensim.test.utils import common_texts\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "\n",
    "from nltk import SnowballStemmer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import emoji\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', 400)\n",
    "# pd.set_option('display.max_rowwidth', 100)\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmt = WordNetLemmatizer()\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "freqdist = nltk.FreqDist()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tweet_tokenizer = TweetTokenizer()\n",
    "\n",
    "\"\"\" Replaces contractions from a string to their equivalents \"\"\"\n",
    "contraction_patterns = [ (r'won\\'t', 'will not'), (r'can\\'t', 'cannot'), (r'i\\'m', 'i am'), (r'ain\\'t', 'is not'), (r'(\\w+)\\'ll', '\\g<1> will'), (r'(\\w+)n\\'t', '\\g<1> not'),\n",
    "                         (r'(\\w+)\\'ve', '\\g<1> have'), (r'(\\w+)\\'s', '\\g<1> is'), (r'(\\w+)\\'re', '\\g<1> are'), (r'(\\w+)\\'d', '\\g<1> would'), (r'&', 'and'), (r'dammit', 'damn it'), (r'dont', 'do not'), (r'wont', 'will not'), \n",
    "                         (r'i\\'d', 'i would'), (r'I\\'d', 'I would'), (r'he\\'d', 'he would'), (r'she\\'d', 'she would'), (r'they\\'d', 'they would'), (r'we\\'d', 'we would')]\n",
    "def replaceContraction(text):\n",
    "    patterns = [(re.compile(regex), repl) for (regex, repl) in contraction_patterns]\n",
    "    for (pattern, repl) in patterns:\n",
    "        (text, count) = re.subn(pattern, repl, text)\n",
    "    return text\n",
    "\n",
    "def capitalratio(tweet_text):\n",
    "    uppers = [l for l in tweet_text if l.isupper()]\n",
    "    capitalratio = len(uppers) / len(tweet_text)\n",
    "    return capitalratio \n",
    "\n",
    "def getTokenization(sent):\n",
    "    tweet_tokens = []\n",
    "    sent = sent.lower()\n",
    "    sent = replaceContraction(sent)\n",
    "\n",
    "    sent = re.sub(r\"http\\S+\", \"*\", sent) # http link -> '*'\n",
    "    # sent = re.sub(r\"@\\S+\", \"@\", sent)   # mention -> '@'\n",
    "    sent = re.sub(r\"@[^\\s]+\", \"@\", sent)   # mention -> '@'\n",
    "    sent = re.sub(r\"(#)(\\S+)\", r'\\1 \\2', sent) \n",
    "\n",
    "    sent = re.sub(r'([^\\s\\w@#\\*]|_)+', '', sent) # Erasing Special Characters\n",
    "    # sent = re.sub('@[^\\s]+','atUser',sent)\n",
    "    # sent = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','url',sent)\n",
    "    # sent = re.sub(r'#([^\\s]+)', r'\\1', sent)\n",
    "\n",
    "\n",
    "    # sent = re.sub('', '', sent.lower())\n",
    "    # sent = [tweet_tokenizer.tokenize(sent)]\n",
    "    sent = tweet_tokenizer.tokenize(sent)\n",
    "    sent = [stemmer.stem(token) for token in sent]\n",
    "    sent = [lmt.lemmatize(token) for token in sent]\n",
    "\n",
    "    temp = [token for token in sent if not token in stop_words]\n",
    "    url=0\n",
    "    for token in temp:\n",
    "        if token.startswith('*'):\n",
    "            url+=1\n",
    "    # tweet_tokens.append([temp])\n",
    "    # tweet_tokens.append(tweet_tokenizer.tokenize(sent))\n",
    "    # df_tokens = pd.DataFrame(tweet_tokens, columns=['token'])\n",
    "    return temp, url\n",
    "\n",
    "def extract_urls(entities_dicts):\n",
    "    if len(entities_dicts) < 1:\n",
    "        return 0\n",
    "    if len(entities_dicts) == 1:\n",
    "        return 1\n",
    "    if len(entities_dicts) == 2:\n",
    "        return 2\n",
    "\n",
    "    # urls = []\n",
    "    # urls_expanded = []\n",
    "\n",
    "    # key = 'url'\n",
    "    # key2 = 'expanded_url'\n",
    "    # # print(len(entities_dict))\n",
    "    # for i in entities_dicts:\n",
    "    #     urls.append(i[key])\n",
    "    #     urls_expanded.append(i[key2])\n",
    "    # return 1, urls, urls_expanded\n",
    "\n",
    "def getposcount(tokens):\n",
    "    postag = []\n",
    "    poscount = {}\n",
    "    poscount['Noun']=0\n",
    "    poscount['Verb']=0\n",
    "    poscount['Adjective'] = 0\n",
    "    poscount['Pronoun']=0\n",
    "    poscount['FirstPersonPronoun']=0\n",
    "    poscount['SecondPersonPronoun']=0\n",
    "    poscount['ThirdPersonPronoun']=0\n",
    "    poscount['Adverb']=0\n",
    "    poscount['Numeral']=0\n",
    "    poscount['Conjunction_inj']=0\n",
    "    poscount['Particle']=0\n",
    "    poscount['Determiner']=0\n",
    "    poscount['Modal']=0\n",
    "    poscount['Whs']=0\n",
    "\n",
    "    Nouns = {'NN','NNS','NNP','NNPS'}\n",
    "    Adverbs = {'RB','RBR','RBS'}\n",
    "    Whs = {'WDT','WP','WRB'} # Composition of wh-determiner(that,what), wh-pronoun(who), wh-adverb(how)\n",
    "    Verbs={'VB','VBP','VBZ','VBN','VBG','VBD','To'}\n",
    "    first_person_pronouns=['i','I','me','my','mine','we','us','our','ours'] #'i',\n",
    "    second_person_pronouns=['you','your','yours', 'ya']\n",
    "    third_person_pronouns=['he','she','it','him','her','it','his','hers','its','they','them','their','theirs']\n",
    "\n",
    "    for word in tokens:\n",
    "        w_lower=word.lower()\n",
    "        if w_lower in first_person_pronouns:\n",
    "            poscount['FirstPersonPronoun']+=1\n",
    "        elif w_lower in second_person_pronouns:\n",
    "            poscount['SecondPersonPronoun']+=1\n",
    "        elif w_lower in third_person_pronouns:\n",
    "            poscount['ThirdPersonPronoun']+=1\n",
    "    \n",
    "    postag = nltk.pos_tag(tokens)\n",
    "    for g1 in postag:\n",
    "        if g1[1] in Nouns:\n",
    "            poscount['Noun'] += 1\n",
    "        elif g1[1] in Verbs:\n",
    "            poscount['Verb']+= 1\n",
    "        elif g1[1]=='ADJ'or g1[1]=='JJ':\n",
    "            poscount['Adjective']+=1\n",
    "        elif g1[1]=='PRP' or g1[1]=='PRON' or g1[1]=='PRP$':\n",
    "            poscount['Pronoun']+=1\n",
    "        elif g1[1] in Adverbs or g1[1]=='ADV':\n",
    "            poscount['Adverb']+=1\n",
    "        elif g1[1]=='CD':\n",
    "            poscount['Numeral']+=1\n",
    "        elif g1[1]=='CC' or g1[1]=='IN':\n",
    "            poscount['Conjunction_inj']+=1\n",
    "        elif g1[1]=='RP':\n",
    "            poscount['Particle']+=1\n",
    "        elif g1[1]=='MD':\n",
    "            poscount['Modal']+=1\n",
    "        elif g1[1]=='DT':\n",
    "            poscount['Determiner']+=1\n",
    "        elif g1[1] in Whs:\n",
    "            poscount['Whs']+=1\n",
    "    return poscount\n",
    "\n",
    "def fetchRawText(path, events, tweetType):\n",
    "    jsons = []\n",
    "    for i, event in enumerate(events):\n",
    "        jsons.append(glob('%s/%s/**/%s/*.json' % (path, event,tweetType)))\n",
    "    for i,d in enumerate(jsons): print(\"%s's length is %d\" %(events[i], len(d)))\n",
    "\n",
    "    targets = []\n",
    "    features = []\n",
    "    for index, dataset in enumerate(jsons):\n",
    "        targetEvent = []\n",
    "        dataEvent = []\n",
    "        count = 0  # help var\n",
    "        for jsonFile in dataset:\n",
    "            count += 1\n",
    "            if jsonFile.find(\"non-rumours\") == -1:\n",
    "                targetEvent.append(1)\n",
    "            else:\n",
    "                targetEvent.append(0)\n",
    "\n",
    "            with open(jsonFile, 'r') as f:\n",
    "                for l in f.readlines():\n",
    "                    if not l.strip():  # skip empty lines\n",
    "                        continue\n",
    "                    try:\n",
    "                        json_data = json.loads(l)\n",
    "                    except:\n",
    "                        print (l,\"\\n\\n\")\n",
    "                        break\n",
    "                    dataEvent.append(json_data)\n",
    "        print(index, events[index], len(targetEvent), len(dataEvent))\n",
    "        targets.append(targetEvent)\n",
    "        features.append(dataEvent)\n",
    "\n",
    "    # print(\"\\nNumber of Events:\", len(targets))\n",
    "    # print(\"Number of tweets in the first event:\", len(targets[0]))\n",
    "\n",
    "    # targets은 targetEvent들을 리스트에 담은 것\n",
    "    target_list = []\n",
    "    for event in targets:\n",
    "        for elem in event:\n",
    "            target_list.append(elem)\n",
    "    target = pd.DataFrame(target_list, columns=[\"target\"])\n",
    "\n",
    "    extracted_features = []\n",
    "\n",
    "    extracted = []\n",
    "\n",
    "    for obj_list in features:\n",
    "        extracted_event = []\n",
    "        for obj in obj_list:\n",
    "            output_f = dict()\n",
    "            output_f['text'] = obj['text']\n",
    "            urls_dicts = obj['entities']['urls']\n",
    "            output_f['URLcount'] = extract_urls(urls_dicts)\n",
    "        \n",
    "            # print(type(obj['user']))\n",
    "            # print(obj['user'].contains_key('entities'))\n",
    "            # if ('url' in obj['user']):\n",
    "            #     output_f['hasUserURL'] = 1\n",
    "            #     output_f['user_url'] = 1 if (obj['user']['url'] != None) else 0\n",
    "            # elif ('entities' in obj['user']):\n",
    "            #     output_f['user_entity'] = obj['user']['entities']['url']['urls']\n",
    "            #     # print(obj['user']['entities']['url']['urls'])\n",
    "            #     output_f['user_url'] = obj['user']['entities']['expanded_url']\n",
    "            #     output_f['hasUserURL'] , _ , output_f['user_url'] = extract_urls(obj['user']['entities']['url']['urls'])\n",
    "            # else:\n",
    "            #     # output_f['user_entity'] = None\n",
    "            #     output_f['user_url'] = 0\n",
    "            #     output_f['hasUserURL'] = 0\n",
    "            \n",
    "\n",
    "            output_f['text_token'], output_f['URLcount'] = getTokenization(obj['text'])\n",
    "            '''POS Tagging and text cleansing for POS'''\n",
    "            temp = output_f['text']\n",
    "            temp=  emoji.demojize(temp)\n",
    "            temp = re.sub(r\"(#)(\\S+)\", r'\\1 \\2', temp)\n",
    "            temp = re.sub(r\"http\\S+\", \"\", temp)\n",
    "            temp = replaceContraction(temp.lower())\n",
    "            temp = temp.split()\n",
    "            pos_dict=getposcount(temp)\n",
    "            output_f.update(pos_dict)\n",
    "            output_f['emoji_count'] = emoji.emoji_count(obj['text'])\n",
    "\n",
    "            output_f['char_count'] = len(output_f['text'])\n",
    "            output_f['word_count'] = len(output_f['text'].split())\n",
    "\n",
    "            output_f['has_question'] = \"?\" in output_f[\"text\"]\n",
    "            output_f['has_exclaim'] = \"!\" in output_f[\"text\"]\n",
    "            output_f['has_period'] = \".\" in output_f[\"text\"]\n",
    "\n",
    "            output_f['capital_ratio']=(capitalratio(obj['text']))\n",
    "            output_f['retweet_count'] = obj['retweet_count']\n",
    "            output_f['tweet_count'] = np.log10(obj['user']['statuses_count'])\n",
    "            output_f['listed_count'] = np.log10(obj['user']['listed_count'])\n",
    "            output_f['friends_count'] = np.log10(obj['user']['friends_count'])\n",
    "            output_f['follow_ratio'] = np.log10(obj['user']['followers_count'])\n",
    "\n",
    "            acc_created = datetime.strptime(obj['user']['created_at'], '%a %b %d %H:%M:%S %z %Y')\n",
    "            tweet_created = datetime.strptime(obj['created_at'], '%a %b %d %H:%M:%S %z %Y')\n",
    "            age = (tweet_created - acc_created)\n",
    "            output_f['account_age_days'] = age.days\n",
    "            \n",
    "            output_f['capital_ratio']=(capitalratio(obj['text']))\n",
    "            output_f['verified'] = obj['user']['verified']\n",
    "\n",
    "            extracted_event.append(output_f)\n",
    "        extracted_features.append(extracted_event)\n",
    "\n",
    "    extracted_df = []\n",
    "    for i, data in enumerate(extracted_features):\n",
    "        temp = pd.DataFrame(data)\n",
    "        temp[\"Event\"] = events[i]\n",
    "        extracted_df.append(pd.DataFrame(temp))\n",
    "\n",
    "    final = pd.concat(extracted_df, ignore_index=True)\n",
    "    final = pd.concat([final, target], axis=1)\n",
    "    return final\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHEME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a7e6d1abce43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtweetType\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'source-tweet'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mjsons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mfinal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetchRawText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweetType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverified\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverified\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-d22b68828612>\u001b[0m in \u001b[0;36mfetchRawText\u001b[0;34m(path, events, tweetType)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0mjsons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0mjsons\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s/%s/**/%s/*.json'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtweetType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjsons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s's length is %d\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/glob2/impl.py\u001b[0m in \u001b[0;36mglob\u001b[0;34m(self, pathname, with_matches, include_hidden, recursive, norm_paths, case_sensitive, sep)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mdot\u001b[0m \u001b[0mare\u001b[0m \u001b[0malso\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \"\"\"\n\u001b[0;32m---> 60\u001b[0;31m         return list(self.iglob(pathname, with_matches, include_hidden,\n\u001b[0m\u001b[1;32m     61\u001b[0m                                norm_paths, case_sensitive, sep))\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/glob2/impl.py\u001b[0m in \u001b[0;36m_iglob\u001b[0;34m(self, pathname, rootcall, include_hidden, norm_paths, case_sensitive, sep)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# Resolve ``basename`` expr for every directory found\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_groups\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m             for name, groups in self.resolve_pattern(dirname, basename,\n\u001b[1;32m    128\u001b[0m                                                      \u001b[0;32mnot\u001b[0m \u001b[0mrootcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_hidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/glob2/impl.py\u001b[0m in \u001b[0;36m_iglob\u001b[0;34m(self, pathname, rootcall, include_hidden, norm_paths, case_sensitive, sep)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# Resolve ``basename`` expr for every directory found\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_groups\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m             for name, groups in self.resolve_pattern(dirname, basename,\n\u001b[1;32m    128\u001b[0m                                                      \u001b[0;32mnot\u001b[0m \u001b[0mrootcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_hidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/glob2/impl.py\u001b[0m in \u001b[0;36m_iglob\u001b[0;34m(self, pathname, rootcall, include_hidden, norm_paths, case_sensitive, sep)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# Resolve ``basename`` expr for every directory found\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_groups\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             for name, groups in self.resolve_pattern(dirname, basename,\n\u001b[0m\u001b[1;32m    128\u001b[0m                                                      \u001b[0;32mnot\u001b[0m \u001b[0mrootcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_hidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                                                      norm_paths, case_sensitive, sep):\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/glob2/impl.py\u001b[0m in \u001b[0;36mresolve_pattern\u001b[0;34m(self, dirname, pattern, globstar_with_root, include_hidden, norm_paths, case_sensitive, sep)\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0;31m# having to deal with os.path.normpath() later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mglobstar_with_root\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentries\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m                     \u001b[0m_mkabs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_join_paths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                     \u001b[0mnames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_mkabs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/glob2/impl.py\u001b[0m in \u001b[0;36mwalk\u001b[0;34m(self, top, followlinks, sep)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mnew_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_join_paths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfollowlinks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mislink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollowlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/glob2/impl.py\u001b[0m in \u001b[0;36mwalk\u001b[0;34m(self, top, followlinks, sep)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mnew_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_join_paths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfollowlinks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mislink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollowlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/glob2/impl.py\u001b[0m in \u001b[0;36mwalk\u001b[0;34m(self, top, followlinks, sep)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mnew_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_join_paths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfollowlinks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mislink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollowlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/site-packages/glob2/impl.py\u001b[0m in \u001b[0;36mwalk\u001b[0;34m(self, top, followlinks, sep)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mnew_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_join_paths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mfollowlinks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mislink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollowlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rosetta/lib/python3.8/posixpath.py\u001b[0m in \u001b[0;36mislink\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;34m\"\"\"Test whether a path is a symbolic link\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "path = \"../pheme-rnr-dataset\"\n",
    "events = ['charliehebdo', 'ferguson',\n",
    "          'germanwings-crash', 'ottawashooting', 'sydneysiege']\n",
    "tweetType = 'source-tweet'\n",
    "jsons = []\n",
    "final = fetchRawText(path, events, tweetType)\n",
    "target = final.target\n",
    "final.verified = final.verified.replace({True: 1, False: 0}) \n",
    "final.has_question = final.has_question.replace({True: 1, False: 0}) \n",
    "final.has_exclaim = final.has_exclaim.replace({True: 1, False: 0}) \n",
    "final.has_period = final.has_period.replace({True: 1, False: 0}) \n",
    "final = final.replace(-np.inf, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>URLcount</th>\n      <th>Noun</th>\n      <th>Verb</th>\n      <th>Adjective</th>\n      <th>Pronoun</th>\n      <th>FirstPersonPronoun</th>\n      <th>SecondPersonPronoun</th>\n      <th>ThirdPersonPronoun</th>\n      <th>Adverb</th>\n      <th>Numeral</th>\n      <th>Conjunction_inj</th>\n      <th>Particle</th>\n      <th>Determiner</th>\n      <th>Modal</th>\n      <th>Whs</th>\n      <th>emoji_count</th>\n      <th>char_count</th>\n      <th>word_count</th>\n      <th>has_question</th>\n      <th>has_exclaim</th>\n      <th>has_period</th>\n      <th>capital_ratio</th>\n      <th>retweet_count</th>\n      <th>tweet_count</th>\n      <th>listed_count</th>\n      <th>friends_count</th>\n      <th>follow_ratio</th>\n      <th>account_age_days</th>\n      <th>verified</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>7</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>88</td>\n      <td>12</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.159091</td>\n      <td>177</td>\n      <td>4.803286</td>\n      <td>3.855943</td>\n      <td>2.788168</td>\n      <td>5.287349</td>\n      <td>2126</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>53</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.037736</td>\n      <td>134</td>\n      <td>3.031812</td>\n      <td>2.146128</td>\n      <td>2.574031</td>\n      <td>3.672929</td>\n      <td>1050</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>4</td>\n      <td>4</td>\n      <td>7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>136</td>\n      <td>18</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.073529</td>\n      <td>148</td>\n      <td>3.856245</td>\n      <td>2.879669</td>\n      <td>2.772322</td>\n      <td>4.309651</td>\n      <td>2030</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>4</td>\n      <td>5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>138</td>\n      <td>16</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.101449</td>\n      <td>684</td>\n      <td>4.735814</td>\n      <td>5.009820</td>\n      <td>3.016197</td>\n      <td>7.187664</td>\n      <td>2891</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>7</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>117</td>\n      <td>13</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.145299</td>\n      <td>113</td>\n      <td>5.021181</td>\n      <td>4.132996</td>\n      <td>2.662758</td>\n      <td>5.925434</td>\n      <td>1975</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   URLcount  Noun  Verb  Adjective  Pronoun  FirstPersonPronoun  \\\n0         1     7     2          0        0                   0   \n1         0     3     2          0        0                   0   \n2         0     4     4          7        0                   0   \n3         2     4     5          1        0                   0   \n4         2     7     2          0        0                   0   \n\n   SecondPersonPronoun  ThirdPersonPronoun  Adverb  Numeral  Conjunction_inj  \\\n0                    0                   0       0        0                2   \n1                    0                   0       0        0                1   \n2                    0                   0       1        0                2   \n3                    0                   0       0        0                0   \n4                    0                   0       0        0                2   \n\n   Particle  Determiner  Modal  Whs  emoji_count  char_count  word_count  \\\n0         0           0      0    0            0          88          12   \n1         0           0      0    0            0          53           6   \n2         0           0      0    0            0         136          18   \n3         0           2      0    1            0         138          16   \n4         0           0      0    0            0         117          13   \n\n   has_question  has_exclaim  has_period  capital_ratio  retweet_count  \\\n0             0            0           1       0.159091            177   \n1             0            0           1       0.037736            134   \n2             0            0           1       0.073529            148   \n3             0            0           1       0.101449            684   \n4             0            0           1       0.145299            113   \n\n   tweet_count  listed_count  friends_count  follow_ratio  account_age_days  \\\n0     4.803286      3.855943       2.788168      5.287349              2126   \n1     3.031812      2.146128       2.574031      3.672929              1050   \n2     3.856245      2.879669       2.772322      4.309651              2030   \n3     4.735814      5.009820       3.016197      7.187664              2891   \n4     5.021181      4.132996       2.662758      5.925434              1975   \n\n   verified  \n0         1  \n1         0  \n2         0  \n3         1  \n4         1  "
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.drop(['text_token','text','Event','target'], axis=1, inplace=True)\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv('./data/_PHEME_sparse.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHEME (Extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ebola-essien's length is 14\n",
      "prince-toronto's length is 233\n",
      "putinmissing's length is 238\n",
      "0 ebola-essien 14 14\n",
      "1 prince-toronto 233 233\n",
      "2 putinmissing 238 238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-d22b68828612>:227: RuntimeWarning: divide by zero encountered in log10\n",
      "  output_f['listed_count'] = np.log10(obj['user']['listed_count'])\n",
      "<ipython-input-24-d22b68828612>:228: RuntimeWarning: divide by zero encountered in log10\n",
      "  output_f['friends_count'] = np.log10(obj['user']['friends_count'])\n"
     ]
    }
   ],
   "source": [
    "path = \"../PHEME/all-rnr-annotated-threads\"\n",
    "events = ['ebola-essien', 'prince-toronto', 'putinmissing']\n",
    "tweetType = 'source-tweets'\n",
    "jsons = []\n",
    "final_ext = fetchRawText(path,events,tweetType)\n",
    "ext_target = final_ext.target\n",
    "final_ext.verified = final_ext.verified.replace({True: 1, False: 0}) \n",
    "final_ext.has_question = final_ext.has_question.replace({True: 1, False: 0}) \n",
    "final_ext.has_exclaim = final_ext.has_exclaim.replace({True: 1, False: 0}) \n",
    "final_ext.has_period = final_ext.has_period.replace({True: 1, False: 0}) \n",
    "final_ext = final_ext.replace(-np.inf, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>URLcount</th>\n      <th>Noun</th>\n      <th>Verb</th>\n      <th>Adjective</th>\n      <th>Pronoun</th>\n      <th>FirstPersonPronoun</th>\n      <th>SecondPersonPronoun</th>\n      <th>ThirdPersonPronoun</th>\n      <th>Adverb</th>\n      <th>Numeral</th>\n      <th>Conjunction_inj</th>\n      <th>Particle</th>\n      <th>Determiner</th>\n      <th>Modal</th>\n      <th>Whs</th>\n      <th>emoji_count</th>\n      <th>char_count</th>\n      <th>word_count</th>\n      <th>has_question</th>\n      <th>has_exclaim</th>\n      <th>has_period</th>\n      <th>capital_ratio</th>\n      <th>retweet_count</th>\n      <th>tweet_count</th>\n      <th>listed_count</th>\n      <th>friends_count</th>\n      <th>follow_ratio</th>\n      <th>account_age_days</th>\n      <th>verified</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>69</td>\n      <td>8</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.101449</td>\n      <td>117</td>\n      <td>4.609338</td>\n      <td>2.170262</td>\n      <td>2.814248</td>\n      <td>4.339113</td>\n      <td>1570</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>9</td>\n      <td>6</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>148</td>\n      <td>25</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.027027</td>\n      <td>10402</td>\n      <td>2.706718</td>\n      <td>3.210319</td>\n      <td>2.245513</td>\n      <td>5.688861</td>\n      <td>579</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>7</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>119</td>\n      <td>20</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.025210</td>\n      <td>126</td>\n      <td>4.920290</td>\n      <td>3.335458</td>\n      <td>2.158362</td>\n      <td>5.366137</td>\n      <td>2042</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>5</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>130</td>\n      <td>16</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.107692</td>\n      <td>192</td>\n      <td>4.188872</td>\n      <td>2.783904</td>\n      <td>2.854913</td>\n      <td>4.866571</td>\n      <td>468</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>120</td>\n      <td>15</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.066667</td>\n      <td>196</td>\n      <td>4.920290</td>\n      <td>3.335458</td>\n      <td>2.158362</td>\n      <td>5.366137</td>\n      <td>2039</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   URLcount  Noun  Verb  Adjective  Pronoun  FirstPersonPronoun  \\\n0         1     2     2          1        0                   0   \n1         0     9     6          3        0                   2   \n2         0     7     4          1        1                   0   \n3         2     5     3          2        0                   0   \n4         1     4     4          2        0                   0   \n\n   SecondPersonPronoun  ThirdPersonPronoun  Adverb  Numeral  Conjunction_inj  \\\n0                    0                   0       0        0                1   \n1                    0                   0       3        0                4   \n2                    0                   1       0        0                2   \n3                    0                   0       0        0                1   \n4                    0                   0       1        0                2   \n\n   Particle  Determiner  Modal  Whs  emoji_count  char_count  word_count  \\\n0         0           1      0    0            0          69           8   \n1         0           1      1    0            0         148          25   \n2         0           3      0    1            0         119          20   \n3         0           2      0    0            0         130          16   \n4         0           1      0    0            0         120          15   \n\n   has_question  has_exclaim  has_period  capital_ratio  retweet_count  \\\n0             0            0           1       0.101449            117   \n1             0            0           1       0.027027          10402   \n2             0            0           1       0.025210            126   \n3             0            0           1       0.107692            192   \n4             0            0           1       0.066667            196   \n\n   tweet_count  listed_count  friends_count  follow_ratio  account_age_days  \\\n0     4.609338      2.170262       2.814248      4.339113              1570   \n1     2.706718      3.210319       2.245513      5.688861               579   \n2     4.920290      3.335458       2.158362      5.366137              2042   \n3     4.188872      2.783904       2.854913      4.866571               468   \n4     4.920290      3.335458       2.158362      5.366137              2039   \n\n   verified  \n0         0  \n1         1  \n2         0  \n3         1  \n4         0  "
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_ext.drop(['text_token','text','Event','target'], axis=1, inplace=True)\n",
    "final_ext.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ext.to_csv('./data/_PHEMEext_sparse.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHEME ALL (Reactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from glob2 import glob\n",
    "import json\n",
    "\n",
    "pd.options.display.float_format = '{:.5f}'.format\n",
    "\n",
    "def fetchRawText_all(path, events, tweetType):\n",
    "    jsons = []\n",
    "    for i, event in enumerate(events):\n",
    "        jsons.append(glob('%s/%s/**/%s/[0-9]*.json' % (path, event, tweetType)))\n",
    "    for i,d in enumerate(jsons): print(\"%s's length is %d\" %(events[i], len(d)))\n",
    "\n",
    "    targets = []\n",
    "    features = []\n",
    "    isSrcTweet = []\n",
    "    for index, dataset in enumerate(jsons):\n",
    "        targetEvent = []\n",
    "        dataEvent = []\n",
    "        count = 0  # help var\n",
    "        for jsonFile in dataset:\n",
    "            count += 1\n",
    "            if jsonFile.find(\"non-rumours\") == -1:\n",
    "                targetEvent.append(1)\n",
    "            else:\n",
    "                targetEvent.append(0)\n",
    "            if jsonFile.find(\"source-tweet\") == -1:\n",
    "                isSrcTweet.append(0)\n",
    "            else: #if jsonFile.find(\"reactions\") == 1:\n",
    "                isSrcTweet.append(1)\n",
    "                \n",
    "\n",
    "            with open(jsonFile, 'r') as f:\n",
    "                for l in f.readlines():\n",
    "                    if not l.strip():  # skip empty lines\n",
    "                        continue\n",
    "                    json_data = json.loads(l)\n",
    "                    dataEvent.append(json_data)\n",
    "        targets.append(targetEvent)\n",
    "        features.append(dataEvent)\n",
    "        # isSrcTweet.append(isSrcTweet)\n",
    "\n",
    "    # print(\"\\nNumber of Events:\", len(targets))\n",
    "    # print(\"Number of tweets in the first event:\", len(targets[0]))\n",
    "\n",
    "    # targets은 targetEvent들을 리스트에 담은 것\n",
    "    target_list = []\n",
    "    for event in targets:\n",
    "        for elem in event:\n",
    "            target_list.append(elem)\n",
    "    target = pd.DataFrame(target_list, columns=[\"target\"])\n",
    "    isSrcTweet = pd.DataFrame(isSrcTweet, columns=[\"isSrcTweet\"])\n",
    "\n",
    "    extracted_features = []\n",
    "\n",
    "    extracted = []\n",
    "\n",
    "    NoneList = []\n",
    "\n",
    "    for obj_list in features:\n",
    "        extracted_event = []\n",
    "        for obj in obj_list:\n",
    "            output_f = dict()\n",
    "\n",
    "            if (('id' not in obj)):\n",
    "                print('sth happend')\n",
    "                return obj\n",
    "\n",
    "            if ('text' in obj):\n",
    "                output_f['text'] = obj['text']\n",
    "            else:\n",
    "                output_f['text'] = None\n",
    "            if ('id' in obj):\n",
    "                output_f['id'] = obj['id']\n",
    "            else:\n",
    "                output_f['id'] = None\n",
    "            if ('in_reply_to_status_id' in obj):\n",
    "                output_f['pid'] = obj['in_reply_to_status_id']\n",
    "            else:\n",
    "                output_f['pid'] = None\n",
    "            output_f['emoji_count'] = emoji.emoji_count(obj['text'])\n",
    "            urls_dicts = obj['entities']['urls']\n",
    "            if \"media\" in obj['entities']:\n",
    "                output_f['has_media'] = len(obj['entities']['media'])\n",
    "                # output_f['media_type'] = obj['entities']['media'][0]['type']\n",
    "            else:\n",
    "                output_f['has_media'] = 0\n",
    "                # output_f['media_type'] = 0\n",
    "            output_f['URLcount'] = len(urls_dicts)\n",
    "            # output_f['URLcount'] = extract_urls(urls_dicts)\n",
    "            # temp = obj['text'].lower()\n",
    "            temp = re.sub(r\"http\\S+\", \"HTTPURL\", obj['text'])\n",
    "            verification = 0\n",
    "            verification += len(re.findall(r'is(that|this|it) true', obj['text']))\n",
    "            verification += len(re.findall(r'wh[a]*t[?!|!?][?!|!?]*', obj['text']))\n",
    "            verification += len(re.findall(r'(rumour|rumor|debunk)', obj['text']))\n",
    "            verification += len(re.findall(r'(real?|really?|uncomfirmed)', obj['text']))\n",
    "            verification += len(re.findall(r'(that|this|it) is not true', obj['text']))\n",
    "            verification += len(re.findall(r'(that|this|it) is false', obj['text']))\n",
    "            verification += len(re.findall(r'(h[m]*)', obj['text']))\n",
    "            output_f['Skepticism'] = verification            \n",
    "            url, mention = 0, 0\n",
    "            for token in temp:\n",
    "                if token.startswith('HTTPURL'):\n",
    "                # if token.startswith (r\"http\\S+\"):\n",
    "                    url+=1\n",
    "                if token.startswith('@'):\n",
    "                    mention+=1 \n",
    "            # output_f['URLcount'] = url\n",
    "            output_f['MentionCount'] = mention\n",
    "\n",
    "            '''POS Tagging'''\n",
    "            temp = output_f['text']\n",
    "            temp = replaceContraction(temp.lower())\n",
    "            temp = re.sub(r\"(#)(\\S+)\", '', temp)\n",
    "            temp = re.sub(r\"(@)(\\S+)\", '', temp)\n",
    "            temp = re.sub(r\"http\\S+\", \"\", temp)\n",
    "            temp = re.sub(r'([^\\s\\w#\\*]|_)+', '', temp) # Erasing Special Characters\n",
    "\n",
    "            temp = temp.split()\n",
    "            pos_dict=getposcount(temp)\n",
    "            output_f['token_for_POS'] = temp\n",
    "            output_f.update(pos_dict)\n",
    "\n",
    "            output_f['char_count'] = len(output_f['text'])\n",
    "            output_f['word_count'] = len(output_f['text'].split())\n",
    "\n",
    "            # output_f['HashTag'] = len(obj['entities'][0]['hashtags'])\n",
    "            output_f['HashTag'] = len(obj['entities']['hashtags'])\n",
    "\n",
    "            output_f['has_question'] = \"?\" in output_f[\"text\"]\n",
    "            output_f['has_exclaim'] = \"!\" in output_f[\"text\"]\n",
    "            output_f['has_period'] = \".\" in output_f[\"text\"]\n",
    "\n",
    "            output_f['retweet_count'] = obj['retweet_count']\n",
    "            output_f['isRT'] = obj['retweeted']\n",
    "\n",
    "            output_f['tweet_count'] = np.log10(obj['user']['statuses_count'])\n",
    "            output_f['listed_count'] = np.log10(obj['user']['listed_count'])\n",
    "            output_f['friends_count'] = np.log10(obj['user']['friends_count'])\n",
    "            output_f['follow_ratio'] = np.log10(obj['user']['followers_count'])\n",
    "            \n",
    "            acc_created = datetime.strptime(obj['user']['created_at'], '%a %b %d %H:%M:%S %z %Y')\n",
    "            tweet_created = datetime.strptime(obj['created_at'], '%a %b %d %H:%M:%S %z %Y')\n",
    "            age = (tweet_created - acc_created)\n",
    "            output_f['account_age_days'] = age.days\n",
    "            output_f['tweet_created'] = datetime.timestamp(tweet_created)\n",
    "            # output_f['tweet_created2'] = tweet_created\n",
    "\n",
    "\n",
    "\n",
    "            output_f['capital_ratio']=(capitalratio(obj['text']))\n",
    "            output_f['verified'] = obj['user']['verified']\n",
    "\n",
    "            extracted_event.append(output_f)\n",
    "        extracted_features.append(extracted_event)\n",
    "\n",
    "    extracted_df = []\n",
    "    # print(events)\n",
    "    # print(len(extracted_features))\n",
    "    for i, data in enumerate(extracted_features):\n",
    "        temp = pd.DataFrame(data)\n",
    "        temp[\"Event\"] = events[i]\n",
    "        extracted_df.append(pd.DataFrame(temp))\n",
    "\n",
    "    final = pd.concat(extracted_df, ignore_index=True)\n",
    "    final = pd.concat([final, isSrcTweet ,target], axis=1)\n",
    "    final.pid = final.pid\n",
    "    return final\n",
    "\n",
    "def depth(x):\n",
    "    if type(x) is dict and x:\n",
    "        return 1 + max(depth(x[a]) for a in x)\n",
    "    if type(x) is list and x:\n",
    "        return 1 + max(depth(a) for a in x)\n",
    "    return 0\n",
    "\n",
    "def getThreadData(path, events):\n",
    "    import re\n",
    "\n",
    "    sources = []\n",
    "    for i, event in enumerate(events):\n",
    "        sources.append(glob('%s/%s/*/*' % (path, event)))\n",
    "    roots = []\n",
    "    children = []\n",
    "    features = []\n",
    "    isSrcTweet = []\n",
    "    for num, event in enumerate(sources):\n",
    "        for index, dataset in enumerate(event):\n",
    "            # print(dataset)\n",
    "            # children.append(glob('%s/reactions/*/*' % (dataset)))\n",
    "            childs = [os.path.basename(x) for x in glob('%s/reactions/*.json' % (dataset))]\n",
    "            reext = re.compile(r'(.*?)\\.json')\n",
    "            childs = (reext.match(child) for child in childs)\n",
    "            children.append([match.group(1) for match in childs if match])\n",
    "            # print(dataset)\n",
    "            roots.append(os.path.basename(dataset))\n",
    "\n",
    "    df = pd.DataFrame(roots, columns=['Root'])\n",
    "    df = pd.concat([df,pd.DataFrame(children)],axis=1)\n",
    "    \n",
    "    structfile = []\n",
    "    for i, event in enumerate(events):\n",
    "        structfile.append(glob('%s/%s/**/[0-9]*/structure.json' % (path, event)))\n",
    "\n",
    "    for i,d in enumerate(structfile): print(\"%s's structure.json number is %d\" %(events[i], len(d)))\n",
    "    # print(structfile)\n",
    "\n",
    "    thread_depths = []\n",
    "    thread_roots = []\n",
    "    for index, dataset in enumerate(structfile):\n",
    "        targetEvent = []\n",
    "        dataEvent = []\n",
    "        count = 0  # help var\n",
    "        for jsonFile in dataset:\n",
    "            # print(jsonFile)\n",
    "            match = re.search(\"/([0-9]*)/\", jsonFile)\n",
    "            # p.match(\"lalalaI want this partlalala\").group(1)\n",
    "            rootname = match.group(1) if match else None\n",
    "            # print(rootname)\n",
    "            with open(jsonFile, 'r') as f:\n",
    "                for l in f.readlines():\n",
    "                    if not l.strip():  # skip empty lines\n",
    "                        continue\n",
    "                json_data = json.loads(l)\n",
    "                # print(json_data)\n",
    "                thread_depth = depth(json_data)\n",
    "                thread_depths.append([rootname,thread_depth])\n",
    "                # thread_roots.append(rootname)\n",
    "    df_depth = pd.DataFrame(thread_depths, columns=['Root', 'depth'])\n",
    "    df = pd.merge(df, df_depth, on=\"Root\")\n",
    "                \n",
    "    \n",
    "    # return pd.DataFrame(thread_depths)\n",
    "    return df\n",
    "\n",
    "def getThreadDataPHEME(path, events):\n",
    "    import re\n",
    "\n",
    "    sources = []\n",
    "    for i, event in enumerate(events):\n",
    "        sources.append(glob('%s/%s/*/*' % (path, event)))\n",
    "    roots = []\n",
    "    children = []\n",
    "    features = []\n",
    "    isSrcTweet = []\n",
    "    childs_list=[]\n",
    "    for num, event in enumerate(sources):\n",
    "        for index, dataset in enumerate(event):\n",
    "            # print(dataset)\n",
    "            # children.append(glob('%s/reactions/*/*' % (dataset)))\n",
    "            childs = [os.path.basename(x) for x in glob('%s/reactions/*.json' % (dataset))]\n",
    "            reext = re.compile(r'(.*?)\\.json')\n",
    "            childs = (reext.match(child) for child in childs)\n",
    "            children.append([match.group(1) for match in childs if match])\n",
    "            # print(dataset)\n",
    "            roots.append(os.path.basename(dataset))\n",
    "\n",
    "            # childs_list.append(children)\n",
    "\n",
    "    df = pd.DataFrame(roots, columns=['Root'])\n",
    "    return pd.concat([df,pd.DataFrame(children)],axis=1)\n",
    "    return df\n",
    "    \n",
    "    structfile = []\n",
    "    for i, event in enumerate(events):\n",
    "        structfile.append(glob('%s/%s/**/[0-9]*/structure.json' % (path, event)))\n",
    "\n",
    "    for i,d in enumerate(structfile): print(\"%s's structure.json number is %d\" %(events[i], len(d)))\n",
    "    # print(structfile)\n",
    "\n",
    "    thread_depths = []\n",
    "    thread_roots = []\n",
    "    for index, dataset in enumerate(structfile):\n",
    "        targetEvent = []\n",
    "        dataEvent = []\n",
    "        count = 0  # help var\n",
    "        for jsonFile in dataset:\n",
    "            # print(jsonFile)\n",
    "            match = re.search(\"/([0-9]*)/\", jsonFile)\n",
    "            # p.match(\"lalalaI want this partlalala\").group(1)\n",
    "            rootname = match.group(1) if match else None\n",
    "            # print(rootname)\n",
    "            with open(jsonFile, 'r') as f:\n",
    "                for l in f.readlines():\n",
    "                    if not l.strip():  # skip empty lines\n",
    "                        continue\n",
    "                json_data = json.loads(l)\n",
    "                # print(json_data)\n",
    "                thread_depth = depth(json_data)\n",
    "                thread_depths.append([rootname,thread_depth])\n",
    "                # thread_roots.append(rootname)\n",
    "    df_depth = pd.DataFrame(thread_depths, columns=['Root', 'depth'])\n",
    "    df = pd.merge(df, df_depth, on=\"Root\")\n",
    "                \n",
    "    \n",
    "    # return pd.DataFrame(thread_depths)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def getThreadInfo(structure, df):\n",
    "    threadInfo = []\n",
    "    thread_depth = structure[['Root', 'depth']]\n",
    "    structure = structure.drop('depth', axis=1)\n",
    "    for index, data in enumerate(structure.Root):\n",
    "        tweetInfo = []\n",
    "        # print(\"data: %s\\n\" %(data))\n",
    "        # print(\"data: %s\\n%s\\n\" %(data, structure.loc[index,0:].values))\n",
    "        # print(\"root: %s\\tFirst reaction: %s\\n\" %(data, structure.loc[index,0]))\n",
    "\n",
    "        \n",
    "        pid = int(data)\n",
    "        thread = structure.loc[structure['Root']==pid].dropna(axis=1)\n",
    "        # threadRange = structure.loc[structure['Root']==data].any().sum()-1\n",
    "        # print(structure)\n",
    "        threadRange = len(structure.iloc[index,:].dropna())\n",
    "\n",
    "        # 아래로는 성공적인 Features\n",
    "        friends_count = np.sum([np.sum(df.loc[(df['id'] == int(childid))]['friends_count'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        friends_countavg = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['friends_count'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        words_count = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['word_count'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        char_count = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['char_count'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        hashtagavg = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['HashTag'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        hashtagsum = np.sum([np.sum(df.loc[(df['id'] == int(childid))]['HashTag'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        hashtagpercentage = np.sum([np.any(df.loc[(df['id'] == int(childid))]['HashTag']) for childid in structure.loc[index,:].dropna()])/threadRange\n",
    "        urlavg = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['URLcount'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        urlstd = np.std([np.sum(df.loc[(df['id'] == int(childid))]['URLcount'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        urlratio = np.mean([np.any(df.loc[(df['id'] == int(childid))]['URLcount'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        mentionsum = np.sum([np.sum(df.loc[(df['id'] == int(childid))]['MentionCount'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        mentionavg = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['MentionCount'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        mentionpercentage = np.sum([np.any(df.loc[(df['id'] == int(childid))]['MentionCount'].values) for childid in structure.loc[index,:].dropna()])/threadRange\n",
    "        verifiedratio = np.mean([np.any(df.loc[(df['id'] == int(childid))]['verified'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        verifiedsum = np.sum([np.sum(df.loc[(df['id'] == int(childid))]['verified'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        retweetsum = np.sum([np.sum(df.loc[(df['id'] == int(childid))]['retweet_count'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        retweetavg = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['retweet_count'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        retweetstd = np.std([np.sum(df.loc[(df['id'] == int(childid))]['retweet_count'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        accageavg = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['account_age_days'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        accagestd = np.std([np.sum(df.loc[(df['id'] == int(childid))]['account_age_days'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        emojistd = np.std([np.sum(df.loc[(df['id'] == int(childid))]['emoji_count'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        emojimean = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['emoji_count'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        mediaratio = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['has_media'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        questionratio = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['has_question'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        exclamationratio = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['has_exclaim'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        periodratio = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['has_period'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        FPPmean = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['FirstPersonPronoun'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        FPPstd = np.std([np.sum(df.loc[(df['id'] == int(childid))]['FirstPersonPronoun'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        SPPmean = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['SecondPersonPronoun'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        SPPstd = np.std([np.sum(df.loc[(df['id'] == int(childid))]['SecondPersonPronoun'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        TPPmean = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['ThirdPersonPronoun'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        TPPstd = np.std([np.sum(df.loc[(df['id'] == int(childid))]['ThirdPersonPronoun'].values) for childid in structure.loc[index,:].dropna()])\n",
    "        Skepticismmean = np.mean([np.sum(df.loc[(df['id'] == int(childid))]['Skepticism'].values) for childid in structure.loc[index,:].dropna()])\n",
    "\n",
    "        # Get the lifetime of thread\n",
    "        # root_created = df.loc[(df['id'] == int(pid))].tweet_created.sum()\n",
    "        # try:\n",
    "        #     thread_latest = np.max([np.sum(df.loc[(df['id'] == childid)]['tweet_created'].values) for childid in structure.loc[index,'0':].dropna()])\n",
    "        # except:\n",
    "        # #     print([df.loc[(df['id'] == int(childid))]['tweet_created'].values for childid in structure.loc[index,'0':].dropna()])\n",
    "        #     print(\"error\")\n",
    "\n",
    "        # thread_life = thread_latest - root_created\n",
    "        try:\n",
    "            thread_life = np.max([np.sum(df.loc[(df['id'] == childid)]['tweet_created']) for childid in structure.loc[index,:].dropna()] - df.loc[(df['id'] == pid)].tweet_created.sum())\n",
    "            # if thread_life < 0: thread_life=0\n",
    "        except:\n",
    "            print(\"index:\", index)\n",
    "\n",
    "        # 해당 스레드의 트윗 개수\n",
    "        thread_node_count = len([childid for childid in structure.loc[index,:].dropna()]) \n",
    "        # print(\"thread_node_count:\",thread_node_count,\", threadRange:\",threadRange, \"lastest Thread:\", thread_latest )\n",
    "        # print(structure.loc[structure.Root == data])\n",
    "\n",
    "        tweetInfo.append(data)\n",
    "        tweetInfo.append(friends_count)\n",
    "        tweetInfo.append(friends_countavg)\n",
    "        tweetInfo.append(words_count)\n",
    "        tweetInfo.append(char_count)\n",
    "        tweetInfo.append(hashtagavg)\n",
    "        tweetInfo.append(hashtagsum)\n",
    "        tweetInfo.append(hashtagpercentage)\n",
    "        tweetInfo.append(urlavg)\n",
    "        tweetInfo.append(urlstd)\n",
    "        tweetInfo.append(urlratio)\n",
    "        tweetInfo.append(mentionsum)\n",
    "        tweetInfo.append(mentionavg)\n",
    "        tweetInfo.append(mentionpercentage)\n",
    "        tweetInfo.append(thread_node_count)\n",
    "        tweetInfo.append(verifiedratio)\n",
    "        tweetInfo.append(verifiedsum)\n",
    "        tweetInfo.append(retweetsum)\n",
    "        tweetInfo.append(retweetavg)\n",
    "        tweetInfo.append(retweetstd)\n",
    "        tweetInfo.append(accageavg)\n",
    "        tweetInfo.append(accagestd)\n",
    "        tweetInfo.append(thread_life)\n",
    "        tweetInfo.append(emojistd)\n",
    "        tweetInfo.append(emojimean)\n",
    "        tweetInfo.append(mediaratio)\n",
    "        tweetInfo.append(questionratio)\n",
    "        tweetInfo.append(exclamationratio)\n",
    "        tweetInfo.append(periodratio)\n",
    "        tweetInfo.append(FPPmean)\n",
    "        tweetInfo.append(FPPstd)\n",
    "        tweetInfo.append(SPPmean)\n",
    "        tweetInfo.append(SPPstd)\n",
    "        tweetInfo.append(TPPmean)\n",
    "        tweetInfo.append(TPPstd)\n",
    "        tweetInfo.append(Skepticismmean)\n",
    "\n",
    "        threadInfo.append(tweetInfo)\n",
    "\n",
    "        result = pd.DataFrame(threadInfo, columns=['Root', 'SUM FriendsCount','AVG FriendsCount', 'AVG WordCount', 'AVG CharCount', 'AVG HashTag', 'SUM HashTag', 'Ratio HashTag', 'AVG Url','STD Url','RATIO Url','SUM Mention', 'AVG Mention', 'Ratio Mention', 'Tweets Count', 'Ratio Verified','SUM Verified','SUM RT', 'AVG RT','STD RT', 'AVG AccAge', 'STD AccAge', 'thread_time', \"STD Emoji\",\"AVG Emoji\",\"Ratio Media\",'RATIO Question', 'RATIO Exclaim','RATIO Period', 'AVG FPP','STD FPP','AVG SPP','STD SPP','AVG TPP','STD TPP','AVG Skepticism'])\n",
    "        result = pd.merge(thread_depth, result, on=\"Root\").drop(['Root'], axis=1)\n",
    "    # print(threadInfo)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'structure_ext' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-adb077c51d3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure_ext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'structure_ext' is not defined"
     ]
    }
   ],
   "source": [
    "len(structure_ext.loc[0,'0':].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": "3"
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threadRange = len(structure_ext.loc[9,'0':].dropna())\n",
    "print(threadRange)\n",
    "print(np.sum([np.sum(all_ext.loc[(all_ext['id'] == int(childid))]['HashTag'].values) for childid in structure_ext.loc[9,'0':].dropna()]))\n",
    "np.sum([np.any(all_ext.loc[(all_ext['id'] == int(childid))]['HashTag'].values) for childid in structure_ext.loc[9,'0':].dropna()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PHEME ALL Create\n",
    "\n",
    "420120 Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"../pheme-rnr-dataset\"\n",
    "# events = ['charliehebdo', 'ferguson',\n",
    "#           'germanwings-crash', 'ottawashooting', 'sydneysiege']\n",
    "# # events = ['germanwings-crash']\n",
    "# # events = [eventname+\"-all-rnr-threads\" for eventname in events]\n",
    "\n",
    "# tweetType = '*'\n",
    "# final = fetchRawText_all(path, events, tweetType)\n",
    "final.isRT = final.isRT.replace({True: 1, False: 0}) \n",
    "final.verified = final.verified.replace({True: 1, False: 0}) \n",
    "final.has_question = final.has_question.replace({True: 1, False: 0}) \n",
    "final.has_exclaim = final.has_exclaim.replace({True: 1, False: 0}) \n",
    "final.has_period = final.has_period.replace({True: 1, False: 0}) \n",
    "final = final.replace(-np.inf, 0)\n",
    "\n",
    "all_pheme = final\n",
    "# all_pheme.to_csv('./data/all/_PHEMEall.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "charliehebdo-all-rnr-threads's structure.json number is 2079\n",
      "ferguson-all-rnr-threads's structure.json number is 1143\n",
      "germanwings-crash-all-rnr-threads's structure.json number is 469\n",
      "ottawashooting-all-rnr-threads's structure.json number is 890\n",
      "sydneysiege-all-rnr-threads's structure.json number is 1221\n"
     ]
    }
   ],
   "source": [
    "path = \"../PHEME/all-rnr-annotated-threads\"\n",
    "events = ['charliehebdo', 'ferguson',\n",
    "          'germanwings-crash', 'ottawashooting', 'sydneysiege']\n",
    "events = [eventname+\"-all-rnr-threads\" for eventname in events]\n",
    "pheme_structure = getThreadData(path, events)\n",
    "# pheme_structure.to_csv('./data/all/_PHEME_structure.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Root</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n      <th>24</th>\n      <th>25</th>\n      <th>26</th>\n      <th>27</th>\n      <th>28</th>\n      <th>29</th>\n      <th>30</th>\n      <th>31</th>\n      <th>32</th>\n      <th>33</th>\n      <th>34</th>\n      <th>35</th>\n      <th>36</th>\n      <th>37</th>\n      <th>38</th>\n      <th>39</th>\n      <th>40</th>\n      <th>41</th>\n      <th>42</th>\n      <th>43</th>\n      <th>44</th>\n      <th>45</th>\n      <th>46</th>\n      <th>47</th>\n      <th>48</th>\n      <th>49</th>\n      <th>50</th>\n      <th>51</th>\n      <th>52</th>\n      <th>53</th>\n      <th>54</th>\n      <th>55</th>\n      <th>56</th>\n      <th>57</th>\n      <th>58</th>\n      <th>59</th>\n      <th>60</th>\n      <th>61</th>\n      <th>62</th>\n      <th>63</th>\n      <th>64</th>\n      <th>65</th>\n      <th>66</th>\n      <th>67</th>\n      <th>68</th>\n      <th>69</th>\n      <th>70</th>\n      <th>71</th>\n      <th>72</th>\n      <th>73</th>\n      <th>74</th>\n      <th>75</th>\n      <th>76</th>\n      <th>77</th>\n      <th>78</th>\n      <th>79</th>\n      <th>80</th>\n      <th>81</th>\n      <th>82</th>\n      <th>83</th>\n      <th>84</th>\n      <th>85</th>\n      <th>86</th>\n      <th>87</th>\n      <th>88</th>\n      <th>89</th>\n      <th>90</th>\n      <th>91</th>\n      <th>92</th>\n      <th>93</th>\n      <th>94</th>\n      <th>95</th>\n      <th>96</th>\n      <th>97</th>\n      <th>98</th>\n      <th>99</th>\n      <th>100</th>\n      <th>101</th>\n      <th>102</th>\n      <th>103</th>\n      <th>104</th>\n      <th>105</th>\n      <th>106</th>\n      <th>107</th>\n      <th>108</th>\n      <th>109</th>\n      <th>110</th>\n      <th>111</th>\n      <th>112</th>\n      <th>113</th>\n      <th>114</th>\n      <th>115</th>\n      <th>116</th>\n      <th>117</th>\n      <th>118</th>\n      <th>119</th>\n      <th>120</th>\n      <th>121</th>\n      <th>122</th>\n      <th>123</th>\n      <th>124</th>\n      <th>125</th>\n      <th>126</th>\n      <th>127</th>\n      <th>128</th>\n      <th>129</th>\n      <th>130</th>\n      <th>131</th>\n      <th>132</th>\n      <th>133</th>\n      <th>134</th>\n      <th>135</th>\n      <th>136</th>\n      <th>137</th>\n      <th>138</th>\n      <th>139</th>\n      <th>140</th>\n      <th>141</th>\n      <th>142</th>\n      <th>143</th>\n      <th>144</th>\n      <th>145</th>\n      <th>146</th>\n      <th>147</th>\n      <th>148</th>\n      <th>149</th>\n      <th>150</th>\n      <th>151</th>\n      <th>152</th>\n      <th>153</th>\n      <th>154</th>\n      <th>155</th>\n      <th>156</th>\n      <th>157</th>\n      <th>158</th>\n      <th>159</th>\n      <th>160</th>\n      <th>161</th>\n      <th>162</th>\n      <th>163</th>\n      <th>164</th>\n      <th>165</th>\n      <th>166</th>\n      <th>167</th>\n      <th>168</th>\n      <th>169</th>\n      <th>170</th>\n      <th>171</th>\n      <th>172</th>\n      <th>173</th>\n      <th>174</th>\n      <th>175</th>\n      <th>176</th>\n      <th>177</th>\n      <th>178</th>\n      <th>179</th>\n      <th>180</th>\n      <th>181</th>\n      <th>182</th>\n      <th>183</th>\n      <th>184</th>\n      <th>185</th>\n      <th>186</th>\n      <th>187</th>\n      <th>188</th>\n      <th>189</th>\n      <th>190</th>\n      <th>191</th>\n      <th>192</th>\n      <th>193</th>\n      <th>194</th>\n      <th>195</th>\n      <th>196</th>\n      <th>197</th>\n      <th>198</th>\n      <th>199</th>\n      <th>200</th>\n      <th>201</th>\n      <th>202</th>\n      <th>203</th>\n      <th>204</th>\n      <th>205</th>\n      <th>206</th>\n      <th>207</th>\n      <th>208</th>\n      <th>209</th>\n      <th>210</th>\n      <th>211</th>\n      <th>212</th>\n      <th>213</th>\n      <th>214</th>\n      <th>215</th>\n      <th>216</th>\n      <th>217</th>\n      <th>218</th>\n      <th>219</th>\n      <th>220</th>\n      <th>221</th>\n      <th>222</th>\n      <th>223</th>\n      <th>224</th>\n      <th>225</th>\n      <th>226</th>\n      <th>227</th>\n      <th>228</th>\n      <th>229</th>\n      <th>230</th>\n      <th>231</th>\n      <th>232</th>\n      <th>233</th>\n      <th>234</th>\n      <th>235</th>\n      <th>236</th>\n      <th>237</th>\n      <th>238</th>\n      <th>239</th>\n      <th>240</th>\n      <th>241</th>\n      <th>242</th>\n      <th>243</th>\n      <th>244</th>\n      <th>245</th>\n      <th>246</th>\n      <th>247</th>\n      <th>248</th>\n      <th>249</th>\n      <th>250</th>\n      <th>251</th>\n      <th>252</th>\n      <th>253</th>\n      <th>254</th>\n      <th>255</th>\n      <th>256</th>\n      <th>257</th>\n      <th>258</th>\n      <th>259</th>\n      <th>260</th>\n      <th>261</th>\n      <th>262</th>\n      <th>263</th>\n      <th>264</th>\n      <th>265</th>\n      <th>266</th>\n      <th>267</th>\n      <th>268</th>\n      <th>269</th>\n      <th>270</th>\n      <th>271</th>\n      <th>272</th>\n      <th>273</th>\n      <th>274</th>\n      <th>275</th>\n      <th>276</th>\n      <th>277</th>\n      <th>278</th>\n      <th>279</th>\n      <th>280</th>\n      <th>281</th>\n      <th>282</th>\n      <th>283</th>\n      <th>284</th>\n      <th>285</th>\n      <th>286</th>\n      <th>287</th>\n      <th>288</th>\n      <th>289</th>\n      <th>290</th>\n      <th>291</th>\n      <th>292</th>\n      <th>293</th>\n      <th>294</th>\n      <th>295</th>\n      <th>296</th>\n      <th>297</th>\n      <th>298</th>\n      <th>299</th>\n      <th>300</th>\n      <th>301</th>\n      <th>302</th>\n      <th>303</th>\n      <th>304</th>\n      <th>305</th>\n      <th>306</th>\n      <th>307</th>\n      <th>308</th>\n      <th>309</th>\n      <th>310</th>\n      <th>311</th>\n      <th>312</th>\n      <th>313</th>\n      <th>314</th>\n      <th>315</th>\n      <th>316</th>\n      <th>317</th>\n      <th>318</th>\n      <th>319</th>\n      <th>320</th>\n      <th>321</th>\n      <th>322</th>\n      <th>323</th>\n      <th>324</th>\n      <th>325</th>\n      <th>326</th>\n      <th>327</th>\n      <th>328</th>\n      <th>329</th>\n      <th>330</th>\n      <th>331</th>\n      <th>332</th>\n      <th>333</th>\n      <th>334</th>\n      <th>335</th>\n      <th>336</th>\n      <th>337</th>\n      <th>338</th>\n      <th>339</th>\n      <th>340</th>\n      <th>341</th>\n      <th>342</th>\n      <th>343</th>\n      <th>344</th>\n      <th>depth</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>553529101659566080</td>\n      <td>553530890908098561</td>\n      <td>553547184000339968</td>\n      <td>553546643941761024</td>\n      <td>553530583583047680</td>\n      <td>553547846612295681</td>\n      <td>553529275127963650</td>\n      <td>553546424453836801</td>\n      <td>553543300544618498</td>\n      <td>553546244811792385</td>\n      <td>553547413512675329</td>\n      <td>553545294462197760</td>\n      <td>553548113332285440</td>\n      <td>553530877607948288</td>\n      <td>553545602705793026</td>\n      <td>553546983437115393</td>\n      <td>553530334160384000</td>\n      <td>553531136501362688</td>\n      <td>553547587668553732</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>553587735613952001</td>\n      <td>553588921662455808</td>\n      <td>553588691130941441</td>\n      <td>553591458390097920</td>\n      <td>553689534446465026</td>\n      <td>553588158592733184</td>\n      <td>553588782109564928</td>\n      <td>553591848821092353</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>552816932643405824</td>\n      <td>552823532716298240</td>\n      <td>552852220924788736</td>\n      <td>552885622520958976</td>\n      <td>552817493170204672</td>\n      <td>552817741288443905</td>\n      <td>552819314332811266</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>553515399438811136</td>\n      <td>553516443833495552</td>\n      <td>553523060662611968</td>\n      <td>553520353172267008</td>\n      <td>553516582836928512</td>\n      <td>553943262827143168</td>\n      <td>553516583168253952</td>\n      <td>553522248364343296</td>\n      <td>553979514439888900</td>\n      <td>553529219972468736</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>552808620187217920</td>\n      <td>552809691311775746</td>\n      <td>552809447668457473</td>\n      <td>552809551364624384</td>\n      <td>552814199706230784</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5797</th>\n      <td>544463778780557312</td>\n      <td>544473650309890048</td>\n      <td>544483200735526912</td>\n      <td>544494908392763392</td>\n      <td>544478943899025408</td>\n      <td>544476804137123840</td>\n      <td>544488274530541568</td>\n      <td>544486617709178880</td>\n      <td>544484236992864256</td>\n      <td>544465003223728128</td>\n      <td>544514927788961792</td>\n      <td>544513605836607488</td>\n      <td>544496856739246080</td>\n      <td>544557597852856320</td>\n      <td>544500215236284416</td>\n      <td>544476576025677825</td>\n      <td>544486729260863488</td>\n      <td>544483262081818624</td>\n      <td>544513491663466497</td>\n      <td>544477207343931392</td>\n      <td>544475703811801088</td>\n      <td>544488545725861888</td>\n      <td>544501639487713280</td>\n      <td>544502491195256832</td>\n      <td>544468256870772737</td>\n      <td>544475397166211075</td>\n      <td>544493100903579649</td>\n      <td>544690153654980608</td>\n      <td>544493666015150080</td>\n      <td>544495170075770882</td>\n      <td>544573390044942336</td>\n      <td>544496551260061696</td>\n      <td>544465917409652736</td>\n      <td>544498000840519680</td>\n      <td>544490889465573376</td>\n      <td>544497833517535232</td>\n      <td>544495766191218688</td>\n      <td>544495483079913472</td>\n      <td>544494276873551872</td>\n      <td>544501825626701824</td>\n      <td>544493934898982912</td>\n      <td>544485016504258560</td>\n      <td>544482941943173120</td>\n      <td>544489629835984896</td>\n      <td>544498126087000064</td>\n      <td>544497542478958592</td>\n      <td>544478198344728576</td>\n      <td>544465923080720384</td>\n      <td>544501426223726592</td>\n      <td>544492558010052608</td>\n      <td>544557704073588736</td>\n      <td>544495085606699008</td>\n      <td>544494823709736960</td>\n      <td>544620307852439552</td>\n      <td>544501612673134592</td>\n      <td>544496566258503681</td>\n      <td>544473977369137152</td>\n      <td>544530260533186561</td>\n      <td>544475211652153344</td>\n      <td>544495324824629249</td>\n      <td>544478765880197120</td>\n      <td>544477209516601344</td>\n      <td>544494898742046722</td>\n      <td>544492853670318081</td>\n      <td>544479755815636993</td>\n      <td>544483899431079936</td>\n      <td>544493205585403905</td>\n      <td>544491205690945536</td>\n      <td>544495355081928704</td>\n      <td>544501088137662464</td>\n      <td>544471773719584768</td>\n      <td>544497581985120256</td>\n      <td>544499619489931266</td>\n      <td>544497040202268672</td>\n      <td>544470068319379456</td>\n      <td>544470532955971584</td>\n      <td>544488517020053504</td>\n      <td>544471036037591041</td>\n      <td>544488734922518528</td>\n      <td>544507807685308418</td>\n      <td>544502160742834177</td>\n      <td>544480727111598082</td>\n      <td>544465027928166400</td>\n      <td>544494939842023425</td>\n      <td>544467535404752896</td>\n      <td>544476135367909376</td>\n      <td>544492345010692096</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>5798</th>\n      <td>544305018439204864</td>\n      <td>544315210702794752</td>\n      <td>544310135120592896</td>\n      <td>544450933745541120</td>\n      <td>544732351524536320</td>\n      <td>544732885539094528</td>\n      <td>544305231107198978</td>\n      <td>544733008826470400</td>\n      <td>544731625050099712</td>\n      <td>544317627263647744</td>\n      <td>544307419199729664</td>\n      <td>544731699863900160</td>\n      <td>544314712461434880</td>\n      <td>544732305227804672</td>\n      <td>544342856064720896</td>\n      <td>544306061147389952</td>\n      <td>544733901068185600</td>\n      <td>544305476138057730</td>\n      <td>544733382329262080</td>\n      <td>544730116837113857</td>\n      <td>544681271746899968</td>\n      <td>544731280290906112</td>\n      <td>544308460817362944</td>\n      <td>544306253736841216</td>\n      <td>544733198329344000</td>\n      <td>544732442385342464</td>\n      <td>544730153377861632</td>\n      <td>544730817252315136</td>\n      <td>544317184701251584</td>\n      <td>544732076407537666</td>\n      <td>544733677520187392</td>\n      <td>544732565832482816</td>\n      <td>544353253106786305</td>\n      <td>544733768750469120</td>\n      <td>544732204837130241</td>\n      <td>544681678246252545</td>\n      <td>544732161098936320</td>\n      <td>544345538465136640</td>\n      <td>544731755044143105</td>\n      <td>544733949474668544</td>\n      <td>544732253319094272</td>\n      <td>544346548310921216</td>\n      <td>544450553208930305</td>\n      <td>544346957310091264</td>\n      <td>544345005868191744</td>\n      <td>544323831305752576</td>\n      <td>544306640762458112</td>\n      <td>544733333306245120</td>\n      <td>544732022405885952</td>\n      <td>544574634642137089</td>\n      <td>544733301303676928</td>\n      <td>544316744987594755</td>\n      <td>544733924778590208</td>\n      <td>544733866230296576</td>\n      <td>544730920243453952</td>\n      <td>544305941798477824</td>\n      <td>544315080041435136</td>\n      <td>544316071994347521</td>\n      <td>544305711430127616</td>\n      <td>544310549228425216</td>\n      <td>544308993619816448</td>\n      <td>544733032796921857</td>\n      <td>544704828493279232</td>\n      <td>544305815927394304</td>\n      <td>544733829706293249</td>\n      <td>544733553456844800</td>\n      <td>544731515322916864</td>\n      <td>544730290393219072</td>\n      <td>544731876859318272</td>\n      <td>544732619347619840</td>\n      <td>544307963100667904</td>\n      <td>544731021074505728</td>\n      <td>544305156758994944</td>\n      <td>544729954798555136</td>\n      <td>544731613075357697</td>\n      <td>544730649203322880</td>\n      <td>544733736919912448</td>\n      <td>544731418052816897</td>\n      <td>544732060561461249</td>\n      <td>544306010781806594</td>\n      <td>544730925511483392</td>\n      <td>544731786472087553</td>\n      <td>544732914924417025</td>\n      <td>544705174317846528</td>\n      <td>544731405901905920</td>\n      <td>544323294514520064</td>\n      <td>544732553203429377</td>\n      <td>544731899357569024</td>\n      <td>544733153462853632</td>\n      <td>544306150418956288</td>\n      <td>544732767268126721</td>\n      <td>544582091456147458</td>\n      <td>544305358412324864</td>\n      <td>544546180274077697</td>\n      <td>544306235835957249</td>\n      <td>544686998880268288</td>\n      <td>544574063461810176</td>\n      <td>544731165413081088</td>\n      <td>544733689046122496</td>\n      <td>544535472312053760</td>\n      <td>544309726033375232</td>\n      <td>544867340362727424</td>\n      <td>544305766430416898</td>\n      <td>544450625048956929</td>\n      <td>544306392463851520</td>\n      <td>544732667384979456</td>\n      <td>544548015047184384</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>5799</th>\n      <td>544415816851021824</td>\n      <td>544428170103906304</td>\n      <td>544916189609066496</td>\n      <td>544915155385999360</td>\n      <td>544417985620742147</td>\n      <td>544417068649439232</td>\n      <td>544918572095401984</td>\n      <td>544423583879929856</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>5800</th>\n      <td>544495066258362368</td>\n      <td>544496999723446272</td>\n      <td>544526409683972098</td>\n      <td>544498051188940800</td>\n      <td>544506798603251712</td>\n      <td>544509560883777536</td>\n      <td>544496919259533312</td>\n      <td>544515869972643840</td>\n      <td>544504888550768642</td>\n      <td>544503570758762496</td>\n      <td>544502981904064512</td>\n      <td>544495378452971520</td>\n      <td>544497109593239552</td>\n      <td>544506421052989441</td>\n      <td>544504301931204609</td>\n      <td>544504784347480065</td>\n      <td>544501114071416832</td>\n      <td>544506819893551105</td>\n      <td>544496145066491904</td>\n      <td>544518136322863104</td>\n      <td>544497727561031680</td>\n      <td>544498007425961984</td>\n      <td>544512272270655488</td>\n      <td>544495548846596096</td>\n      <td>544495428788822016</td>\n      <td>544509567535939584</td>\n      <td>544498865014317056</td>\n      <td>544495828036235264</td>\n      <td>544507459638132736</td>\n      <td>544499983215771649</td>\n      <td>544504506437095424</td>\n      <td>544502757194223616</td>\n      <td>544509814512967680</td>\n      <td>544498579877138432</td>\n      <td>544495428923043841</td>\n      <td>544508826771550210</td>\n      <td>544495702450405380</td>\n      <td>544507092200357888</td>\n      <td>544496736363102210</td>\n      <td>544506108162088961</td>\n      <td>544496930366443520</td>\n      <td>544496467516600320</td>\n      <td>544495523303288832</td>\n      <td>544507954222092288</td>\n      <td>544496900763025411</td>\n      <td>544506227850358785</td>\n      <td>544502434958409728</td>\n      <td>544495959221501952</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>5801</th>\n      <td>544419008615702528</td>\n      <td>544430607665618944</td>\n      <td>544420034861207552</td>\n      <td>544448562054959104</td>\n      <td>544439593634779136</td>\n      <td>544420339904573440</td>\n      <td>544427788745592832</td>\n      <td>544440722129031168</td>\n      <td>544421326664896512</td>\n      <td>544425604188090370</td>\n      <td>544439684655378433</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>5802 rows × 347 columns</p>\n</div>",
      "text/plain": "                    Root                   0                   1  \\\n0     553529101659566080  553530890908098561  553547184000339968   \n1     553587735613952001  553588921662455808  553588691130941441   \n2     552816932643405824  552823532716298240  552852220924788736   \n3     553515399438811136  553516443833495552  553523060662611968   \n4     552808620187217920  552809691311775746  552809447668457473   \n...                  ...                 ...                 ...   \n5797  544463778780557312  544473650309890048  544483200735526912   \n5798  544305018439204864  544315210702794752  544310135120592896   \n5799  544415816851021824  544428170103906304  544916189609066496   \n5800  544495066258362368  544496999723446272  544526409683972098   \n5801  544419008615702528  544430607665618944  544420034861207552   \n\n                       2                   3                   4  \\\n0     553546643941761024  553530583583047680  553547846612295681   \n1     553591458390097920  553689534446465026  553588158592733184   \n2     552885622520958976  552817493170204672  552817741288443905   \n3     553520353172267008  553516582836928512  553943262827143168   \n4     552809551364624384  552814199706230784                None   \n...                  ...                 ...                 ...   \n5797  544494908392763392  544478943899025408  544476804137123840   \n5798  544450933745541120  544732351524536320  544732885539094528   \n5799  544915155385999360  544417985620742147  544417068649439232   \n5800  544498051188940800  544506798603251712  544509560883777536   \n5801  544448562054959104  544439593634779136  544420339904573440   \n\n                       5                   6                   7  \\\n0     553529275127963650  553546424453836801  553543300544618498   \n1     553588782109564928  553591848821092353                None   \n2     552819314332811266                None                None   \n3     553516583168253952  553522248364343296  553979514439888900   \n4                   None                None                None   \n...                  ...                 ...                 ...   \n5797  544488274530541568  544486617709178880  544484236992864256   \n5798  544305231107198978  544733008826470400  544731625050099712   \n5799  544918572095401984  544423583879929856                None   \n5800  544496919259533312  544515869972643840  544504888550768642   \n5801  544427788745592832  544440722129031168  544421326664896512   \n\n                       8                   9                  10  \\\n0     553546244811792385  553547413512675329  553545294462197760   \n1                   None                None                None   \n2                   None                None                None   \n3     553529219972468736                None                None   \n4                   None                None                None   \n...                  ...                 ...                 ...   \n5797  544465003223728128  544514927788961792  544513605836607488   \n5798  544317627263647744  544307419199729664  544731699863900160   \n5799                None                None                None   \n5800  544503570758762496  544502981904064512  544495378452971520   \n5801  544425604188090370  544439684655378433                None   \n\n                      11                  12                  13  \\\n0     553548113332285440  553530877607948288  553545602705793026   \n1                   None                None                None   \n2                   None                None                None   \n3                   None                None                None   \n4                   None                None                None   \n...                  ...                 ...                 ...   \n5797  544496856739246080  544557597852856320  544500215236284416   \n5798  544314712461434880  544732305227804672  544342856064720896   \n5799                None                None                None   \n5800  544497109593239552  544506421052989441  544504301931204609   \n5801                None                None                None   \n\n                      14                  15                  16  \\\n0     553546983437115393  553530334160384000  553531136501362688   \n1                   None                None                None   \n2                   None                None                None   \n3                   None                None                None   \n4                   None                None                None   \n...                  ...                 ...                 ...   \n5797  544476576025677825  544486729260863488  544483262081818624   \n5798  544306061147389952  544733901068185600  544305476138057730   \n5799                None                None                None   \n5800  544504784347480065  544501114071416832  544506819893551105   \n5801                None                None                None   \n\n                      17                  18                  19  \\\n0     553547587668553732                None                None   \n1                   None                None                None   \n2                   None                None                None   \n3                   None                None                None   \n4                   None                None                None   \n...                  ...                 ...                 ...   \n5797  544513491663466497  544477207343931392  544475703811801088   \n5798  544733382329262080  544730116837113857  544681271746899968   \n5799                None                None                None   \n5800  544496145066491904  544518136322863104  544497727561031680   \n5801                None                None                None   \n\n                      20                  21                  22  \\\n0                   None                None                None   \n1                   None                None                None   \n2                   None                None                None   \n3                   None                None                None   \n4                   None                None                None   \n...                  ...                 ...                 ...   \n5797  544488545725861888  544501639487713280  544502491195256832   \n5798  544731280290906112  544308460817362944  544306253736841216   \n5799                None                None                None   \n5800  544498007425961984  544512272270655488  544495548846596096   \n5801                None                None                None   \n\n                      23                  24                  25  \\\n0                   None                None                None   \n1                   None                None                None   \n2                   None                None                None   \n3                   None                None                None   \n4                   None                None                None   \n...                  ...                 ...                 ...   \n5797  544468256870772737  544475397166211075  544493100903579649   \n5798  544733198329344000  544732442385342464  544730153377861632   \n5799                None                None                None   \n5800  544495428788822016  544509567535939584  544498865014317056   \n5801                None                None                None   \n\n                      26                  27                  28  \\\n0                   None                None                None   \n1                   None                None                None   \n2                   None                None                None   \n3                   None                None                None   \n4                   None                None                None   \n...                  ...                 ...                 ...   \n5797  544690153654980608  544493666015150080  544495170075770882   \n5798  544730817252315136  544317184701251584  544732076407537666   \n5799                None                None                None   \n5800  544495828036235264  544507459638132736  544499983215771649   \n5801                None                None                None   \n\n                      29                  30                  31  \\\n0                   None                None                None   \n1                   None                None                None   \n2                   None                None                None   \n3                   None                None                None   \n4                   None                None                None   \n...                  ...                 ...                 ...   \n5797  544573390044942336  544496551260061696  544465917409652736   \n5798  544733677520187392  544732565832482816  544353253106786305   \n5799                None                None                None   \n5800  544504506437095424  544502757194223616  544509814512967680   \n5801                None                None                None   \n\n                      32                  33                  34  \\\n0                   None                None                None   \n1                   None                None                None   \n2                   None                None                None   \n3                   None                None                None   \n4                   None                None                None   \n...                  ...                 ...                 ...   \n5797  544498000840519680  544490889465573376  544497833517535232   \n5798  544733768750469120  544732204837130241  544681678246252545   \n5799                None                None                None   \n5800  544498579877138432  544495428923043841  544508826771550210   \n5801                None                None                None   \n\n                      35                  36                  37  \\\n0                   None                None                None   \n1                   None                None                None   \n2                   None                None                None   \n3                   None                None                None   \n4                   None                None                None   \n...                  ...                 ...                 ...   \n5797  544495766191218688  544495483079913472  544494276873551872   \n5798  544732161098936320  544345538465136640  544731755044143105   \n5799                None                None                None   \n5800  544495702450405380  544507092200357888  544496736363102210   \n5801                None                None                None   \n\n                      38                  39                  40  \\\n0                   None                None                None   \n1                   None                None                None   \n2                   None                None                None   \n3                   None                None                None   \n4                   None                None                None   \n...                  ...                 ...                 ...   \n5797  544501825626701824  544493934898982912  544485016504258560   \n5798  544733949474668544  544732253319094272  544346548310921216   \n5799                None                None                None   \n5800  544506108162088961  544496930366443520  544496467516600320   \n5801                None                None                None   \n\n                      41                  42                  43  \\\n0                   None                None                None   \n1                   None                None                None   \n2                   None                None                None   \n3                   None                None                None   \n4                   None                None                None   \n...                  ...                 ...                 ...   \n5797  544482941943173120  544489629835984896  544498126087000064   \n5798  544450553208930305  544346957310091264  544345005868191744   \n5799                None                None                None   \n5800  544495523303288832  544507954222092288  544496900763025411   \n5801                None                None                None   \n\n                      44                  45                  46  \\\n0                   None                None                None   \n1                   None                None                None   \n2                   None                None                None   \n3                   None                None                None   \n4                   None                None                None   \n...                  ...                 ...                 ...   \n5797  544497542478958592  544478198344728576  544465923080720384   \n5798  544323831305752576  544306640762458112  544733333306245120   \n5799                None                None                None   \n5800  544506227850358785  544502434958409728  544495959221501952   \n5801                None                None                None   \n\n                      47                  48                  49  \\\n0                   None                None                None   \n1                   None                None                None   \n2                   None                None                None   \n3                   None                None                None   \n4                   None                None                None   \n...                  ...                 ...                 ...   \n5797  544501426223726592  544492558010052608  544557704073588736   \n5798  544732022405885952  544574634642137089  544733301303676928   \n5799                None                None                None   \n5800                None                None                None   \n5801                None                None                None   \n\n                      50                  51                  52  \\\n0                   None                None                None   \n1                   None                None                None   \n2                   None                None                None   \n3                   None                None                None   \n4                   None                None                None   \n...                  ...                 ...                 ...   \n5797  544495085606699008  544494823709736960  544620307852439552   \n5798  544316744987594755  544733924778590208  544733866230296576   \n5799                None                None                None   \n5800                None                None                None   \n5801                None                None                None   \n\n                      53                  54                  55  \\\n0                   None                None                None   \n1                   None                None                None   \n2                   None                None                None   \n3                   None                None                None   \n4                   None                None                None   \n...                  ...                 ...                 ...   \n5797  544501612673134592  544496566258503681  544473977369137152   \n5798  544730920243453952  544305941798477824  544315080041435136   \n5799                None                None                None   \n5800                None                None                None   \n5801                None                None                None   \n\n                      56                  57                  58  \\\n0                   None                None                None   \n1                   None                None                None   \n2                   None                None                None   \n3                   None                None                None   \n4                   None                None                None   \n...                  ...                 ...                 ...   \n5797  544530260533186561  544475211652153344  544495324824629249   \n5798  544316071994347521  544305711430127616  544310549228425216   \n5799                None                None                None   \n5800                None                None                None   \n5801                None                None                None   \n\n                      59                  60                  61  \\\n0                   None                None                None   \n1                   None                None                None   \n2                   None                None                None   \n3                   None                None                None   \n4                   None                None                None   \n...                  ...                 ...                 ...   \n5797  544478765880197120  544477209516601344  544494898742046722   \n5798  544308993619816448  544733032796921857  544704828493279232   \n5799                None                None                None   \n5800                None                None                None   \n5801                None                None                None   \n\n                      62                  63                  64  \\\n0                   None                None                None   \n1                   None                None                None   \n2                   None                None                None   \n3                   None                None                None   \n4                   None                None                None   \n...                  ...                 ...                 ...   \n5797  544492853670318081  544479755815636993  544483899431079936   \n5798  544305815927394304  544733829706293249  544733553456844800   \n5799                None                None                None   \n5800                None                None                None   \n5801                None                None                None   \n\n                      65                  66                  67  \\\n0                   None                None                None   \n1                   None                None                None   \n2                   None                None                None   \n3                   None                None                None   \n4                   None                None                None   \n...                  ...                 ...                 ...   \n5797  544493205585403905  544491205690945536  544495355081928704   \n5798  544731515322916864  544730290393219072  544731876859318272   \n5799                None                None                None   \n5800                None                None                None   \n5801                None                None                None   \n\n                      68                  69                  70  \\\n0                   None                None                None   \n1                   None                None                None   \n2                   None                None                None   \n3                   None                None                None   \n4                   None                None                None   \n...                  ...                 ...                 ...   \n5797  544501088137662464  544471773719584768  544497581985120256   \n5798  544732619347619840  544307963100667904  544731021074505728   \n5799                None                None                None   \n5800                None                None                None   \n5801                None                None                None   \n\n                      71                  72                  73  \\\n0                   None                None                None   \n1                   None                None                None   \n2                   None                None                None   \n3                   None                None                None   \n4                   None                None                None   \n...                  ...                 ...                 ...   \n5797  544499619489931266  544497040202268672  544470068319379456   \n5798  544305156758994944  544729954798555136  544731613075357697   \n5799                None                None                None   \n5800                None                None                None   \n5801                None                None                None   \n\n                      74                  75                  76  \\\n0                   None                None                None   \n1                   None                None                None   \n2                   None                None                None   \n3                   None                None                None   \n4                   None                None                None   \n...                  ...                 ...                 ...   \n5797  544470532955971584  544488517020053504  544471036037591041   \n5798  544730649203322880  544733736919912448  544731418052816897   \n5799                None                None                None   \n5800                None                None                None   \n5801                None                None                None   \n\n                      77                  78                  79  \\\n0                   None                None                None   \n1                   None                None                None   \n2                   None                None                None   \n3                   None                None                None   \n4                   None                None                None   \n...                  ...                 ...                 ...   \n5797  544488734922518528  544507807685308418  544502160742834177   \n5798  544732060561461249  544306010781806594  544730925511483392   \n5799                None                None                None   \n5800                None                None                None   \n5801                None                None                None   \n\n                      80                  81                  82  \\\n0                   None                None                None   \n1                   None                None                None   \n2                   None                None                None   \n3                   None                None                None   \n4                   None                None                None   \n...                  ...                 ...                 ...   \n5797  544480727111598082  544465027928166400  544494939842023425   \n5798  544731786472087553  544732914924417025  544705174317846528   \n5799                None                None                None   \n5800                None                None                None   \n5801                None                None                None   \n\n                      83                  84                  85  \\\n0                   None                None                None   \n1                   None                None                None   \n2                   None                None                None   \n3                   None                None                None   \n4                   None                None                None   \n...                  ...                 ...                 ...   \n5797  544467535404752896  544476135367909376  544492345010692096   \n5798  544731405901905920  544323294514520064  544732553203429377   \n5799                None                None                None   \n5800                None                None                None   \n5801                None                None                None   \n\n                      86                  87                  88  \\\n0                   None                None                None   \n1                   None                None                None   \n2                   None                None                None   \n3                   None                None                None   \n4                   None                None                None   \n...                  ...                 ...                 ...   \n5797                None                None                None   \n5798  544731899357569024  544733153462853632  544306150418956288   \n5799                None                None                None   \n5800                None                None                None   \n5801                None                None                None   \n\n                      89                  90                  91  \\\n0                   None                None                None   \n1                   None                None                None   \n2                   None                None                None   \n3                   None                None                None   \n4                   None                None                None   \n...                  ...                 ...                 ...   \n5797                None                None                None   \n5798  544732767268126721  544582091456147458  544305358412324864   \n5799                None                None                None   \n5800                None                None                None   \n5801                None                None                None   \n\n                      92                  93                  94  \\\n0                   None                None                None   \n1                   None                None                None   \n2                   None                None                None   \n3                   None                None                None   \n4                   None                None                None   \n...                  ...                 ...                 ...   \n5797                None                None                None   \n5798  544546180274077697  544306235835957249  544686998880268288   \n5799                None                None                None   \n5800                None                None                None   \n5801                None                None                None   \n\n                      95                  96                  97  \\\n0                   None                None                None   \n1                   None                None                None   \n2                   None                None                None   \n3                   None                None                None   \n4                   None                None                None   \n...                  ...                 ...                 ...   \n5797                None                None                None   \n5798  544574063461810176  544731165413081088  544733689046122496   \n5799                None                None                None   \n5800                None                None                None   \n5801                None                None                None   \n\n                      98                  99                 100  \\\n0                   None                None                None   \n1                   None                None                None   \n2                   None                None                None   \n3                   None                None                None   \n4                   None                None                None   \n...                  ...                 ...                 ...   \n5797                None                None                None   \n5798  544535472312053760  544309726033375232  544867340362727424   \n5799                None                None                None   \n5800                None                None                None   \n5801                None                None                None   \n\n                     101                 102                 103  \\\n0                   None                None                None   \n1                   None                None                None   \n2                   None                None                None   \n3                   None                None                None   \n4                   None                None                None   \n...                  ...                 ...                 ...   \n5797                None                None                None   \n5798  544305766430416898  544450625048956929  544306392463851520   \n5799                None                None                None   \n5800                None                None                None   \n5801                None                None                None   \n\n                     104                 105   106   107   108   109   110  \\\n0                   None                None  None  None  None  None  None   \n1                   None                None  None  None  None  None  None   \n2                   None                None  None  None  None  None  None   \n3                   None                None  None  None  None  None  None   \n4                   None                None  None  None  None  None  None   \n...                  ...                 ...   ...   ...   ...   ...   ...   \n5797                None                None  None  None  None  None  None   \n5798  544732667384979456  544548015047184384  None  None  None  None  None   \n5799                None                None  None  None  None  None  None   \n5800                None                None  None  None  None  None  None   \n5801                None                None  None  None  None  None  None   \n\n       111   112   113   114   115   116   117   118   119   120   121   122  \\\n0     None  None  None  None  None  None  None  None  None  None  None  None   \n1     None  None  None  None  None  None  None  None  None  None  None  None   \n2     None  None  None  None  None  None  None  None  None  None  None  None   \n3     None  None  None  None  None  None  None  None  None  None  None  None   \n4     None  None  None  None  None  None  None  None  None  None  None  None   \n...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n5797  None  None  None  None  None  None  None  None  None  None  None  None   \n5798  None  None  None  None  None  None  None  None  None  None  None  None   \n5799  None  None  None  None  None  None  None  None  None  None  None  None   \n5800  None  None  None  None  None  None  None  None  None  None  None  None   \n5801  None  None  None  None  None  None  None  None  None  None  None  None   \n\n       123   124   125   126   127   128   129   130   131   132   133   134  \\\n0     None  None  None  None  None  None  None  None  None  None  None  None   \n1     None  None  None  None  None  None  None  None  None  None  None  None   \n2     None  None  None  None  None  None  None  None  None  None  None  None   \n3     None  None  None  None  None  None  None  None  None  None  None  None   \n4     None  None  None  None  None  None  None  None  None  None  None  None   \n...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n5797  None  None  None  None  None  None  None  None  None  None  None  None   \n5798  None  None  None  None  None  None  None  None  None  None  None  None   \n5799  None  None  None  None  None  None  None  None  None  None  None  None   \n5800  None  None  None  None  None  None  None  None  None  None  None  None   \n5801  None  None  None  None  None  None  None  None  None  None  None  None   \n\n       135   136   137   138   139   140   141   142   143   144   145   146  \\\n0     None  None  None  None  None  None  None  None  None  None  None  None   \n1     None  None  None  None  None  None  None  None  None  None  None  None   \n2     None  None  None  None  None  None  None  None  None  None  None  None   \n3     None  None  None  None  None  None  None  None  None  None  None  None   \n4     None  None  None  None  None  None  None  None  None  None  None  None   \n...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n5797  None  None  None  None  None  None  None  None  None  None  None  None   \n5798  None  None  None  None  None  None  None  None  None  None  None  None   \n5799  None  None  None  None  None  None  None  None  None  None  None  None   \n5800  None  None  None  None  None  None  None  None  None  None  None  None   \n5801  None  None  None  None  None  None  None  None  None  None  None  None   \n\n       147   148   149   150   151   152   153   154   155   156   157   158  \\\n0     None  None  None  None  None  None  None  None  None  None  None  None   \n1     None  None  None  None  None  None  None  None  None  None  None  None   \n2     None  None  None  None  None  None  None  None  None  None  None  None   \n3     None  None  None  None  None  None  None  None  None  None  None  None   \n4     None  None  None  None  None  None  None  None  None  None  None  None   \n...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n5797  None  None  None  None  None  None  None  None  None  None  None  None   \n5798  None  None  None  None  None  None  None  None  None  None  None  None   \n5799  None  None  None  None  None  None  None  None  None  None  None  None   \n5800  None  None  None  None  None  None  None  None  None  None  None  None   \n5801  None  None  None  None  None  None  None  None  None  None  None  None   \n\n       159   160   161   162   163   164   165   166   167   168   169   170  \\\n0     None  None  None  None  None  None  None  None  None  None  None  None   \n1     None  None  None  None  None  None  None  None  None  None  None  None   \n2     None  None  None  None  None  None  None  None  None  None  None  None   \n3     None  None  None  None  None  None  None  None  None  None  None  None   \n4     None  None  None  None  None  None  None  None  None  None  None  None   \n...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n5797  None  None  None  None  None  None  None  None  None  None  None  None   \n5798  None  None  None  None  None  None  None  None  None  None  None  None   \n5799  None  None  None  None  None  None  None  None  None  None  None  None   \n5800  None  None  None  None  None  None  None  None  None  None  None  None   \n5801  None  None  None  None  None  None  None  None  None  None  None  None   \n\n       171   172   173   174   175   176   177   178   179   180   181   182  \\\n0     None  None  None  None  None  None  None  None  None  None  None  None   \n1     None  None  None  None  None  None  None  None  None  None  None  None   \n2     None  None  None  None  None  None  None  None  None  None  None  None   \n3     None  None  None  None  None  None  None  None  None  None  None  None   \n4     None  None  None  None  None  None  None  None  None  None  None  None   \n...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n5797  None  None  None  None  None  None  None  None  None  None  None  None   \n5798  None  None  None  None  None  None  None  None  None  None  None  None   \n5799  None  None  None  None  None  None  None  None  None  None  None  None   \n5800  None  None  None  None  None  None  None  None  None  None  None  None   \n5801  None  None  None  None  None  None  None  None  None  None  None  None   \n\n       183   184   185   186   187   188   189   190   191   192   193   194  \\\n0     None  None  None  None  None  None  None  None  None  None  None  None   \n1     None  None  None  None  None  None  None  None  None  None  None  None   \n2     None  None  None  None  None  None  None  None  None  None  None  None   \n3     None  None  None  None  None  None  None  None  None  None  None  None   \n4     None  None  None  None  None  None  None  None  None  None  None  None   \n...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n5797  None  None  None  None  None  None  None  None  None  None  None  None   \n5798  None  None  None  None  None  None  None  None  None  None  None  None   \n5799  None  None  None  None  None  None  None  None  None  None  None  None   \n5800  None  None  None  None  None  None  None  None  None  None  None  None   \n5801  None  None  None  None  None  None  None  None  None  None  None  None   \n\n       195   196   197   198   199   200   201   202   203   204   205   206  \\\n0     None  None  None  None  None  None  None  None  None  None  None  None   \n1     None  None  None  None  None  None  None  None  None  None  None  None   \n2     None  None  None  None  None  None  None  None  None  None  None  None   \n3     None  None  None  None  None  None  None  None  None  None  None  None   \n4     None  None  None  None  None  None  None  None  None  None  None  None   \n...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n5797  None  None  None  None  None  None  None  None  None  None  None  None   \n5798  None  None  None  None  None  None  None  None  None  None  None  None   \n5799  None  None  None  None  None  None  None  None  None  None  None  None   \n5800  None  None  None  None  None  None  None  None  None  None  None  None   \n5801  None  None  None  None  None  None  None  None  None  None  None  None   \n\n       207   208   209   210   211   212   213   214   215   216   217   218  \\\n0     None  None  None  None  None  None  None  None  None  None  None  None   \n1     None  None  None  None  None  None  None  None  None  None  None  None   \n2     None  None  None  None  None  None  None  None  None  None  None  None   \n3     None  None  None  None  None  None  None  None  None  None  None  None   \n4     None  None  None  None  None  None  None  None  None  None  None  None   \n...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n5797  None  None  None  None  None  None  None  None  None  None  None  None   \n5798  None  None  None  None  None  None  None  None  None  None  None  None   \n5799  None  None  None  None  None  None  None  None  None  None  None  None   \n5800  None  None  None  None  None  None  None  None  None  None  None  None   \n5801  None  None  None  None  None  None  None  None  None  None  None  None   \n\n       219   220   221   222   223   224   225   226   227   228   229   230  \\\n0     None  None  None  None  None  None  None  None  None  None  None  None   \n1     None  None  None  None  None  None  None  None  None  None  None  None   \n2     None  None  None  None  None  None  None  None  None  None  None  None   \n3     None  None  None  None  None  None  None  None  None  None  None  None   \n4     None  None  None  None  None  None  None  None  None  None  None  None   \n...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n5797  None  None  None  None  None  None  None  None  None  None  None  None   \n5798  None  None  None  None  None  None  None  None  None  None  None  None   \n5799  None  None  None  None  None  None  None  None  None  None  None  None   \n5800  None  None  None  None  None  None  None  None  None  None  None  None   \n5801  None  None  None  None  None  None  None  None  None  None  None  None   \n\n       231   232   233   234   235   236   237   238   239   240   241   242  \\\n0     None  None  None  None  None  None  None  None  None  None  None  None   \n1     None  None  None  None  None  None  None  None  None  None  None  None   \n2     None  None  None  None  None  None  None  None  None  None  None  None   \n3     None  None  None  None  None  None  None  None  None  None  None  None   \n4     None  None  None  None  None  None  None  None  None  None  None  None   \n...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n5797  None  None  None  None  None  None  None  None  None  None  None  None   \n5798  None  None  None  None  None  None  None  None  None  None  None  None   \n5799  None  None  None  None  None  None  None  None  None  None  None  None   \n5800  None  None  None  None  None  None  None  None  None  None  None  None   \n5801  None  None  None  None  None  None  None  None  None  None  None  None   \n\n       243   244   245   246   247   248   249   250   251   252   253   254  \\\n0     None  None  None  None  None  None  None  None  None  None  None  None   \n1     None  None  None  None  None  None  None  None  None  None  None  None   \n2     None  None  None  None  None  None  None  None  None  None  None  None   \n3     None  None  None  None  None  None  None  None  None  None  None  None   \n4     None  None  None  None  None  None  None  None  None  None  None  None   \n...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n5797  None  None  None  None  None  None  None  None  None  None  None  None   \n5798  None  None  None  None  None  None  None  None  None  None  None  None   \n5799  None  None  None  None  None  None  None  None  None  None  None  None   \n5800  None  None  None  None  None  None  None  None  None  None  None  None   \n5801  None  None  None  None  None  None  None  None  None  None  None  None   \n\n       255   256   257   258   259   260   261   262   263   264   265   266  \\\n0     None  None  None  None  None  None  None  None  None  None  None  None   \n1     None  None  None  None  None  None  None  None  None  None  None  None   \n2     None  None  None  None  None  None  None  None  None  None  None  None   \n3     None  None  None  None  None  None  None  None  None  None  None  None   \n4     None  None  None  None  None  None  None  None  None  None  None  None   \n...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n5797  None  None  None  None  None  None  None  None  None  None  None  None   \n5798  None  None  None  None  None  None  None  None  None  None  None  None   \n5799  None  None  None  None  None  None  None  None  None  None  None  None   \n5800  None  None  None  None  None  None  None  None  None  None  None  None   \n5801  None  None  None  None  None  None  None  None  None  None  None  None   \n\n       267   268   269   270   271   272   273   274   275   276   277   278  \\\n0     None  None  None  None  None  None  None  None  None  None  None  None   \n1     None  None  None  None  None  None  None  None  None  None  None  None   \n2     None  None  None  None  None  None  None  None  None  None  None  None   \n3     None  None  None  None  None  None  None  None  None  None  None  None   \n4     None  None  None  None  None  None  None  None  None  None  None  None   \n...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n5797  None  None  None  None  None  None  None  None  None  None  None  None   \n5798  None  None  None  None  None  None  None  None  None  None  None  None   \n5799  None  None  None  None  None  None  None  None  None  None  None  None   \n5800  None  None  None  None  None  None  None  None  None  None  None  None   \n5801  None  None  None  None  None  None  None  None  None  None  None  None   \n\n       279   280   281   282   283   284   285   286   287   288   289   290  \\\n0     None  None  None  None  None  None  None  None  None  None  None  None   \n1     None  None  None  None  None  None  None  None  None  None  None  None   \n2     None  None  None  None  None  None  None  None  None  None  None  None   \n3     None  None  None  None  None  None  None  None  None  None  None  None   \n4     None  None  None  None  None  None  None  None  None  None  None  None   \n...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n5797  None  None  None  None  None  None  None  None  None  None  None  None   \n5798  None  None  None  None  None  None  None  None  None  None  None  None   \n5799  None  None  None  None  None  None  None  None  None  None  None  None   \n5800  None  None  None  None  None  None  None  None  None  None  None  None   \n5801  None  None  None  None  None  None  None  None  None  None  None  None   \n\n       291   292   293   294   295   296   297   298   299   300   301   302  \\\n0     None  None  None  None  None  None  None  None  None  None  None  None   \n1     None  None  None  None  None  None  None  None  None  None  None  None   \n2     None  None  None  None  None  None  None  None  None  None  None  None   \n3     None  None  None  None  None  None  None  None  None  None  None  None   \n4     None  None  None  None  None  None  None  None  None  None  None  None   \n...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n5797  None  None  None  None  None  None  None  None  None  None  None  None   \n5798  None  None  None  None  None  None  None  None  None  None  None  None   \n5799  None  None  None  None  None  None  None  None  None  None  None  None   \n5800  None  None  None  None  None  None  None  None  None  None  None  None   \n5801  None  None  None  None  None  None  None  None  None  None  None  None   \n\n       303   304   305   306   307   308   309   310   311   312   313   314  \\\n0     None  None  None  None  None  None  None  None  None  None  None  None   \n1     None  None  None  None  None  None  None  None  None  None  None  None   \n2     None  None  None  None  None  None  None  None  None  None  None  None   \n3     None  None  None  None  None  None  None  None  None  None  None  None   \n4     None  None  None  None  None  None  None  None  None  None  None  None   \n...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n5797  None  None  None  None  None  None  None  None  None  None  None  None   \n5798  None  None  None  None  None  None  None  None  None  None  None  None   \n5799  None  None  None  None  None  None  None  None  None  None  None  None   \n5800  None  None  None  None  None  None  None  None  None  None  None  None   \n5801  None  None  None  None  None  None  None  None  None  None  None  None   \n\n       315   316   317   318   319   320   321   322   323   324   325   326  \\\n0     None  None  None  None  None  None  None  None  None  None  None  None   \n1     None  None  None  None  None  None  None  None  None  None  None  None   \n2     None  None  None  None  None  None  None  None  None  None  None  None   \n3     None  None  None  None  None  None  None  None  None  None  None  None   \n4     None  None  None  None  None  None  None  None  None  None  None  None   \n...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n5797  None  None  None  None  None  None  None  None  None  None  None  None   \n5798  None  None  None  None  None  None  None  None  None  None  None  None   \n5799  None  None  None  None  None  None  None  None  None  None  None  None   \n5800  None  None  None  None  None  None  None  None  None  None  None  None   \n5801  None  None  None  None  None  None  None  None  None  None  None  None   \n\n       327   328   329   330   331   332   333   334   335   336   337   338  \\\n0     None  None  None  None  None  None  None  None  None  None  None  None   \n1     None  None  None  None  None  None  None  None  None  None  None  None   \n2     None  None  None  None  None  None  None  None  None  None  None  None   \n3     None  None  None  None  None  None  None  None  None  None  None  None   \n4     None  None  None  None  None  None  None  None  None  None  None  None   \n...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n5797  None  None  None  None  None  None  None  None  None  None  None  None   \n5798  None  None  None  None  None  None  None  None  None  None  None  None   \n5799  None  None  None  None  None  None  None  None  None  None  None  None   \n5800  None  None  None  None  None  None  None  None  None  None  None  None   \n5801  None  None  None  None  None  None  None  None  None  None  None  None   \n\n       339   340   341   342   343   344  depth  \n0     None  None  None  None  None  None      2  \n1     None  None  None  None  None  None      4  \n2     None  None  None  None  None  None      2  \n3     None  None  None  None  None  None      3  \n4     None  None  None  None  None  None      2  \n...    ...   ...   ...   ...   ...   ...    ...  \n5797  None  None  None  None  None  None     20  \n5798  None  None  None  None  None  None     20  \n5799  None  None  None  None  None  None      4  \n5800  None  None  None  None  None  None     16  \n5801  None  None  None  None  None  None      3  \n\n[5802 rows x 347 columns]"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pheme_structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PHEME ALL Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125208, 42)\n",
      "(5802, 347)\n"
     ]
    }
   ],
   "source": [
    "all_pheme = pd.read_csv(\"./data/all/_PHEMEall.csv\")\n",
    "structure_pheme = pd.read_csv(\"./data/all/_PHEME_structure.csv\")\n",
    "print(all_pheme.shape)\n",
    "print(structure_pheme.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheme_thread = getThreadInfo(structure_pheme, all_pheme)\n",
    "pheme_thread = pheme_thread.fillna(0)\n",
    "pheme_thread = pheme_thread.replace(-np.inf, 0)\n",
    "pheme_thread.head(15)\n",
    "pheme_thread.to_csv('./data/_PHEME_thread.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PHEME Thread 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PHEMEext Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ebola-essien's length is 226\n",
      "prince-toronto's length is 902\n",
      "putinmissing's length is 835\n",
      "(1963, 42)\n"
     ]
    },
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>id</th>\n      <th>pid</th>\n      <th>emoji_count</th>\n      <th>has_media</th>\n      <th>URLcount</th>\n      <th>Skepticism</th>\n      <th>MentionCount</th>\n      <th>token_for_POS</th>\n      <th>Noun</th>\n      <th>Verb</th>\n      <th>Adjective</th>\n      <th>Pronoun</th>\n      <th>FirstPersonPronoun</th>\n      <th>SecondPersonPronoun</th>\n      <th>ThirdPersonPronoun</th>\n      <th>Adverb</th>\n      <th>Numeral</th>\n      <th>Conjunction_inj</th>\n      <th>Particle</th>\n      <th>Determiner</th>\n      <th>Modal</th>\n      <th>Whs</th>\n      <th>char_count</th>\n      <th>word_count</th>\n      <th>HashTag</th>\n      <th>has_question</th>\n      <th>has_exclaim</th>\n      <th>has_period</th>\n      <th>retweet_count</th>\n      <th>isRT</th>\n      <th>tweet_count</th>\n      <th>listed_count</th>\n      <th>friends_count</th>\n      <th>follow_ratio</th>\n      <th>account_age_days</th>\n      <th>tweet_created</th>\n      <th>capital_ratio</th>\n      <th>verified</th>\n      <th>Event</th>\n      <th>isSrcTweet</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>@Mourinholic 😕😕 http://t.co/sFoV1v8uDo</td>\n      <td>521410632953131008</td>\n      <td>521369179392581632.00000</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>38</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4.89226</td>\n      <td>1.20412</td>\n      <td>3.13799</td>\n      <td>3.56062</td>\n      <td>1569</td>\n      <td>1413148956.00000</td>\n      <td>0.10526</td>\n      <td>0</td>\n      <td>ebola-essien</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>“@Mourinholic: Micheal Essien denying the Ebola rumours like https://t.co/8Yo8iLgISS”</td>\n      <td>521373142347153409</td>\n      <td>521369179392581632.00000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>5</td>\n      <td>1</td>\n      <td>[micheal, essien, denying, the, ebola, rumours, like]</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>85</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3.58827</td>\n      <td>0.90309</td>\n      <td>3.10072</td>\n      <td>3.10653</td>\n      <td>242</td>\n      <td>1413140018.00000</td>\n      <td>0.10588</td>\n      <td>0</td>\n      <td>ebola-essien</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@Mourinholic Hmmm.</td>\n      <td>521369380249432064</td>\n      <td>521369179392581632.00000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>[hmmm]</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>18</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4.52289</td>\n      <td>1.17609</td>\n      <td>1.89209</td>\n      <td>3.14426</td>\n      <td>653</td>\n      <td>1413139121.00000</td>\n      <td>0.11111</td>\n      <td>0</td>\n      <td>ebola-essien</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>@Mourinholic Even though it was against us, it was a bloody amazing goal.</td>\n      <td>521370496928337920</td>\n      <td>521369179392581632.00000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>[even, though, it, was, against, us, it, was, a, bloody, amazing, goal]</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>73</td>\n      <td>13</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.96755</td>\n      <td>0.00000</td>\n      <td>2.35025</td>\n      <td>1.75587</td>\n      <td>1762</td>\n      <td>1413139387.00000</td>\n      <td>0.02740</td>\n      <td>0</td>\n      <td>ebola-essien</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>@CdtChoco1er thanks bro.</td>\n      <td>521370224256614400</td>\n      <td>521370061550809088.00000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>[thanks, bro]</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>24</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4.62381</td>\n      <td>2.20140</td>\n      <td>2.82607</td>\n      <td>4.35601</td>\n      <td>1570</td>\n      <td>1413139322.00000</td>\n      <td>0.08333</td>\n      <td>0</td>\n      <td>ebola-essien</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                                                                    text  \\\n0                                                 @Mourinholic 😕😕 http://t.co/sFoV1v8uDo   \n1  “@Mourinholic: Micheal Essien denying the Ebola rumours like https://t.co/8Yo8iLgISS”   \n2                                                                     @Mourinholic Hmmm.   \n3              @Mourinholic Even though it was against us, it was a bloody amazing goal.   \n4                                                               @CdtChoco1er thanks bro.   \n\n                   id                      pid  emoji_count  has_media  \\\n0  521410632953131008 521369179392581632.00000            2          1   \n1  521373142347153409 521369179392581632.00000            0          0   \n2  521369380249432064 521369179392581632.00000            0          0   \n3  521370496928337920 521369179392581632.00000            0          0   \n4  521370224256614400 521370061550809088.00000            0          0   \n\n   URLcount  Skepticism  MentionCount  \\\n0         0           2             1   \n1         1           5             1   \n2         0           1             1   \n3         0           3             1   \n4         0           2             1   \n\n                                                             token_for_POS  \\\n0                                                                       []   \n1                    [micheal, essien, denying, the, ebola, rumours, like]   \n2                                                                   [hmmm]   \n3  [even, though, it, was, against, us, it, was, a, bloody, amazing, goal]   \n4                                                            [thanks, bro]   \n\n   Noun  Verb  Adjective  Pronoun  FirstPersonPronoun  SecondPersonPronoun  \\\n0     0     0          0        0                   0                    0   \n1     2     2          1        0                   0                    0   \n2     1     0          0        0                   0                    0   \n3     1     2          2        3                   1                    0   \n4     1     1          0        0                   0                    0   \n\n   ThirdPersonPronoun  Adverb  Numeral  Conjunction_inj  Particle  Determiner  \\\n0                   0       0        0                0         0           0   \n1                   0       0        0                1         0           1   \n2                   0       0        0                0         0           0   \n3                   2       1        0                2         0           1   \n4                   0       0        0                0         0           0   \n\n   Modal  Whs  char_count  word_count  HashTag  has_question  has_exclaim  \\\n0      0    0          38           3        0             0            0   \n1      0    0          85           9        0             0            0   \n2      0    0          18           2        0             0            0   \n3      0    0          73          13        0             0            0   \n4      0    0          24           3        0             0            0   \n\n   has_period  retweet_count isRT  tweet_count  listed_count  friends_count  \\\n0           1              0    0      4.89226       1.20412        3.13799   \n1           1              0    0      3.58827       0.90309        3.10072   \n2           1              0    0      4.52289       1.17609        1.89209   \n3           1              0    0      2.96755       0.00000        2.35025   \n4           1              0    0      4.62381       2.20140        2.82607   \n\n   follow_ratio  account_age_days    tweet_created  capital_ratio  verified  \\\n0       3.56062              1569 1413148956.00000        0.10526         0   \n1       3.10653               242 1413140018.00000        0.10588         0   \n2       3.14426               653 1413139121.00000        0.11111         0   \n3       1.75587              1762 1413139387.00000        0.02740         0   \n4       4.35601              1570 1413139322.00000        0.08333         0   \n\n          Event  isSrcTweet  target  \n0  ebola-essien           0       1  \n1  ebola-essien           0       1  \n2  ebola-essien           0       1  \n3  ebola-essien           0       1  \n4  ebola-essien           0       1  "
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../PHEME/all-rnr-annotated-threads\"\n",
    "events = ['ebola-essien', 'prince-toronto', 'putinmissing']\n",
    "# events = ['ebola-essien']\n",
    "tweetType = '*'\n",
    "\n",
    "all_ext = fetchRawText_all(path, events, tweetType)\n",
    "all_ext.isRT = all_ext.isRT.replace({True: 1, False: 0}) \n",
    "all_ext.verified = all_ext.verified.replace({True: 1, False: 0}) \n",
    "all_ext.has_question = all_ext.has_question.replace({True: 1, False: 0}) \n",
    "all_ext.has_exclaim = all_ext.has_exclaim.replace({True: 1, False: 0}) \n",
    "all_ext.has_period = all_ext.has_period.replace({True: 1, False: 0}) \n",
    "all_ext = all_ext.replace(-np.inf, 0)\n",
    "\n",
    "print(all_ext.shape)\n",
    "all_ext.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ext.to_csv('./data/all/_PHEMEextall.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ebola-essien's structure.json number is 14\n",
      "prince-toronto's structure.json number is 233\n",
      "putinmissing's structure.json number is 238\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# ext_structure = getThreadData(path, events)\n",
    "structure_ext = getThreadData(path, events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure_ext.to_csv('./data/all/_PHEMEext_structure.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PHEMEext Thread data PROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1963, 42)\n",
      "(485, 28)\n"
     ]
    }
   ],
   "source": [
    "all_ext = pd.read_csv(\"./data/all/_PHEMEextall.csv\")\n",
    "structure_ext = pd.read_csv(\"./data/all/_PHEMEext_structure.csv\")\n",
    "ext_y = pd.read_csv('./data/_PHEMEext_target.csv')\n",
    "print(all_ext.shape)\n",
    "print(structure_ext.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_ext.loc[all_ext.id.isna() == True] #= all_pheme.id.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUM FriendsCount\tAVG FriendsCount 들이 -inf 값 포함\n",
    "ext_thread = getThreadInfo(structure_ext, all_ext)\n",
    "ext_thread = ext_thread.fillna(0)\n",
    "ext_thread = ext_thread.replace(-np.inf, 0)\n",
    "ext_thread.head(15)\n",
    "ext_thread.to_csv('./data/_PHEMEext_thread.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 👇 Thread 정보만을 추출한 결과\n",
    "아래의 Features들은 모두 한 Root 트윗에 달린 Thread의 정보를 포함한다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>depth</th>\n      <th>SUM FriendsCount</th>\n      <th>AVG FriendsCount</th>\n      <th>AVG WordCount</th>\n      <th>AVG CharCount</th>\n      <th>AVG HashTag</th>\n      <th>SUM HashTag</th>\n      <th>Ratio HashTag</th>\n      <th>AVG Url</th>\n      <th>STD Url</th>\n      <th>RATIO Url</th>\n      <th>SUM Mention</th>\n      <th>AVG Mention</th>\n      <th>Ratio Mention</th>\n      <th>Tweets Count</th>\n      <th>Ratio Verified</th>\n      <th>SUM Verified</th>\n      <th>SUM RT</th>\n      <th>AVG RT</th>\n      <th>STD RT</th>\n      <th>AVG AccAge</th>\n      <th>STD AccAge</th>\n      <th>thread_time</th>\n      <th>STD Emoji</th>\n      <th>AVG Emoji</th>\n      <th>Ratio Media</th>\n      <th>RATIO Question</th>\n      <th>RATIO Exclaim</th>\n      <th>RATIO Period</th>\n      <th>AVG FPP</th>\n      <th>STD FPP</th>\n      <th>AVG SPP</th>\n      <th>STD SPP</th>\n      <th>AVG TPP</th>\n      <th>STD TPP</th>\n      <th>AVG Skepticism</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>57.63909</td>\n      <td>3.03364</td>\n      <td>18.68421</td>\n      <td>116.94737</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.26316</td>\n      <td>0.44035</td>\n      <td>0.26316</td>\n      <td>32.00000</td>\n      <td>1.68421</td>\n      <td>0.94737</td>\n      <td>19</td>\n      <td>0.05263</td>\n      <td>1.00000</td>\n      <td>179.00000</td>\n      <td>9.42105</td>\n      <td>39.50125</td>\n      <td>720.26316</td>\n      <td>955.35553</td>\n      <td>4533.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.15789</td>\n      <td>0.00000</td>\n      <td>0.42105</td>\n      <td>0.05263</td>\n      <td>0.22330</td>\n      <td>0.73684</td>\n      <td>1.20709</td>\n      <td>0.84211</td>\n      <td>1.18158</td>\n      <td>6.00000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>24.49158</td>\n      <td>3.06145</td>\n      <td>12.62500</td>\n      <td>92.75000</td>\n      <td>0.25000</td>\n      <td>2.00000</td>\n      <td>0.25000</td>\n      <td>0.12500</td>\n      <td>0.33072</td>\n      <td>0.12500</td>\n      <td>14.00000</td>\n      <td>1.75000</td>\n      <td>0.87500</td>\n      <td>8</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>136.00000</td>\n      <td>17.00000</td>\n      <td>44.22386</td>\n      <td>1231.12500</td>\n      <td>388.19951</td>\n      <td>24271.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.12500</td>\n      <td>1.00000</td>\n      <td>0.37500</td>\n      <td>0.69597</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.37500</td>\n      <td>0.69597</td>\n      <td>2.75000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>19.66139</td>\n      <td>2.80877</td>\n      <td>15.00000</td>\n      <td>104.71429</td>\n      <td>0.57143</td>\n      <td>4.00000</td>\n      <td>0.28571</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>10.00000</td>\n      <td>1.42857</td>\n      <td>0.85714</td>\n      <td>7</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>149.00000</td>\n      <td>21.28571</td>\n      <td>51.73204</td>\n      <td>1260.00000</td>\n      <td>653.80950</td>\n      <td>16377.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.14286</td>\n      <td>0.00000</td>\n      <td>0.14286</td>\n      <td>0.85714</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.28571</td>\n      <td>0.45175</td>\n      <td>3.71429</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>27.23960</td>\n      <td>2.72396</td>\n      <td>15.90000</td>\n      <td>103.30000</td>\n      <td>0.60000</td>\n      <td>6.00000</td>\n      <td>0.50000</td>\n      <td>0.50000</td>\n      <td>0.67082</td>\n      <td>0.40000</td>\n      <td>12.00000</td>\n      <td>1.20000</td>\n      <td>0.90000</td>\n      <td>10</td>\n      <td>0.10000</td>\n      <td>1.00000</td>\n      <td>685.00000</td>\n      <td>68.50000</td>\n      <td>205.16688</td>\n      <td>1497.30000</td>\n      <td>687.94012</td>\n      <td>110654.00000</td>\n      <td>0.30000</td>\n      <td>0.10000</td>\n      <td>0.00000</td>\n      <td>0.30000</td>\n      <td>0.10000</td>\n      <td>0.70000</td>\n      <td>0.20000</td>\n      <td>0.40000</td>\n      <td>0.40000</td>\n      <td>0.66332</td>\n      <td>0.30000</td>\n      <td>0.64031</td>\n      <td>5.00000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>13.38340</td>\n      <td>2.67668</td>\n      <td>15.00000</td>\n      <td>115.80000</td>\n      <td>0.60000</td>\n      <td>3.00000</td>\n      <td>0.40000</td>\n      <td>0.60000</td>\n      <td>0.48990</td>\n      <td>0.60000</td>\n      <td>5.00000</td>\n      <td>1.00000</td>\n      <td>0.80000</td>\n      <td>5</td>\n      <td>0.20000</td>\n      <td>1.00000</td>\n      <td>115.00000</td>\n      <td>23.00000</td>\n      <td>45.00222</td>\n      <td>1182.60000</td>\n      <td>464.60590</td>\n      <td>1330.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.20000</td>\n      <td>0.20000</td>\n      <td>0.20000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.40000</td>\n      <td>0.48990</td>\n      <td>3.20000</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   depth  SUM FriendsCount  AVG FriendsCount  AVG WordCount  AVG CharCount  \\\n0      2          57.63909           3.03364       18.68421      116.94737   \n1      4          24.49158           3.06145       12.62500       92.75000   \n2      2          19.66139           2.80877       15.00000      104.71429   \n3      3          27.23960           2.72396       15.90000      103.30000   \n4      2          13.38340           2.67668       15.00000      115.80000   \n\n   AVG HashTag  SUM HashTag  Ratio HashTag  AVG Url  STD Url  RATIO Url  \\\n0      0.00000      0.00000        0.00000  0.26316  0.44035    0.26316   \n1      0.25000      2.00000        0.25000  0.12500  0.33072    0.12500   \n2      0.57143      4.00000        0.28571  0.00000  0.00000    0.00000   \n3      0.60000      6.00000        0.50000  0.50000  0.67082    0.40000   \n4      0.60000      3.00000        0.40000  0.60000  0.48990    0.60000   \n\n   SUM Mention  AVG Mention  Ratio Mention  Tweets Count  Ratio Verified  \\\n0     32.00000      1.68421        0.94737            19         0.05263   \n1     14.00000      1.75000        0.87500             8         0.00000   \n2     10.00000      1.42857        0.85714             7         0.00000   \n3     12.00000      1.20000        0.90000            10         0.10000   \n4      5.00000      1.00000        0.80000             5         0.20000   \n\n   SUM Verified    SUM RT   AVG RT    STD RT  AVG AccAge  STD AccAge  \\\n0       1.00000 179.00000  9.42105  39.50125   720.26316   955.35553   \n1       0.00000 136.00000 17.00000  44.22386  1231.12500   388.19951   \n2       0.00000 149.00000 21.28571  51.73204  1260.00000   653.80950   \n3       1.00000 685.00000 68.50000 205.16688  1497.30000   687.94012   \n4       1.00000 115.00000 23.00000  45.00222  1182.60000   464.60590   \n\n   thread_time  STD Emoji  AVG Emoji  Ratio Media  RATIO Question  \\\n0   4533.00000    0.00000    0.00000      0.00000         0.15789   \n1  24271.00000    0.00000    0.00000      0.00000         0.00000   \n2  16377.00000    0.00000    0.00000      0.14286         0.00000   \n3 110654.00000    0.30000    0.10000      0.00000         0.30000   \n4   1330.00000    0.00000    0.00000      0.20000         0.20000   \n\n   RATIO Exclaim  RATIO Period  AVG FPP  STD FPP  AVG SPP  STD SPP  AVG TPP  \\\n0        0.00000       0.42105  0.05263  0.22330  0.73684  1.20709  0.84211   \n1        0.12500       1.00000  0.37500  0.69597  0.00000  0.00000  0.37500   \n2        0.14286       0.85714  0.00000  0.00000  0.00000  0.00000  0.28571   \n3        0.10000       0.70000  0.20000  0.40000  0.40000  0.66332  0.30000   \n4        0.20000       1.00000  0.00000  0.00000  0.00000  0.00000  0.40000   \n\n   STD TPP  AVG Skepticism  \n0  1.18158         6.00000  \n1  0.69597         2.75000  \n2  0.45175         3.71429  \n3  0.64031         5.00000  \n4  0.48990         3.20000  "
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pheme_thread = pd.read_csv(\"./data/_PHEME_thread.csv\")\n",
    "ext_thread = pd.read_csv(\"./data/_PHEMEext_thread.csv\")\n",
    "pheme_thread.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>depth</th>\n      <th>SUM FriendsCount</th>\n      <th>AVG FriendsCount</th>\n      <th>AVG WordCount</th>\n      <th>AVG CharCount</th>\n      <th>AVG HashTag</th>\n      <th>SUM HashTag</th>\n      <th>Ratio HashTag</th>\n      <th>AVG Url</th>\n      <th>STD Url</th>\n      <th>RATIO Url</th>\n      <th>SUM Mention</th>\n      <th>AVG Mention</th>\n      <th>Ratio Mention</th>\n      <th>Tweets Count</th>\n      <th>Ratio Verified</th>\n      <th>SUM Verified</th>\n      <th>SUM RT</th>\n      <th>AVG RT</th>\n      <th>STD RT</th>\n      <th>AVG AccAge</th>\n      <th>STD AccAge</th>\n      <th>thread_time</th>\n      <th>STD Emoji</th>\n      <th>AVG Emoji</th>\n      <th>Ratio Media</th>\n      <th>RATIO Question</th>\n      <th>RATIO Exclaim</th>\n      <th>RATIO Period</th>\n      <th>AVG FPP</th>\n      <th>STD FPP</th>\n      <th>AVG SPP</th>\n      <th>STD SPP</th>\n      <th>AVG TPP</th>\n      <th>STD TPP</th>\n      <th>AVG Skepticism</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4</td>\n      <td>32.98406</td>\n      <td>2.19894</td>\n      <td>6.66667</td>\n      <td>49.33333</td>\n      <td>0.00000</td>\n      <td>0</td>\n      <td>0.00000</td>\n      <td>0.26667</td>\n      <td>0.44222</td>\n      <td>0.26667</td>\n      <td>12</td>\n      <td>0.80000</td>\n      <td>0.73333</td>\n      <td>15</td>\n      <td>0.00000</td>\n      <td>0</td>\n      <td>117</td>\n      <td>7.80000</td>\n      <td>29.18493</td>\n      <td>812.26667</td>\n      <td>613.86887</td>\n      <td>9883.00000</td>\n      <td>0.54160</td>\n      <td>0.20000</td>\n      <td>0.06667</td>\n      <td>0.06667</td>\n      <td>0.13333</td>\n      <td>0.73333</td>\n      <td>0.13333</td>\n      <td>0.33993</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.33333</td>\n      <td>0.69921</td>\n      <td>2.40000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>31.82036</td>\n      <td>1.67476</td>\n      <td>5.68421</td>\n      <td>36.89474</td>\n      <td>0.05263</td>\n      <td>1</td>\n      <td>0.05263</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>15</td>\n      <td>0.78947</td>\n      <td>0.57895</td>\n      <td>19</td>\n      <td>0.05263</td>\n      <td>1</td>\n      <td>10415</td>\n      <td>548.15789</td>\n      <td>2322.57324</td>\n      <td>534.42105</td>\n      <td>527.59936</td>\n      <td>101340.00000</td>\n      <td>0.30689</td>\n      <td>0.10526</td>\n      <td>0.00000</td>\n      <td>0.05263</td>\n      <td>0.15789</td>\n      <td>0.21053</td>\n      <td>0.26316</td>\n      <td>0.63595</td>\n      <td>0.26316</td>\n      <td>0.54696</td>\n      <td>0.05263</td>\n      <td>0.22330</td>\n      <td>1.89474</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>14.53146</td>\n      <td>2.07592</td>\n      <td>12.00000</td>\n      <td>75.28571</td>\n      <td>0.00000</td>\n      <td>0</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>6</td>\n      <td>0.85714</td>\n      <td>0.71429</td>\n      <td>7</td>\n      <td>0.00000</td>\n      <td>0</td>\n      <td>127</td>\n      <td>18.14286</td>\n      <td>44.03385</td>\n      <td>919.14286</td>\n      <td>866.42260</td>\n      <td>2557.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.14286</td>\n      <td>0.14286</td>\n      <td>0.57143</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.57143</td>\n      <td>0.49487</td>\n      <td>2.42857</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>29.11766</td>\n      <td>2.23982</td>\n      <td>11.00000</td>\n      <td>72.92308</td>\n      <td>0.07692</td>\n      <td>1</td>\n      <td>0.07692</td>\n      <td>0.23077</td>\n      <td>0.42133</td>\n      <td>0.23077</td>\n      <td>15</td>\n      <td>1.15385</td>\n      <td>0.84615</td>\n      <td>13</td>\n      <td>0.07692</td>\n      <td>1</td>\n      <td>195</td>\n      <td>15.00000</td>\n      <td>51.09719</td>\n      <td>649.23077</td>\n      <td>584.40346</td>\n      <td>21440.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.15385</td>\n      <td>0.07692</td>\n      <td>0.07692</td>\n      <td>0.61538</td>\n      <td>0.30769</td>\n      <td>0.46154</td>\n      <td>0.07692</td>\n      <td>0.26647</td>\n      <td>0.38462</td>\n      <td>0.62493</td>\n      <td>3.23077</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>10.72732</td>\n      <td>2.14546</td>\n      <td>11.60000</td>\n      <td>96.00000</td>\n      <td>0.00000</td>\n      <td>0</td>\n      <td>0.00000</td>\n      <td>0.40000</td>\n      <td>0.48990</td>\n      <td>0.40000</td>\n      <td>12</td>\n      <td>2.40000</td>\n      <td>1.00000</td>\n      <td>5</td>\n      <td>0.00000</td>\n      <td>0</td>\n      <td>197</td>\n      <td>39.40000</td>\n      <td>78.30096</td>\n      <td>1099.60000</td>\n      <td>695.26760</td>\n      <td>5504.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.20000</td>\n      <td>0.00000</td>\n      <td>0.80000</td>\n      <td>0.20000</td>\n      <td>0.40000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>4.20000</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   depth  SUM FriendsCount  AVG FriendsCount  AVG WordCount  AVG CharCount  \\\n0      4          32.98406           2.19894        6.66667       49.33333   \n1      4          31.82036           1.67476        5.68421       36.89474   \n2      2          14.53146           2.07592       12.00000       75.28571   \n3      3          29.11766           2.23982       11.00000       72.92308   \n4      2          10.72732           2.14546       11.60000       96.00000   \n\n   AVG HashTag  SUM HashTag  Ratio HashTag  AVG Url  STD Url  RATIO Url  \\\n0      0.00000            0        0.00000  0.26667  0.44222    0.26667   \n1      0.05263            1        0.05263  0.00000  0.00000    0.00000   \n2      0.00000            0        0.00000  0.00000  0.00000    0.00000   \n3      0.07692            1        0.07692  0.23077  0.42133    0.23077   \n4      0.00000            0        0.00000  0.40000  0.48990    0.40000   \n\n   SUM Mention  AVG Mention  Ratio Mention  Tweets Count  Ratio Verified  \\\n0           12      0.80000        0.73333            15         0.00000   \n1           15      0.78947        0.57895            19         0.05263   \n2            6      0.85714        0.71429             7         0.00000   \n3           15      1.15385        0.84615            13         0.07692   \n4           12      2.40000        1.00000             5         0.00000   \n\n   SUM Verified  SUM RT    AVG RT     STD RT  AVG AccAge  STD AccAge  \\\n0             0     117   7.80000   29.18493   812.26667   613.86887   \n1             1   10415 548.15789 2322.57324   534.42105   527.59936   \n2             0     127  18.14286   44.03385   919.14286   866.42260   \n3             1     195  15.00000   51.09719   649.23077   584.40346   \n4             0     197  39.40000   78.30096  1099.60000   695.26760   \n\n   thread_time  STD Emoji  AVG Emoji  Ratio Media  RATIO Question  \\\n0   9883.00000    0.54160    0.20000      0.06667         0.06667   \n1 101340.00000    0.30689    0.10526      0.00000         0.05263   \n2   2557.00000    0.00000    0.00000      0.00000         0.14286   \n3  21440.00000    0.00000    0.00000      0.15385         0.07692   \n4   5504.00000    0.00000    0.00000      0.00000         0.20000   \n\n   RATIO Exclaim  RATIO Period  AVG FPP  STD FPP  AVG SPP  STD SPP  AVG TPP  \\\n0        0.13333       0.73333  0.13333  0.33993  0.00000  0.00000  0.33333   \n1        0.15789       0.21053  0.26316  0.63595  0.26316  0.54696  0.05263   \n2        0.14286       0.57143  0.00000  0.00000  0.00000  0.00000  0.57143   \n3        0.07692       0.61538  0.30769  0.46154  0.07692  0.26647  0.38462   \n4        0.00000       0.80000  0.20000  0.40000  0.00000  0.00000  0.00000   \n\n   STD TPP  AVG Skepticism  \n0  0.69921         2.40000  \n1  0.22330         1.89474  \n2  0.49487         2.42857  \n3  0.62493         3.23077  \n4  0.00000         4.20000  "
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ext_thread.head()\n",
    "# ext_thread.sample(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>depth</th>\n      <th>SUM FriendsCount</th>\n      <th>AVG FriendsCount</th>\n      <th>AVG WordCount</th>\n      <th>AVG CharCount</th>\n      <th>AVG HashTag</th>\n      <th>SUM HashTag</th>\n      <th>Ratio HashTag</th>\n      <th>AVG Url</th>\n      <th>STD Url</th>\n      <th>RATIO Url</th>\n      <th>SUM Mention</th>\n      <th>AVG Mention</th>\n      <th>Ratio Mention</th>\n      <th>Tweets Count</th>\n      <th>Ratio Verified</th>\n      <th>SUM Verified</th>\n      <th>SUM RT</th>\n      <th>AVG RT</th>\n      <th>STD RT</th>\n      <th>AVG AccAge</th>\n      <th>STD AccAge</th>\n      <th>thread_time</th>\n      <th>STD Emoji</th>\n      <th>AVG Emoji</th>\n      <th>Ratio Media</th>\n      <th>RATIO Question</th>\n      <th>RATIO Exclaim</th>\n      <th>RATIO Period</th>\n      <th>AVG FPP</th>\n      <th>STD FPP</th>\n      <th>AVG SPP</th>\n      <th>STD SPP</th>\n      <th>AVG TPP</th>\n      <th>STD TPP</th>\n      <th>AVG Skepticism</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>4.44485</td>\n      <td>47.71738</td>\n      <td>2.69625</td>\n      <td>14.12534</td>\n      <td>98.17147</td>\n      <td>0.49636</td>\n      <td>5.68218</td>\n      <td>0.30148</td>\n      <td>0.16980</td>\n      <td>0.23129</td>\n      <td>0.15955</td>\n      <td>30.27749</td>\n      <td>1.40993</td>\n      <td>0.85680</td>\n      <td>17.78904</td>\n      <td>0.09014</td>\n      <td>0.93554</td>\n      <td>593.67890</td>\n      <td>54.18365</td>\n      <td>107.02151</td>\n      <td>1301.45512</td>\n      <td>656.56185</td>\n      <td>42042.33919</td>\n      <td>0.13800</td>\n      <td>0.05157</td>\n      <td>0.15089</td>\n      <td>0.12817</td>\n      <td>0.11582</td>\n      <td>0.68090</td>\n      <td>0.28007</td>\n      <td>0.44079</td>\n      <td>0.16835</td>\n      <td>0.31677</td>\n      <td>0.36429</td>\n      <td>0.52918</td>\n      <td>3.43485</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>3.88666</td>\n      <td>54.60815</td>\n      <td>0.42489</td>\n      <td>3.31060</td>\n      <td>20.47492</td>\n      <td>0.58934</td>\n      <td>6.19011</td>\n      <td>0.26675</td>\n      <td>0.24628</td>\n      <td>0.22348</td>\n      <td>0.22659</td>\n      <td>46.74222</td>\n      <td>0.65022</td>\n      <td>0.22467</td>\n      <td>20.09487</td>\n      <td>0.16636</td>\n      <td>1.54716</td>\n      <td>3559.90091</td>\n      <td>253.02338</td>\n      <td>618.82036</td>\n      <td>404.98186</td>\n      <td>278.92828</td>\n      <td>105966.08161</td>\n      <td>0.57902</td>\n      <td>0.22355</td>\n      <td>0.23264</td>\n      <td>0.13394</td>\n      <td>0.13547</td>\n      <td>0.22620</td>\n      <td>0.28947</td>\n      <td>0.32284</td>\n      <td>0.22777</td>\n      <td>0.29921</td>\n      <td>0.33694</td>\n      <td>0.36382</td>\n      <td>1.18817</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>4.00000</td>\n      <td>32.05263</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>25.00000</td>\n      <td>0.80399</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2.00000</td>\n      <td>17.68543</td>\n      <td>2.45857</td>\n      <td>12.00000</td>\n      <td>85.55952</td>\n      <td>0.14286</td>\n      <td>2.00000</td>\n      <td>0.10526</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>8.00000</td>\n      <td>1.00000</td>\n      <td>0.85714</td>\n      <td>7.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>135.00000</td>\n      <td>11.36364</td>\n      <td>35.36346</td>\n      <td>1050.45909</td>\n      <td>550.85241</td>\n      <td>852.50000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.54545</td>\n      <td>0.06667</td>\n      <td>0.22330</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.12500</td>\n      <td>0.31427</td>\n      <td>2.66667</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>3.00000</td>\n      <td>37.92571</td>\n      <td>2.66155</td>\n      <td>14.03274</td>\n      <td>97.69925</td>\n      <td>0.33333</td>\n      <td>4.00000</td>\n      <td>0.23077</td>\n      <td>0.06667</td>\n      <td>0.22906</td>\n      <td>0.06667</td>\n      <td>20.00000</td>\n      <td>1.33333</td>\n      <td>0.93750</td>\n      <td>14.00000</td>\n      <td>0.04348</td>\n      <td>1.00000</td>\n      <td>214.00000</td>\n      <td>21.14286</td>\n      <td>54.70362</td>\n      <td>1278.36250</td>\n      <td>671.42693</td>\n      <td>6901.50000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.05000</td>\n      <td>0.11111</td>\n      <td>0.09091</td>\n      <td>0.68182</td>\n      <td>0.22500</td>\n      <td>0.44536</td>\n      <td>0.10526</td>\n      <td>0.30689</td>\n      <td>0.32143</td>\n      <td>0.53619</td>\n      <td>3.34580</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>5.00000</td>\n      <td>57.75385</td>\n      <td>2.88499</td>\n      <td>16.00000</td>\n      <td>109.60000</td>\n      <td>0.65217</td>\n      <td>8.00000</td>\n      <td>0.42105</td>\n      <td>0.25000</td>\n      <td>0.41574</td>\n      <td>0.22727</td>\n      <td>34.00000</td>\n      <td>1.73684</td>\n      <td>0.96296</td>\n      <td>21.00000</td>\n      <td>0.10526</td>\n      <td>1.00000</td>\n      <td>486.00000</td>\n      <td>42.74107</td>\n      <td>97.66895</td>\n      <td>1524.67544</td>\n      <td>783.81545</td>\n      <td>30902.25000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.20000</td>\n      <td>0.20000</td>\n      <td>0.16667</td>\n      <td>0.81818</td>\n      <td>0.40000</td>\n      <td>0.65555</td>\n      <td>0.25000</td>\n      <td>0.51034</td>\n      <td>0.52174</td>\n      <td>0.76244</td>\n      <td>4.04545</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>48.00000</td>\n      <td>986.34693</td>\n      <td>5.83813</td>\n      <td>37.75000</td>\n      <td>228.00000</td>\n      <td>7.50000</td>\n      <td>97.00000</td>\n      <td>1.00000</td>\n      <td>2.66667</td>\n      <td>2.16025</td>\n      <td>1.00000</td>\n      <td>972.00000</td>\n      <td>6.16667</td>\n      <td>1.00000</td>\n      <td>346.00000</td>\n      <td>1.00000</td>\n      <td>40.00000</td>\n      <td>207563.00000</td>\n      <td>13837.53333</td>\n      <td>35263.04180</td>\n      <td>3462.66667</td>\n      <td>2233.77450</td>\n      <td>1317255.00000</td>\n      <td>25.43456</td>\n      <td>7.16667</td>\n      <td>1.66667</td>\n      <td>1.00000</td>\n      <td>1.66667</td>\n      <td>1.66667</td>\n      <td>4.00000</td>\n      <td>3.05505</td>\n      <td>4.00000</td>\n      <td>2.73354</td>\n      <td>6.00000</td>\n      <td>3.76663</td>\n      <td>12.00000</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "           depth  SUM FriendsCount  AVG FriendsCount  AVG WordCount  \\\ncount 5802.00000        5802.00000        5802.00000     5802.00000   \nmean     4.44485          47.71738           2.69625       14.12534   \nstd      3.88666          54.60815           0.42489        3.31060   \nmin      1.00000           0.00000           0.00000        4.00000   \n25%      2.00000          17.68543           2.45857       12.00000   \n50%      3.00000          37.92571           2.66155       14.03274   \n75%      5.00000          57.75385           2.88499       16.00000   \nmax     48.00000         986.34693           5.83813       37.75000   \n\n       AVG CharCount  AVG HashTag  SUM HashTag  Ratio HashTag    AVG Url  \\\ncount     5802.00000   5802.00000   5802.00000     5802.00000 5802.00000   \nmean        98.17147      0.49636      5.68218        0.30148    0.16980   \nstd         20.47492      0.58934      6.19011        0.26675    0.24628   \nmin         32.05263      0.00000      0.00000        0.00000    0.00000   \n25%         85.55952      0.14286      2.00000        0.10526    0.00000   \n50%         97.69925      0.33333      4.00000        0.23077    0.06667   \n75%        109.60000      0.65217      8.00000        0.42105    0.25000   \nmax        228.00000      7.50000     97.00000        1.00000    2.66667   \n\n         STD Url  RATIO Url  SUM Mention  AVG Mention  Ratio Mention  \\\ncount 5802.00000 5802.00000   5802.00000   5802.00000     5802.00000   \nmean     0.23129    0.15955     30.27749      1.40993        0.85680   \nstd      0.22348    0.22659     46.74222      0.65022        0.22467   \nmin      0.00000    0.00000      0.00000      0.00000        0.00000   \n25%      0.00000    0.00000      8.00000      1.00000        0.85714   \n50%      0.22906    0.06667     20.00000      1.33333        0.93750   \n75%      0.41574    0.22727     34.00000      1.73684        0.96296   \nmax      2.16025    1.00000    972.00000      6.16667        1.00000   \n\n       Tweets Count  Ratio Verified  SUM Verified       SUM RT      AVG RT  \\\ncount    5802.00000      5802.00000    5802.00000   5802.00000  5802.00000   \nmean       17.78904         0.09014       0.93554    593.67890    54.18365   \nstd        20.09487         0.16636       1.54716   3559.90091   253.02338   \nmin         1.00000         0.00000       0.00000     25.00000     0.80399   \n25%         7.00000         0.00000       0.00000    135.00000    11.36364   \n50%        14.00000         0.04348       1.00000    214.00000    21.14286   \n75%        21.00000         0.10526       1.00000    486.00000    42.74107   \nmax       346.00000         1.00000      40.00000 207563.00000 13837.53333   \n\n           STD RT  AVG AccAge  STD AccAge   thread_time  STD Emoji  AVG Emoji  \\\ncount  5802.00000  5802.00000  5802.00000    5802.00000 5802.00000 5802.00000   \nmean    107.02151  1301.45512   656.56185   42042.33919    0.13800    0.05157   \nstd     618.82036   404.98186   278.92828  105966.08161    0.57902    0.22355   \nmin       0.00000     0.00000     0.00000       0.00000    0.00000    0.00000   \n25%      35.36346  1050.45909   550.85241     852.50000    0.00000    0.00000   \n50%      54.70362  1278.36250   671.42693    6901.50000    0.00000    0.00000   \n75%      97.66895  1524.67544   783.81545   30902.25000    0.00000    0.00000   \nmax   35263.04180  3462.66667  2233.77450 1317255.00000   25.43456    7.16667   \n\n       Ratio Media  RATIO Question  RATIO Exclaim  RATIO Period    AVG FPP  \\\ncount   5802.00000      5802.00000     5802.00000    5802.00000 5802.00000   \nmean       0.15089         0.12817        0.11582       0.68090    0.28007   \nstd        0.23264         0.13394        0.13547       0.22620    0.28947   \nmin        0.00000         0.00000        0.00000       0.00000    0.00000   \n25%        0.00000         0.00000        0.00000       0.54545    0.06667   \n50%        0.05000         0.11111        0.09091       0.68182    0.22500   \n75%        0.20000         0.20000        0.16667       0.81818    0.40000   \nmax        1.66667         1.00000        1.66667       1.66667    4.00000   \n\n         STD FPP    AVG SPP    STD SPP    AVG TPP    STD TPP  AVG Skepticism  \ncount 5802.00000 5802.00000 5802.00000 5802.00000 5802.00000      5802.00000  \nmean     0.44079    0.16835    0.31677    0.36429    0.52918         3.43485  \nstd      0.32284    0.22777    0.29921    0.33694    0.36382         1.18817  \nmin      0.00000    0.00000    0.00000    0.00000    0.00000         0.00000  \n25%      0.22330    0.00000    0.00000    0.12500    0.31427         2.66667  \n50%      0.44536    0.10526    0.30689    0.32143    0.53619         3.34580  \n75%      0.65555    0.25000    0.51034    0.52174    0.76244         4.04545  \nmax      3.05505    4.00000    2.73354    6.00000    3.76663        12.00000  "
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pheme_thread.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>depth</th>\n      <th>SUM FriendsCount</th>\n      <th>AVG FriendsCount</th>\n      <th>AVG WordCount</th>\n      <th>AVG CharCount</th>\n      <th>AVG HashTag</th>\n      <th>SUM HashTag</th>\n      <th>Ratio HashTag</th>\n      <th>AVG Url</th>\n      <th>STD Url</th>\n      <th>RATIO Url</th>\n      <th>SUM Mention</th>\n      <th>AVG Mention</th>\n      <th>Ratio Mention</th>\n      <th>Tweets Count</th>\n      <th>Ratio Verified</th>\n      <th>SUM Verified</th>\n      <th>SUM RT</th>\n      <th>AVG RT</th>\n      <th>STD RT</th>\n      <th>AVG AccAge</th>\n      <th>STD AccAge</th>\n      <th>thread_time</th>\n      <th>STD Emoji</th>\n      <th>AVG Emoji</th>\n      <th>Ratio Media</th>\n      <th>RATIO Question</th>\n      <th>RATIO Exclaim</th>\n      <th>RATIO Period</th>\n      <th>AVG FPP</th>\n      <th>STD FPP</th>\n      <th>AVG SPP</th>\n      <th>STD SPP</th>\n      <th>AVG TPP</th>\n      <th>STD TPP</th>\n      <th>AVG Skepticism</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2.19794</td>\n      <td>7.61952</td>\n      <td>1.91587</td>\n      <td>10.01375</td>\n      <td>69.41844</td>\n      <td>0.59794</td>\n      <td>1.25361</td>\n      <td>0.29762</td>\n      <td>0.22614</td>\n      <td>0.10124</td>\n      <td>0.22078</td>\n      <td>3.59381</td>\n      <td>0.60497</td>\n      <td>0.40513</td>\n      <td>4.04742</td>\n      <td>0.06684</td>\n      <td>0.15258</td>\n      <td>40.95258</td>\n      <td>4.41943</td>\n      <td>9.69219</td>\n      <td>986.42153</td>\n      <td>370.60815</td>\n      <td>15581.70722</td>\n      <td>0.06312</td>\n      <td>0.03985</td>\n      <td>0.13214</td>\n      <td>0.15139</td>\n      <td>0.10150</td>\n      <td>0.52345</td>\n      <td>0.18014</td>\n      <td>0.19884</td>\n      <td>0.06492</td>\n      <td>0.06322</td>\n      <td>0.24703</td>\n      <td>0.20441</td>\n      <td>2.26836</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.70257</td>\n      <td>9.62440</td>\n      <td>1.05029</td>\n      <td>6.36584</td>\n      <td>42.83633</td>\n      <td>0.96245</td>\n      <td>1.75798</td>\n      <td>0.39206</td>\n      <td>0.37453</td>\n      <td>0.18859</td>\n      <td>0.35968</td>\n      <td>6.05126</td>\n      <td>0.66793</td>\n      <td>0.35595</td>\n      <td>4.83785</td>\n      <td>0.21699</td>\n      <td>0.38759</td>\n      <td>482.16712</td>\n      <td>25.62266</td>\n      <td>107.48288</td>\n      <td>709.21957</td>\n      <td>392.53652</td>\n      <td>51235.86482</td>\n      <td>0.25042</td>\n      <td>0.20250</td>\n      <td>0.29372</td>\n      <td>0.28140</td>\n      <td>0.21562</td>\n      <td>0.38458</td>\n      <td>0.33362</td>\n      <td>0.35683</td>\n      <td>0.22990</td>\n      <td>0.16169</td>\n      <td>0.40823</td>\n      <td>0.32968</td>\n      <td>1.75281</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.00000</td>\n      <td>2.48855</td>\n      <td>1.31377</td>\n      <td>5.50000</td>\n      <td>39.40000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>475.66667</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.16667</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>2.00000</td>\n      <td>3.79844</td>\n      <td>2.07485</td>\n      <td>10.00000</td>\n      <td>69.53333</td>\n      <td>0.04167</td>\n      <td>1.00000</td>\n      <td>0.04167</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0.50000</td>\n      <td>0.50000</td>\n      <td>2.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>3.00000</td>\n      <td>2.00000</td>\n      <td>0.00000</td>\n      <td>938.46154</td>\n      <td>209.00000</td>\n      <td>561.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.50000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>2.00000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>3.00000</td>\n      <td>9.19258</td>\n      <td>2.70672</td>\n      <td>15.00000</td>\n      <td>104.00000</td>\n      <td>1.00000</td>\n      <td>2.00000</td>\n      <td>0.50000</td>\n      <td>0.33333</td>\n      <td>0.00000</td>\n      <td>0.33333</td>\n      <td>4.00000</td>\n      <td>1.00000</td>\n      <td>0.66667</td>\n      <td>5.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>8.00000</td>\n      <td>4.00000</td>\n      <td>2.49444</td>\n      <td>1443.00000</td>\n      <td>726.71193</td>\n      <td>6964.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.05556</td>\n      <td>0.16667</td>\n      <td>0.11111</td>\n      <td>1.00000</td>\n      <td>0.25000</td>\n      <td>0.40000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.40000</td>\n      <td>0.43301</td>\n      <td>3.00000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>16.00000</td>\n      <td>57.40306</td>\n      <td>4.38684</td>\n      <td>29.00000</td>\n      <td>143.00000</td>\n      <td>6.00000</td>\n      <td>12.00000</td>\n      <td>1.00000</td>\n      <td>2.00000</td>\n      <td>0.94281</td>\n      <td>1.00000</td>\n      <td>38.00000</td>\n      <td>6.50000</td>\n      <td>1.00000</td>\n      <td>27.00000</td>\n      <td>1.00000</td>\n      <td>3.00000</td>\n      <td>10415.00000</td>\n      <td>548.15789</td>\n      <td>2322.57324</td>\n      <td>3021.00000</td>\n      <td>1432.00000</td>\n      <td>753999.00000</td>\n      <td>2.76385</td>\n      <td>3.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>2.00000</td>\n      <td>2.00000</td>\n      <td>2.00000</td>\n      <td>1.00000</td>\n      <td>2.00000</td>\n      <td>2.00000</td>\n      <td>9.00000</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "          depth  SUM FriendsCount  AVG FriendsCount  AVG WordCount  \\\ncount 485.00000         485.00000         485.00000      485.00000   \nmean    2.19794           7.61952           1.91587       10.01375   \nstd     1.70257           9.62440           1.05029        6.36584   \nmin     1.00000           0.00000           0.00000        0.00000   \n25%     1.00000           2.48855           1.31377        5.50000   \n50%     2.00000           3.79844           2.07485       10.00000   \n75%     3.00000           9.19258           2.70672       15.00000   \nmax    16.00000          57.40306           4.38684       29.00000   \n\n       AVG CharCount  AVG HashTag  SUM HashTag  Ratio HashTag   AVG Url  \\\ncount      485.00000    485.00000    485.00000      485.00000 485.00000   \nmean        69.41844      0.59794      1.25361        0.29762   0.22614   \nstd         42.83633      0.96245      1.75798        0.39206   0.37453   \nmin          0.00000      0.00000      0.00000        0.00000   0.00000   \n25%         39.40000      0.00000      0.00000        0.00000   0.00000   \n50%         69.53333      0.04167      1.00000        0.04167   0.00000   \n75%        104.00000      1.00000      2.00000        0.50000   0.33333   \nmax        143.00000      6.00000     12.00000        1.00000   2.00000   \n\n        STD Url  RATIO Url  SUM Mention  AVG Mention  Ratio Mention  \\\ncount 485.00000  485.00000    485.00000    485.00000      485.00000   \nmean    0.10124    0.22078      3.59381      0.60497        0.40513   \nstd     0.18859    0.35968      6.05126      0.66793        0.35595   \nmin     0.00000    0.00000      0.00000      0.00000        0.00000   \n25%     0.00000    0.00000      0.00000      0.00000        0.00000   \n50%     0.00000    0.00000      1.00000      0.50000        0.50000   \n75%     0.00000    0.33333      4.00000      1.00000        0.66667   \nmax     0.94281    1.00000     38.00000      6.50000        1.00000   \n\n       Tweets Count  Ratio Verified  SUM Verified      SUM RT    AVG RT  \\\ncount     485.00000       485.00000     485.00000   485.00000 485.00000   \nmean        4.04742         0.06684       0.15258    40.95258   4.41943   \nstd         4.83785         0.21699       0.38759   482.16712  25.62266   \nmin         1.00000         0.00000       0.00000     0.00000   0.00000   \n25%         1.00000         0.00000       0.00000     0.00000   0.00000   \n50%         2.00000         0.00000       0.00000     3.00000   2.00000   \n75%         5.00000         0.00000       0.00000     8.00000   4.00000   \nmax        27.00000         1.00000       3.00000 10415.00000 548.15789   \n\n          STD RT  AVG AccAge  STD AccAge  thread_time  STD Emoji  AVG Emoji  \\\ncount  485.00000   485.00000   485.00000    485.00000  485.00000  485.00000   \nmean     9.69219   986.42153   370.60815  15581.70722    0.06312    0.03985   \nstd    107.48288   709.21957   392.53652  51235.86482    0.25042    0.20250   \nmin      0.00000     0.00000     0.00000      0.00000    0.00000    0.00000   \n25%      0.00000   475.66667     0.00000      0.00000    0.00000    0.00000   \n50%      0.00000   938.46154   209.00000    561.00000    0.00000    0.00000   \n75%      2.49444  1443.00000   726.71193   6964.00000    0.00000    0.00000   \nmax   2322.57324  3021.00000  1432.00000 753999.00000    2.76385    3.00000   \n\n       Ratio Media  RATIO Question  RATIO Exclaim  RATIO Period   AVG FPP  \\\ncount    485.00000       485.00000      485.00000     485.00000 485.00000   \nmean       0.13214         0.15139        0.10150       0.52345   0.18014   \nstd        0.29372         0.28140        0.21562       0.38458   0.33362   \nmin        0.00000         0.00000        0.00000       0.00000   0.00000   \n25%        0.00000         0.00000        0.00000       0.16667   0.00000   \n50%        0.00000         0.00000        0.00000       0.50000   0.00000   \n75%        0.05556         0.16667        0.11111       1.00000   0.25000   \nmax        1.00000         1.00000        1.00000       1.00000   2.00000   \n\n        STD FPP   AVG SPP   STD SPP   AVG TPP   STD TPP  AVG Skepticism  \ncount 485.00000 485.00000 485.00000 485.00000 485.00000       485.00000  \nmean    0.19884   0.06492   0.06322   0.24703   0.20441         2.26836  \nstd     0.35683   0.22990   0.16169   0.40823   0.32968         1.75281  \nmin     0.00000   0.00000   0.00000   0.00000   0.00000         0.00000  \n25%     0.00000   0.00000   0.00000   0.00000   0.00000         1.00000  \n50%     0.00000   0.00000   0.00000   0.00000   0.00000         2.00000  \n75%     0.40000   0.00000   0.00000   0.40000   0.43301         3.00000  \nmax     2.00000   2.00000   1.00000   2.00000   2.00000         9.00000  "
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "ext_thread.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/x.notebook.stream": "depth : -0.06069342688788918\nSUM FriendsCount : -0.06658383688147566\nAVG FriendsCount : -0.033291526306805735\nAVG WordCount : -0.028745368201758378\nAVG CharCount : -0.0585156573504035\nAVG HashTag : -0.057490549769171874\nSUM HashTag : -0.08296439012596422\nRatio HashTag : -0.05857458130737733\nAVG Url : 0.06221989854036648\nSTD Url : 0.04448522719648556\nRATIO Url : 0.07631115413175521\nSUM Mention : -0.0679517260459248\nAVG Mention : -0.049444382744994735\nRatio Mention : -0.008521806634464309\nTweets Count : -0.06609829968334364\nRatio Verified : 0.06967897492773252\nSUM Verified : 0.02472399503205972\nSUM RT : -0.03489936869947932\nAVG RT : -0.028877087864229267\nSTD RT : -0.02833104088630045\nAVG AccAge : 0.0328554654001057\nSTD AccAge : 0.005046520701145404\nthread_time : -0.1155786014640931\nSTD Emoji : -0.020083094068074823\nAVG Emoji : -0.02932855173423856\nRatio Media : -0.09314308316176101\nRATIO Question : -0.005989377712117246\nRATIO Exclaim : -0.058622874185368906\nRATIO Period : -0.05938796457234243\nAVG FPP : -0.18118515882862224\nSTD FPP : -0.15020796677268272\nAVG SPP : -0.1603819613841158\nSTD SPP : -0.1520458386681659\nAVG TPP : 0.013960176308594596\nSTD TPP : 0.01317048096081552\nAVG Skepticism : -0.08496878134829233\n"
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "# for data in ext_thread.columns:\n",
    "    # print(data,\":\",ext_thread[data].corr(ext_y))\n",
    "for data in pheme_thread.columns:\n",
    "    print(data,\":\",pheme_thread[data].corr(pheme_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>depth</th>\n      <th>SUM FriendsCount</th>\n      <th>AVG FriendsCount</th>\n      <th>AVG WordCount</th>\n      <th>AVG CharCount</th>\n      <th>AVG HashTag</th>\n      <th>SUM HashTag</th>\n      <th>Ratio HashTag</th>\n      <th>AVG Url</th>\n      <th>STD Url</th>\n      <th>RATIO Url</th>\n      <th>SUM Mention</th>\n      <th>AVG Mention</th>\n      <th>Ratio Mention</th>\n      <th>Tweets Count</th>\n      <th>Ratio Verified</th>\n      <th>SUM Verified</th>\n      <th>SUM RT</th>\n      <th>AVG RT</th>\n      <th>STD RT</th>\n      <th>AVG AccAge</th>\n      <th>STD AccAge</th>\n      <th>thread_time</th>\n      <th>STD Emoji</th>\n      <th>AVG Emoji</th>\n      <th>Ratio Media</th>\n      <th>RATIO Question</th>\n      <th>RATIO Exclaim</th>\n      <th>RATIO Period</th>\n      <th>AVG FPP</th>\n      <th>STD FPP</th>\n      <th>AVG SPP</th>\n      <th>STD SPP</th>\n      <th>AVG TPP</th>\n      <th>STD TPP</th>\n      <th>AVG Skepticism</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4</td>\n      <td>32.98406</td>\n      <td>2.19894</td>\n      <td>6.66667</td>\n      <td>49.33333</td>\n      <td>0.00000</td>\n      <td>0</td>\n      <td>0.00000</td>\n      <td>0.26667</td>\n      <td>0.44222</td>\n      <td>0.26667</td>\n      <td>12</td>\n      <td>0.80000</td>\n      <td>0.73333</td>\n      <td>15</td>\n      <td>0.00000</td>\n      <td>0</td>\n      <td>117</td>\n      <td>7.80000</td>\n      <td>29.18493</td>\n      <td>812.26667</td>\n      <td>613.86887</td>\n      <td>9883.00000</td>\n      <td>0.54160</td>\n      <td>0.20000</td>\n      <td>0.06667</td>\n      <td>0.06667</td>\n      <td>0.13333</td>\n      <td>0.73333</td>\n      <td>0.13333</td>\n      <td>0.33993</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.33333</td>\n      <td>0.69921</td>\n      <td>2.40000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>31.82036</td>\n      <td>1.67476</td>\n      <td>5.68421</td>\n      <td>36.89474</td>\n      <td>0.05263</td>\n      <td>1</td>\n      <td>0.05263</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>15</td>\n      <td>0.78947</td>\n      <td>0.57895</td>\n      <td>19</td>\n      <td>0.05263</td>\n      <td>1</td>\n      <td>10415</td>\n      <td>548.15789</td>\n      <td>2322.57324</td>\n      <td>534.42105</td>\n      <td>527.59936</td>\n      <td>101340.00000</td>\n      <td>0.30689</td>\n      <td>0.10526</td>\n      <td>0.00000</td>\n      <td>0.05263</td>\n      <td>0.15789</td>\n      <td>0.21053</td>\n      <td>0.26316</td>\n      <td>0.63595</td>\n      <td>0.26316</td>\n      <td>0.54696</td>\n      <td>0.05263</td>\n      <td>0.22330</td>\n      <td>1.89474</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>14.53146</td>\n      <td>2.07592</td>\n      <td>12.00000</td>\n      <td>75.28571</td>\n      <td>0.00000</td>\n      <td>0</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>6</td>\n      <td>0.85714</td>\n      <td>0.71429</td>\n      <td>7</td>\n      <td>0.00000</td>\n      <td>0</td>\n      <td>127</td>\n      <td>18.14286</td>\n      <td>44.03385</td>\n      <td>919.14286</td>\n      <td>866.42260</td>\n      <td>2557.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.14286</td>\n      <td>0.14286</td>\n      <td>0.57143</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.57143</td>\n      <td>0.49487</td>\n      <td>2.42857</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>29.11766</td>\n      <td>2.23982</td>\n      <td>11.00000</td>\n      <td>72.92308</td>\n      <td>0.07692</td>\n      <td>1</td>\n      <td>0.07692</td>\n      <td>0.23077</td>\n      <td>0.42133</td>\n      <td>0.23077</td>\n      <td>15</td>\n      <td>1.15385</td>\n      <td>0.84615</td>\n      <td>13</td>\n      <td>0.07692</td>\n      <td>1</td>\n      <td>195</td>\n      <td>15.00000</td>\n      <td>51.09719</td>\n      <td>649.23077</td>\n      <td>584.40346</td>\n      <td>21440.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.15385</td>\n      <td>0.07692</td>\n      <td>0.07692</td>\n      <td>0.61538</td>\n      <td>0.30769</td>\n      <td>0.46154</td>\n      <td>0.07692</td>\n      <td>0.26647</td>\n      <td>0.38462</td>\n      <td>0.62493</td>\n      <td>3.23077</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>10.72732</td>\n      <td>2.14546</td>\n      <td>11.60000</td>\n      <td>96.00000</td>\n      <td>0.00000</td>\n      <td>0</td>\n      <td>0.00000</td>\n      <td>0.40000</td>\n      <td>0.48990</td>\n      <td>0.40000</td>\n      <td>12</td>\n      <td>2.40000</td>\n      <td>1.00000</td>\n      <td>5</td>\n      <td>0.00000</td>\n      <td>0</td>\n      <td>197</td>\n      <td>39.40000</td>\n      <td>78.30096</td>\n      <td>1099.60000</td>\n      <td>695.26760</td>\n      <td>5504.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.20000</td>\n      <td>0.00000</td>\n      <td>0.80000</td>\n      <td>0.20000</td>\n      <td>0.40000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>4.20000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>480</th>\n      <td>2</td>\n      <td>9.03601</td>\n      <td>3.01200</td>\n      <td>12.33333</td>\n      <td>96.00000</td>\n      <td>1.33333</td>\n      <td>4</td>\n      <td>0.33333</td>\n      <td>0.33333</td>\n      <td>0.47140</td>\n      <td>0.33333</td>\n      <td>3</td>\n      <td>1.00000</td>\n      <td>0.66667</td>\n      <td>3</td>\n      <td>0.00000</td>\n      <td>0</td>\n      <td>32</td>\n      <td>10.66667</td>\n      <td>15.08494</td>\n      <td>1912.66667</td>\n      <td>156.03917</td>\n      <td>3965.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.33333</td>\n      <td>0.00000</td>\n      <td>0.33333</td>\n      <td>0.66667</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.33333</td>\n      <td>0.47140</td>\n      <td>1.33333</td>\n    </tr>\n    <tr>\n      <th>481</th>\n      <td>1</td>\n      <td>2.44091</td>\n      <td>2.44091</td>\n      <td>10.00000</td>\n      <td>64.00000</td>\n      <td>1.00000</td>\n      <td>1</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1</td>\n      <td>0.00000</td>\n      <td>0</td>\n      <td>3</td>\n      <td>3.00000</td>\n      <td>0.00000</td>\n      <td>2029.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>2.00000</td>\n    </tr>\n    <tr>\n      <th>482</th>\n      <td>2</td>\n      <td>4.17085</td>\n      <td>2.08542</td>\n      <td>4.00000</td>\n      <td>44.00000</td>\n      <td>0.50000</td>\n      <td>1</td>\n      <td>0.50000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1</td>\n      <td>0.50000</td>\n      <td>0.50000</td>\n      <td>2</td>\n      <td>0.00000</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1.50000</td>\n      <td>1.50000</td>\n      <td>1111.50000</td>\n      <td>1106.50000</td>\n      <td>2549.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>2.00000</td>\n    </tr>\n    <tr>\n      <th>483</th>\n      <td>2</td>\n      <td>5.49250</td>\n      <td>1.37312</td>\n      <td>8.25000</td>\n      <td>53.75000</td>\n      <td>0.00000</td>\n      <td>0</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1</td>\n      <td>0.25000</td>\n      <td>0.25000</td>\n      <td>4</td>\n      <td>0.00000</td>\n      <td>0</td>\n      <td>8</td>\n      <td>2.00000</td>\n      <td>2.91548</td>\n      <td>800.25000</td>\n      <td>889.28409</td>\n      <td>4472.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.50000</td>\n      <td>0.25000</td>\n      <td>0.43301</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.50000</td>\n      <td>0.50000</td>\n      <td>3.00000</td>\n    </tr>\n    <tr>\n      <th>484</th>\n      <td>1</td>\n      <td>3.79844</td>\n      <td>3.79844</td>\n      <td>10.00000</td>\n      <td>93.00000</td>\n      <td>3.00000</td>\n      <td>3</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1</td>\n      <td>0.00000</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2.00000</td>\n      <td>0.00000</td>\n      <td>1573.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>2.00000</td>\n    </tr>\n  </tbody>\n</table>\n<p>485 rows × 36 columns</p>\n</div>",
      "text/plain": "     depth  SUM FriendsCount  AVG FriendsCount  AVG WordCount  AVG CharCount  \\\n0        4          32.98406           2.19894        6.66667       49.33333   \n1        4          31.82036           1.67476        5.68421       36.89474   \n2        2          14.53146           2.07592       12.00000       75.28571   \n3        3          29.11766           2.23982       11.00000       72.92308   \n4        2          10.72732           2.14546       11.60000       96.00000   \n..     ...               ...               ...            ...            ...   \n480      2           9.03601           3.01200       12.33333       96.00000   \n481      1           2.44091           2.44091       10.00000       64.00000   \n482      2           4.17085           2.08542        4.00000       44.00000   \n483      2           5.49250           1.37312        8.25000       53.75000   \n484      1           3.79844           3.79844       10.00000       93.00000   \n\n     AVG HashTag  SUM HashTag  Ratio HashTag  AVG Url  STD Url  RATIO Url  \\\n0        0.00000            0        0.00000  0.26667  0.44222    0.26667   \n1        0.05263            1        0.05263  0.00000  0.00000    0.00000   \n2        0.00000            0        0.00000  0.00000  0.00000    0.00000   \n3        0.07692            1        0.07692  0.23077  0.42133    0.23077   \n4        0.00000            0        0.00000  0.40000  0.48990    0.40000   \n..           ...          ...            ...      ...      ...        ...   \n480      1.33333            4        0.33333  0.33333  0.47140    0.33333   \n481      1.00000            1        1.00000  0.00000  0.00000    0.00000   \n482      0.50000            1        0.50000  0.00000  0.00000    0.00000   \n483      0.00000            0        0.00000  0.00000  0.00000    0.00000   \n484      3.00000            3        1.00000  1.00000  0.00000    1.00000   \n\n     SUM Mention  AVG Mention  Ratio Mention  Tweets Count  Ratio Verified  \\\n0             12      0.80000        0.73333            15         0.00000   \n1             15      0.78947        0.57895            19         0.05263   \n2              6      0.85714        0.71429             7         0.00000   \n3             15      1.15385        0.84615            13         0.07692   \n4             12      2.40000        1.00000             5         0.00000   \n..           ...          ...            ...           ...             ...   \n480            3      1.00000        0.66667             3         0.00000   \n481            0      0.00000        0.00000             1         0.00000   \n482            1      0.50000        0.50000             2         0.00000   \n483            1      0.25000        0.25000             4         0.00000   \n484            0      0.00000        0.00000             1         0.00000   \n\n     SUM Verified  SUM RT    AVG RT     STD RT  AVG AccAge  STD AccAge  \\\n0               0     117   7.80000   29.18493   812.26667   613.86887   \n1               1   10415 548.15789 2322.57324   534.42105   527.59936   \n2               0     127  18.14286   44.03385   919.14286   866.42260   \n3               1     195  15.00000   51.09719   649.23077   584.40346   \n4               0     197  39.40000   78.30096  1099.60000   695.26760   \n..            ...     ...       ...        ...         ...         ...   \n480             0      32  10.66667   15.08494  1912.66667   156.03917   \n481             0       3   3.00000    0.00000  2029.00000     0.00000   \n482             0       3   1.50000    1.50000  1111.50000  1106.50000   \n483             0       8   2.00000    2.91548   800.25000   889.28409   \n484             0       2   2.00000    0.00000  1573.00000     0.00000   \n\n     thread_time  STD Emoji  AVG Emoji  Ratio Media  RATIO Question  \\\n0     9883.00000    0.54160    0.20000      0.06667         0.06667   \n1   101340.00000    0.30689    0.10526      0.00000         0.05263   \n2     2557.00000    0.00000    0.00000      0.00000         0.14286   \n3    21440.00000    0.00000    0.00000      0.15385         0.07692   \n4     5504.00000    0.00000    0.00000      0.00000         0.20000   \n..           ...        ...        ...          ...             ...   \n480   3965.00000    0.00000    0.00000      0.33333         0.00000   \n481      0.00000    0.00000    0.00000      0.00000         0.00000   \n482   2549.00000    0.00000    0.00000      1.00000         0.00000   \n483   4472.00000    0.00000    0.00000      0.00000         0.00000   \n484      0.00000    0.00000    0.00000      0.00000         0.00000   \n\n     RATIO Exclaim  RATIO Period  AVG FPP  STD FPP  AVG SPP  STD SPP  AVG TPP  \\\n0          0.13333       0.73333  0.13333  0.33993  0.00000  0.00000  0.33333   \n1          0.15789       0.21053  0.26316  0.63595  0.26316  0.54696  0.05263   \n2          0.14286       0.57143  0.00000  0.00000  0.00000  0.00000  0.57143   \n3          0.07692       0.61538  0.30769  0.46154  0.07692  0.26647  0.38462   \n4          0.00000       0.80000  0.20000  0.40000  0.00000  0.00000  0.00000   \n..             ...           ...      ...      ...      ...      ...      ...   \n480        0.33333       0.66667  0.00000  0.00000  0.00000  0.00000  0.33333   \n481        0.00000       0.00000  0.00000  0.00000  0.00000  0.00000  0.00000   \n482        0.00000       1.00000  0.00000  0.00000  0.00000  0.00000  0.00000   \n483        0.00000       0.50000  0.25000  0.43301  0.00000  0.00000  0.50000   \n484        0.00000       1.00000  0.00000  0.00000  0.00000  0.00000  0.00000   \n\n     STD TPP  AVG Skepticism  \n0    0.69921         2.40000  \n1    0.22330         1.89474  \n2    0.49487         2.42857  \n3    0.62493         3.23077  \n4    0.00000         4.20000  \n..       ...             ...  \n480  0.47140         1.33333  \n481  0.00000         2.00000  \n482  0.00000         2.00000  \n483  0.50000         3.00000  \n484  0.00000         2.00000  \n\n[485 rows x 36 columns]"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ext_thread = pd.read_csv('./data/_PHEMEext_thread.csv')\n",
    "ext_thread\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>depth</th>\n      <th>SUM FriendsCount</th>\n      <th>AVG FriendsCount</th>\n      <th>AVG WordCount</th>\n      <th>AVG CharCount</th>\n      <th>AVG HashTag</th>\n      <th>SUM HashTag</th>\n      <th>Ratio HashTag</th>\n      <th>AVG Url</th>\n      <th>STD Url</th>\n      <th>RATIO Url</th>\n      <th>SUM Mention</th>\n      <th>AVG Mention</th>\n      <th>Ratio Mention</th>\n      <th>Tweets Count</th>\n      <th>Ratio Verified</th>\n      <th>SUM Verified</th>\n      <th>SUM RT</th>\n      <th>AVG RT</th>\n      <th>STD RT</th>\n      <th>AVG AccAge</th>\n      <th>STD AccAge</th>\n      <th>thread_time</th>\n      <th>STD Emoji</th>\n      <th>AVG Emoji</th>\n      <th>Ratio Media</th>\n      <th>RATIO Question</th>\n      <th>RATIO Exclaim</th>\n      <th>RATIO Period</th>\n      <th>AVG FPP</th>\n      <th>STD FPP</th>\n      <th>AVG SPP</th>\n      <th>STD SPP</th>\n      <th>AVG TPP</th>\n      <th>STD TPP</th>\n      <th>AVG Skepticism</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2.19794</td>\n      <td>7.61952</td>\n      <td>1.91587</td>\n      <td>10.01375</td>\n      <td>69.41844</td>\n      <td>0.59794</td>\n      <td>1.25361</td>\n      <td>0.29762</td>\n      <td>0.22614</td>\n      <td>0.10124</td>\n      <td>0.22078</td>\n      <td>3.59381</td>\n      <td>0.60497</td>\n      <td>0.40513</td>\n      <td>4.04742</td>\n      <td>0.06684</td>\n      <td>0.15258</td>\n      <td>40.95258</td>\n      <td>4.41943</td>\n      <td>9.69219</td>\n      <td>986.42153</td>\n      <td>370.60815</td>\n      <td>15581.70722</td>\n      <td>0.06312</td>\n      <td>0.03985</td>\n      <td>0.13214</td>\n      <td>0.15139</td>\n      <td>0.10150</td>\n      <td>0.52345</td>\n      <td>0.18014</td>\n      <td>0.19884</td>\n      <td>0.06492</td>\n      <td>0.06322</td>\n      <td>0.24703</td>\n      <td>0.20441</td>\n      <td>2.26836</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.70257</td>\n      <td>9.62440</td>\n      <td>1.05029</td>\n      <td>6.36584</td>\n      <td>42.83633</td>\n      <td>0.96245</td>\n      <td>1.75798</td>\n      <td>0.39206</td>\n      <td>0.37453</td>\n      <td>0.18859</td>\n      <td>0.35968</td>\n      <td>6.05126</td>\n      <td>0.66793</td>\n      <td>0.35595</td>\n      <td>4.83785</td>\n      <td>0.21699</td>\n      <td>0.38759</td>\n      <td>482.16712</td>\n      <td>25.62266</td>\n      <td>107.48288</td>\n      <td>709.21957</td>\n      <td>392.53652</td>\n      <td>51235.86482</td>\n      <td>0.25042</td>\n      <td>0.20250</td>\n      <td>0.29372</td>\n      <td>0.28140</td>\n      <td>0.21562</td>\n      <td>0.38458</td>\n      <td>0.33362</td>\n      <td>0.35683</td>\n      <td>0.22990</td>\n      <td>0.16169</td>\n      <td>0.40823</td>\n      <td>0.32968</td>\n      <td>1.75281</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.00000</td>\n      <td>2.48855</td>\n      <td>1.31377</td>\n      <td>5.50000</td>\n      <td>39.40000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>475.66667</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.16667</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>2.00000</td>\n      <td>3.79844</td>\n      <td>2.07485</td>\n      <td>10.00000</td>\n      <td>69.53333</td>\n      <td>0.04167</td>\n      <td>1.00000</td>\n      <td>0.04167</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0.50000</td>\n      <td>0.50000</td>\n      <td>2.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>3.00000</td>\n      <td>2.00000</td>\n      <td>0.00000</td>\n      <td>938.46154</td>\n      <td>209.00000</td>\n      <td>561.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.50000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>2.00000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>3.00000</td>\n      <td>9.19258</td>\n      <td>2.70672</td>\n      <td>15.00000</td>\n      <td>104.00000</td>\n      <td>1.00000</td>\n      <td>2.00000</td>\n      <td>0.50000</td>\n      <td>0.33333</td>\n      <td>0.00000</td>\n      <td>0.33333</td>\n      <td>4.00000</td>\n      <td>1.00000</td>\n      <td>0.66667</td>\n      <td>5.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>8.00000</td>\n      <td>4.00000</td>\n      <td>2.49444</td>\n      <td>1443.00000</td>\n      <td>726.71193</td>\n      <td>6964.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.05556</td>\n      <td>0.16667</td>\n      <td>0.11111</td>\n      <td>1.00000</td>\n      <td>0.25000</td>\n      <td>0.40000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.40000</td>\n      <td>0.43301</td>\n      <td>3.00000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>16.00000</td>\n      <td>57.40306</td>\n      <td>4.38684</td>\n      <td>29.00000</td>\n      <td>143.00000</td>\n      <td>6.00000</td>\n      <td>12.00000</td>\n      <td>1.00000</td>\n      <td>2.00000</td>\n      <td>0.94281</td>\n      <td>1.00000</td>\n      <td>38.00000</td>\n      <td>6.50000</td>\n      <td>1.00000</td>\n      <td>27.00000</td>\n      <td>1.00000</td>\n      <td>3.00000</td>\n      <td>10415.00000</td>\n      <td>548.15789</td>\n      <td>2322.57324</td>\n      <td>3021.00000</td>\n      <td>1432.00000</td>\n      <td>753999.00000</td>\n      <td>2.76385</td>\n      <td>3.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>2.00000</td>\n      <td>2.00000</td>\n      <td>2.00000</td>\n      <td>1.00000</td>\n      <td>2.00000</td>\n      <td>2.00000</td>\n      <td>9.00000</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "          depth  SUM FriendsCount  AVG FriendsCount  AVG WordCount  \\\ncount 485.00000         485.00000         485.00000      485.00000   \nmean    2.19794           7.61952           1.91587       10.01375   \nstd     1.70257           9.62440           1.05029        6.36584   \nmin     1.00000           0.00000           0.00000        0.00000   \n25%     1.00000           2.48855           1.31377        5.50000   \n50%     2.00000           3.79844           2.07485       10.00000   \n75%     3.00000           9.19258           2.70672       15.00000   \nmax    16.00000          57.40306           4.38684       29.00000   \n\n       AVG CharCount  AVG HashTag  SUM HashTag  Ratio HashTag   AVG Url  \\\ncount      485.00000    485.00000    485.00000      485.00000 485.00000   \nmean        69.41844      0.59794      1.25361        0.29762   0.22614   \nstd         42.83633      0.96245      1.75798        0.39206   0.37453   \nmin          0.00000      0.00000      0.00000        0.00000   0.00000   \n25%         39.40000      0.00000      0.00000        0.00000   0.00000   \n50%         69.53333      0.04167      1.00000        0.04167   0.00000   \n75%        104.00000      1.00000      2.00000        0.50000   0.33333   \nmax        143.00000      6.00000     12.00000        1.00000   2.00000   \n\n        STD Url  RATIO Url  SUM Mention  AVG Mention  Ratio Mention  \\\ncount 485.00000  485.00000    485.00000    485.00000      485.00000   \nmean    0.10124    0.22078      3.59381      0.60497        0.40513   \nstd     0.18859    0.35968      6.05126      0.66793        0.35595   \nmin     0.00000    0.00000      0.00000      0.00000        0.00000   \n25%     0.00000    0.00000      0.00000      0.00000        0.00000   \n50%     0.00000    0.00000      1.00000      0.50000        0.50000   \n75%     0.00000    0.33333      4.00000      1.00000        0.66667   \nmax     0.94281    1.00000     38.00000      6.50000        1.00000   \n\n       Tweets Count  Ratio Verified  SUM Verified      SUM RT    AVG RT  \\\ncount     485.00000       485.00000     485.00000   485.00000 485.00000   \nmean        4.04742         0.06684       0.15258    40.95258   4.41943   \nstd         4.83785         0.21699       0.38759   482.16712  25.62266   \nmin         1.00000         0.00000       0.00000     0.00000   0.00000   \n25%         1.00000         0.00000       0.00000     0.00000   0.00000   \n50%         2.00000         0.00000       0.00000     3.00000   2.00000   \n75%         5.00000         0.00000       0.00000     8.00000   4.00000   \nmax        27.00000         1.00000       3.00000 10415.00000 548.15789   \n\n          STD RT  AVG AccAge  STD AccAge  thread_time  STD Emoji  AVG Emoji  \\\ncount  485.00000   485.00000   485.00000    485.00000  485.00000  485.00000   \nmean     9.69219   986.42153   370.60815  15581.70722    0.06312    0.03985   \nstd    107.48288   709.21957   392.53652  51235.86482    0.25042    0.20250   \nmin      0.00000     0.00000     0.00000      0.00000    0.00000    0.00000   \n25%      0.00000   475.66667     0.00000      0.00000    0.00000    0.00000   \n50%      0.00000   938.46154   209.00000    561.00000    0.00000    0.00000   \n75%      2.49444  1443.00000   726.71193   6964.00000    0.00000    0.00000   \nmax   2322.57324  3021.00000  1432.00000 753999.00000    2.76385    3.00000   \n\n       Ratio Media  RATIO Question  RATIO Exclaim  RATIO Period   AVG FPP  \\\ncount    485.00000       485.00000      485.00000     485.00000 485.00000   \nmean       0.13214         0.15139        0.10150       0.52345   0.18014   \nstd        0.29372         0.28140        0.21562       0.38458   0.33362   \nmin        0.00000         0.00000        0.00000       0.00000   0.00000   \n25%        0.00000         0.00000        0.00000       0.16667   0.00000   \n50%        0.00000         0.00000        0.00000       0.50000   0.00000   \n75%        0.05556         0.16667        0.11111       1.00000   0.25000   \nmax        1.00000         1.00000        1.00000       1.00000   2.00000   \n\n        STD FPP   AVG SPP   STD SPP   AVG TPP   STD TPP  AVG Skepticism  \ncount 485.00000 485.00000 485.00000 485.00000 485.00000       485.00000  \nmean    0.19884   0.06492   0.06322   0.24703   0.20441         2.26836  \nstd     0.35683   0.22990   0.16169   0.40823   0.32968         1.75281  \nmin     0.00000   0.00000   0.00000   0.00000   0.00000         0.00000  \n25%     0.00000   0.00000   0.00000   0.00000   0.00000         1.00000  \n50%     0.00000   0.00000   0.00000   0.00000   0.00000         2.00000  \n75%     0.40000   0.00000   0.00000   0.40000   0.43301         3.00000  \nmax     2.00000   2.00000   1.00000   2.00000   2.00000         9.00000  "
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ext_thread.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['depth', 'SUM FriendsCount', 'AVG FriendsCount', 'AVG WordCount',\n       'AVG CharCount', 'AVG HashTag', 'SUM HashTag', 'Ratio HashTag',\n       'AVG Url', 'STD Url', 'RATIO Url', 'SUM Mention', 'AVG Mention',\n       'Ratio Mention', 'Tweets Count', 'Ratio Verified', 'SUM Verified',\n       'SUM RT', 'AVG RT', 'STD RT', 'AVG AccAge', 'STD AccAge', 'thread_time',\n       'STD Emoji', 'AVG Emoji', 'Ratio Media', 'RATIO Question',\n       'RATIO Exclaim', 'RATIO Period', 'AVG FPP', 'STD FPP', 'AVG SPP',\n       'STD SPP', 'AVG TPP', 'STD TPP', 'AVG Skepticism'],\n      dtype='object')"
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ext_thread.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>id</th>\n      <th>pid</th>\n      <th>emoji_count</th>\n      <th>has_media</th>\n      <th>URLcount</th>\n      <th>Skepticism</th>\n      <th>MentionCount</th>\n      <th>token_for_POS</th>\n      <th>Noun</th>\n      <th>Verb</th>\n      <th>Adjective</th>\n      <th>Pronoun</th>\n      <th>FirstPersonPronoun</th>\n      <th>SecondPersonPronoun</th>\n      <th>ThirdPersonPronoun</th>\n      <th>Adverb</th>\n      <th>Numeral</th>\n      <th>Conjunction_inj</th>\n      <th>Particle</th>\n      <th>Determiner</th>\n      <th>Modal</th>\n      <th>Whs</th>\n      <th>char_count</th>\n      <th>word_count</th>\n      <th>HashTag</th>\n      <th>has_question</th>\n      <th>has_exclaim</th>\n      <th>has_period</th>\n      <th>retweet_count</th>\n      <th>isRT</th>\n      <th>tweet_count</th>\n      <th>listed_count</th>\n      <th>friends_count</th>\n      <th>follow_ratio</th>\n      <th>account_age_days</th>\n      <th>tweet_created</th>\n      <th>capital_ratio</th>\n      <th>verified</th>\n      <th>Event</th>\n      <th>isSrcTweet</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>15</th>\n      <td>@MichaelEssien Glad you are healthy and well! #ForzaMilan</td>\n      <td>521368486053150721</td>\n      <td>521367917322338304.00000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>[glad, you, are, healthy, and, well]</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>57</td>\n      <td>8</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4.59222</td>\n      <td>2.09342</td>\n      <td>2.99782</td>\n      <td>3.52840</td>\n      <td>2118</td>\n      <td>1413138908.00000</td>\n      <td>0.08772</td>\n      <td>0</td>\n      <td>ebola-essien</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>@MichaelEssien that's a shame wanted to Invest in you😔</td>\n      <td>521368752135610368</td>\n      <td>521367917322338304.00000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>[that, is, a, shame, wanted, to, invest, in, you]</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>54</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>4.86344</td>\n      <td>0.69897</td>\n      <td>2.75282</td>\n      <td>4.02057</td>\n      <td>342</td>\n      <td>1413138971.00000</td>\n      <td>0.05556</td>\n      <td>0</td>\n      <td>ebola-essien</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>@MichaelEssien u got kik?</td>\n      <td>521368597734912000</td>\n      <td>521367917322338304.00000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>[u, got, kik]</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>25</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4.66114</td>\n      <td>0.47712</td>\n      <td>1.99123</td>\n      <td>3.22968</td>\n      <td>512</td>\n      <td>1413138934.00000</td>\n      <td>0.08000</td>\n      <td>0</td>\n      <td>ebola-essien</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                                         text  \\\n15  @MichaelEssien Glad you are healthy and well! #ForzaMilan   \n16     @MichaelEssien that's a shame wanted to Invest in you😔   \n18                                  @MichaelEssien u got kik?   \n\n                    id                      pid  emoji_count  has_media  \\\n15  521368486053150721 521367917322338304.00000            0          0   \n16  521368752135610368 521367917322338304.00000            1          0   \n18  521368597734912000 521367917322338304.00000            0          0   \n\n    URLcount  Skepticism  MentionCount  \\\n15         0           3             1   \n16         0           3             1   \n18         0           1             1   \n\n                                        token_for_POS  Noun  Verb  Adjective  \\\n15               [glad, you, are, healthy, and, well]     1     1          1   \n16  [that, is, a, shame, wanted, to, invest, in, you]     1     3          0   \n18                                      [u, got, kik]     1     1          1   \n\n    Pronoun  FirstPersonPronoun  SecondPersonPronoun  ThirdPersonPronoun  \\\n15        1                   0                    1                   0   \n16        1                   0                    1                   0   \n18        0                   0                    0                   0   \n\n    Adverb  Numeral  Conjunction_inj  Particle  Determiner  Modal  Whs  \\\n15       1        0                1         0           0      0    0   \n16       0        0                1         0           2      0    0   \n18       0        0                0         0           0      0    0   \n\n    char_count  word_count  HashTag  has_question  has_exclaim  has_period  \\\n15          57           8        1             0            1           0   \n16          54           9        0             0            0           0   \n18          25           4        0             1            0           0   \n\n    retweet_count isRT  tweet_count  listed_count  friends_count  \\\n15              0    0      4.59222       2.09342        2.99782   \n16              2    0      4.86344       0.69897        2.75282   \n18              1    0      4.66114       0.47712        1.99123   \n\n    follow_ratio  account_age_days    tweet_created  capital_ratio  verified  \\\n15       3.52840              2118 1413138908.00000        0.08772         0   \n16       4.02057               342 1413138971.00000        0.05556         0   \n18       3.22968               512 1413138934.00000        0.08000         0   \n\n           Event  isSrcTweet  target  \n15  ebola-essien           0       1  \n16  ebola-essien           0       1  \n18  ebola-essien           0       1  "
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ext.loc[(all_ext['pid'] == int(521367917322338304))].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BERT & EMOJI 이모지 다루는 차이 😂😂😂😂😂\n",
    "\n",
    "> Before applying fastBPE to the pre-training corpus of 850M English Tweets, we tokenized these Tweets using TweetTokenizer from the NLTK toolkit and used the emoji package to translate emotion icons into text strings (here, each icon is referred to as a word token). We also normalized the Tweets by converting user mentions and web/url links into special tokens @USER and HTTPURL, respectively. Thus it is recommended to also apply the same pre-processing step for BERTweet-based downstream applications w.r.t. the raw input Tweets. BERTweet provides this pre-processing step by enabling the normalization argument.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer \n",
    "bertweet = AutoModel.from_pretrained(\"vinai/bertweet-base\", )\n",
    "\n",
    "# For transformers v4.x+: \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=False, normalization=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[array(['2014-10-12 21:22:36+00:00'], dtype=object),\n array([], dtype=object),\n array(['2014-10-12 18:38:41+00:00'], dtype=object),\n array(['2014-10-12 18:43:07+00:00'], dtype=object),\n array(['2014-10-12 18:42:02+00:00'], dtype=object),\n array(['2014-10-12 18:44:13+00:00'], dtype=object),\n array(['2014-10-12 19:15:21+00:00'], dtype=object),\n array([], dtype=object),\n array(['2014-10-12 18:54:47+00:00'], dtype=object),\n array(['2014-10-12 18:39:06+00:00'], dtype=object),\n array(['2014-10-12 18:41:23+00:00'], dtype=object),\n array(['2014-10-12 18:39:51+00:00'], dtype=object),\n array([], dtype=object),\n array(['2014-10-12 18:56:53+00:00'], dtype=object)]"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ext_thread.thread_time[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT TWEET IS ALREADY NORMALIZED!\n",
    "line = \"@MichaelEssien that's a shame wanted to Invest in you😔\"\n",
    "print(line)\n",
    "print(tokenizer.encode(line),\"\\n\")\n",
    "input_ids = torch.tensor([tokenizer.encode(line)])\n",
    "# print(input_ids)\n",
    "\n",
    "line = \"HTTPURL @MichaelEssien that's a shame wanted to Invest INVEST in you😔😂😂 http://www.google.com\"\n",
    "input_ids = torch.tensor([tokenizer.encode(line)])\n",
    "print(line)\n",
    "print(tokenizer.encode(line),\"\\n\")\n",
    "\n",
    "line = \"HTTPURL @USER that's a shame wanted to Invest INVEST in you:pensive_face::face_with_tears_of_joy::face_with_tears_of_joy: HTTPURL\"\n",
    "input_ids = torch.tensor([tokenizer.encode(line)])\n",
    "print(line)\n",
    "print(tokenizer.encode(line),\"\\n\")\n",
    "\n",
    "line = \"HTTPURL @USER that's a shame wanted to Invest INVEST in you pensive_face face_with_tears_of_joy face_with_tears_of_joy :grinning_face_with_big_eyes: HTTPURL  \"\n",
    "input_ids = torch.tensor([tokenizer.encode(line)])\n",
    "print(line)\n",
    "print(tokenizer.encode(line))\n",
    "\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     features = bertweet(input_ids)  # Models outputs are now tuples\n",
    "# print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"HTTPURL @MichaelEssien that's a shame wanted to Invest INVEST in you😔😂😂😃 http://www.google.com\"\n",
    "print(emoji.emoji_count(text),\"\\n\")\n",
    "print(text)\n",
    "text = emoji.demojize(text)\n",
    "# print(emoji.get_emoji_regexp(),\"\\n\")\n",
    "# text=text.strip(':')\n",
    "# text = re.sub(r'(@.*?)[\\s]', '@USER ', text)\n",
    "text = re.sub(r\"@\\S+\", \"@USER\", text)   # mention -> '@'\n",
    "text = re.sub(r\"http\\S+\", \"HTTPURL\", text)  # http link -> '*'\n",
    "emojis = re.findall(r'(::)', text)\n",
    "print(emojis)\n",
    "# print(text,\"\\n\")\n",
    "text = re.sub(r':[^:]*:', r' \\g<0>', text)  # http link -> '*'\n",
    "print(text,\"\\n\")\n",
    "\n",
    "text=text.split()\n",
    "# text= re.sub(r'(:[!_\\-\\w]+:)', '', text)\n",
    "print(text,\"\\n\")\n",
    "# emojis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 추가 데이터들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ext.loc[(all_ext['id'] == int(529657433866915840))].HashTag.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ext.loc[(all_ext['pid'] == int(521367917322338304))][['text','token_for_POS','HashTag','Pronoun','FirstPersonPronoun','SecondPersonPronoun','ThirdPersonPronoun','Numeral','Modal','Whs', 'Noun', 'Verb','Adjective','has_question',\t'has_exclaim',\t'has_period']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_ext.loc[((all_ext['Skepticism'] >-1))].groupby('target').mean()  #[['text','URLcount','token_for_POS','id','pid','HashTag','Pronoun','FirstPersonPronoun','SecondPersonPronoun','ThirdPersonPronoun']]\n",
    "all_ext.loc[((all_ext['Skepticism'] >-1))].groupby('target').mean()  #[['text','URLcount','token_for_POS','id','pid','HashTag','Pronoun','FirstPersonPronoun','SecondPersonPronoun','ThirdPersonPronoun']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([ext_thread, ext_y], axis=1).groupby('target').mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ext[['id','text','token_for_POS','HashTag','URLcount','target','Skepticism']].loc[all_ext.HashTag > 4]\n",
    "# all_ext['HashTag'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.max([np.sum(all_ext.loc[(all_ext['id'] == int(childid))]['tweet_created'].values) for childid in structure_ext.loc[0,'0':].dropna()])\n",
    "# np.max([np.sum(all_ext.loc[(all_ext['id'] == childid)]['tweet_created']) for childid in structure_ext.loc[0,'0':'13'].dropna()] - all_ext.loc[(all_ext['id'] == int(521369179392581632))].tweet_created.sum())\n",
    "[np.sum(all_ext.loc[(all_ext['id'] == childid)]['urls_dicts_len']) for childid in structure_ext.loc[11,:].dropna().drop(['depth'],axis=0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thread()를 만드는데 필요한 정보들\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>pid</th>\n      <th>emoji_count</th>\n      <th>has_media</th>\n      <th>URLcount</th>\n      <th>Skepticism</th>\n      <th>MentionCount</th>\n      <th>Noun</th>\n      <th>Verb</th>\n      <th>Adjective</th>\n      <th>Pronoun</th>\n      <th>FirstPersonPronoun</th>\n      <th>SecondPersonPronoun</th>\n      <th>ThirdPersonPronoun</th>\n      <th>Adverb</th>\n      <th>Numeral</th>\n      <th>Conjunction_inj</th>\n      <th>Particle</th>\n      <th>Determiner</th>\n      <th>Modal</th>\n      <th>Whs</th>\n      <th>char_count</th>\n      <th>word_count</th>\n      <th>HashTag</th>\n      <th>has_question</th>\n      <th>has_exclaim</th>\n      <th>has_period</th>\n      <th>retweet_count</th>\n      <th>tweet_count</th>\n      <th>listed_count</th>\n      <th>friends_count</th>\n      <th>follow_ratio</th>\n      <th>account_age_days</th>\n      <th>tweet_created</th>\n      <th>capital_ratio</th>\n      <th>verified</th>\n      <th>isSrcTweet</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1963.00000</td>\n      <td>1478.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n      <td>1963.00000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>548748486071387968.00000</td>\n      <td>547483663616841984.00000</td>\n      <td>0.08304</td>\n      <td>0.11768</td>\n      <td>0.19511</td>\n      <td>3.03311</td>\n      <td>1.26490</td>\n      <td>3.49465</td>\n      <td>2.37341</td>\n      <td>0.89812</td>\n      <td>0.65869</td>\n      <td>0.33724</td>\n      <td>0.11258</td>\n      <td>0.39226</td>\n      <td>0.72033</td>\n      <td>0.12124</td>\n      <td>1.29954</td>\n      <td>0.06928</td>\n      <td>0.78859</td>\n      <td>0.20122</td>\n      <td>0.18136</td>\n      <td>88.74325</td>\n      <td>13.01528</td>\n      <td>0.44320</td>\n      <td>0.18747</td>\n      <td>0.17728</td>\n      <td>0.63169</td>\n      <td>13.43301</td>\n      <td>3.85033</td>\n      <td>1.18417</td>\n      <td>2.67871</td>\n      <td>2.86539</td>\n      <td>1296.51605</td>\n      <td>1419666808.49159</td>\n      <td>0.08952</td>\n      <td>0.06470</td>\n      <td>0.24707</td>\n      <td>0.81915</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>24197288222753516.00000</td>\n      <td>24194908479467996.00000</td>\n      <td>0.52533</td>\n      <td>0.32231</td>\n      <td>0.40779</td>\n      <td>2.08666</td>\n      <td>0.92597</td>\n      <td>2.55108</td>\n      <td>1.83844</td>\n      <td>0.99326</td>\n      <td>0.92956</td>\n      <td>0.72692</td>\n      <td>0.36411</td>\n      <td>0.68698</td>\n      <td>0.98238</td>\n      <td>0.37989</td>\n      <td>1.26827</td>\n      <td>0.26190</td>\n      <td>0.91239</td>\n      <td>0.46241</td>\n      <td>0.44552</td>\n      <td>39.00655</td>\n      <td>6.42202</td>\n      <td>0.98470</td>\n      <td>0.39039</td>\n      <td>0.38200</td>\n      <td>0.48247</td>\n      <td>254.08308</td>\n      <td>0.81881</td>\n      <td>0.92393</td>\n      <td>0.59617</td>\n      <td>0.93745</td>\n      <td>737.28048</td>\n      <td>5769083.07608</td>\n      <td>0.07571</td>\n      <td>0.24605</td>\n      <td>0.43142</td>\n      <td>0.38499</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>521310417696858112.00000</td>\n      <td>521310417696858112.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>8.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.30103</td>\n      <td>3.00000</td>\n      <td>1413125063.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>529676680548595712.00000</td>\n      <td>529654768249354240.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>55.00000</td>\n      <td>8.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>3.39872</td>\n      <td>0.47712</td>\n      <td>2.32118</td>\n      <td>2.24674</td>\n      <td>652.00000</td>\n      <td>1415119735.50000</td>\n      <td>0.04167</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>529753935545118720.00000</td>\n      <td>529735657531656192.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>3.00000</td>\n      <td>1.00000</td>\n      <td>3.00000</td>\n      <td>2.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>90.00000</td>\n      <td>13.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>3.94161</td>\n      <td>1.11394</td>\n      <td>2.73957</td>\n      <td>2.82478</td>\n      <td>1313.00000</td>\n      <td>1415138155.00000</td>\n      <td>0.07246</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>576560832456267776.00000</td>\n      <td>576504635738951680.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>4.00000</td>\n      <td>2.00000</td>\n      <td>5.00000</td>\n      <td>4.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>2.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>128.00000</td>\n      <td>18.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>2.00000</td>\n      <td>4.43603</td>\n      <td>1.78174</td>\n      <td>3.04513</td>\n      <td>3.39436</td>\n      <td>2031.00000</td>\n      <td>1426297788.50000</td>\n      <td>0.11611</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>579479145828257792.00000</td>\n      <td>577453947599777792.00000</td>\n      <td>10.00000</td>\n      <td>1.00000</td>\n      <td>2.00000</td>\n      <td>12.00000</td>\n      <td>7.00000</td>\n      <td>21.00000</td>\n      <td>10.00000</td>\n      <td>6.00000</td>\n      <td>5.00000</td>\n      <td>7.00000</td>\n      <td>3.00000</td>\n      <td>5.00000</td>\n      <td>6.00000</td>\n      <td>3.00000</td>\n      <td>7.00000</td>\n      <td>2.00000</td>\n      <td>5.00000</td>\n      <td>3.00000</td>\n      <td>3.00000</td>\n      <td>148.00000</td>\n      <td>29.00000</td>\n      <td>7.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>10402.00000</td>\n      <td>5.73594</td>\n      <td>4.15927</td>\n      <td>4.83829</td>\n      <td>6.31487</td>\n      <td>3021.00000</td>\n      <td>1426993569.00000</td>\n      <td>0.76471</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                            id                      pid  emoji_count  \\\ncount               1963.00000               1478.00000   1963.00000   \nmean  548748486071387968.00000 547483663616841984.00000      0.08304   \nstd    24197288222753516.00000  24194908479467996.00000      0.52533   \nmin   521310417696858112.00000 521310417696858112.00000      0.00000   \n25%   529676680548595712.00000 529654768249354240.00000      0.00000   \n50%   529753935545118720.00000 529735657531656192.00000      0.00000   \n75%   576560832456267776.00000 576504635738951680.00000      0.00000   \nmax   579479145828257792.00000 577453947599777792.00000     10.00000   \n\n       has_media   URLcount  Skepticism  MentionCount       Noun       Verb  \\\ncount 1963.00000 1963.00000  1963.00000    1963.00000 1963.00000 1963.00000   \nmean     0.11768    0.19511     3.03311       1.26490    3.49465    2.37341   \nstd      0.32231    0.40779     2.08666       0.92597    2.55108    1.83844   \nmin      0.00000    0.00000     0.00000       0.00000    0.00000    0.00000   \n25%      0.00000    0.00000     1.00000       1.00000    1.00000    1.00000   \n50%      0.00000    0.00000     3.00000       1.00000    3.00000    2.00000   \n75%      0.00000    0.00000     4.00000       2.00000    5.00000    4.00000   \nmax      1.00000    2.00000    12.00000       7.00000   21.00000   10.00000   \n\n       Adjective    Pronoun  FirstPersonPronoun  SecondPersonPronoun  \\\ncount 1963.00000 1963.00000          1963.00000           1963.00000   \nmean     0.89812    0.65869             0.33724              0.11258   \nstd      0.99326    0.92956             0.72692              0.36411   \nmin      0.00000    0.00000             0.00000              0.00000   \n25%      0.00000    0.00000             0.00000              0.00000   \n50%      1.00000    0.00000             0.00000              0.00000   \n75%      1.00000    1.00000             0.00000              0.00000   \nmax      6.00000    5.00000             7.00000              3.00000   \n\n       ThirdPersonPronoun     Adverb    Numeral  Conjunction_inj   Particle  \\\ncount          1963.00000 1963.00000 1963.00000       1963.00000 1963.00000   \nmean              0.39226    0.72033    0.12124          1.29954    0.06928   \nstd               0.68698    0.98238    0.37989          1.26827    0.26190   \nmin               0.00000    0.00000    0.00000          0.00000    0.00000   \n25%               0.00000    0.00000    0.00000          0.00000    0.00000   \n50%               0.00000    0.00000    0.00000          1.00000    0.00000   \n75%               1.00000    1.00000    0.00000          2.00000    0.00000   \nmax               5.00000    6.00000    3.00000          7.00000    2.00000   \n\n       Determiner      Modal        Whs  char_count  word_count    HashTag  \\\ncount  1963.00000 1963.00000 1963.00000  1963.00000  1963.00000 1963.00000   \nmean      0.78859    0.20122    0.18136    88.74325    13.01528    0.44320   \nstd       0.91239    0.46241    0.44552    39.00655     6.42202    0.98470   \nmin       0.00000    0.00000    0.00000     8.00000     1.00000    0.00000   \n25%       0.00000    0.00000    0.00000    55.00000     8.00000    0.00000   \n50%       1.00000    0.00000    0.00000    90.00000    13.00000    0.00000   \n75%       1.00000    0.00000    0.00000   128.00000    18.00000    0.00000   \nmax       5.00000    3.00000    3.00000   148.00000    29.00000    7.00000   \n\n       has_question  has_exclaim  has_period  retweet_count  tweet_count  \\\ncount    1963.00000   1963.00000  1963.00000     1963.00000   1963.00000   \nmean        0.18747      0.17728     0.63169       13.43301      3.85033   \nstd         0.39039      0.38200     0.48247      254.08308      0.81881   \nmin         0.00000      0.00000     0.00000        0.00000      0.00000   \n25%         0.00000      0.00000     0.00000        0.00000      3.39872   \n50%         0.00000      0.00000     1.00000        0.00000      3.94161   \n75%         0.00000      0.00000     1.00000        2.00000      4.43603   \nmax         1.00000      1.00000     1.00000    10402.00000      5.73594   \n\n       listed_count  friends_count  follow_ratio  account_age_days  \\\ncount    1963.00000     1963.00000    1963.00000        1963.00000   \nmean        1.18417        2.67871       2.86539        1296.51605   \nstd         0.92393        0.59617       0.93745         737.28048   \nmin         0.00000        0.00000       0.30103           3.00000   \n25%         0.47712        2.32118       2.24674         652.00000   \n50%         1.11394        2.73957       2.82478        1313.00000   \n75%         1.78174        3.04513       3.39436        2031.00000   \nmax         4.15927        4.83829       6.31487        3021.00000   \n\n         tweet_created  capital_ratio   verified  isSrcTweet     target  \ncount       1963.00000     1963.00000 1963.00000  1963.00000 1963.00000  \nmean  1419666808.49159        0.08952    0.06470     0.24707    0.81915  \nstd      5769083.07608        0.07571    0.24605     0.43142    0.38499  \nmin   1413125063.00000        0.00000    0.00000     0.00000    0.00000  \n25%   1415119735.50000        0.04167    0.00000     0.00000    1.00000  \n50%   1415138155.00000        0.07246    0.00000     0.00000    1.00000  \n75%   1426297788.50000        0.11611    0.00000     0.00000    1.00000  \nmax   1426993569.00000        0.76471    1.00000     1.00000    1.00000  "
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ext.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "target\n1    71\n0    26\ndtype: int64"
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ext.loc[all_ext['account_age_days']<100][['account_age_days','verified', 'HashTag', 'URLcount',\n",
    "                                           'MentionCount', 'retweet_count', 'isSrcTweet', 'target']].value_counts('target')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-240-4b19871eb0f9>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-240-4b19871eb0f9>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    all_ext.loc[all_ext['depth']<5][['account_age_days','verified', 'HashTag', 'URLcount',\u001b[0m\n\u001b[0m                                                                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "all_ext.loc[all_ext['depth']<10][['account_age_days','verified', 'HashTag', 'URLcount',\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>verified</th>\n      <th>HashTag</th>\n      <th>URLcount</th>\n      <th>MentionCount</th>\n      <th>retweet_count</th>\n      <th>isSrcTweet</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>320</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>272</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>442</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1860</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1657</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>8</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1177</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>915</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1873</th>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1712</th>\n      <td>0</td>\n      <td>5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>15</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>603</th>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1779</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1528</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>11</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>574</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>280</th>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>10</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>13</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>659</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>22</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>666</th>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>562</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "      verified  HashTag  URLcount  MentionCount  retweet_count  isSrcTweet  \\\n320          0        1         0             2              1           0   \n272          0        0         0             0              2           1   \n442          1        1         1             0              2           1   \n1860         0        0         0             1              1           0   \n1657         0        0         0             1              8           0   \n1177         0        1         1             1              5           1   \n915          0        0         0             1              1           0   \n1873         0        2         0             1              1           0   \n1712         0        5         1             0             15           1   \n603          0        0         2             0              3           1   \n1779         0        1         2             0              4           1   \n1528         0        0         1             0             11           1   \n574          0        1         1             2              2           1   \n280          0        2         0             0             10           1   \n198          0        0         0             1             13           0   \n659          1        0         0             0             22           1   \n666          0        3         1             2              1           0   \n562          0        0         0             0              2           1   \n\n      target  \n320        1  \n272        1  \n442        1  \n1860       0  \n1657       0  \n1177       1  \n915        1  \n1873       0  \n1712       0  \n603        1  \n1779       0  \n1528       1  \n574        1  \n280        1  \n198        1  \n659        1  \n666        1  \n562        1  "
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ext.loc[(all_ext['retweet_count'] > 0) and (all_ext.pid==521369179392581632)][['verified', 'HashTag', 'URLcount',\n",
    "                                           'MentionCount', 'retweet_count', 'isSrcTweet', 'target']].sample(18)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>verified</th>\n      <th>HashTag</th>\n      <th>URLcount</th>\n      <th>MentionCount</th>\n      <th>retweet_count</th>\n    </tr>\n    <tr>\n      <th>target</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.03356</td>\n      <td>1.77852</td>\n      <td>0.65772</td>\n      <td>0.44966</td>\n      <td>12.28859</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.19880</td>\n      <td>0.73695</td>\n      <td>0.73695</td>\n      <td>0.68273</td>\n      <td>49.27309</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "        verified  HashTag  URLcount  MentionCount  retweet_count\ntarget                                                          \n0        0.03356  1.77852   0.65772       0.44966       12.28859\n1        0.19880  0.73695   0.73695       0.68273       49.27309"
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ext.loc[all_ext['retweet_count']>0][['text', 'verified', 'HashTag', 'URLcount', 'MentionCount','retweet_count','target']].groupby('target').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0    521410632953131008.00000\n1    521373142347153408.00000\n2    521369380249432064.00000\n3    521370496928337920.00000\n4    521370224256614400.00000\n5    521370771793670144.00000\n6    521378607231279104.00000\n7    521370530134626304.00000\n8    521373433654157312.00000\n9    521369485144387584.00000\n10   521370061550809088.00000\n11   521369671975858176.00000\n12   521372372927266816.00000\n13   521373960509079552.00000\nName: 0, dtype: float64"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structure_ext.loc[0,'0':].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "15"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# friends_count = [np.sum(all_ext.loc[(all_ext['id'] == int(childid))]['friends_count'].values) for childid in structure_ext.loc[0,'0':].dropna()]\n",
    "len([childid for childid in structure_ext.loc[0,:].dropna()]) \n",
    "\n",
    "# # '''print where 'Sum Friends Count' is 0'''\n",
    "# ext_thread.loc[ext_thread['Sum Friends Count'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Root   521369179392581632.00000\n0      521410632953131008.00000\n1      521373142347153408.00000\n2      521369380249432064.00000\n3      521370496928337920.00000\n4      521370224256614400.00000\n5      521370771793670144.00000\n6      521378607231279104.00000\n7      521370530134626304.00000\n8      521373433654157312.00000\n9      521369485144387584.00000\n10     521370061550809088.00000\n11     521369671975858176.00000\n12     521372372927266816.00000\n13     521373960509079552.00000\nName: 0, dtype: float64"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structure_ext.loc[0].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth : 0.09651135294025893\n",
      "SUM FriendsCount : 0.11708794533602392\n",
      "AVG FriendsCount : 0.06858376543611712\n",
      "AVG WordCount : 0.08943391962695811\n",
      "AVG CharCount : 0.05225660220179892\n",
      "AVG HashTag : -0.2712498153933583\n",
      "SUM HashTag : -0.2020213812062223\n",
      "Ratio HashTag : -0.240456334984137\n",
      "AVG Url : 0.14876200291574\n",
      "STD Url : 0.12458058557305425\n",
      "RATIO Url : 0.1453347220107918\n",
      "SUM Mention : 0.12588775058523002\n",
      "AVG Mention : 0.17327324771229943\n",
      "Ratio Mention : 0.18082808972064832\n",
      "Tweets Count : 0.11451521885513202\n",
      "Ratio Verified : 0.17773330379532\n",
      "SUM Verified : 0.20925620944171405\n",
      "SUM RT : 0.04211967680606234\n",
      "AVG RT : 0.008996997540094446\n",
      "STD RT : 0.04153692828246094\n",
      "AVG AccAge : 0.07005471617303197\n",
      "STD AccAge : 0.04071581547793717\n",
      "thread_time : 0.5331074867901635\n",
      "STD Emoji : 0.10345835221768021\n",
      "AVG Emoji : 0.034777051500645445\n",
      "Ratio Media : -0.23048349004434254\n",
      "RATIO Question : 0.07184087232996553\n",
      "RATIO Exclaim : -0.013189960608181589\n",
      "RATIO Period : -0.028188725777964507\n",
      "AVG FPP : -0.0063552516058029895\n",
      "STD FPP : 0.09478814765368376\n",
      "AVG SPP : -0.028301014299289187\n",
      "STD SPP : 0.008505390026803394\n",
      "AVG TPP : -0.0633077622426266\n",
      "STD TPP : 0.039503662633227604\n",
      "AVG Skepticism : -0.008395034821742257\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (all_ext.loc[(all_ext['pid'] == 521369179392581632)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(X_train, X_test, y_train, y_test, clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    result = clf.predict(X_test)\n",
    "    print(\"Accuracy:\\t\\t\",accuracy_score(y_test,result))\n",
    "    print('Precision Score:\\t', str(precision_score(y_test,result)))\n",
    "    print('Recall Score:\\t\\t' + str(recall_score(y_test,result)))\n",
    "    print(\"F1 Score:\\t\\t\",f1_score(y_test, result, average='macro', zero_division=True))\n",
    "    print(classification_report(y_test, result))\n",
    "    \n",
    "pheme_all = pd.read_csv(\"./data/all/_PHEMEall.csv\")\n",
    "pheme_thread = pd.read_csv(\"./data/_PHEME_thread.csv\")\n",
    "pheme_y = pd.read_csv('./data/_PHEME_text.csv').target\n",
    "ext_all = pd.read_csv(\"./data/all/_PHEMEextall.csv\")\n",
    "ext_thread = pd.read_csv(\"./data/_PHEMEext_thread.csv\")\n",
    "ext_y = pd.read_csv('./data/_PHEMEext_text.csv').target\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# ext_thread = ext_thread.replace(-np.inf, 0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(ext_thread.iloc[:,:], ext_y, test_size=0.12, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "pheme_thread_scaled = scaler.fit_transform(pheme_thread)\n",
    "ext_thread_scaled = scaler.transform(ext_thread)\n",
    "\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.6907216494845361\n",
      "Precision Score:\t 0.6907216494845361\n",
      "Recall Score:\t\t1.0\n",
      "F1 Score:\t\t 0.40853658536585363\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        30\n",
      "           1       0.69      1.00      0.82        67\n",
      "\n",
      "    accuracy                           0.69        97\n",
      "   macro avg       0.35      0.50      0.41        97\n",
      "weighted avg       0.48      0.69      0.56        97\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Part of X_ext\n",
    "clf = SVC()\n",
    "train_test(X_train.iloc[:,0:11], X_test.iloc[:,0:11], y_train, y_test, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.7627118644067796\n",
      "Precision Score:\t 0.9032258064516129\n",
      "Recall Score:\t\t0.717948717948718\n",
      "F1 Score:\t\t 0.7541666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.85      0.71        20\n",
      "           1       0.90      0.72      0.80        39\n",
      "\n",
      "    accuracy                           0.76        59\n",
      "   macro avg       0.76      0.78      0.75        59\n",
      "weighted avg       0.80      0.76      0.77        59\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# All X_ext\n",
    "clf = GaussianNB()\n",
    "train_test(X_train, X_test, y_train, y_test, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.7796610169491526\n",
      "Precision Score:\t 0.76\n",
      "Recall Score:\t\t0.9743589743589743\n",
      "F1 Score:\t\t 0.7028283611003487\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.40      0.55        20\n",
      "           1       0.76      0.97      0.85        39\n",
      "\n",
      "    accuracy                           0.78        59\n",
      "   macro avg       0.82      0.69      0.70        59\n",
      "weighted avg       0.80      0.78      0.75        59\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 12\n",
    "clf = SVC()\n",
    "train_test(X_train, X_test, y_train, y_test, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.6247422680412371\n",
      "Precision Score:\t 0.7741935483870968\n",
      "Recall Score:\t\t0.7154471544715447\n",
      "F1 Score:\t\t 0.5218309859154929\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.34      0.30       116\n",
      "           1       0.77      0.72      0.74       369\n",
      "\n",
      "    accuracy                           0.62       485\n",
      "   macro avg       0.52      0.53      0.52       485\n",
      "weighted avg       0.65      0.62      0.64       485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# All PHEME/ext\n",
    "clf = GaussianNB()\n",
    "train_test(pheme_thread_scaled, ext_thread_scaled, pheme_y, ext_y, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DL\n",
    "\n",
    "Training data: pheme_thread_scaled\n",
    "\n",
    "Testing data: ext_thread_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>depth</th>\n      <th>SUM FriendsCount</th>\n      <th>AVG FriendsCount</th>\n      <th>AVG WordCount</th>\n      <th>AVG CharCount</th>\n      <th>AVG HashTag</th>\n      <th>SUM HashTag</th>\n      <th>Ratio HashTag</th>\n      <th>AVG Url</th>\n      <th>STD Url</th>\n      <th>RATIO Url</th>\n      <th>SUM Mention</th>\n      <th>AVG Mention</th>\n      <th>Ratio Mention</th>\n      <th>Tweets Count</th>\n      <th>Ratio Verified</th>\n      <th>SUM Verified</th>\n      <th>SUM RT</th>\n      <th>AVG RT</th>\n      <th>STD RT</th>\n      <th>AVG AccAge</th>\n      <th>STD AccAge</th>\n      <th>thread_time</th>\n      <th>STD Emoji</th>\n      <th>AVG Emoji</th>\n      <th>Ratio Media</th>\n      <th>RATIO Question</th>\n      <th>RATIO Exclaim</th>\n      <th>RATIO Period</th>\n      <th>AVG FPP</th>\n      <th>STD FPP</th>\n      <th>AVG SPP</th>\n      <th>STD SPP</th>\n      <th>AVG TPP</th>\n      <th>STD TPP</th>\n      <th>AVG Skepticism</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n      <td>5802.00000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>4.44485</td>\n      <td>47.71738</td>\n      <td>2.69625</td>\n      <td>14.12534</td>\n      <td>98.17147</td>\n      <td>0.49636</td>\n      <td>5.68218</td>\n      <td>0.30148</td>\n      <td>0.16980</td>\n      <td>0.23129</td>\n      <td>0.15955</td>\n      <td>30.27749</td>\n      <td>1.40993</td>\n      <td>0.85680</td>\n      <td>17.78904</td>\n      <td>0.09014</td>\n      <td>0.93554</td>\n      <td>593.67890</td>\n      <td>54.18365</td>\n      <td>107.02151</td>\n      <td>1301.45512</td>\n      <td>656.56185</td>\n      <td>42042.33919</td>\n      <td>0.13800</td>\n      <td>0.05157</td>\n      <td>0.15089</td>\n      <td>0.12817</td>\n      <td>0.11582</td>\n      <td>0.68090</td>\n      <td>0.28007</td>\n      <td>0.44079</td>\n      <td>0.16835</td>\n      <td>0.31677</td>\n      <td>0.36429</td>\n      <td>0.52918</td>\n      <td>3.43485</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>3.88666</td>\n      <td>54.60815</td>\n      <td>0.42489</td>\n      <td>3.31060</td>\n      <td>20.47492</td>\n      <td>0.58934</td>\n      <td>6.19011</td>\n      <td>0.26675</td>\n      <td>0.24628</td>\n      <td>0.22348</td>\n      <td>0.22659</td>\n      <td>46.74222</td>\n      <td>0.65022</td>\n      <td>0.22467</td>\n      <td>20.09487</td>\n      <td>0.16636</td>\n      <td>1.54716</td>\n      <td>3559.90091</td>\n      <td>253.02338</td>\n      <td>618.82036</td>\n      <td>404.98186</td>\n      <td>278.92828</td>\n      <td>105966.08161</td>\n      <td>0.57902</td>\n      <td>0.22355</td>\n      <td>0.23264</td>\n      <td>0.13394</td>\n      <td>0.13547</td>\n      <td>0.22620</td>\n      <td>0.28947</td>\n      <td>0.32284</td>\n      <td>0.22777</td>\n      <td>0.29921</td>\n      <td>0.33694</td>\n      <td>0.36382</td>\n      <td>1.18817</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>4.00000</td>\n      <td>32.05263</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>25.00000</td>\n      <td>0.80399</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2.00000</td>\n      <td>17.68543</td>\n      <td>2.45857</td>\n      <td>12.00000</td>\n      <td>85.55952</td>\n      <td>0.14286</td>\n      <td>2.00000</td>\n      <td>0.10526</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>8.00000</td>\n      <td>1.00000</td>\n      <td>0.85714</td>\n      <td>7.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>135.00000</td>\n      <td>11.36364</td>\n      <td>35.36346</td>\n      <td>1050.45909</td>\n      <td>550.85241</td>\n      <td>852.50000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.54545</td>\n      <td>0.06667</td>\n      <td>0.22330</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.12500</td>\n      <td>0.31427</td>\n      <td>2.66667</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>3.00000</td>\n      <td>37.92571</td>\n      <td>2.66155</td>\n      <td>14.03274</td>\n      <td>97.69925</td>\n      <td>0.33333</td>\n      <td>4.00000</td>\n      <td>0.23077</td>\n      <td>0.06667</td>\n      <td>0.22906</td>\n      <td>0.06667</td>\n      <td>20.00000</td>\n      <td>1.33333</td>\n      <td>0.93750</td>\n      <td>14.00000</td>\n      <td>0.04348</td>\n      <td>1.00000</td>\n      <td>214.00000</td>\n      <td>21.14286</td>\n      <td>54.70362</td>\n      <td>1278.36250</td>\n      <td>671.42693</td>\n      <td>6901.50000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.05000</td>\n      <td>0.11111</td>\n      <td>0.09091</td>\n      <td>0.68182</td>\n      <td>0.22500</td>\n      <td>0.44536</td>\n      <td>0.10526</td>\n      <td>0.30689</td>\n      <td>0.32143</td>\n      <td>0.53619</td>\n      <td>3.34580</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>5.00000</td>\n      <td>57.75385</td>\n      <td>2.88499</td>\n      <td>16.00000</td>\n      <td>109.60000</td>\n      <td>0.65217</td>\n      <td>8.00000</td>\n      <td>0.42105</td>\n      <td>0.25000</td>\n      <td>0.41574</td>\n      <td>0.22727</td>\n      <td>34.00000</td>\n      <td>1.73684</td>\n      <td>0.96296</td>\n      <td>21.00000</td>\n      <td>0.10526</td>\n      <td>1.00000</td>\n      <td>486.00000</td>\n      <td>42.74107</td>\n      <td>97.66895</td>\n      <td>1524.67544</td>\n      <td>783.81545</td>\n      <td>30902.25000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.20000</td>\n      <td>0.20000</td>\n      <td>0.16667</td>\n      <td>0.81818</td>\n      <td>0.40000</td>\n      <td>0.65555</td>\n      <td>0.25000</td>\n      <td>0.51034</td>\n      <td>0.52174</td>\n      <td>0.76244</td>\n      <td>4.04545</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>48.00000</td>\n      <td>986.34693</td>\n      <td>5.83813</td>\n      <td>37.75000</td>\n      <td>228.00000</td>\n      <td>7.50000</td>\n      <td>97.00000</td>\n      <td>1.00000</td>\n      <td>2.66667</td>\n      <td>2.16025</td>\n      <td>1.00000</td>\n      <td>972.00000</td>\n      <td>6.16667</td>\n      <td>1.00000</td>\n      <td>346.00000</td>\n      <td>1.00000</td>\n      <td>40.00000</td>\n      <td>207563.00000</td>\n      <td>13837.53333</td>\n      <td>35263.04180</td>\n      <td>3462.66667</td>\n      <td>2233.77450</td>\n      <td>1317255.00000</td>\n      <td>25.43456</td>\n      <td>7.16667</td>\n      <td>1.66667</td>\n      <td>1.00000</td>\n      <td>1.66667</td>\n      <td>1.66667</td>\n      <td>4.00000</td>\n      <td>3.05505</td>\n      <td>4.00000</td>\n      <td>2.73354</td>\n      <td>6.00000</td>\n      <td>3.76663</td>\n      <td>12.00000</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "           depth  SUM FriendsCount  AVG FriendsCount  AVG WordCount  \\\ncount 5802.00000        5802.00000        5802.00000     5802.00000   \nmean     4.44485          47.71738           2.69625       14.12534   \nstd      3.88666          54.60815           0.42489        3.31060   \nmin      1.00000           0.00000           0.00000        4.00000   \n25%      2.00000          17.68543           2.45857       12.00000   \n50%      3.00000          37.92571           2.66155       14.03274   \n75%      5.00000          57.75385           2.88499       16.00000   \nmax     48.00000         986.34693           5.83813       37.75000   \n\n       AVG CharCount  AVG HashTag  SUM HashTag  Ratio HashTag    AVG Url  \\\ncount     5802.00000   5802.00000   5802.00000     5802.00000 5802.00000   \nmean        98.17147      0.49636      5.68218        0.30148    0.16980   \nstd         20.47492      0.58934      6.19011        0.26675    0.24628   \nmin         32.05263      0.00000      0.00000        0.00000    0.00000   \n25%         85.55952      0.14286      2.00000        0.10526    0.00000   \n50%         97.69925      0.33333      4.00000        0.23077    0.06667   \n75%        109.60000      0.65217      8.00000        0.42105    0.25000   \nmax        228.00000      7.50000     97.00000        1.00000    2.66667   \n\n         STD Url  RATIO Url  SUM Mention  AVG Mention  Ratio Mention  \\\ncount 5802.00000 5802.00000   5802.00000   5802.00000     5802.00000   \nmean     0.23129    0.15955     30.27749      1.40993        0.85680   \nstd      0.22348    0.22659     46.74222      0.65022        0.22467   \nmin      0.00000    0.00000      0.00000      0.00000        0.00000   \n25%      0.00000    0.00000      8.00000      1.00000        0.85714   \n50%      0.22906    0.06667     20.00000      1.33333        0.93750   \n75%      0.41574    0.22727     34.00000      1.73684        0.96296   \nmax      2.16025    1.00000    972.00000      6.16667        1.00000   \n\n       Tweets Count  Ratio Verified  SUM Verified       SUM RT      AVG RT  \\\ncount    5802.00000      5802.00000    5802.00000   5802.00000  5802.00000   \nmean       17.78904         0.09014       0.93554    593.67890    54.18365   \nstd        20.09487         0.16636       1.54716   3559.90091   253.02338   \nmin         1.00000         0.00000       0.00000     25.00000     0.80399   \n25%         7.00000         0.00000       0.00000    135.00000    11.36364   \n50%        14.00000         0.04348       1.00000    214.00000    21.14286   \n75%        21.00000         0.10526       1.00000    486.00000    42.74107   \nmax       346.00000         1.00000      40.00000 207563.00000 13837.53333   \n\n           STD RT  AVG AccAge  STD AccAge   thread_time  STD Emoji  AVG Emoji  \\\ncount  5802.00000  5802.00000  5802.00000    5802.00000 5802.00000 5802.00000   \nmean    107.02151  1301.45512   656.56185   42042.33919    0.13800    0.05157   \nstd     618.82036   404.98186   278.92828  105966.08161    0.57902    0.22355   \nmin       0.00000     0.00000     0.00000       0.00000    0.00000    0.00000   \n25%      35.36346  1050.45909   550.85241     852.50000    0.00000    0.00000   \n50%      54.70362  1278.36250   671.42693    6901.50000    0.00000    0.00000   \n75%      97.66895  1524.67544   783.81545   30902.25000    0.00000    0.00000   \nmax   35263.04180  3462.66667  2233.77450 1317255.00000   25.43456    7.16667   \n\n       Ratio Media  RATIO Question  RATIO Exclaim  RATIO Period    AVG FPP  \\\ncount   5802.00000      5802.00000     5802.00000    5802.00000 5802.00000   \nmean       0.15089         0.12817        0.11582       0.68090    0.28007   \nstd        0.23264         0.13394        0.13547       0.22620    0.28947   \nmin        0.00000         0.00000        0.00000       0.00000    0.00000   \n25%        0.00000         0.00000        0.00000       0.54545    0.06667   \n50%        0.05000         0.11111        0.09091       0.68182    0.22500   \n75%        0.20000         0.20000        0.16667       0.81818    0.40000   \nmax        1.66667         1.00000        1.66667       1.66667    4.00000   \n\n         STD FPP    AVG SPP    STD SPP    AVG TPP    STD TPP  AVG Skepticism  \ncount 5802.00000 5802.00000 5802.00000 5802.00000 5802.00000      5802.00000  \nmean     0.44079    0.16835    0.31677    0.36429    0.52918         3.43485  \nstd      0.32284    0.22777    0.29921    0.33694    0.36382         1.18817  \nmin      0.00000    0.00000    0.00000    0.00000    0.00000         0.00000  \n25%      0.22330    0.00000    0.00000    0.12500    0.31427         2.66667  \n50%      0.44536    0.10526    0.30689    0.32143    0.53619         3.34580  \n75%      0.65555    0.25000    0.51034    0.52174    0.76244         4.04545  \nmax      3.05505    4.00000    2.73354    6.00000    3.76663        12.00000  "
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pheme_thread.info()\n",
    "pheme_thread.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>depth</th>\n      <th>SUM FriendsCount</th>\n      <th>AVG FriendsCount</th>\n      <th>AVG WordCount</th>\n      <th>AVG CharCount</th>\n      <th>AVG HashTag</th>\n      <th>SUM HashTag</th>\n      <th>Ratio HashTag</th>\n      <th>AVG Url</th>\n      <th>STD Url</th>\n      <th>RATIO Url</th>\n      <th>SUM Mention</th>\n      <th>AVG Mention</th>\n      <th>Ratio Mention</th>\n      <th>Tweets Count</th>\n      <th>Ratio Verified</th>\n      <th>SUM Verified</th>\n      <th>SUM RT</th>\n      <th>AVG RT</th>\n      <th>STD RT</th>\n      <th>AVG AccAge</th>\n      <th>STD AccAge</th>\n      <th>thread_time</th>\n      <th>STD Emoji</th>\n      <th>AVG Emoji</th>\n      <th>Ratio Media</th>\n      <th>RATIO Question</th>\n      <th>RATIO Exclaim</th>\n      <th>RATIO Period</th>\n      <th>AVG FPP</th>\n      <th>STD FPP</th>\n      <th>AVG SPP</th>\n      <th>STD SPP</th>\n      <th>AVG TPP</th>\n      <th>STD TPP</th>\n      <th>AVG Skepticism</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n      <td>485.00000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2.19794</td>\n      <td>10.84186</td>\n      <td>2.72841</td>\n      <td>14.26121</td>\n      <td>99.20002</td>\n      <td>0.84626</td>\n      <td>1.79381</td>\n      <td>0.41010</td>\n      <td>0.34205</td>\n      <td>0.13854</td>\n      <td>0.33213</td>\n      <td>5.11959</td>\n      <td>0.88153</td>\n      <td>0.58595</td>\n      <td>4.04742</td>\n      <td>0.10093</td>\n      <td>0.26186</td>\n      <td>54.36907</td>\n      <td>6.15717</td>\n      <td>12.34183</td>\n      <td>1407.53838</td>\n      <td>306.40342</td>\n      <td>-1420562049.76082</td>\n      <td>0.08762</td>\n      <td>0.05846</td>\n      <td>0.17974</td>\n      <td>0.21324</td>\n      <td>0.14564</td>\n      <td>0.75296</td>\n      <td>0.27241</td>\n      <td>0.24974</td>\n      <td>0.09706</td>\n      <td>0.08811</td>\n      <td>0.35316</td>\n      <td>0.25523</td>\n      <td>3.22114</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.70257</td>\n      <td>12.99575</td>\n      <td>0.51150</td>\n      <td>4.16138</td>\n      <td>25.41987</td>\n      <td>1.11570</td>\n      <td>2.08169</td>\n      <td>0.41270</td>\n      <td>0.42563</td>\n      <td>0.21214</td>\n      <td>0.40211</td>\n      <td>8.14323</td>\n      <td>0.80019</td>\n      <td>0.40283</td>\n      <td>4.83785</td>\n      <td>0.25315</td>\n      <td>0.56361</td>\n      <td>514.15357</td>\n      <td>27.35858</td>\n      <td>112.42284</td>\n      <td>599.53507</td>\n      <td>330.59886</td>\n      <td>5668373.99026</td>\n      <td>0.34064</td>\n      <td>0.28811</td>\n      <td>0.32602</td>\n      <td>0.32331</td>\n      <td>0.26356</td>\n      <td>0.30629</td>\n      <td>0.43975</td>\n      <td>0.39512</td>\n      <td>0.28692</td>\n      <td>0.19393</td>\n      <td>0.46498</td>\n      <td>0.35308</td>\n      <td>1.49462</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>4.00000</td>\n      <td>39.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>2.00000</td>\n      <td>0.12500</td>\n      <td>0.00000</td>\n      <td>5.00000</td>\n      <td>0.00000</td>\n      <td>-1426484176.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.00000</td>\n      <td>2.98811</td>\n      <td>2.46835</td>\n      <td>11.00000</td>\n      <td>81.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>2.00000</td>\n      <td>1.75000</td>\n      <td>0.00000</td>\n      <td>1028.33333</td>\n      <td>0.00000</td>\n      <td>-1426316918.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.50000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>2.00000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>2.00000</td>\n      <td>5.47855</td>\n      <td>2.73241</td>\n      <td>14.00000</td>\n      <td>96.85714</td>\n      <td>0.50000</td>\n      <td>1.00000</td>\n      <td>0.25000</td>\n      <td>0.15789</td>\n      <td>0.00000</td>\n      <td>0.14286</td>\n      <td>2.00000</td>\n      <td>0.93333</td>\n      <td>0.75000</td>\n      <td>2.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>5.00000</td>\n      <td>2.75000</td>\n      <td>1.00000</td>\n      <td>1390.61538</td>\n      <td>186.20201</td>\n      <td>-1415143918.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.16667</td>\n      <td>0.00000</td>\n      <td>3.00000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>3.00000</td>\n      <td>13.37434</td>\n      <td>3.00346</td>\n      <td>17.00000</td>\n      <td>121.00000</td>\n      <td>1.00000</td>\n      <td>3.00000</td>\n      <td>1.00000</td>\n      <td>0.53846</td>\n      <td>0.39031</td>\n      <td>0.50000</td>\n      <td>6.00000</td>\n      <td>1.25000</td>\n      <td>0.96296</td>\n      <td>5.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>12.00000</td>\n      <td>5.00000</td>\n      <td>4.00000</td>\n      <td>1924.00000</td>\n      <td>575.88878</td>\n      <td>-1415124588.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.20000</td>\n      <td>0.33333</td>\n      <td>0.20000</td>\n      <td>1.00000</td>\n      <td>0.50000</td>\n      <td>0.47140</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.60000</td>\n      <td>0.48412</td>\n      <td>4.00000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>16.00000</td>\n      <td>78.86282</td>\n      <td>4.38684</td>\n      <td>29.00000</td>\n      <td>143.00000</td>\n      <td>7.00000</td>\n      <td>15.00000</td>\n      <td>1.00000</td>\n      <td>2.00000</td>\n      <td>0.94281</td>\n      <td>1.00000</td>\n      <td>44.00000</td>\n      <td>6.50000</td>\n      <td>1.00000</td>\n      <td>27.00000</td>\n      <td>1.00000</td>\n      <td>5.00000</td>\n      <td>10416.00000</td>\n      <td>548.21053</td>\n      <td>2322.56083</td>\n      <td>3021.00000</td>\n      <td>1371.00000</td>\n      <td>-1413125063.00000</td>\n      <td>4.00000</td>\n      <td>4.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>4.00000</td>\n      <td>2.00000</td>\n      <td>3.00000</td>\n      <td>1.00000</td>\n      <td>2.00000</td>\n      <td>1.93907</td>\n      <td>9.00000</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "          depth  SUM FriendsCount  AVG FriendsCount  AVG WordCount  \\\ncount 485.00000         485.00000         485.00000      485.00000   \nmean    2.19794          10.84186           2.72841       14.26121   \nstd     1.70257          12.99575           0.51150        4.16138   \nmin     1.00000           0.00000           0.00000        4.00000   \n25%     1.00000           2.98811           2.46835       11.00000   \n50%     2.00000           5.47855           2.73241       14.00000   \n75%     3.00000          13.37434           3.00346       17.00000   \nmax    16.00000          78.86282           4.38684       29.00000   \n\n       AVG CharCount  AVG HashTag  SUM HashTag  Ratio HashTag   AVG Url  \\\ncount      485.00000    485.00000    485.00000      485.00000 485.00000   \nmean        99.20002      0.84626      1.79381        0.41010   0.34205   \nstd         25.41987      1.11570      2.08169        0.41270   0.42563   \nmin         39.00000      0.00000      0.00000        0.00000   0.00000   \n25%         81.00000      0.00000      0.00000        0.00000   0.00000   \n50%         96.85714      0.50000      1.00000        0.25000   0.15789   \n75%        121.00000      1.00000      3.00000        1.00000   0.53846   \nmax        143.00000      7.00000     15.00000        1.00000   2.00000   \n\n        STD Url  RATIO Url  SUM Mention  AVG Mention  Ratio Mention  \\\ncount 485.00000  485.00000    485.00000    485.00000      485.00000   \nmean    0.13854    0.33213      5.11959      0.88153        0.58595   \nstd     0.21214    0.40211      8.14323      0.80019        0.40283   \nmin     0.00000    0.00000      0.00000      0.00000        0.00000   \n25%     0.00000    0.00000      0.00000      0.00000        0.00000   \n50%     0.00000    0.14286      2.00000      0.93333        0.75000   \n75%     0.39031    0.50000      6.00000      1.25000        0.96296   \nmax     0.94281    1.00000     44.00000      6.50000        1.00000   \n\n       Tweets Count  Ratio Verified  SUM Verified      SUM RT    AVG RT  \\\ncount     485.00000       485.00000     485.00000   485.00000 485.00000   \nmean        4.04742         0.10093       0.26186    54.36907   6.15717   \nstd         4.83785         0.25315       0.56361   514.15357  27.35858   \nmin         1.00000         0.00000       0.00000     2.00000   0.12500   \n25%         1.00000         0.00000       0.00000     2.00000   1.75000   \n50%         2.00000         0.00000       0.00000     5.00000   2.75000   \n75%         5.00000         0.00000       0.00000    12.00000   5.00000   \nmax        27.00000         1.00000       5.00000 10416.00000 548.21053   \n\n          STD RT  AVG AccAge  STD AccAge       thread_time  STD Emoji  \\\ncount  485.00000   485.00000   485.00000         485.00000  485.00000   \nmean    12.34183  1407.53838   306.40342 -1420562049.76082    0.08762   \nstd    112.42284   599.53507   330.59886     5668373.99026    0.34064   \nmin      0.00000     5.00000     0.00000 -1426484176.00000    0.00000   \n25%      0.00000  1028.33333     0.00000 -1426316918.00000    0.00000   \n50%      1.00000  1390.61538   186.20201 -1415143918.00000    0.00000   \n75%      4.00000  1924.00000   575.88878 -1415124588.00000    0.00000   \nmax   2322.56083  3021.00000  1371.00000 -1413125063.00000    4.00000   \n\n       AVG Emoji  Ratio Media  RATIO Question  RATIO Exclaim  RATIO Period  \\\ncount  485.00000    485.00000       485.00000      485.00000     485.00000   \nmean     0.05846      0.17974         0.21324        0.14564       0.75296   \nstd      0.28811      0.32602         0.32331        0.26356       0.30629   \nmin      0.00000      0.00000         0.00000        0.00000       0.00000   \n25%      0.00000      0.00000         0.00000        0.00000       0.50000   \n50%      0.00000      0.00000         0.00000        0.00000       1.00000   \n75%      0.00000      0.20000         0.33333        0.20000       1.00000   \nmax      4.00000      1.00000         1.00000        1.00000       1.00000   \n\n        AVG FPP   STD FPP   AVG SPP   STD SPP   AVG TPP   STD TPP  \\\ncount 485.00000 485.00000 485.00000 485.00000 485.00000 485.00000   \nmean    0.27241   0.24974   0.09706   0.08811   0.35316   0.25523   \nstd     0.43975   0.39512   0.28692   0.19393   0.46498   0.35308   \nmin     0.00000   0.00000   0.00000   0.00000   0.00000   0.00000   \n25%     0.00000   0.00000   0.00000   0.00000   0.00000   0.00000   \n50%     0.00000   0.00000   0.00000   0.00000   0.16667   0.00000   \n75%     0.50000   0.47140   0.00000   0.00000   0.60000   0.48412   \nmax     4.00000   2.00000   3.00000   1.00000   2.00000   1.93907   \n\n       AVG Skepticism  \ncount       485.00000  \nmean          3.22114  \nstd           1.49462  \nmin           0.00000  \n25%           2.00000  \n50%           3.00000  \n75%           4.00000  \nmax           9.00000  "
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ext_thread.info()\n",
    "ext_thread.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fetchData import fetchdata \n",
    "import __MLP\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5802, 36]) torch.Size([485, 36])\n",
      "torch.Size([5105, 36]) torch.Size([697, 36])\n",
      "torch.Size([5105, 36]) torch.Size([697, 36])\n",
      "torch.Size([5802, 36]) torch.Size([485, 36])\n"
     ]
    }
   ],
   "source": [
    "pheme_thread = pd.read_csv(\"./data/all/_PHEME_thread.csv\")\n",
    "ext_thread = pd.read_csv(\"./data/all/_PHEMEext_thread.csv\")\n",
    "pheme_y = pd.read_csv('./data/_PHEME_target.csv')\n",
    "ext_y = pd.read_csv('./data/_PHEMEext_target.csv')\n",
    "# pd.read_csv('./data/_PHEME_text.csv').target\n",
    "X_train, X_test, y_train, y_test = train_test_split(pheme_thread, pheme_y, test_size=0.12, random_state=42)\n",
    "print(torch.Tensor(pheme_thread.values).shape,torch.Tensor(ext_thread.values).shape)\n",
    "print(torch.Tensor(X_train.values).shape,torch.Tensor(X_test.values).shape)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "pheme_thread_scaled = scaler.fit_transform(X_train)\n",
    "ext_thread_scaled = scaler.transform(X_test)\n",
    "print(torch.Tensor(pheme_thread_scaled).shape,torch.Tensor(ext_thread_scaled).shape)\n",
    "\n",
    "pheme_thread_scaled = scaler.fit_transform(pheme_thread)\n",
    "ext_thread_scaled = scaler.transform(ext_thread)\n",
    "print(torch.Tensor(pheme_thread_scaled).shape,torch.Tensor(ext_thread_scaled).shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "# pheme_thread_scaled = scaler.fit_transform(pheme_thread)\n",
    "# ext_thread_scaled = scaler.transform(ext_thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5802, 36) (485, 36)\n",
      "(5802, 36) (485, 36)\n",
      "(5802, 1) (485, 1)\n"
     ]
    }
   ],
   "source": [
    "print(pheme_thread.shape, ext_thread.shape)\n",
    "print(pheme_thread_scaled.shape, ext_thread_scaled.shape)\n",
    "print(pheme_y.shape, ext_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5105, 36) (697, 36)\n",
      "(5105, 1) (697, 1)\n",
      "(5802, 36) (485, 36)\n",
      "(5802, 36) (485, 36)\n",
      "(5802, 1) (485, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)\n",
    "print(pheme_thread.shape, ext_thread.shape)\n",
    "print(pheme_thread_scaled.shape, ext_thread_scaled.shape)\n",
    "print(pheme_y.shape, ext_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X Size: torch.Size([5802, 1, 36]) / Train y Size: torch.Size([5802, 1])\n",
      "Test X Size: torch.Size([485, 1, 36]) / Test y Size: torch.Size([485, 1])\n",
      "\n",
      "Train X Size: torch.Size([5802, 1, 36]) / Train y Size: torch.Size([5802, 1])\n",
      "Test X Size: torch.Size([485, 1, 36]) / Test y Size: torch.Size([485, 1])\n",
      "Train Size 5802 Test Size 485\n"
     ]
    }
   ],
   "source": [
    "# -------------------------- only training/valid set ------------------------- #\n",
    "\n",
    "# tensor_x1 = torch.Tensor(pheme_sparse.values).unsqueeze(1)\n",
    "# tensor_x1 = torch.Tensor(X_train.values).unsqueeze(1)\n",
    "# tensor_x1 = torch.Tensor(pheme_thread_scaled).unsqueeze(1)\n",
    "tensor_x1 = torch.Tensor(pheme_thread.values).unsqueeze(1)\n",
    "# tensor_y1 = torch.Tensor(y_train.values)\n",
    "tensor_y1 = torch.Tensor(pheme_y.values)\n",
    "train_dataset = TensorDataset(tensor_x1,tensor_y1)\n",
    "\n",
    "# tensor_x2 = torch.Tensor(ext_sparse.values).unsqueeze(1)\n",
    "# tensor_x2 = torch.Tensor(X_test.values).unsqueeze(1)\n",
    "\n",
    "tensor_x2 = torch.Tensor(ext_thread.values).unsqueeze(1)\n",
    "# tensor_y2 = torch.Tensor(y_test.values)\n",
    "tensor_y2 = torch.Tensor(ext_y.values)\n",
    "test_dataset = TensorDataset(tensor_x2,tensor_y2)\n",
    "\n",
    "print(\"Train X Size:\", tensor_x1.shape, \"/ Train y Size:\", tensor_y1.shape)\n",
    "print(\"Test X Size:\", tensor_x2.shape, \"/ Test y Size:\", tensor_y2.shape)\n",
    "print()\n",
    "\n",
    "# ------------------------------ training / test ----------------------------- #\n",
    "\n",
    "\n",
    "# tensor_x1 = torch.Tensor(pheme_thread.values)\n",
    "# tensor_y1 = torch.Tensor(pheme_y.values)\n",
    "# train_dataset = TensorDataset(tensor_x1,tensor_y1)\n",
    "\n",
    "# tensor_x2 = torch.Tensor(ext_thread.values)\n",
    "# tensor_y2 = torch.Tensor(ext_y.values)\n",
    "# test_dataset = TensorDataset(tensor_x2,tensor_y2)\n",
    "\n",
    "\n",
    "# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
    "batch_size = 8\n",
    "\n",
    "# Initialize WeightedRandomSampler to deal with the unbalanced dataset\n",
    "counts = np.bincount(pheme_y.target)\n",
    "# counts = np.bincount(pheme_y)\n",
    "labels_weights = 1. / counts\n",
    "weights = labels_weights[pheme_y.target]\n",
    "# weights = labels_weights[pheme_y]\n",
    "train_sampler = WeightedRandomSampler(weights, len(weights))\n",
    "test_sampler = SequentialSampler(tensor_x2)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler, num_workers=2)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "train_size = int(tensor_y1.size(0))\n",
    "test_size = int(tensor_y2.size(0))\n",
    "print(\"Train X Size:\", tensor_x1.shape, \"/ Train y Size:\", tensor_y1.shape)\n",
    "print(\"Test X Size:\", tensor_x2.shape, \"/ Test y Size:\", tensor_y2.shape)\n",
    "print(\"Train Size\",train_size,\"Test Size\",test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(counts)\n",
    "# print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(5105, 1)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pheme_y.target.values.shape\n",
    "y_train.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.0000e+00, 5.7639e+01, 3.0336e+00, 1.8684e+01, 1.1695e+02, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 2.6316e-01, 4.4035e-01, 2.6316e-01, 3.2000e+01,\n",
      "         1.6842e+00, 9.4737e-01, 1.9000e+01, 5.2632e-02, 1.0000e+00, 1.7900e+02,\n",
      "         9.4211e+00, 3.9501e+01, 7.2026e+02, 9.5536e+02, 4.5330e+03, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.5789e-01, 0.0000e+00, 4.2105e-01, 5.2632e-02,\n",
      "         2.2330e-01, 7.3684e-01, 1.2071e+00, 8.4211e-01, 1.1816e+00, 6.0000e+00]])\n",
      "tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "print(tensor_x1[0])\n",
    "print(tensor_y1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sparse_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(sparse_model, self).__init__() # 1*20\n",
    "        self.fc1 = nn.Linear(36, 12, bias=True) # 420\n",
    "        self.fc3 = nn.Linear(12, 1)\n",
    "\n",
    "        self.drop_3 = nn.Dropout(0.3)\n",
    "        self.drop_4 = nn.Dropout(0.4)\n",
    "        self.drop_2 = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.drop_2(F.elu(self.fc1(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sparse = sparse_model()\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# optimizer = optim.SGD(model_sparse.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizer = optim.Adam(model_sparse.parameters(), lr=5e-5, eps=1e-8, weight_decay=1e-6)\n",
    "# scheduler = lr_scheduler.ExponentialLR(optimizer, gamma= 0.99)  \n",
    "\n",
    "epochs = 100\n",
    "\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps=0,  # Default value\n",
    "                                            num_training_steps=total_steps)\n",
    "\n",
    "PATH = \"./Model/state_dict_sparse_model.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf_report(train_loss, train_acc, val_loss, val_acc):\n",
    "    fig, ax = plt.subplots(4, 1, figsize=(12,8))\n",
    "    ax[0].plot(train_loss[:])\n",
    "    ax[0].set_ylabel('Loss')\n",
    "    ax[0].set_title('Training Loss')\n",
    "\n",
    "    ax[1].plot(train_acc[:])\n",
    "    ax[1].set_ylabel('Classification Accuracy')\n",
    "    ax[1].set_title('Training Accuracy')\n",
    "\n",
    "    ax[2].plot(val_loss[:])\n",
    "    ax[2].set_ylabel('Classification Accuracy')\n",
    "    ax[2].set_title('Testing Loss')\n",
    "\n",
    "    ax[3].plot(val_acc[:])\n",
    "    ax[3].set_ylabel('Classification Accuracy')\n",
    "    ax[3].set_title('Testing Accuracy')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Min of Training Loss: %4f\"%(np.min(train_loss)))\n",
    "    print(\"Max of Training Accuracy: %4f\"%(np.max(train_acc)))\n",
    "    print(\"Mean of Training Loss: %4f\"%(np.mean(train_loss)))\n",
    "    print(\"Mean of Training Accuracy: %4f\"%(np.mean(train_acc)))\n",
    "    print(\"----\")\n",
    "    print(\"Max of Testing Accuracy: %4f\"%(np.max(val_acc)))\n",
    "    print(\"Mean of Testing Loss: %4f\"%(np.mean(val_loss)))\n",
    "    print(\"Mean of Testing Accuracy: %4f\"%(np.mean(val_acc)))\n",
    "\n",
    "def set_seed(seed_value=42):\n",
    "    \"\"\"Set seed for reproducibility.\n",
    "    \"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "def train1(model, num_epochs, criterion, optimizer, scheduler, train_loader, train_size, test_loader=None, test_size=None, patience=5, PATH='./state_dict_model.pt'):\n",
    "    set_seed(42)\n",
    "    train_loss = []\n",
    "    patience_count = 0\n",
    "    train_accuracy = []\n",
    "    prev_loss = 10\n",
    "    best_loss = 10.0\n",
    "    val_corrects_list = []\n",
    "    val_loss_list = []\n",
    "    val_acc_list = []\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        # print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        # print('-' * 10)\n",
    "        running_corrects = 0.0\n",
    "        running_loss = 0.0\n",
    "        model.train()  # Set model to training mode\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.float(), labels.float()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            #  _, predictions = torch.max(outputs.data, 1) won’t work if your output only contains a single output unit.\n",
    "            # _, preds = torch.max(outputs, 1)\n",
    "            # print(outputs.flatten().size())\n",
    "            preds = outputs.squeeze(1) > 0.0\n",
    "\n",
    "            loss = criterion(outputs, labels.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # step function\n",
    "            scheduler.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / train_size\n",
    "        # print(running_loss)\n",
    "        # print(train_size)\n",
    "        epoch_acc = running_corrects.double() / train_size\n",
    "        train_loss.append(epoch_loss)\n",
    "        train_accuracy.append(epoch_acc)\n",
    "\n",
    "        if (epoch % 2 == 0):\n",
    "            print('Epoch {}/{}\\tTrain) Acc: {:.4f}, Loss: {:.4f}'.format(epoch,\n",
    "                                                                         num_epochs - 1, epoch_acc, epoch_loss))\n",
    "\n",
    "        if (test_loader != None):\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_loss = 0.0\n",
    "                val_corrects = 0\n",
    "                val_preds_list = []\n",
    "                val_label_list = []\n",
    "                for j, val in enumerate(test_loader, 0):\n",
    "                    val_x, val_label = val\n",
    "                    val_x, val_label = val_x.float(), val_label.float()\n",
    "                    val_outputs = model(val_x)\n",
    "                    # _, val_preds = torch.max(val_outputs, 1)\n",
    "                    val_preds = val_outputs.squeeze(1) > 0.0\n",
    "                    # print(\"val_preds:\\n\", val_preds)\n",
    "                    # print(\"val_labels:\\n\", val_label)\n",
    "\n",
    "                    val_preds_list.append(val_preds)\n",
    "                    val_label_list.append(val_label)\n",
    "                    v_loss = criterion(val_outputs, val_label.unsqueeze(1))\n",
    "                    val_loss += (v_loss.item() * val_x.size(0))\n",
    "                    val_corrects += torch.sum(val_preds == val_label)\n",
    "                    # print(\"val_corrects:\\n\", val_corrects)\n",
    "                    # accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
    "\n",
    "                if (epoch % 2 == 0):\n",
    "                    val_preds_list = torch.cat(val_preds_list, 0)\n",
    "                    val_label_list = torch.cat(val_label_list, 0)\n",
    "                    # print(\"\\t\\tValidation) Acc: {:.4f} Loss:{:.4f} F1 score: {:4f}\".format(val_corrects/test_size, val_loss/test_size, f1_score(val_label_list,val_preds_list,average='macro')))\n",
    "                    print(\"\\t\\tValidation) Acc: {:.4f} Loss:{:.4f}\".format(\n",
    "                        val_corrects/test_size, val_loss/test_size))\n",
    "            # print(\"val_corrects:\\n\", val_corrects)\n",
    "\n",
    "            val_corrects_list.append(val_corrects/test_size)\n",
    "            val_loss_list.append(val_loss/test_size)\n",
    "            val_acc = val_corrects.double() / test_size\n",
    "            val_acc_list.append(val_acc)\n",
    "\n",
    "        if epoch_loss < best_loss:\n",
    "            # print(\"prev_loss: {:.5f}\".format(prev_loss))\n",
    "            # print(\"loss: {:.5f}\".format(loss))\n",
    "            print(\n",
    "                \"\\t\\tSaving the best model w/ loss {:.4f}\".format(epoch_loss))\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "            best_loss = epoch_loss\n",
    "            patience_count = 0\n",
    "        elif best_loss < epoch_loss:\n",
    "            patience_count += 1\n",
    "        if patience_count >= patience:\n",
    "            print(\"Finishing the Model: Loss is not decreasing...\")\n",
    "            print(train_loss[-6:-1])\n",
    "            return train_accuracy, train_loss, val_acc_list, val_loss_list\n",
    "    return train_accuracy, train_loss, val_acc_list, val_loss_list\n",
    "\n",
    "def train2(model, num_epochs, criterion, optimizer, train_loader, train_size, test_loader=None, test_size=None, patience=5, PATH='./state_dict_model.pt'):\n",
    "    set_seed(42)\n",
    "    train_loss = []\n",
    "    patience_count = 0\n",
    "    train_accuracy = []\n",
    "    prev_loss = 10\n",
    "    best_loss = 10.0\n",
    "    val_corrects_list = []\n",
    "    val_loss_list = []\n",
    "    val_acc_list = []\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        # print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        # print('-' * 10)\n",
    "        running_corrects = 0.0\n",
    "        running_loss = 0.0\n",
    "        model.train()  # Set model to training mode\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.float(), labels.float()\n",
    "            print(inputs.size())\n",
    "            print(labels.size())\n",
    "            print(inputs.flatten())\n",
    "            print(labels.flatten())\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            print(\"outputs:\",outputs.size())\n",
    "            print(\"outputs:\",outputs)\n",
    "            print(\"labels:\",labels.size())\n",
    "            print(\"labels:\",labels.unsqueeze(1).size())\n",
    "\n",
    "            #  _, predictions = torch.max(outputs.data, 1) won’t work if your output only contains a single output unit.\n",
    "            # _, preds = torch.max(outputs, 1)\n",
    "            preds = torch.argmax(outputs, dim=1).flatten()\n",
    "            # print(outputs.flatten().size())\n",
    "            # preds = outputs > 0.0\n",
    "            # labels = labels.view(-1)\n",
    "            loss = criterion(outputs, labels.long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # step function\n",
    "            scheduler.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            # print('running correct')\n",
    "            # print(running_corrects)\n",
    "\n",
    "        epoch_loss = running_loss / train_size\n",
    "        # print(running_loss)\n",
    "        # print(train_size)\n",
    "        epoch_acc = running_corrects.double() / train_size\n",
    "        train_loss.append(epoch_loss)\n",
    "        train_accuracy.append(epoch_acc)\n",
    "\n",
    "        if (epoch % 2 == 0):\n",
    "            print('Epoch {}/{}\\tTrain) Acc: {:.4f}, Loss: {:.4f}'.format(epoch,\n",
    "                                                                         num_epochs - 1, epoch_acc, epoch_loss))\n",
    "\n",
    "        if (test_loader != None):\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_loss = 0.0\n",
    "                val_corrects = 0\n",
    "                val_preds_list = []\n",
    "                val_label_list = []\n",
    "                for j, val in enumerate(test_loader, 0):\n",
    "                    val_x, val_label = val\n",
    "                    val_x, val_label = val_x.float(), val_label.float()\n",
    "                    val_outputs = model(val_x)\n",
    "                    val_preds = torch.argmax(val_outputs, dim=1).flatten()\n",
    "                    # _, val_preds = torch.max(val_outputs, 1)\n",
    "                    # print(\"val_outputs:\",val_outputs.flatten())\n",
    "                    # val_preds = val_outputs > 0.0\n",
    "                    # print(\"val_preds:\",val_preds)\n",
    "                    val_preds_list.append(val_preds)\n",
    "                    val_label_list.append(val_label)\n",
    "                    v_loss = criterion(val_outputs, val_label.unsqueeze(1))\n",
    "                    val_loss += (v_loss.item() * val_x.size(0))\n",
    "                    val_corrects += torch.sum(val_preds ==\n",
    "                                              val_label.data).double()\n",
    "                if (epoch % 2 == 0):\n",
    "                    val_preds_list = torch.cat(val_preds_list, 0)\n",
    "                    val_label_list = torch.cat(val_label_list, 0)\n",
    "                    # print(\"\\t\\tValidation) Acc: {:.4f} Loss:{:.4f} F1 score: {:4f}\".format(val_corrects/test_size, val_loss/test_size, f1_score(val_label_list,val_preds_list,average='macro')))\n",
    "                    print(\"\\t\\tValidation) Acc: {:.4f} Loss:{:.4f}\".format(\n",
    "                        val_corrects/test_size, val_loss/test_size))\n",
    "            val_corrects_list.append(val_corrects/test_size)\n",
    "            val_loss_list.append(val_loss/test_size)\n",
    "            val_acc = val_corrects.double() / test_size\n",
    "            val_acc_list.append(val_acc)\n",
    "\n",
    "        if epoch_loss < best_loss:\n",
    "            # print(\"prev_loss: {:.5f}\".format(prev_loss))\n",
    "            # print(\"loss: {:.5f}\".format(loss))\n",
    "            print(\n",
    "                \"\\t\\tSaving the best model w/ loss {:.4f}\".format(epoch_loss))\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "            best_loss = epoch_loss\n",
    "            patience_count = 0\n",
    "        elif best_loss < epoch_loss:\n",
    "            patience_count += 1\n",
    "        if patience_count >= patience:\n",
    "            print(\"Finishing the Model: Loss is not decreasing...\")\n",
    "            print(train_loss[-6:-1])\n",
    "            return train_accuracy, train_loss, val_acc_list, val_loss_list\n",
    "    return train_accuracy, train_loss, val_acc_list, val_loss_list\n",
    "\n",
    "def predict(model, criterion, val_dataloader, val_size):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "        for j, val in enumerate(val_dataloader, 0):\n",
    "            val_x, val_label = val\n",
    "            val_x, val_label = val_x.float(), val_label.float()\n",
    "            val_outputs = model(val_x)\n",
    "            val_preds = val_outputs.squeeze(1) > 0.0\n",
    "\n",
    "            val_preds_list.append(val_preds)\n",
    "            val_label_list.append(val_label)\n",
    "            v_loss = criterion(val_outputs, val_label.unsqueeze(1))\n",
    "            val_loss += (v_loss.item() * val_x.size(0))\n",
    "            val_corrects += torch.sum(val_preds == val_label)\n",
    "\n",
    "    val_preds_list = torch.cat(val_preds_list, 0)\n",
    "    val_label_list = torch.cat(val_label_list, 0)\n",
    "    val_corrects = val_corrects/val_size\n",
    "    val_loss/test_size\n",
    "    val_acc = val_corrects.double() / val_size\n",
    "    print(\"\\t\\tValidation) Acc: {:.4f} Loss:{:.4f}\".format(\n",
    "        val_corrects/val_size, val_loss/test_size))\n",
    "    # print(\"\\t\\tValidation) Acc: {:.4f} Loss:{:.4f} F1 score: {:4f}\".format(val_corrects/val_size, val_loss/test_size, f1_score(val_label_list,val_preds_list,average='macro')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/99\tTrain) Acc: 0.4850, Loss: 636.4584\n",
      "\t\tValidation) Acc: 0.2392 Loss:31807142.0371\n",
      "Epoch 2/99\tTrain) Acc: 0.5334, Loss: 147.0444\n",
      "\t\tValidation) Acc: 0.2392 Loss:29914220.6351\n",
      "Epoch 4/99\tTrain) Acc: 0.5502, Loss: 95.6186\n",
      "\t\tValidation) Acc: 0.2392 Loss:23171577.5670\n",
      "Epoch 6/99\tTrain) Acc: 0.5664, Loss: 83.8377\n",
      "\t\tValidation) Acc: 0.2392 Loss:19225171.7608\n",
      "Epoch 8/99\tTrain) Acc: 0.5312, Loss: 63.8331\n",
      "\t\tValidation) Acc: 0.2392 Loss:17395937.3691\n",
      "Epoch 10/99\tTrain) Acc: 0.5364, Loss: 35.7393\n",
      "\t\tValidation) Acc: 0.2392 Loss:17313927.1258\n",
      "Epoch 12/99\tTrain) Acc: 0.5243, Loss: 21.3467\n",
      "\t\tValidation) Acc: 0.2392 Loss:17521499.6124\n",
      "Epoch 14/99\tTrain) Acc: 0.4976, Loss: 10.5320\n",
      "\t\tValidation) Acc: 0.2392 Loss:17649676.7670\n",
      "\t\tSaving the best model w/ loss 6.9953\n",
      "Epoch 16/99\tTrain) Acc: 0.4764, Loss: 4.8236\n",
      "\t\tValidation) Acc: 0.2392 Loss:17881660.6515\n",
      "\t\tSaving the best model w/ loss 4.8236\n",
      "\t\tSaving the best model w/ loss 3.2026\n",
      "Epoch 18/99\tTrain) Acc: 0.5010, Loss: 1.8487\n",
      "\t\tValidation) Acc: 0.2392 Loss:17939742.8454\n",
      "\t\tSaving the best model w/ loss 1.8487\n",
      "\t\tSaving the best model w/ loss 1.3289\n",
      "Epoch 20/99\tTrain) Acc: 0.5060, Loss: 1.1159\n",
      "\t\tValidation) Acc: 0.2392 Loss:18488990.2351\n",
      "\t\tSaving the best model w/ loss 1.1159\n",
      "\t\tSaving the best model w/ loss 0.9018\n",
      "Epoch 22/99\tTrain) Acc: 0.5045, Loss: 0.7997\n",
      "\t\tValidation) Acc: 0.2392 Loss:18410409.9629\n",
      "\t\tSaving the best model w/ loss 0.7997\n",
      "Epoch 24/99\tTrain) Acc: 0.5129, Loss: 0.8912\n",
      "\t\tValidation) Acc: 0.2392 Loss:18975257.3856\n",
      "\t\tSaving the best model w/ loss 0.7375\n",
      "Epoch 26/99\tTrain) Acc: 0.5307, Loss: 0.8438\n",
      "\t\tValidation) Acc: 0.2392 Loss:19064014.1526\n",
      "Epoch 28/99\tTrain) Acc: 0.5253, Loss: 0.7730\n",
      "\t\tValidation) Acc: 0.2392 Loss:18912953.5835\n",
      "Epoch 30/99\tTrain) Acc: 0.5267, Loss: 0.7571\n",
      "\t\tValidation) Acc: 0.2392 Loss:19580376.6433\n",
      "Epoch 32/99\tTrain) Acc: 0.5198, Loss: 0.7862\n",
      "\t\tValidation) Acc: 0.2392 Loss:19845069.4763\n",
      "Epoch 34/99\tTrain) Acc: 0.5298, Loss: 0.7475\n",
      "\t\tValidation) Acc: 0.2392 Loss:19856860.1237\n",
      "\t\tSaving the best model w/ loss 0.7231\n",
      "Epoch 36/99\tTrain) Acc: 0.5441, Loss: 0.7008\n",
      "\t\tValidation) Acc: 0.2392 Loss:19787313.0722\n",
      "\t\tSaving the best model w/ loss 0.7008\n",
      "Epoch 38/99\tTrain) Acc: 0.5203, Loss: 0.7210\n",
      "\t\tValidation) Acc: 0.2392 Loss:19627432.6598\n",
      "Epoch 40/99\tTrain) Acc: 0.5469, Loss: 0.7323\n",
      "\t\tValidation) Acc: 0.2392 Loss:18823899.9918\n",
      "Epoch 42/99\tTrain) Acc: 0.5336, Loss: 0.7141\n",
      "\t\tValidation) Acc: 0.2392 Loss:18756104.3959\n",
      "Epoch 44/99\tTrain) Acc: 0.5364, Loss: 0.7074\n",
      "\t\tValidation) Acc: 0.2392 Loss:18674992.3794\n",
      "Epoch 46/99\tTrain) Acc: 0.5303, Loss: 0.7163\n",
      "\t\tValidation) Acc: 0.2392 Loss:17835670.4495\n",
      "Epoch 48/99\tTrain) Acc: 0.5381, Loss: 0.7211\n",
      "\t\tValidation) Acc: 0.2392 Loss:17200529.2371\n",
      "\t\tSaving the best model w/ loss 0.7006\n",
      "Epoch 50/99\tTrain) Acc: 0.5286, Loss: 0.7007\n",
      "\t\tValidation) Acc: 0.2392 Loss:16389452.9320\n",
      "\t\tSaving the best model w/ loss 0.6944\n",
      "Epoch 52/99\tTrain) Acc: 0.5348, Loss: 0.6941\n",
      "\t\tValidation) Acc: 0.2392 Loss:14841753.1381\n",
      "\t\tSaving the best model w/ loss 0.6941\n",
      "Epoch 54/99\tTrain) Acc: 0.5131, Loss: 0.7201\n",
      "\t\tValidation) Acc: 0.2392 Loss:12905789.9546\n",
      "Epoch 56/99\tTrain) Acc: 0.5267, Loss: 0.6981\n",
      "\t\tValidation) Acc: 0.2392 Loss:10188090.5155\n",
      "Epoch 58/99\tTrain) Acc: 0.5291, Loss: 0.6955\n",
      "\t\tValidation) Acc: 0.2392 Loss:6979606.5897\n",
      "\t\tSaving the best model w/ loss 0.6891\n",
      "Epoch 60/99\tTrain) Acc: 0.5402, Loss: 0.6962\n",
      "\t\tValidation) Acc: 0.2392 Loss:4284753.6907\n",
      "Epoch 62/99\tTrain) Acc: 0.5207, Loss: 0.7058\n",
      "\t\tValidation) Acc: 0.2392 Loss:2139002.8433\n",
      "Epoch 64/99\tTrain) Acc: 0.5322, Loss: 0.7092\n",
      "\t\tValidation) Acc: 0.2392 Loss:262375.6771\n",
      "Epoch 66/99\tTrain) Acc: 0.5286, Loss: 0.6940\n",
      "\t\tValidation) Acc: 0.7608 Loss:376473.3227\n",
      "Epoch 68/99\tTrain) Acc: 0.5234, Loss: 0.7281\n",
      "\t\tValidation) Acc: 0.7608 Loss:612712.7871\n",
      "Epoch 70/99\tTrain) Acc: 0.5281, Loss: 0.6960\n",
      "\t\tValidation) Acc: 0.7608 Loss:620653.0582\n",
      "Epoch 72/99\tTrain) Acc: 0.5383, Loss: 0.6921\n",
      "\t\tValidation) Acc: 0.7608 Loss:679923.6196\n",
      "\t\tSaving the best model w/ loss 0.6857\n",
      "Epoch 74/99\tTrain) Acc: 0.5264, Loss: 0.6923\n",
      "\t\tValidation) Acc: 0.7608 Loss:675074.8428\n",
      "Epoch 76/99\tTrain) Acc: 0.5395, Loss: 0.6934\n",
      "\t\tValidation) Acc: 0.7608 Loss:699895.5330\n",
      "Epoch 78/99\tTrain) Acc: 0.5286, Loss: 0.6901\n",
      "\t\tValidation) Acc: 0.7608 Loss:681315.7985\n",
      "Epoch 80/99\tTrain) Acc: 0.5295, Loss: 0.6928\n",
      "\t\tValidation) Acc: 0.7608 Loss:638120.0902\n",
      "Epoch 82/99\tTrain) Acc: 0.5295, Loss: 0.6960\n",
      "\t\tValidation) Acc: 0.7608 Loss:666102.7825\n",
      "Epoch 84/99\tTrain) Acc: 0.5193, Loss: 0.7273\n",
      "\t\tValidation) Acc: 0.7608 Loss:635628.3577\n",
      "Epoch 86/99\tTrain) Acc: 0.5412, Loss: 0.6893\n",
      "\t\tValidation) Acc: 0.7608 Loss:629286.1907\n",
      "Epoch 88/99\tTrain) Acc: 0.5440, Loss: 0.6889\n",
      "\t\tValidation) Acc: 0.7608 Loss:640680.8361\n",
      "Epoch 90/99\tTrain) Acc: 0.5303, Loss: 0.6905\n",
      "\t\tValidation) Acc: 0.7608 Loss:660771.7500\n",
      "Epoch 92/99\tTrain) Acc: 0.5262, Loss: 0.6916\n",
      "\t\tValidation) Acc: 0.7608 Loss:666665.4876\n",
      "Epoch 94/99\tTrain) Acc: 0.5303, Loss: 0.6949\n",
      "\t\tValidation) Acc: 0.7608 Loss:655959.8649\n",
      "Epoch 96/99\tTrain) Acc: 0.5252, Loss: 0.6877\n",
      "\t\tValidation) Acc: 0.7608 Loss:634865.5660\n",
      "Epoch 98/99\tTrain) Acc: 0.5198, Loss: 0.6945\n",
      "\t\tValidation) Acc: 0.7608 Loss:612707.3361\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "train_acc, train_loss, val_acc, val_loss_list = train1(model=model_sparse, num_epochs=epochs,patience=30, criterion=criterion, optimizer=optimizer, scheduler=scheduler, train_loader=train_dataloader, train_size=train_size, test_loader=test_dataloader, test_size=test_size, PATH=PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 864x576 with 4 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min of Training Loss: 0.685660\n",
      "Max of Training Accuracy: 0.566356\n",
      "Mean of Training Loss: 17.487568\n",
      "Mean of Training Accuracy: 0.526705\n",
      "----\n",
      "Max of Testing Accuracy: 0.760825\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'val_loss_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-4f5d2641781e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m__MLP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclf_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Code/FYP/code_data/__MLP.py\u001b[0m in \u001b[0;36mclf_report\u001b[0;34m(train_loss, train_acc, val_loss, val_acc)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"----\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Max of Testing Accuracy: %4f\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mean of Testing Loss: %4f\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mean of Testing Accuracy: %4f\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val_loss_list' is not defined"
     ]
    }
   ],
   "source": [
    "__MLP.clf_report(train_loss, train_acc, val_loss_list, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[317066.51713917527,\n 201521.53221649484,\n 143836.59671391753,\n 191701.70277061855,\n 231669.77280927834,\n 403299.20644329896,\n 522603.7418814433,\n 608191.4347938144,\n 719660.6056701031,\n 723971.6600515464,\n 582670.6443298969,\n 584056.094072165]"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[tensor(27.3897, dtype=torch.float64),\n tensor(27.3897, dtype=torch.float64),\n tensor(27.3897, dtype=torch.float64),\n tensor(27.3897, dtype=torch.float64),\n tensor(27.3897, dtype=torch.float64),\n tensor(27.3897, dtype=torch.float64),\n tensor(27.3897, dtype=torch.float64),\n tensor(27.3897, dtype=torch.float64),\n tensor(27.3897, dtype=torch.float64),\n tensor(27.3897, dtype=torch.float64),\n tensor(27.3897, dtype=torch.float64),\n tensor(27.3897, dtype=torch.float64)]"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rosetta",
   "language": "python",
   "name": "rosetta"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}