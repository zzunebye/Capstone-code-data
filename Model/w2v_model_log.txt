

************************************************************
STARTING A CROSS-VALIDATION ... [2] epochs
************************************************************
TIME: 01/04/2021 10:54:40
LAYER: [Sequential(
  (0): Linear(in_features=200, out_features=36, bias=True)
  (1): ELU(alpha=1.0)
  (2): Dropout(p=0.5, inplace=False)
  (3): Linear(in_features=36, out_features=8, bias=True)
  (4): ELU(alpha=1.0)
  (5): Dropout(p=0.5, inplace=False)
  (6): Linear(in_features=8, out_features=1, bias=True)
)]

STARTING TEST of 2 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: -0.0005307710962370038, std: 0.24665184319019318
Train Size: 4346, Test Size: 2079
total step: 1088
PATH: ./Model/w2v_model_1.pt
Accuracy for fold 1: 53.632
F1 Score for fold 1: 0.370
Loss for fold 1: 0.684
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: -0.007624366320669651, std: 0.24960531294345856
Train Size: 5282, Test Size: 1143
total step: 1322
PATH: ./Model/w2v_model_2.pt
Accuracy for fold 2: 71.479
F1 Score for fold 2: 0.486
Loss for fold 2: 0.640
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: -0.008379822596907616, std: 0.2669864892959595
Train Size: 5956, Test Size: 469
total step: 1490
PATH: ./Model/w2v_model_3.pt
Accuracy for fold 3: 53.945
F1 Score for fold 3: 0.366
Loss for fold 3: 0.688
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: -0.0034535101149231195, std: 0.2544417381286621
Train Size: 5535, Test Size: 890
total step: 1384
PATH: ./Model/w2v_model_4.pt
Accuracy for fold 4: 58.202
F1 Score for fold 4: 0.442
Loss for fold 4: 0.675
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: -0.0103662284091115, std: 0.24772290885448456
Train Size: 5204, Test Size: 1221
total step: 1302
PATH: ./Model/w2v_model_5.pt
Accuracy for fold 5: 59.705
F1 Score for fold 5: 0.428
Loss for fold 5: 0.675
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: -0.008188650943338871, std: 0.2506764829158783
Train Size: 6411, Test Size: 14
total step: 1604
PATH: ./Model/w2v_model_6.pt
Accuracy for fold 6: 85.714
F1 Score for fold 6: 0.673
Loss for fold 6: 0.581
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: -0.005613614339381456, std: 0.24195267260074615
Train Size: 6192, Test Size: 233
total step: 1548
PATH: ./Model/w2v_model_7.pt
Accuracy for fold 7: 74.249
F1 Score for fold 7: 0.438
Loss for fold 7: 0.652
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: -0.006872028112411499, std: 0.25464099645614624
Train Size: 6187, Test Size: 238
total step: 1548
PATH: ./Model/w2v_model_8.pt
Accuracy for fold 8: 70.168
F1 Score for fold 8: 0.441
Loss for fold 8: 0.656
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: -0.0003729859599843621, std: 0.2583162486553192
Train Size: 6287, Test Size: 138
total step: 1572
PATH: ./Model/w2v_model_9.pt
Accuracy for fold 9: 50.725
F1 Score for fold 9: 0.341
Loss for fold 9: 0.693

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 53.63155363155363, F1 36.98513701038954
Fold 1: Acc 71.47856517935259, F1 48.60791390975123
Fold 2: Acc 53.94456289978679, F1 36.5899061847889
Fold 3: Acc 58.20224719101124, F1 44.204699170991404
Fold 4: Acc 59.7051597051597, F1 42.79033256305994
Fold 5: Acc 85.71428571428571, F1 67.34693877551021
Fold 6: Acc 74.2489270386266, F1 43.77813888543504
Fold 7: Acc 70.16806722689076, F1 44.074450292937705
Fold 8: Acc 50.72463768115942, F1 34.0526784005045
Average: 64.202%
F1: 44.270%
Loss: 0.660

RESULT:
Average: 64.20%
F1: 44.27%
Loss: 0.66


************************************************************
STARTING A CROSS-VALIDATION ... [100] epochs
************************************************************
TIME: 01/04/2021 10:59:02
LAYER: [Sequential(
  (0): Linear(in_features=200, out_features=36, bias=True)
  (1): ELU(alpha=1.0)
  (2): Dropout(p=0.5, inplace=False)
  (3): Linear(in_features=36, out_features=8, bias=True)
  (4): ELU(alpha=1.0)
  (5): Dropout(p=0.5, inplace=False)
  (6): Linear(in_features=8, out_features=1, bias=True)
)]

STARTING TEST of 100 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 0.0026416690088808537, std: 0.2604503929615021
Train Size: 4346, Test Size: 2079
total step: 54400
PATH: ./Model/w2v_model_1.pt

************************************************************
STARTING A CROSS-VALIDATION ... [50] epochs
************************************************************
TIME: 01/04/2021 10:59:11
LAYER: [Sequential(
  (0): Linear(in_features=200, out_features=36, bias=True)
  (1): ELU(alpha=1.0)
  (2): Dropout(p=0.5, inplace=False)
  (3): Linear(in_features=36, out_features=8, bias=True)
  (4): ELU(alpha=1.0)
  (5): Dropout(p=0.5, inplace=False)
  (6): Linear(in_features=8, out_features=1, bias=True)
)]

STARTING TEST of 50 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: -0.0020330301485955715, std: 0.2709122896194458
Train Size: 4346, Test Size: 2079
total step: 27200
PATH: ./Model/w2v_model_1.pt

************************************************************
STARTING A CROSS-VALIDATION ... [50] epochs
************************************************************
TIME: 01/04/2021 10:59:28
LAYER: [Sequential(
  (0): Linear(in_features=200, out_features=36, bias=True)
  (1): ELU(alpha=1.0)
  (2): Dropout(p=0.5, inplace=False)
  (3): Linear(in_features=36, out_features=8, bias=True)
  (4): ELU(alpha=1.0)
  (5): Dropout(p=0.5, inplace=False)
  (6): Linear(in_features=8, out_features=1, bias=True)
)]

STARTING TEST of 50 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: -0.008325337432324886, std: 0.23575490713119507
Train Size: 4346, Test Size: 2079
total step: 27200
PATH: ./Model/w2v_model_1.pt
Accuracy for fold 1: 70.130
F1 Score for fold 1: 0.461
Loss for fold 1: 0.649
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: -0.009293538518249989, std: 0.26502034068107605
Train Size: 5282, Test Size: 1143
total step: 33050
PATH: ./Model/w2v_model_2.pt
Accuracy for fold 2: 65.267
F1 Score for fold 2: 0.404
Loss for fold 2: 0.670
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: -0.005528465379029512, std: 0.24326953291893005
Train Size: 5956, Test Size: 469
total step: 37250
PATH: ./Model/w2v_model_3.pt
Accuracy for fold 3: 62.047
F1 Score for fold 3: 0.371
Loss for fold 3: 0.763
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: -0.0068963151425123215, std: 0.2572157084941864
Train Size: 5535, Test Size: 890
total step: 34600
PATH: ./Model/w2v_model_4.pt
Accuracy for fold 4: 68.989
F1 Score for fold 4: 0.438
Loss for fold 4: 0.624
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: -0.0025100389029830694, std: 0.23244675993919373
Train Size: 5204, Test Size: 1221
total step: 32550
PATH: ./Model/w2v_model_5.pt
Accuracy for fold 5: 73.137
F1 Score for fold 5: 0.473
Loss for fold 5: 0.598
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: -0.00686386413872242, std: 0.2337779551744461
Train Size: 6411, Test Size: 14
total step: 40100
PATH: ./Model/w2v_model_6.pt
Accuracy for fold 6: 85.714
F1 Score for fold 6: 0.673
Loss for fold 6: 0.300
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: -0.0036601193714886904, std: 0.25225138664245605
Train Size: 6192, Test Size: 233
total step: 38700
PATH: ./Model/w2v_model_7.pt
Accuracy for fold 7: 42.489
F1 Score for fold 7: 0.295
Loss for fold 7: 0.887
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: -0.001372892060317099, std: 0.24701136350631714
Train Size: 6187, Test Size: 238
total step: 38700
PATH: ./Model/w2v_model_8.pt
Accuracy for fold 8: 61.765
F1 Score for fold 8: 0.469
Loss for fold 8: 0.707
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: -0.008961599320173264, std: 0.24729371070861816
Train Size: 6287, Test Size: 138
total step: 39300
PATH: ./Model/w2v_model_9.pt
Accuracy for fold 9: 63.768
F1 Score for fold 9: 0.472
Loss for fold 9: 0.661

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 70.12987012987013, F1 46.06955013881423
Fold 1: Acc 65.26684164479441, F1 40.385446185971176
Fold 2: Acc 62.046908315565034, F1 37.1036875940927
Fold 3: Acc 68.98876404494382, F1 43.7617064583357
Fold 4: Acc 73.13677313677314, F1 47.30382184927644
Fold 5: Acc 85.71428571428571, F1 67.34693877551021
Fold 6: Acc 42.48927038626609, F1 29.52080823325459
Fold 7: Acc 61.76470588235294, F1 46.906650772197
Fold 8: Acc 63.76811594202898, F1 47.19464110768459
Average: 65.923%
F1: 45.066%
Loss: 0.651

RESULT:
Average: 65.92%
F1: 45.07%
Loss: 0.65


************************************************************
STARTING A CROSS-VALIDATION ... [50] epochs
************************************************************
TIME: 01/04/2021 11:12:50
LAYER: [Sequential(
  (0): Linear(in_features=200, out_features=36, bias=True)
  (1): ELU(alpha=1.0)
  (2): Dropout(p=0.5, inplace=False)
  (3): Linear(in_features=36, out_features=8, bias=True)
  (4): ELU(alpha=1.0)
  (5): Dropout(p=0.5, inplace=False)
  (6): Linear(in_features=8, out_features=1, bias=True)
)]

STARTING TEST of 50 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: -0.005388594698160887, std: 0.23294185101985931
Train Size: 4346, Test Size: 2079
total step: 27200
PATH: ./Model/w2v_model_1.pt
Accuracy for fold 1: 69.986
F1 Score for fold 1: 0.459
Loss for fold 1: 0.669
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: -0.012561185285449028, std: 0.2510482668876648
Train Size: 5282, Test Size: 1143
total step: 33050
PATH: ./Model/w2v_model_2.pt
Accuracy for fold 2: 68.154
F1 Score for fold 2: 0.423
Loss for fold 2: 0.624
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: -0.007811576593667269, std: 0.2742559611797333
Train Size: 5956, Test Size: 469
total step: 37250
PATH: ./Model/w2v_model_3.pt
Accuracy for fold 3: 61.620
F1 Score for fold 3: 0.385
Loss for fold 3: 0.784
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: -0.0059756385162472725, std: 0.2650356888771057
Train Size: 5535, Test Size: 890
total step: 34600
PATH: ./Model/w2v_model_4.pt
Accuracy for fold 4: 67.528
F1 Score for fold 4: 0.414
Loss for fold 4: 0.650
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: -0.010106495581567287, std: 0.27867457270622253
Train Size: 5204, Test Size: 1221
total step: 32550
PATH: ./Model/w2v_model_5.pt
Accuracy for fold 5: 71.990
F1 Score for fold 5: 0.464
Loss for fold 5: 0.608
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: -0.0077984631061553955, std: 0.2525824308395386
Train Size: 6411, Test Size: 14
total step: 40100
PATH: ./Model/w2v_model_6.pt
Accuracy for fold 6: 85.714
F1 Score for fold 6: 0.673
Loss for fold 6: 0.386
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: -0.002362085273489356, std: 0.262489378452301
Train Size: 6192, Test Size: 233
total step: 38700
PATH: ./Model/w2v_model_7.pt
Accuracy for fold 7: 44.206
F1 Score for fold 7: 0.304
Loss for fold 7: 0.882
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: -0.009931972250342369, std: 0.2756860554218292
Train Size: 6187, Test Size: 238
total step: 38700
PATH: ./Model/w2v_model_8.pt
Accuracy for fold 8: 63.445
F1 Score for fold 8: 0.431
Loss for fold 8: 0.771
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: -0.006373935844749212, std: 0.25965142250061035
Train Size: 6287, Test Size: 138
total step: 39300
PATH: ./Model/w2v_model_9.pt
Accuracy for fold 9: 63.043
F1 Score for fold 9: 0.420
Loss for fold 9: 0.638

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 69.98556998556998, F1 45.904490464375066
Fold 1: Acc 68.15398075240596, F1 42.29554153438674
Fold 2: Acc 61.62046908315565, F1 38.470413736938255
Fold 3: Acc 67.52808988764045, F1 41.365021994235505
Fold 4: Acc 71.99017199017199, F1 46.408199135471904
Fold 5: Acc 85.71428571428571, F1 67.34693877551021
Fold 6: Acc 44.20600858369099, F1 30.44783542637619
Fold 7: Acc 63.4453781512605, F1 43.121080600072204
Fold 8: Acc 63.04347826086957, F1 41.9520254302863
Average: 66.187%
F1: 44.146%
Loss: 0.668

RESULT:
Average: 66.19%
F1: 44.15%
Loss: 0.67


************************************************************
STARTING A CROSS-VALIDATION ... [50] epochs
************************************************************
TIME: 01/04/2021 12:08:01
LAYER: [Sequential(
  (0): Linear(in_features=200, out_features=36, bias=True)
  (1): ELU(alpha=1.0)
  (2): Dropout(p=0.5, inplace=False)
  (3): Linear(in_features=36, out_features=8, bias=True)
  (4): ELU(alpha=1.0)
  (5): Dropout(p=0.5, inplace=False)
  (6): Linear(in_features=8, out_features=1, bias=True)
)]

STARTING TEST of 50 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: -0.007722786627709866, std: 0.26258766651153564
Train Size: 4346, Test Size: 2079
total step: 27200
PATH: ./Model/w2v_model_1.pt
Accuracy for fold 1: 70.899
F1 Score for fold 1: 0.449
Loss for fold 1: 0.639
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: -0.005611484870314598, std: 0.23905596137046814
Train Size: 5282, Test Size: 1143
total step: 33050
PATH: ./Model/w2v_model_2.pt
Accuracy for fold 2: 63.780
F1 Score for fold 2: 0.394
Loss for fold 2: 0.663
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: -0.0027889085467904806, std: 0.24189241230487823
Train Size: 5956, Test Size: 469
total step: 37250
PATH: ./Model/w2v_model_3.pt
Accuracy for fold 3: 60.768
F1 Score for fold 3: 0.398
Loss for fold 3: 0.807
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: -0.004913875833153725, std: 0.25207045674324036
Train Size: 5535, Test Size: 890
total step: 34600
PATH: ./Model/w2v_model_4.pt
Accuracy for fold 4: 69.101
F1 Score for fold 4: 0.450
Loss for fold 4: 0.639
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: -0.0032243747264146805, std: 0.24842318892478943
Train Size: 5204, Test Size: 1221
total step: 32550
PATH: ./Model/w2v_model_5.pt
Accuracy for fold 5: 72.482
F1 Score for fold 5: 0.478
Loss for fold 5: 0.581
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: -0.006521359086036682, std: 0.26404061913490295
Train Size: 6411, Test Size: 14
total step: 40100
PATH: ./Model/w2v_model_6.pt
Accuracy for fold 6: 85.714
F1 Score for fold 6: 0.673
Loss for fold 6: 0.342
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: -0.004148661624640226, std: 0.2612050175666809
Train Size: 6192, Test Size: 233
total step: 38700
PATH: ./Model/w2v_model_7.pt
Accuracy for fold 7: 43.777
F1 Score for fold 7: 0.298
Loss for fold 7: 0.883
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: -0.010317277163267136, std: 0.2524499297142029
Train Size: 6187, Test Size: 238
total step: 38700
PATH: ./Model/w2v_model_8.pt
Accuracy for fold 8: 61.765
F1 Score for fold 8: 0.413
Loss for fold 8: 0.738
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: -0.0006756351212970912, std: 0.25798770785331726
Train Size: 6287, Test Size: 138
total step: 39300
PATH: ./Model/w2v_model_9.pt
Accuracy for fold 9: 63.768
F1 Score for fold 9: 0.473
Loss for fold 9: 0.692

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 70.8994708994709, F1 44.90384715492945
Fold 1: Acc 63.77952755905512, F1 39.43861815252898
Fold 2: Acc 60.76759061833689, F1 39.75443651349833
Fold 3: Acc 69.10112359550563, F1 44.97417688428927
Fold 4: Acc 72.48157248157248, F1 47.75074593256415
Fold 5: Acc 85.71428571428571, F1 67.34693877551021
Fold 6: Acc 43.776824034334766, F1 29.831494209176608
Fold 7: Acc 61.76470588235294, F1 41.28627674846163
Fold 8: Acc 63.76811594202898, F1 47.31896123200471
Average: 65.784%
F1: 44.734%
Loss: 0.665

RESULT:
Average: 65.78%
F1: 44.73%
Loss: 0.66
