53.164
Accuracy for fold 9: 48.551
F1 Score for fold 9: 0.318
Loss for fold 9: 886.402

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 49.06204906204906, F1 32.41891932649999
Fold 1: Acc 48.90638670166229, F1 32.6447123849179
Fold 2: Acc 49.89339019189765, F1 32.9388188951317
Fold 3: Acc 52.02247191011236, F1 34.416650711939624
Fold 4: Acc 46.027846027846024, F1 30.534917009495462
Fold 5: Acc 78.57142857142857, F1 44.0
Fold 6: Acc 38.62660944206009, F1 28.162079947909984
Fold 7: Acc 49.159663865546214, F1 32.661287291174034
Fold 8: Acc 48.55072463768116, F1 31.77933177933178
Average: 51.202%
F1: 33.284%
Loss: 5833.773



************************************************************
STARTING A CROSS-VALIDATION ... [5] epochs
************************************************************
TIME: 31/03/2021 17:08:02
LAYER: [Sequential(
  (0): Linear(in_features=49, out_features=16, bias=True)
  (1): ELU(alpha=1.0)
  (2): Dropout(p=0.5, inplace=False)
  (3): Linear(in_features=16, out_features=5, bias=True)
  (4): ELU(alpha=1.0)
  (5): Dropout(p=0.5, inplace=False)
  (6): Linear(in_features=5, out_features=1, bias=True)
)]

STARTING TEST of 5 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 20152.685546875, std: 290054.71875
Train Size: 4346, Test Size: 2079
total step: 1360
PATH: ./Model/root_model_1.pt
Accuracy for fold 1: 50.120
F1 Score for fold 1: 0.332
Loss for fold 1: 3722.096
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 74357.2578125, std: 965926.6875
Train Size: 5282, Test Size: 1143
total step: 1655
PATH: ./Model/root_model_2.pt
Accuracy for fold 2: 51.094
F1 Score for fold 2: 0.334
Loss for fold 2: 1255.088
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 49451.09375, std: 857311.6875
Train Size: 5956, Test Size: 469
total step: 1865
PATH: ./Model/root_model_3.pt
Accuracy for fold 3: 46.269
F1 Score for fold 3: 0.303
Loss for fold 3: 8747.370
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 40646.2265625, std: 822879.375
Train Size: 5535, Test Size: 890
total step: 1730
PATH: ./Model/root_model_4.pt
Accuracy for fold 4: 50.112
F1 Score for fold 4: 0.318
Loss for fold 4: 2748.510
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 83210.125, std: 1073895.625
Train Size: 5204, Test Size: 1221
total step: 1630
PATH: ./Model/root_model_5.pt
Accuracy for fold 5: 48.894
F1 Score for fold 5: 0.325
Loss for fold 5: 12926.844
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 10182.3828125, std: 182689.4375
Train Size: 6411, Test Size: 14
total step: 2005
PATH: ./Model/root_model_6.pt
Accuracy for fold 6: 50.000
F1 Score for fold 6: 0.333
Loss for fold 6: 1706.161
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 32006.72265625, std: 544311.625
Train Size: 6192, Test Size: 233
total step: 1935
PATH: ./Model/root_model_7.pt
Accuracy for fold 7: 67.382
F1 Score for fold 7: 0.407
Loss for fold 7: 1391.346
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 18234.361328125, std: 209889.140625
Train Size: 6187, Test Size: 238
total step: 1935
PATH: ./Model/root_model_8.pt
Accuracy for fold 8: 52.101
F1 Score for fold 8: 0.341
Loss for fold 8: 50.130
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 63570.28125, std: 948942.4375
Train Size: 6287, Test Size: 138
total step: 1965
PATH: ./Model/root_model_9.pt
Accuracy for fold 9: 56.522
F1 Score for fold 9: 0.364
Loss for fold 9: 165.137

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 50.12025012025012, F1 33.16648095484528
Fold 1: Acc 51.0936132983377, F1 33.380161303990185
Fold 2: Acc 46.26865671641791, F1 30.292607104861613
Fold 3: Acc 50.112359550561806, F1 31.844011798027374
Fold 4: Acc 48.894348894348894, F1 32.50930293548697
Fold 5: Acc 50.0, F1 33.33333333333333
Fold 6: Acc 67.38197424892704, F1 40.742481494385146
Fold 7: Acc 52.10084033613446, F1 34.08772907121213
Fold 8: Acc 56.52173913043478, F1 36.40224234953468
Average: 52.499%
F1: 33.973%
Loss: 3634.742



************************************************************
STARTING A CROSS-VALIDATION ... [5] epochs
************************************************************
TIME: 31/03/2021 17:09:01
LAYER: [Sequential(
  (0): Linear(in_features=49, out_features=16, bias=True)
  (1): ELU(alpha=1.0)
  (2): Dropout(p=0.5, inplace=False)
  (3): Linear(in_features=16, out_features=5, bias=True)
  (4): ELU(alpha=1.0)
  (5): Dropout(p=0.5, inplace=False)
  (6): Linear(in_features=5, out_features=1, bias=True)
)]

STARTING TEST of 5 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 28093.1640625, std: 407627.625
Train Size: 4346, Test Size: 2079
total step: 1360
PATH: ./Model/root_model_1.pt
Accuracy for fold 1: 61.616
F1 Score for fold 1: 0.370
Loss for fold 1: 2809.052
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 67125.59375, std: 815854.8125
Train Size: 5282, Test Size: 1143
total step: 1655
PATH: ./Model/root_model_2.pt
Accuracy for fold 2: 50.831
F1 Score for fold 2: 0.332
Loss for fold 2: 1167.621
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 19612.60546875, std: 270190.65625
Train Size: 5956, Test Size: 469
total step: 1865
PATH: ./Model/root_model_3.pt

************************************************************
STARTING A CROSS-VALIDATION ... [] epochs
************************************************************
TIME: 31/03/2021 17:09:49
LAYER: [Sequential(
  (0): Linear(in_features=49, out_features=16, bias=True)
  (1): ELU(alpha=1.0)
  (2): Dropout(p=0.5, inplace=False)
  (3): Linear(in_features=16, out_features=5, bias=True)
  (4): ELU(alpha=1.0)
  (5): Dropout(p=0.5, inplace=False)
  (6): Linear(in_features=5, out_features=1, bias=True)
)]


************************************************************
STARTING A CROSS-VALIDATION ... [3] epochs
************************************************************
TIME: 31/03/2021 17:10:57
LAYER: [Sequential(
  (0): Linear(in_features=49, out_features=16, bias=True)
  (1): ELU(alpha=1.0)
  (2): Dropout(p=0.5, inplace=False)
  (3): Linear(in_features=16, out_features=5, bias=True)
  (4): ELU(alpha=1.0)
  (5): Dropout(p=0.5, inplace=False)
  (6): Linear(in_features=5, out_features=1, bias=True)
)]

STARTING TEST of 3 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 33799.23046875, std: 726607.5
Train Size: 4346, Test Size: 2079
total step: 816
PATH: ./Model/root_model_1.pt
Accuracy for fold 1: 43.001
F1 Score for fold 1: 0.296
Loss for fold 1: 10892.882
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 36745.26953125, std: 568313.625
Train Size: 5282, Test Size: 1143
total step: 993
PATH: ./Model/root_model_2.pt
Accuracy for fold 2: 57.043
F1 Score for fold 2: 0.359
Loss for fold 2: 1642.261
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 32123.58203125, std: 400945.625
Train Size: 5956, Test Size: 469
total step: 1119
PATH: ./Model/root_model_3.pt
Accuracy for fold 3: 48.614
F1 Score for fold 3: 0.319
Loss for fold 3: 8684.861
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 34116.953125, std: 549064.3125
Train Size: 5535, Test Size: 890
total step: 1038
PATH: ./Model/root_model_4.pt
Accuracy for fold 4: 50.225
F1 Score for fold 4: 0.332
Loss for fold 4: 20675.156
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 9332.2265625, std: 155439.921875
Train Size: 5204, Test Size: 1221
total step: 978
PATH: ./Model/root_model_5.pt
Accuracy for fold 5: 49.468
F1 Score for fold 5: 0.317
Loss for fold 5: 4566.577
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 18772.986328125, std: 277409.0
Train Size: 6411, Test Size: 14
total step: 1203
PATH: ./Model/root_model_6.pt
Accuracy for fold 6: 28.571
F1 Score for fold 6: 0.222
Loss for fold 6: 1062.447
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 46632.00390625, std: 544864.3125
Train Size: 6192, Test Size: 233
total step: 1161
PATH: ./Model/root_model_7.pt
Accuracy for fold 7: 51.502
F1 Score for fold 7: 0.338
Loss for fold 7: 698.105
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 15742.5078125, std: 204631.25
Train Size: 6187, Test Size: 238
total step: 1161
PATH: ./Model/root_model_8.pt
Accuracy for fold 8: 45.798
F1 Score for fold 8: 0.305
Loss for fold 8: 200.770
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 10965.021484375, std: 124886.6875
Train Size: 6287, Test Size: 138
total step: 1179
PATH: ./Model/root_model_9.pt
Accuracy for fold 9: 47.826
F1 Score for fold 9: 0.330
Loss for fold 9: 543.851

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 43.001443001443, F1 29.564437856608958
Fold 1: Acc 57.042869641294836, F1 35.87546566683645
Fold 2: Acc 48.61407249466951, F1 31.879413150943698
Fold 3: Acc 50.2247191011236, F1 33.19036505256799
Fold 4: Acc 49.467649467649466, F1 31.735315499107767
Fold 5: Acc 28.57142857142857, F1 22.222222222222225
Fold 6: Acc 51.50214592274678, F1 33.77455849493543
Fold 7: Acc 45.79831932773109, F1 30.472780254292857
Fold 8: Acc 47.82608695652174, F1 33.01623923930162
Average: 46.894%
F1: 31.303%
Loss: 5440.768

RESULT: [[{0: [43.001443001443, 29.564437856608958, 10892.881542344801], 1: [57.042869641294836, 35.87546566683645, 1642.2608975187686], 2: [48.61407249466951, 31.879413150943698, 8684.860516540022], 3: [50.2247191011236, 33.19036505256799, 20675.156155095476], 4: [49.467649467649466, 31.735315499107767, 4566.577301421193], 5: [28.57142857142857, 22.222222222222225, 1062.4466552734375], 6: [51.50214592274678, 33.77455849493543, 698.1045148464743], 7: [45.79831932773109, 30.472780254292857, 200.76985899340204], 8: [47.82608695652174, 33.01623923930162, 543.8511102095894]}]]


************************************************************
STARTING A CROSS-VALIDATION ... [3] epochs
************************************************************
TIME: 31/03/2021 17:18:16
LAYER: [Sequential(
  (0): Linear(in_features=49, out_features=16, bias=True)
  (1): ELU(alpha=1.0)
  (2): Dropout(p=0.5, inplace=False)
  (3): Linear(in_features=16, out_features=5, bias=True)
  (4): ELU(alpha=1.0)
  (5): Dropout(p=0.5, inplace=False)
  (6): Linear(in_features=5, out_features=1, bias=True)
)]

STARTING TEST of 3 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 15655.2373046875, std: 172513.984375
Train Size: 4346, Test Size: 2079
total step: 816
PATH: ./Model/root_model_1.pt
Accuracy for fold 1: 41.655
F1 Score for fold 1: 0.287
Loss for fold 1: 1624.101
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 6682.287109375, std: 78234.0
Train Size: 5282, Test Size: 1143
total step: 993
PATH: ./Model/root_model_2.pt
Accuracy for fold 2: 62.205
F1 Score for fold 2: 0.372
Loss for fold 2: 1869.209
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 11657.6962890625, std: 154556.734375
Train Size: 5956, Test Size: 469
total step: 1119
PATH: ./Model/root_model_3.pt
Accuracy for fold 3: 48.401
F1 Score for fold 3: 0.323
Loss for fold 3: 1554.054
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 9496.9990234375, std: 167290.3125
Train Size: 5535, Test Size: 890
total step: 1038
PATH: ./Model/root_model_4.pt
Accuracy for fold 4: 49.888
F1 Score for fold 4: 0.313
Loss for fold 4: 19043.445
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 24923.341796875, std: 319774.34375
Train Size: 5204, Test Size: 1221
total step: 978
PATH: ./Model/root_model_5.pt
Accuracy for fold 5: 48.812
F1 Score for fold 5: 0.323
Loss for fold 5: 1953.741
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 39176.3125, std: 585737.375
Train Size: 6411, Test Size: 14
total step: 1203
PATH: ./Model/root_model_6.pt
Accuracy for fold 6: 42.857
F1 Score for fold 6: 0.300
Loss for fold 6: 2238.611
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 8955.4736328125, std: 100914.1328125
Train Size: 6192, Test Size: 233
total step: 1161
PATH: ./Model/root_model_7.pt
Accuracy for fold 7: 72.103
F1 Score for fold 7: 0.425
Loss for fold 7: 30.242
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 33421.8359375, std: 634344.4375
Train Size: 6187, Test Size: 238
total step: 1161
PATH: ./Model/root_model_8.pt
Accuracy for fold 8: 52.521
F1 Score for fold 8: 0.352
Loss for fold 8: 297.664
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 41758.47265625, std: 833941.375
Train Size: 6287, Test Size: 138
total step: 1179
PATH: ./Model/root_model_9.pt
Accuracy for fold 9: 50.725
F1 Score for fold 9: 0.329
Loss for fold 9: 452.799

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 41.65464165464166, F1 28.687081153257484
Fold 1: Acc 62.20472440944882, F1 37.21544023274375
Fold 2: Acc 48.40085287846482, F1 32.30184670280828
Fold 3: Acc 49.8876404494382, F1 31.334025294718806
Fold 4: Acc 48.812448812448814, F1 32.26231559376357
Fold 5: Acc 42.857142857142854, F1 30.0
Fold 6: Acc 72.1030042918455, F1 42.48269935054011
Fold 7: Acc 52.52100840336135, F1 35.216480673550464
Fold 8: Acc 50.72463768115942, F1 32.8891585261197
Average: 52.130%
F1: 33.599%
Loss: 3229.318

RESULT: Average: 52.13%
F1: 33.60%
Loss: 3229.32
 

************************************************************
STARTING A CROSS-VALIDATION ... [3] epochs
************************************************************
TIME: 31/03/2021 17:19:06
LAYER: [Sequential(
  (0): Linear(in_features=49, out_features=16, bias=True)
  (1): ELU(alpha=1.0)
  (2): Dropout(p=0.5, inplace=False)
  (3): Linear(in_features=16, out_features=5, bias=True)
  (4): ELU(alpha=1.0)
  (5): Dropout(p=0.5, inplace=False)
  (6): Linear(in_features=5, out_features=1, bias=True)
)]

STARTING TEST of 3 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 16194.5, std: 249093.609375
Train Size: 4346, Test Size: 2079
total step: 816
PATH: ./Model/root_model_1.pt
Accuracy for fold 1: 54.882
F1 Score for fold 1: 0.345
Loss for fold 1: 8821.395
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 25273.751953125, std: 583600.6875
Train Size: 5282, Test Size: 1143
total step: 993
PATH: ./Model/root_model_2.pt
Accuracy for fold 2: 63.780
F1 Score for fold 2: 0.365
Loss for fold 2: 2105.122
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 18509.296875, std: 235537.171875
Train Size: 5956, Test Size: 469
total step: 1119
PATH: ./Model/root_model_3.pt
Accuracy for fold 3: 47.761
F1 Score for fold 3: 0.317
Loss for fold 3: 9029.184
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 18577.091796875, std: 217394.25
Train Size: 5535, Test Size: 890
total step: 1038
PATH: ./Model/root_model_4.pt
Accuracy for fold 4: 50.337
F1 Score for fold 4: 0.322
Loss for fold 4: 4745.986
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 17164.6953125, std: 199000.171875
Train Size: 5204, Test Size: 1221
total step: 978
PATH: ./Model/root_model_5.pt
Accuracy for fold 5: 48.075
F1 Score for fold 5: 0.321
Loss for fold 5: 15139.316
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 9426.2236328125, std: 154101.984375
Train Size: 6411, Test Size: 14
total step: 1203
PATH: ./Model/root_model_6.pt
Accuracy for fold 6: 64.286
F1 Score for fold 6: 0.391
Loss for fold 6: 1746.757
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 58218.19921875, std: 807728.125
Train Size: 6192, Test Size: 233
total step: 1161
PATH: ./Model/root_model_7.pt
Accuracy for fold 7: 59.227
F1 Score for fold 7: 0.376
Loss for fold 7: 332.627
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 14097.6943359375, std: 199300.484375
Train Size: 6187, Test Size: 238
total step: 1161
PATH: ./Model/root_model_8.pt
Accuracy for fold 8: 48.319
F1 Score for fold 8: 0.301
Loss for fold 8: 141.802
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 27267.05859375, std: 359968.3125
Train Size: 6287, Test Size: 138
total step: 1179
PATH: ./Model/root_model_9.pt
Accuracy for fold 9: 47.826
F1 Score for fold 9: 0.328
Loss for fold 9: 463.236

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 54.882154882154886, F1 34.48665243006165
Fold 1: Acc 63.77952755905512, F1 36.456563245195056
Fold 2: Acc 47.76119402985074, F1 31.697347913866526
Fold 3: Acc 50.337078651685395, F1 32.17693689740695
Fold 4: Acc 48.075348075348074, F1 32.09046897057437
Fold 5: Acc 64.28571428571429, F1 39.130434782608695
Fold 6: Acc 59.227467811158796, F1 37.59862074025163
Fold 7: Acc 48.319327731092436, F1 30.117132586779157
Fold 8: Acc 47.82608695652174, F1 32.78340353472864
Average: 53.833%
F1: 34.060%
Loss: 4725.047

RESULT:
Average: 53.83%
F1: 34.06%
Loss: 4725.05


************************************************************
STARTING A CROSS-VALIDATION ... [50, 100] epochs
************************************************************

STARTING TEST of 50 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 14036.4921875, std: 217669.015625
Train Size: 4346, Test Size: 2079
total step: 13600
PATH: ./Model/root_model_1.pt

************************************************************
STARTING A CROSS-VALIDATION ... [50, 100] epochs
************************************************************
TIME: 31/03/2021 17:20:24
LAYER: [Sequential(
  (0): Linear(in_features=49, out_features=16, bias=True)
  (1): ELU(alpha=1.0)
  (2): Dropout(p=0.5, inplace=False)
  (3): Linear(in_features=16, out_features=5, bias=True)
  (4): ELU(alpha=1.0)
  (5): Dropout(p=0.5, inplace=False)
  (6): Linear(in_features=5, out_features=1, bias=True)
)]

STARTING TEST of 50 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 5156.8173828125, std: 79743.421875
Train Size: 4346, Test Size: 2079
total step: 13600
PATH: ./Model/root_model_1.pt
Accuracy for fold 1: 70.034
F1 Score for fold 1: 0.409
Loss for fold 1: 156.629
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 46768.83203125, std: 853231.9375
Train Size: 5282, Test Size: 1143
total step: 16550
PATH: ./Model/root_model_2.pt
Accuracy for fold 2: 38.670
F1 Score for fold 2: 0.267
Loss for fold 2: 16.704
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 32274.2578125, std: 460886.0625
Train Size: 5956, Test Size: 469
total step: 18650
PATH: ./Model/root_model_3.pt
Accuracy for fold 3: 48.827
F1 Score for fold 3: 0.321
Loss for fold 3: 32.161
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 46363.84375, std: 566023.0625
Train Size: 5535, Test Size: 890
total step: 17300
PATH: ./Model/root_model_4.pt
Accuracy for fold 4: 46.404
F1 Score for fold 4: 0.303
Loss for fold 4: 172.420
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 52191.53515625, std: 771434.875
Train Size: 5204, Test Size: 1221
total step: 16300
PATH: ./Model/root_model_5.pt
Accuracy for fold 5: 50.369
F1 Score for fold 5: 0.332
Loss for fold 5: 99.226
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 14753.92578125, std: 155624.90625
Train Size: 6411, Test Size: 14
total step: 20050
PATH: ./Model/root_model_6.pt
Accuracy for fold 6: 50.000
F1 Score for fold 6: 0.333
Loss for fold 6: 0.828
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 51456.18359375, std: 805073.25
Train Size: 6192, Test Size: 233
total step: 19350
PATH: ./Model/root_model_7.pt
Accuracy for fold 7: 37.768
F1 Score for fold 7: 0.282
Loss for fold 7: 0.895
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 22203.443359375, std: 315450.65625
Train Size: 6187, Test Size: 238
total step: 19350
PATH: ./Model/root_model_8.pt
Accuracy for fold 8: 49.580
F1 Score for fold 8: 0.332
Loss for fold 8: 15.970
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 36724.59375, std: 514185.5
Train Size: 6287, Test Size: 138
total step: 19650
PATH: ./Model/root_model_9.pt
Accuracy for fold 9: 48.551
F1 Score for fold 9: 0.311
Loss for fold 9: 2.211

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 70.03367003367003, F1 40.87801407886232
Fold 1: Acc 38.67016622922135, F1 26.74172838169872
Fold 2: Acc 48.8272921108742, F1 32.094636747382864
Fold 3: Acc 46.40449438202247, F1 30.29869188335157
Fold 4: Acc 50.368550368550366, F1 33.209206772345034
Fold 5: Acc 50.0, F1 33.33333333333333
Fold 6: Acc 37.76824034334764, F1 28.173473599859122
Fold 7: Acc 49.57983193277311, F1 33.15127344631557
Fold 8: Acc 48.55072463768116, F1 31.07488714975295
Average: 48.911%
F1: 32.106%
Loss: 55.227


STARTING TEST of 100 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 10987.0615234375, std: 158605.828125
Train Size: 4346, Test Size: 2079
total step: 27200
PATH: ./Model/root_model_1.pt
Accuracy for fold 1: 64.358
F1 Score for fold 1: 0.380
Loss for fold 1: 127.815
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 14459.767578125, std: 236396.203125
Train Size: 5282, Test Size: 1143
total step: 33100
PATH: ./Model/root_model_2.pt
Accuracy for fold 2: 61.855
F1 Score for fold 2: 0.377
Loss for fold 2: 1.857
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 2892.2080078125, std: 30687.0546875
Train Size: 5956, Test Size: 469
total step: 37300
PATH: ./Model/root_model_3.pt
Accuracy for fold 3: 48.827
F1 Score for fold 3: 0.310
Loss for fold 3: 0.732
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 18878.76171875, std: 266088.03125
Train Size: 5535, Test Size: 890
total step: 34600
PATH: ./Model/root_model_4.pt
Accuracy for fold 4: 49.888
F1 Score for fold 4: 0.325
Loss for fold 4: 0.756
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 7176.2666015625, std: 80588.328125
Train Size: 5204, Test Size: 1221
total step: 32600
PATH: ./Model/root_model_5.pt
Accuracy for fold 5: 48.157
F1 Score for fold 5: 0.321
Loss for fold 5: 8.821
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 47899.8046875, std: 603871.4375
Train Size: 6411, Test Size: 14
total step: 40100
PATH: ./Model/root_model_6.pt
Accuracy for fold 6: 50.000
F1 Score for fold 6: 0.333
Loss for fold 6: 0.660
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 31672.517578125, std: 538898.875
Train Size: 6192, Test Size: 233
total step: 38700
PATH: ./Model/root_model_7.pt
Accuracy for fold 7: 87.124
F1 Score for fold 7: 0.499
Loss for fold 7: 0.530
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 58045.14453125, std: 624158.75
Train Size: 6187, Test Size: 238
total step: 38700
PATH: ./Model/root_model_8.pt
Accuracy for fold 8: 52.101
F1 Score for fold 8: 0.344
Loss for fold 8: 1.324
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 11614.7734375, std: 113104.5234375
Train Size: 6287, Test Size: 138
total step: 39300
PATH: ./Model/root_model_9.pt
Accuracy for fold 9: 45.652
F1 Score for fold 9: 0.328
Loss for fold 9: 3.096

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 64.35786435786436, F1 37.95488219331184
Fold 1: Acc 61.85476815398076, F1 37.72776469725731
Fold 2: Acc 48.8272921108742, F1 30.987707564408325
Fold 3: Acc 49.8876404494382, F1 32.458608970269864
Fold 4: Acc 48.157248157248155, F1 32.057231113989815
Fold 5: Acc 50.0, F1 33.33333333333333
Fold 6: Acc 87.1244635193133, F1 49.85622920032637
Fold 7: Acc 52.10084033613446, F1 34.43219881784003
Fold 8: Acc 45.65217391304348, F1 32.750727533336224
Average: 56.440%
F1: 35.729%
Loss: 16.177

RESULT:
Average: 48.91%
F1: 32.11%
Loss: 55.23


************************************************************
STARTING A CROSS-VALIDATION ... [50, 100] epochs
************************************************************
TIME: 31/03/2021 17:25:36
LAYER: [Sequential(
  (0): Linear(in_features=49, out_features=12, bias=True)
  (1): ELU(alpha=1.0)
  (2): Dropout(p=0.5, inplace=False)
  (3): Linear(in_features=12, out_features=4, bias=True)
  (4): ELU(alpha=1.0)
  (5): Dropout(p=0.5, inplace=False)
  (6): Linear(in_features=4, out_features=1, bias=True)
)]

STARTING TEST of 50 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 20382.599609375, std: 291256.0625
Train Size: 4346, Test Size: 2079
total step: 13600
PATH: ./Model/root_model_1.pt
Accuracy for fold 1: 73.785
F1 Score for fold 1: 0.493
Loss for fold 1: 359.594
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 56295.1171875, std: 730059.625
Train Size: 5282, Test Size: 1143
total step: 16550
PATH: ./Model/root_model_2.pt
Accuracy for fold 2: 61.155
F1 Score for fold 2: 0.373
Loss for fold 2: 4.499
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 29511.060546875, std: 354216.9375
Train Size: 5956, Test Size: 469
total step: 18650
PATH: ./Model/root_model_3.pt
Accuracy for fold 3: 53.092
F1 Score for fold 3: 0.337
Loss for fold 3: 4.419
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 8563.24609375, std: 170147.453125
Train Size: 5535, Test Size: 890
total step: 17300
PATH: ./Model/root_model_4.pt
Accuracy for fold 4: 54.157
F1 Score for fold 4: 0.352
Loss for fold 4: 65.909
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 18934.419921875, std: 275104.5
Train Size: 5204, Test Size: 1221
total step: 16300
PATH: ./Model/root_model_5.pt
Accuracy for fold 5: 54.218
F1 Score for fold 5: 0.342
Loss for fold 5: 338.181
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 25450.34375, std: 316813.25
Train Size: 6411, Test Size: 14
total step: 20050
PATH: ./Model/root_model_6.pt
Accuracy for fold 6: 14.286
F1 Score for fold 6: 0.125
Loss for fold 6: 0.885
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 13646.8466796875, std: 258693.875
Train Size: 6192, Test Size: 233
total step: 19350
PATH: ./Model/root_model_7.pt
Accuracy for fold 7: 74.678
F1 Score for fold 7: 0.460
Loss for fold 7: 5.044
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 7024.52099609375, std: 67307.8203125
Train Size: 6187, Test Size: 238
total step: 19350
PATH: ./Model/root_model_8.pt
Accuracy for fold 8: 45.798
F1 Score for fold 8: 0.312
Loss for fold 8: 2.587
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 81280.3046875, std: 1085401.0
Train Size: 6287, Test Size: 138
total step: 19650
PATH: ./Model/root_model_9.pt
Accuracy for fold 9: 57.246
F1 Score for fold 9: 0.422
Loss for fold 9: 0.849

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 73.78547378547378, F1 49.294405363446195
Fold 1: Acc 61.15485564304461, F1 37.3151144511986
Fold 2: Acc 53.09168443496801, F1 33.74488664436882
Fold 3: Acc 54.157303370786515, F1 35.227680370111
Fold 4: Acc 54.217854217854224, F1 34.159599099712
Fold 5: Acc 14.285714285714285, F1 12.5
Fold 6: Acc 74.67811158798283, F1 45.99774339747701
Fold 7: Acc 45.79831932773109, F1 31.223268754141976
Fold 8: Acc 57.2463768115942, F1 42.19624954547816
Average: 54.268%
F1: 35.740%
Loss: 86.885


STARTING TEST of 100 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 33329.87890625, std: 388168.6875
Train Size: 4346, Test Size: 2079
total step: 27200
PATH: ./Model/root_model_1.pt
Accuracy for fold 1: 23.569
F1 Score for fold 1: 0.210
Loss for fold 1: 26.624
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 39408.96484375, std: 551129.9375
Train Size: 5282, Test Size: 1143
total step: 33100
PATH: ./Model/root_model_2.pt
Accuracy for fold 2: 61.767
F1 Score for fold 2: 0.377
Loss for fold 2: 0.699
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 28603.052734375, std: 491376.625
Train Size: 5956, Test Size: 469
total step: 37300
PATH: ./Model/root_model_3.pt
Accuracy for fold 3: 48.827
F1 Score for fold 3: 0.385
Loss for fold 3: 14.180
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 27568.681640625, std: 488475.53125
Train Size: 5535, Test Size: 890
total step: 34600
PATH: ./Model/root_model_4.pt
Accuracy for fold 4: 54.607
F1 Score for fold 4: 0.345
Loss for fold 4: 25.578
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 11297.416015625, std: 203342.578125
Train Size: 5204, Test Size: 1221
total step: 32600
PATH: ./Model/root_model_5.pt
Accuracy for fold 5: 51.351
F1 Score for fold 5: 0.320
Loss for fold 5: 0.706
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 15326.134765625, std: 205419.046875
Train Size: 6411, Test Size: 14
total step: 40100
PATH: ./Model/root_model_6.pt
Accuracy for fold 6: 57.143
F1 Score for fold 6: 0.364
Loss for fold 6: 0.712
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 28827.119140625, std: 344147.6875
Train Size: 6192, Test Size: 233
total step: 38700
PATH: ./Model/root_model_7.pt
Accuracy for fold 7: 50.215
F1 Score for fold 7: 0.338
Loss for fold 7: 0.696
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 18642.95703125, std: 245931.9375
Train Size: 6187, Test Size: 238
total step: 38700
PATH: ./Model/root_model_8.pt
Accuracy for fold 8: 49.580
F1 Score for fold 8: 0.327
Loss for fold 8: 0.838
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 58210.6015625, std: 639290.25
Train Size: 6287, Test Size: 138
total step: 39300
PATH: ./Model/root_model_9.pt
Accuracy for fold 9: 44.928
F1 Score for fold 9: 0.315
Loss for fold 9: 0.722

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 23.56902356902357, F1 20.97733601242531
Fold 1: Acc 61.76727909011374, F1 37.72010715829083
Fold 2: Acc 48.8272921108742, F1 38.500431213055464
Fold 3: Acc 54.606741573033716, F1 34.48935521289566
Fold 4: Acc 51.35135135135135, F1 32.00788066845551
Fold 5: Acc 57.14285714285714, F1 36.36363636363636
Fold 6: Acc 50.21459227467812, F1 33.75091457028386
Fold 7: Acc 49.57983193277311, F1 32.69319692337595
Fold 8: Acc 44.927536231884055, F1 31.54263508353336
Average: 49.110%
F1: 33.116%
Loss: 7.862

RESULT:
Average: 54.27%
F1: 35.74%
Loss: 86.89


************************************************************
STARTING A CROSS-VALIDATION ... [50, 100] epochs
************************************************************
TIME: 31/03/2021 17:30:37
LAYER: [Sequential(
  (0): Linear(in_features=49, out_features=8, bias=True)
  (1): ELU(alpha=1.0)
  (2): Dropout(p=0.5, inplace=False)
  (3): Linear(in_features=8, out_features=3, bias=True)
  (4): ELU(alpha=1.0)
  (5): Dropout(p=0.5, inplace=False)
  (6): Linear(in_features=3, out_features=1, bias=True)
)]

STARTING TEST of 50 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 4907.43408203125, std: 72844.203125
Train Size: 4346, Test Size: 2079
total step: 13600
PATH: ./Model/root_model_1.pt
Accuracy for fold 1: 54.978
F1 Score for fold 1: 0.352
Loss for fold 1: 57.421
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 34369.5546875, std: 733407.25
Train Size: 5282, Test Size: 1143
total step: 16550
PATH: ./Model/root_model_2.pt
Accuracy for fold 2: 44.707
F1 Score for fold 2: 0.303
Loss for fold 2: 5.118
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 28585.810546875, std: 365107.5625
Train Size: 5956, Test Size: 469
total step: 18650
PATH: ./Model/root_model_3.pt
Accuracy for fold 3: 49.254
F1 Score for fold 3: 0.345
Loss for fold 3: 359.946
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 45916.76171875, std: 639270.5
Train Size: 5535, Test Size: 890
total step: 17300
PATH: ./Model/root_model_4.pt
Accuracy for fold 4: 49.213
F1 Score for fold 4: 0.323
Loss for fold 4: 1.154
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 45420.40234375, std: 606384.75
Train Size: 5204, Test Size: 1221
total step: 16300
PATH: ./Model/root_model_5.pt
Accuracy for fold 5: 51.269
F1 Score for fold 5: 0.326
Loss for fold 5: 456.362
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 15489.0986328125, std: 235908.25
Train Size: 6411, Test Size: 14
total step: 20050
PATH: ./Model/root_model_6.pt
Accuracy for fold 6: 64.286
F1 Score for fold 6: 0.391
Loss for fold 6: 0.715
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 88799.3671875, std: 1092785.25
Train Size: 6192, Test Size: 233
total step: 19350
PATH: ./Model/root_model_7.pt
Accuracy for fold 7: 12.446
F1 Score for fold 7: 0.107
Loss for fold 7: 0.866
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 32106.890625, std: 554668.0625
Train Size: 6187, Test Size: 238
total step: 19350
PATH: ./Model/root_model_8.pt
Accuracy for fold 8: 50.420
F1 Score for fold 8: 0.350
Loss for fold 8: 0.736
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 9210.7109375, std: 154949.3125
Train Size: 6287, Test Size: 138
total step: 19650
PATH: ./Model/root_model_9.pt
Accuracy for fold 9: 51.449
F1 Score for fold 9: 0.337
Loss for fold 9: 211.703

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 54.97835497835498, F1 35.23458110574113
Fold 1: Acc 44.70691163604549, F1 30.3485136693663
Fold 2: Acc 49.25373134328358, F1 34.492233367378645
Fold 3: Acc 49.21348314606742, F1 32.297152042094005
Fold 4: Acc 51.269451269451274, F1 32.62862890971249
Fold 5: Acc 64.28571428571429, F1 39.130434782608695
Fold 6: Acc 12.446351931330472, F1 10.656407280930596
Fold 7: Acc 50.42016806722689, F1 34.963672749139874
Fold 8: Acc 51.449275362318836, F1 33.66582368691841
Average: 47.558%
F1: 31.491%
Loss: 121.558


STARTING TEST of 100 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 11244.3740234375, std: 174914.59375
Train Size: 4346, Test Size: 2079
total step: 27200
PATH: ./Model/root_model_1.pt
Accuracy for fold 1: 40.837
F1 Score for fold 1: 0.280
Loss for fold 1: 1.080
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 102118.4453125, std: 1047692.5625
Train Size: 5282, Test Size: 1143
total step: 33100
PATH: ./Model/root_model_2.pt
Accuracy for fold 2: 50.044
F1 Score for fold 2: 0.331
Loss for fold 2: 1.031
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 44911.12890625, std: 837789.0625
Train Size: 5956, Test Size: 469
total step: 37300
PATH: ./Model/root_model_3.pt
Accuracy for fold 3: 47.548
F1 Score for fold 3: 0.307
Loss for fold 3: 0.705
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 10363.73046875, std: 159844.4375
Train Size: 5535, Test Size: 890
total step: 34600
PATH: ./Model/root_model_4.pt
Accuracy for fold 4: 49.101
F1 Score for fold 4: 0.328
Loss for fold 4: 0.746
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 41757.85546875, std: 549549.25
Train Size: 5204, Test Size: 1221
total step: 32600
PATH: ./Model/root_model_5.pt
Accuracy for fold 5: 57.658
F1 Score for fold 5: 0.516
Loss for fold 5: 0.700
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 34820.5234375, std: 718835.3125
Train Size: 6411, Test Size: 14
total step: 40100
PATH: ./Model/root_model_6.pt
Accuracy for fold 6: 57.143
F1 Score for fold 6: 0.364
Loss for fold 6: 0.730
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 10762.412109375, std: 126873.96875
Train Size: 6192, Test Size: 233
total step: 38700
PATH: ./Model/root_model_7.pt
Accuracy for fold 7: 69.099
F1 Score for fold 7: 0.438
Loss for fold 7: 0.668
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 15567.80859375, std: 255395.015625
Train Size: 6187, Test Size: 238
total step: 38700
PATH: ./Model/root_model_8.pt
Accuracy for fold 8: 49.160
F1 Score for fold 8: 0.328
Loss for fold 8: 1.253
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 29852.658203125, std: 410697.59375
Train Size: 6287, Test Size: 138
total step: 39300
PATH: ./Model/root_model_9.pt
Accuracy for fold 9: 48.551
F1 Score for fold 9: 0.327
Loss for fold 9: 0.712

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 40.83694083694084, F1 28.042188897053016
Fold 1: Acc 50.04374453193351, F1 33.05969730110105
Fold 2: Acc 47.54797441364605, F1 30.727148246778064
Fold 3: Acc 49.10112359550562, F1 32.800408540752926
Fold 4: Acc 57.65765765765766, F1 51.590395419962434
Fold 5: Acc 57.14285714285714, F1 36.36363636363636
Fold 6: Acc 69.09871244635193, F1 43.80193686314937
Fold 7: Acc 49.159663865546214, F1 32.813235497446016
Fold 8: Acc 48.55072463768116, F1 32.665882762061216
Average: 52.127%
F1: 35.763%
Loss: 0.847

RESULT:
Average: 47.56%
F1: 31.49%
Loss: 121.56


************************************************************
STARTING A CROSS-VALIDATION ... [100] epochs
************************************************************
TIME: 31/03/2021 21:34:10
LAYER: [Sequential(
  (0): Linear(in_features=49, out_features=16, bias=True)
  (1): ELU(alpha=1.0)
  (2): Dropout(p=0.5, inplace=False)
  (3): Linear(in_features=16, out_features=5, bias=True)
  (4): ELU(alpha=1.0)
  (5): Dropout(p=0.5, inplace=False)
  (6): Linear(in_features=5, out_features=1, bias=True)
)]

STARTING TEST of 100 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 28464.32421875, std: 466529.59375
Train Size: 4346, Test Size: 2079
total step: 27200
PATH: ./Model/root_model_1.pt
Accuracy for fold 1: 77.970
F1 Score for fold 1: 0.599
Loss for fold 1: 0.902
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 12608.2861328125, std: 113038.4375
Train Size: 5282, Test Size: 1143
total step: 33100
PATH: ./Model/root_model_2.pt