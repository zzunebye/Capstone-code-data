

************************************************************
STARTING A CROSS-VALIDATION ... [50] epochs
************************************************************
TIME: 01/04/2021 12:50:40
LAYER: [Sequential(
  (0): Linear(in_features=301, out_features=48, bias=True)
  (1): ELU(alpha=1.0)
  (2): Dropout(p=0.5, inplace=False)
  (3): Linear(in_features=48, out_features=8, bias=True)
  (4): ELU(alpha=1.0)
  (5): Dropout(p=0.5, inplace=False)
  (6): Linear(in_features=8, out_features=1, bias=True)
)]

STARTING TEST of 50 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 3457.350341796875, std: 46896.43359375
Train Size: 4346, Test Size: 2079
total step: 27200
PATH: ./Model/w2v_sparse_model_1.pt

************************************************************
STARTING A CROSS-VALIDATION ... [50] epochs
************************************************************
TIME: 01/04/2021 12:53:11
LAYER: [Sequential(
  (0): Linear(in_features=301, out_features=48, bias=True)
  (1): ELU(alpha=1.0)
  (2): Dropout(p=0.5, inplace=False)
  (3): Linear(in_features=48, out_features=8, bias=True)
  (4): ELU(alpha=1.0)
  (5): Dropout(p=0.5, inplace=False)
  (6): Linear(in_features=8, out_features=1, bias=True)
)]

STARTING TEST of 50 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 4438.4052734375, std: 116125.25
Train Size: 4346, Test Size: 2079
total step: 27200
PATH: ./Model/w2v_sparse_model_1.pt
Accuracy for fold 1: 54.642
F1 Score for fold 1: 0.347
Loss for fold 1: 3.581
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 13176.8408203125, std: 452769.5
Train Size: 5282, Test Size: 1143
total step: 33050
PATH: ./Model/w2v_sparse_model_2.pt
Accuracy for fold 2: 50.656
F1 Score for fold 2: 0.331
Loss for fold 2: 0.931
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 1664.5079345703125, std: 39769.03125
Train Size: 5956, Test Size: 469
total step: 37250
PATH: ./Model/w2v_sparse_model_3.pt
Accuracy for fold 3: 48.827
F1 Score for fold 3: 0.317
Loss for fold 3: 0.728
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 7789.416015625, std: 180554.515625
Train Size: 5535, Test Size: 890
total step: 34600
PATH: ./Model/w2v_sparse_model_4.pt
Accuracy for fold 4: 52.247
F1 Score for fold 4: 0.335
Loss for fold 4: 1.743
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 7662.5009765625, std: 146353.921875
Train Size: 5204, Test Size: 1221
total step: 32550
PATH: ./Model/w2v_sparse_model_5.pt
Accuracy for fold 5: 49.304
F1 Score for fold 5: 0.325
Loss for fold 5: 3.555
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 4385.34716796875, std: 112374.390625
Train Size: 6411, Test Size: 14
total step: 40100
PATH: ./Model/w2v_sparse_model_6.pt
Accuracy for fold 6: 71.429
F1 Score for fold 6: 0.415
Loss for fold 6: 0.650
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 3883.515869140625, std: 102944.890625
Train Size: 6192, Test Size: 233
total step: 38700
PATH: ./Model/w2v_sparse_model_7.pt
Accuracy for fold 7: 42.489
F1 Score for fold 7: 0.296
Loss for fold 7: 0.724
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 5845.74560546875, std: 160356.15625
Train Size: 6187, Test Size: 238
total step: 38700
PATH: ./Model/w2v_sparse_model_8.pt
Accuracy for fold 8: 49.580
F1 Score for fold 8: 0.332
Loss for fold 8: 0.724
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 4094.75, std: 90522.2734375
Train Size: 6287, Test Size: 138
total step: 39300
PATH: ./Model/w2v_sparse_model_9.pt
Accuracy for fold 9: 52.174
F1 Score for fold 9: 0.348
Loss for fold 9: 0.695

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 54.64165464165465, F1 34.685573632182596
Fold 1: Acc 50.65616797900262, F1 33.12667987208673
Fold 2: Acc 48.8272921108742, F1 31.746344155725833
Fold 3: Acc 52.24719101123596, F1 33.48689762172907
Fold 4: Acc 49.303849303849304, F1 32.473414291596185
Fold 5: Acc 71.42857142857143, F1 41.458541458541454
Fold 6: Acc 42.48927038626609, F1 29.63102705591976
Fold 7: Acc 49.57983193277311, F1 33.15175487444395
Fold 8: Acc 52.17391304347826, F1 34.78840000579132
Average: 52.372%
F1: 33.839%
Loss: 1.481



************************************************************
STARTING A CROSS-VALIDATION ... [50] epochs
************************************************************
TIME: 01/04/2021 13:07:07
LAYER: [Sequential(
  (0): Linear(in_features=301, out_features=52, bias=True)
  (1): ELU(alpha=1.0)
  (2): Dropout(p=0.5, inplace=False)
  (3): Linear(in_features=52, out_features=12, bias=True)
  (4): ELU(alpha=1.0)
  (5): Dropout(p=0.5, inplace=False)
  (6): Linear(in_features=12, out_features=1, bias=True)
)]

STARTING TEST of 50 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 14043.345703125, std: 417858.375
Train Size: 4346, Test Size: 2079
total step: 27200
PATH: ./Model/w2v_sparse_model_1.pt
Accuracy for fold 1: 56.950
F1 Score for fold 1: 0.365
Loss for fold 1: 5.499
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 1968.0948486328125, std: 47924.4140625
Train Size: 5282, Test Size: 1143
total step: 33050
PATH: ./Model/w2v_sparse_model_2.pt
Accuracy for fold 2: 52.843
F1 Score for fold 2: 0.338
Loss for fold 2: 0.794
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 13702.1923828125, std: 303847.03125
Train Size: 5956, Test Size: 469
total step: 37250
PATH: ./Model/w2v_sparse_model_3.pt
Accuracy for fold 3: 46.482
F1 Score for fold 3: 0.308
Loss for fold 3: 0.718
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 2636.723388671875, std: 79903.859375
Train Size: 5535, Test Size: 890
total step: 34600
PATH: ./Model/w2v_sparse_model_4.pt
Accuracy for fold 4: 49.551
F1 Score for fold 4: 0.326
Loss for fold 4: 0.934
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 7262.021484375, std: 299768.65625
Train Size: 5204, Test Size: 1221
total step: 32550
PATH: ./Model/w2v_sparse_model_5.pt
Accuracy for fold 5: 47.912
F1 Score for fold 5: 0.317
Loss for fold 5: 0.750
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 5513.7265625, std: 139657.453125
Train Size: 6411, Test Size: 14
total step: 40100
PATH: ./Model/w2v_sparse_model_6.pt
Accuracy for fold 6: 78.571
F1 Score for fold 6: 0.438
Loss for fold 6: 0.630
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 22837.07421875, std: 547263.875
Train Size: 6192, Test Size: 233
total step: 38700
PATH: ./Model/w2v_sparse_model_7.pt
Accuracy for fold 7: 58.798
F1 Score for fold 7: 0.377
Loss for fold 7: 0.694
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 11029.4423828125, std: 297089.90625
Train Size: 6187, Test Size: 238
total step: 38700
PATH: ./Model/w2v_sparse_model_8.pt
Accuracy for fold 8: 43.697
F1 Score for fold 8: 0.302
Loss for fold 8: 1.343
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 657.1932373046875, std: 6504.8271484375
Train Size: 6287, Test Size: 138
total step: 39300
PATH: ./Model/w2v_sparse_model_9.pt
Accuracy for fold 9: 51.449
F1 Score for fold 9: 0.354
Loss for fold 9: 1.827

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 56.95045695045695, F1 36.49240116411838
Fold 1: Acc 52.84339457567804, F1 33.78423462412968
Fold 2: Acc 46.481876332622605, F1 30.758107090729688
Fold 3: Acc 49.550561797752806, F1 32.589388139949925
Fold 4: Acc 47.91154791154791, F1 31.68752623298083
Fold 5: Acc 78.57142857142857, F1 43.80952380952381
Fold 6: Acc 58.798283261802574, F1 37.693951256183034
Fold 7: Acc 43.69747899159664, F1 30.1745126955211
Fold 8: Acc 51.449275362318836, F1 35.37206754598059
Average: 54.028%
F1: 34.707%
Loss: 1.465



************************************************************
STARTING A CROSS-VALIDATION ... [50] epochs
************************************************************
TIME: 01/04/2021 13:14:37
LAYER: [Sequential(
  (0): Linear(in_features=301, out_features=52, bias=True)
  (1): ELU(alpha=1.0)
  (2): Dropout(p=0.5, inplace=False)
  (3): Linear(in_features=52, out_features=1, bias=True)
)]

STARTING TEST of 50 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 3710.6884765625, std: 95524.25
Train Size: 4346, Test Size: 2079
total step: 27200
PATH: ./Model/w2v_sparse_model_1.pt
Accuracy for fold 1: 49.110
F1 Score for fold 1: 0.320
Loss for fold 1: 1.541
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 3251.09423828125, std: 76326.2421875
Train Size: 5282, Test Size: 1143
total step: 33050
PATH: ./Model/w2v_sparse_model_2.pt
Accuracy for fold 2: 50.744
F1 Score for fold 2: 0.331
Loss for fold 2: 3.429
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 1736.7752685546875, std: 30216.048828125
Train Size: 5956, Test Size: 469
total step: 37250
PATH: ./Model/w2v_sparse_model_3.pt
Accuracy for fold 3: 49.893
F1 Score for fold 3: 0.324
Loss for fold 3: 0.744
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 4440.767578125, std: 147928.921875
Train Size: 5535, Test Size: 890
total step: 34600
PATH: ./Model/w2v_sparse_model_4.pt
Accuracy for fold 4: 51.124
F1 Score for fold 4: 0.336
Loss for fold 4: 0.705
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 884.389404296875, std: 18684.40625
Train Size: 5204, Test Size: 1221
total step: 32550
PATH: ./Model/w2v_sparse_model_5.pt
Accuracy for fold 5: 48.976
F1 Score for fold 5: 0.319
Loss for fold 5: 5.697
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 10895.2646484375, std: 296221.78125
Train Size: 6411, Test Size: 14
total step: 40100
PATH: ./Model/w2v_sparse_model_6.pt
Accuracy for fold 6: 42.857
F1 Score for fold 6: 0.299
Loss for fold 6: 0.711
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 1145.1314697265625, std: 26309.609375
Train Size: 6192, Test Size: 233
total step: 38700
PATH: ./Model/w2v_sparse_model_7.pt
Accuracy for fold 7: 51.931
F1 Score for fold 7: 0.340
Loss for fold 7: 0.683
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 10907.56640625, std: 411236.90625
Train Size: 6187, Test Size: 238
total step: 38700
PATH: ./Model/w2v_sparse_model_8.pt
Accuracy for fold 8: 47.059
F1 Score for fold 8: 0.315
Loss for fold 8: 2.297
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 8495.6953125, std: 303858.15625
Train Size: 6287, Test Size: 138
total step: 39300
PATH: ./Model/w2v_sparse_model_9.pt
Accuracy for fold 9: 51.449
F1 Score for fold 9: 0.340
Loss for fold 9: 0.780

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 49.11014911014911, F1 31.978535066558187
Fold 1: Acc 50.743657042869636, F1 33.111626392466334
Fold 2: Acc 49.89339019189765, F1 32.44044926880748
Fold 3: Acc 51.12359550561798, F1 33.58356998806436
Fold 4: Acc 48.976248976248975, F1 31.90077008258832
Fold 5: Acc 42.857142857142854, F1 29.87012987012987
Fold 6: Acc 51.931330472103, F1 33.99843837612079
Fold 7: Acc 47.05882352941176, F1 31.474552524972697
Fold 8: Acc 51.449275362318836, F1 33.97809919549049
Average: 49.238%
F1: 32.482%
Loss: 1.843



************************************************************
STARTING A CROSS-VALIDATION ... [50] epochs
************************************************************
TIME: 01/04/2021 13:24:37
LAYER: [Sequential(
  (0): Linear(in_features=301, out_features=30, bias=True)
  (1): ELU(alpha=1.0)
  (2): Dropout(p=0.5, inplace=False)
  (3): Linear(in_features=30, out_features=5, bias=True)
  (4): ELU(alpha=1.0)
  (5): Dropout(p=0.5, inplace=False)
  (6): Linear(in_features=5, out_features=1, bias=True)
)]

STARTING TEST of 50 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 2563.621337890625, std: 62301.171875
Train Size: 4346, Test Size: 2079
total step: 27200
PATH: ./Model/w2v_sparse_model_1.pt
Accuracy for fold 1: 52.381
F1 Score for fold 1: 0.334
Loss for fold 1: 0.718
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 2078.981689453125, std: 37572.14453125
Train Size: 5282, Test Size: 1143
total step: 33050
PATH: ./Model/w2v_sparse_model_2.pt
Accuracy for fold 2: 48.119
F1 Score for fold 2: 0.317
Loss for fold 2: 0.755
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 8073.455078125, std: 278073.71875
Train Size: 5956, Test Size: 469
total step: 37250
PATH: ./Model/w2v_sparse_model_3.pt
Accuracy for fold 3: 52.026
F1 Score for fold 3: 0.333
Loss for fold 3: 0.712
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 3998.0830078125, std: 118690.59375
Train Size: 5535, Test Size: 890
total step: 34600
PATH: ./Model/w2v_sparse_model_4.pt
Accuracy for fold 4: 47.528
F1 Score for fold 4: 0.297
Loss for fold 4: 0.834
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 17665.50390625, std: 404579.0625
Train Size: 5204, Test Size: 1221
total step: 32550
PATH: ./Model/w2v_sparse_model_5.pt
Accuracy for fold 5: 49.222
F1 Score for fold 5: 0.318
Loss for fold 5: 1.884
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 16238.890625, std: 413152.96875
Train Size: 6411, Test Size: 14
total step: 40100
PATH: ./Model/w2v_sparse_model_6.pt
Accuracy for fold 6: 35.714
F1 Score for fold 6: 0.257
Loss for fold 6: 0.690
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 12466.5380859375, std: 302582.84375
Train Size: 6192, Test Size: 233
total step: 38700
PATH: ./Model/w2v_sparse_model_7.pt
Accuracy for fold 7: 47.639
F1 Score for fold 7: 0.313
Loss for fold 7: 0.718
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 13252.890625, std: 318920.03125
Train Size: 6187, Test Size: 238
total step: 38700
PATH: ./Model/w2v_sparse_model_8.pt
Accuracy for fold 8: 50.420
F1 Score for fold 8: 0.332
Loss for fold 8: 0.704
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 1928.48193359375, std: 63619.5234375
Train Size: 6287, Test Size: 138
total step: 39300
PATH: ./Model/w2v_sparse_model_9.pt
Accuracy for fold 9: 50.000
F1 Score for fold 9: 0.330
Loss for fold 9: 0.721

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 52.38095238095239, F1 33.4199475902218
Fold 1: Acc 48.118985126859144, F1 31.689578041284108
Fold 2: Acc 52.02558635394456, F1 33.261739445108304
Fold 3: Acc 47.52808988764045, F1 29.717902571835104
Fold 4: Acc 49.221949221949224, F1 31.774070864980015
Fold 5: Acc 35.714285714285715, F1 25.714285714285715
Fold 6: Acc 47.63948497854077, F1 31.265348861915395
Fold 7: Acc 50.42016806722689, F1 33.24975677916855
Fold 8: Acc 50.0, F1 33.0193478019565
Average: 48.117%
F1: 31.457%
Loss: 0.860



************************************************************
STARTING A CROSS-VALIDATION ... [50] epochs
************************************************************
TIME: 01/04/2021 13:34:25
LAYER: [Sequential(
  (0): Linear(in_features=301, out_features=31, bias=True)
  (1): ELU(alpha=1.0)
  (2): Dropout(p=0.5, inplace=False)
  (3): Linear(in_features=31, out_features=4, bias=True)
  (4): ELU(alpha=1.0)
  (5): Dropout(p=0.5, inplace=False)
  (6): Linear(in_features=4, out_features=1, bias=True)
)]

STARTING TEST of 50 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 11104.4931640625, std: 299456.875
Train Size: 4346, Test Size: 2079
total step: 27200
PATH: ./Model/w2v_sparse_model_1.pt
Accuracy for fold 1: 57.528
F1 Score for fold 1: 0.364
Loss for fold 1: 5.439
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 11383.5361328125, std: 314260.28125
Train Size: 5282, Test Size: 1143
total step: 33050
PATH: ./Model/w2v_sparse_model_2.pt
Accuracy for fold 2: 45.232
F1 Score for fold 2: 0.302
Loss for fold 2: 0.730
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 3575.886962890625, std: 93480.0859375
Train Size: 5956, Test Size: 469
total step: 37250
PATH: ./Model/w2v_sparse_model_3.pt
Accuracy for fold 3: 48.827
F1 Score for fold 3: 0.321
Loss for fold 3: 3.719
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 12656.359375, std: 300922.84375
Train Size: 5535, Test Size: 890
total step: 34600
PATH: ./Model/w2v_sparse_model_4.pt
Accuracy for fold 4: 47.640
F1 Score for fold 4: 0.313
Loss for fold 4: 0.720
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 11159.8408203125, std: 461792.625
Train Size: 5204, Test Size: 1221
total step: 32550
PATH: ./Model/w2v_sparse_model_5.pt
Accuracy for fold 5: 51.925
F1 Score for fold 5: 0.324
Loss for fold 5: 0.725
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 1355.239990234375, std: 23345.5078125
Train Size: 6411, Test Size: 14
total step: 40100
PATH: ./Model/w2v_sparse_model_6.pt
Accuracy for fold 6: 50.000
F1 Score for fold 6: 0.327
Loss for fold 6: 0.697
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 5958.853515625, std: 174014.953125
Train Size: 6192, Test Size: 233
total step: 38700
PATH: ./Model/w2v_sparse_model_7.pt
Accuracy for fold 7: 55.794
F1 Score for fold 7: 0.356
Loss for fold 7: 0.723
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 7203.94677734375, std: 281149.5625
Train Size: 6187, Test Size: 238
total step: 38700
PATH: ./Model/w2v_sparse_model_8.pt
Accuracy for fold 8: 51.261
F1 Score for fold 8: 0.325
Loss for fold 8: 0.716
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 1700.1170654296875, std: 38171.80078125
Train Size: 6287, Test Size: 138
total step: 39300
PATH: ./Model/w2v_sparse_model_9.pt
Accuracy for fold 9: 39.855
F1 Score for fold 9: 0.280
Loss for fold 9: 0.759

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 57.527657527657524, F1 36.420368952836505
Fold 1: Acc 45.2318460192476, F1 30.221945838743792
Fold 2: Acc 48.8272921108742, F1 32.075773077905275
Fold 3: Acc 47.640449438202246, F1 31.256294267530205
Fold 4: Acc 51.92465192465192, F1 32.37813305995127
Fold 5: Acc 50.0, F1 32.72727272727273
Fold 6: Acc 55.793991416309005, F1 35.6242803453104
Fold 7: Acc 51.26050420168067, F1 32.455984724892296
Fold 8: Acc 39.85507246376812, F1 28.038467168901956
Average: 49.785%
F1: 32.355%
Loss: 1.581

