

************************************************************
STARTING A CROSS-VALIDATION ... [2, 3, 4, 5, 10, 25, 50, 100] epochs
************************************************************

STARTING TEST of 2 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 691.299072265625, std: 47066.671875
Train Size: 4346, Test Size: 2079
total step: 544
PATH: ./Model/bert_sparse_model_1.pt

************************************************************
STARTING A CROSS-VALIDATION ... [2, 3, 4, 5, 10, 25, 50, 100] epochs
************************************************************

STARTING TEST of 2 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 709.2988891601562, std: 28349.9609375
Train Size: 4346, Test Size: 2079
total step: 544
PATH: ./Model/bert_sparse_model_1.pt
Accuracy for fold 1: 53.968
F1 Score for fold 1: 0.346
Loss for fold 1: 872.611
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 2267.25830078125, std: 102359.4453125
Train Size: 5282, Test Size: 1143
total step: 662
PATH: ./Model/bert_sparse_model_2.pt
Accuracy for fold 2: 60.105
F1 Score for fold 2: 0.370
Loss for fold 2: 127.908
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 1007.3795776367188, std: 62819.06640625
Train Size: 5956, Test Size: 469
total step: 746
PATH: ./Model/bert_sparse_model_3.pt
Accuracy for fold 3: 49.680
F1 Score for fold 3: 0.324
Loss for fold 3: 1144.520
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 906.640869140625, std: 43548.62890625
Train Size: 5535, Test Size: 890
total step: 692
PATH: ./Model/bert_sparse_model_4.pt
Accuracy for fold 4: 46.854
F1 Score for fold 4: 0.304
Loss for fold 4: 526.728
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 804.7229614257812, std: 41809.74609375
Train Size: 5204, Test Size: 1221
total step: 652
PATH: ./Model/bert_sparse_model_5.pt
Accuracy for fold 5: 52.416
F1 Score for fold 5: 0.337
Loss for fold 5: 694.418
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 909.83935546875, std: 48129.1875
Train Size: 6411, Test Size: 14
total step: 802
PATH: ./Model/bert_sparse_model_6.pt
Accuracy for fold 6: 78.571
F1 Score for fold 6: 0.440
Loss for fold 6: 5.071
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 884.3621215820312, std: 34629.12890625
Train Size: 6192, Test Size: 233
total step: 774
PATH: ./Model/bert_sparse_model_7.pt
Accuracy for fold 7: 15.451
F1 Score for fold 7: 0.132
Loss for fold 7: 1.191
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 2677.651611328125, std: 135798.390625
Train Size: 6187, Test Size: 238
total step: 774
PATH: ./Model/bert_sparse_model_8.pt
Accuracy for fold 8: 55.882
F1 Score for fold 8: 0.360
Loss for fold 8: 5.835
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 813.625, std: 38037.69140625
Train Size: 6287, Test Size: 138
total step: 786
PATH: ./Model/bert_sparse_model_9.pt
Accuracy for fold 9: 49.275
F1 Score for fold 9: 0.336
Loss for fold 9: 1.150

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 53.96825396825397, F1 34.601724126999834
Fold 1: Acc 60.10498687664042, F1 36.98149550850507
Fold 2: Acc 49.68017057569296, F1 32.446973991992294
Fold 3: Acc 46.853932584269664, F1 30.363768711542207
Fold 4: Acc 52.416052416052416, F1 33.67409036155636
Fold 5: Acc 78.57142857142857, F1 44.0
Fold 6: Acc 15.450643776824036, F1 13.241133212565202
Fold 7: Acc 55.88235294117647, F1 36.03811368063696
Fold 8: Acc 49.275362318840585, F1 33.59751949758602
Average: 51.356%
F1: 32.772%
Loss: 375.492%


STARTING TEST of 3 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 1503.67724609375, std: 74677.96875
Train Size: 4346, Test Size: 2079
total step: 816
PATH: ./Model/bert_sparse_model_1.pt
Accuracy for fold 1: 47.234
F1 Score for fold 1: 0.317
Loss for fold 1: 258.500
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 1267.170166015625, std: 61618.76171875
Train Size: 5282, Test Size: 1143
total step: 993
PATH: ./Model/bert_sparse_model_2.pt
Accuracy for fold 2: 53.806
F1 Score for fold 2: 0.346
Loss for fold 2: 80.364
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 2548.070556640625, std: 131005.5625
Train Size: 5956, Test Size: 469
total step: 1119
PATH: ./Model/bert_sparse_model_3.pt
Accuracy for fold 3: 50.107
F1 Score for fold 3: 0.338
Loss for fold 3: 144.686
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 1781.5472412109375, std: 82838.4921875
Train Size: 5535, Test Size: 890
total step: 1038
PATH: ./Model/bert_sparse_model_4.pt
Accuracy for fold 4: 48.876
F1 Score for fold 4: 0.323
Loss for fold 4: 247.806
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 769.1471557617188, std: 44295.7734375
Train Size: 5204, Test Size: 1221
total step: 978
PATH: ./Model/bert_sparse_model_5.pt
Accuracy for fold 5: 49.222
F1 Score for fold 5: 0.325
Loss for fold 5: 186.384
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 903.6775512695312, std: 38668.8828125
Train Size: 6411, Test Size: 14
total step: 1203
PATH: ./Model/bert_sparse_model_6.pt
Accuracy for fold 6: 50.000
F1 Score for fold 6: 0.333
Loss for fold 6: 0.725
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 341.9225769042969, std: 10503.939453125
Train Size: 6192, Test Size: 233
total step: 1161
PATH: ./Model/bert_sparse_model_7.pt
Accuracy for fold 7: 39.485
F1 Score for fold 7: 0.285
Loss for fold 7: 0.758
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 5205.951171875, std: 263527.28125
Train Size: 6187, Test Size: 238
total step: 1161
PATH: ./Model/bert_sparse_model_8.pt
Accuracy for fold 8: 47.059
F1 Score for fold 8: 0.298
Loss for fold 8: 18.202
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 2311.042236328125, std: 132440.890625
Train Size: 6287, Test Size: 138
total step: 1179
PATH: ./Model/bert_sparse_model_9.pt
Accuracy for fold 9: 45.652
F1 Score for fold 9: 0.308
Loss for fold 9: 200.704

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 47.234247234247235, F1 31.651457859681674
Fold 1: Acc 53.805774278215225, F1 34.58945042120513
Fold 2: Acc 50.10660980810234, F1 33.75766509497724
Fold 3: Acc 48.87640449438202, F1 32.26803277504431
Fold 4: Acc 49.221949221949224, F1 32.51830940895498
Fold 5: Acc 50.0, F1 33.33333333333333
Fold 6: Acc 39.48497854077253, F1 28.473287613052495
Fold 7: Acc 47.05882352941176, F1 29.77241315263709
Fold 8: Acc 45.65217391304348, F1 30.83580843279941
Average: 47.938%
F1: 31.911%
Loss: 126.459%


STARTING TEST of 4 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 617.779296875, std: 26715.3828125
Train Size: 4346, Test Size: 2079
total step: 1088
PATH: ./Model/bert_sparse_model_1.pt
Accuracy for fold 1: 38.624
F1 Score for fold 1: 0.267
Loss for fold 1: 772.674
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 650.2893676757812, std: 21774.646484375
Train Size: 5282, Test Size: 1143
total step: 1324
PATH: ./Model/bert_sparse_model_2.pt
Accuracy for fold 2: 36.395
F1 Score for fold 2: 0.246
Loss for fold 2: 27.331
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 2472.14990234375, std: 141011.40625
Train Size: 5956, Test Size: 469
total step: 1492
PATH: ./Model/bert_sparse_model_3.pt
Accuracy for fold 3: 50.320
F1 Score for fold 3: 0.334
Loss for fold 3: 244.741
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 4372.55224609375, std: 227236.5
Train Size: 5535, Test Size: 890
total step: 1384
PATH: ./Model/bert_sparse_model_4.pt
Accuracy for fold 4: 52.360
F1 Score for fold 4: 0.345
Loss for fold 4: 397.562
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 4160.61376953125, std: 254026.078125
Train Size: 5204, Test Size: 1221
total step: 1304
PATH: ./Model/bert_sparse_model_5.pt
Accuracy for fold 5: 51.024
F1 Score for fold 5: 0.338
Loss for fold 5: 587.618
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 3767.577880859375, std: 226674.6875
Train Size: 6411, Test Size: 14
total step: 1604
PATH: ./Model/bert_sparse_model_6.pt
Accuracy for fold 6: 50.000
F1 Score for fold 6: 0.333
Loss for fold 6: 0.665
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 1553.1759033203125, std: 112276.25
Train Size: 6192, Test Size: 233
total step: 1548
PATH: ./Model/bert_sparse_model_7.pt
Accuracy for fold 7: 63.090
F1 Score for fold 7: 0.382
Loss for fold 7: 5.940
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 1144.489501953125, std: 48945.12109375
Train Size: 6187, Test Size: 238
total step: 1548
PATH: ./Model/bert_sparse_model_8.pt
Accuracy for fold 8: 47.899
F1 Score for fold 8: 0.326
Loss for fold 8: 5.449
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 5522.5166015625, std: 306051.75
Train Size: 6287, Test Size: 138
total step: 1572
PATH: ./Model/bert_sparse_model_9.pt
Accuracy for fold 9: 60.870
F1 Score for fold 9: 0.387
Loss for fold 9: 28.829

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 38.62433862433862, F1 26.697025742486648
Fold 1: Acc 36.39545056867892, F1 24.633937956652243
Fold 2: Acc 50.31982942430704, F1 33.41233417464865
Fold 3: Acc 52.359550561797754, F1 34.4839282150267
Fold 4: Acc 51.02375102375102, F1 33.80136890156999
Fold 5: Acc 50.0, F1 33.33333333333333
Fold 6: Acc 63.0901287553648, F1 38.174676010948865
Fold 7: Acc 47.89915966386555, F1 32.5530340695235
Fold 8: Acc 60.86956521739131, F1 38.687551980161835
Average: 50.065%
F1: 32.864%
Loss: 230.090%


STARTING TEST of 5 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 1191.0628662109375, std: 66564.6796875
Train Size: 4346, Test Size: 2079
total step: 1360
PATH: ./Model/bert_sparse_model_1.pt
Accuracy for fold 1: 58.490
F1 Score for fold 1: 0.362
Loss for fold 1: 142.030
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 1309.314208984375, std: 67803.484375
Train Size: 5282, Test Size: 1143
total step: 1655
PATH: ./Model/bert_sparse_model_2.pt
Accuracy for fold 2: 37.708
F1 Score for fold 2: 0.262
Loss for fold 2: 36.315
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 1695.08642578125, std: 116234.1171875
Train Size: 5956, Test Size: 469
total step: 1865
PATH: ./Model/bert_sparse_model_3.pt
Accuracy for fold 3: 53.092
F1 Score for fold 3: 0.340
Loss for fold 3: 484.130
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 713.593017578125, std: 48340.70703125
Train Size: 5535, Test Size: 890
total step: 1730
PATH: ./Model/bert_sparse_model_4.pt
Accuracy for fold 4: 47.191
F1 Score for fold 4: 0.306
Loss for fold 4: 260.633
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 2366.460693359375, std: 194142.921875
Train Size: 5204, Test Size: 1221
total step: 1630
PATH: ./Model/bert_sparse_model_5.pt
Accuracy for fold 5: 56.839
F1 Score for fold 5: 0.370
Loss for fold 5: 211.851
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 3728.6923828125, std: 174828.15625
Train Size: 6411, Test Size: 14
total step: 2005
PATH: ./Model/bert_sparse_model_6.pt
Accuracy for fold 6: 21.429
F1 Score for fold 6: 0.176
Loss for fold 6: 34.040
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 2714.304931640625, std: 97727.7734375
Train Size: 6192, Test Size: 233
total step: 1935
PATH: ./Model/bert_sparse_model_7.pt
Accuracy for fold 7: 87.124
F1 Score for fold 7: 0.565
Loss for fold 7: 19.632
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 1598.68359375, std: 77239.265625
Train Size: 6187, Test Size: 238
total step: 1935
PATH: ./Model/bert_sparse_model_8.pt
Accuracy for fold 8: 49.160
F1 Score for fold 8: 0.290
Loss for fold 8: 12.191
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 1149.9608154296875, std: 40928.60546875
Train Size: 6287, Test Size: 138
total step: 1965
PATH: ./Model/bert_sparse_model_9.pt
Accuracy for fold 9: 52.899
F1 Score for fold 9: 0.350
Loss for fold 9: 2.189

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 58.48965848965849, F1 36.2302430077649
Fold 1: Acc 37.70778652668417, F1 26.153483470416123
Fold 2: Acc 53.09168443496801, F1 33.9624297171968
Fold 3: Acc 47.19101123595505, F1 30.637765686649633
Fold 4: Acc 56.838656838656846, F1 37.03710190174573
Fold 5: Acc 21.428571428571427, F1 17.647058823529413
Fold 6: Acc 87.1244635193133, F1 56.51367177509721
Fold 7: Acc 49.159663865546214, F1 28.990635667132693
Fold 8: Acc 52.89855072463768, F1 34.95337161846298
Average: 51.548%
F1: 33.570%
Loss: 133.668%


STARTING TEST of 10 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 5932.7001953125, std: 256237.65625
Train Size: 4346, Test Size: 2079
total step: 2720
PATH: ./Model/bert_sparse_model_1.pt
Accuracy for fold 1: 42.665
F1 Score for fold 1: 0.295
Loss for fold 1: 252.578
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 1243.8515625, std: 53307.625
Train Size: 5282, Test Size: 1143
total step: 3310
PATH: ./Model/bert_sparse_model_2.pt
Accuracy for fold 2: 54.331
F1 Score for fold 2: 0.347
Loss for fold 2: 10.256
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 4842.11181640625, std: 239206.40625
Train Size: 5956, Test Size: 469
total step: 3730
PATH: ./Model/bert_sparse_model_3.pt
Accuracy for fold 3: 52.665
F1 Score for fold 3: 0.346
Loss for fold 3: 44.137
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 526.14794921875, std: 20418.640625
Train Size: 5535, Test Size: 890
total step: 3460
PATH: ./Model/bert_sparse_model_4.pt
Accuracy for fold 4: 47.865
F1 Score for fold 4: 0.301
Loss for fold 4: 34.950
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 2179.482666015625, std: 116753.90625
Train Size: 5204, Test Size: 1221
total step: 3260
PATH: ./Model/bert_sparse_model_5.pt
Accuracy for fold 5: 56.429
F1 Score for fold 5: 0.356
Loss for fold 5: 50.216
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 2923.134521484375, std: 224156.578125
Train Size: 6411, Test Size: 14
total step: 4010
PATH: ./Model/bert_sparse_model_6.pt
Accuracy for fold 6: 14.286
F1 Score for fold 6: 0.125
Loss for fold 6: 1.012
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 2535.443359375, std: 144677.578125
Train Size: 6192, Test Size: 233
total step: 3870
PATH: ./Model/bert_sparse_model_7.pt
Accuracy for fold 7: 74.249
F1 Score for fold 7: 0.425
Loss for fold 7: 0.550
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 2437.270751953125, std: 125361.359375
Train Size: 6187, Test Size: 238
total step: 3870
PATH: ./Model/bert_sparse_model_8.pt
Accuracy for fold 8: 47.899
F1 Score for fold 8: 0.342
Loss for fold 8: 3.757
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 1580.4384765625, std: 75080.3515625
Train Size: 6287, Test Size: 138
total step: 3930
PATH: ./Model/bert_sparse_model_9.pt
Accuracy for fold 9: 51.449
F1 Score for fold 9: 0.331
Loss for fold 9: 0.809

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 42.66474266474267, F1 29.45245234146356
Fold 1: Acc 54.330708661417326, F1 34.681848180139134
Fold 2: Acc 52.66524520255863, F1 34.55073802862808
Fold 3: Acc 47.86516853932584, F1 30.075995301542896
Fold 4: Acc 56.42915642915642, F1 35.57143494819916
Fold 5: Acc 14.285714285714285, F1 12.5
Fold 6: Acc 74.2489270386266, F1 42.541146825592584
Fold 7: Acc 47.89915966386555, F1 34.16411547962236
Fold 8: Acc 51.449275362318836, F1 33.10650828127384
Average: 49.093%
F1: 31.849%
Loss: 44.252%


STARTING TEST of 25 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 1174.2186279296875, std: 57993.58203125
Train Size: 4346, Test Size: 2079
total step: 6800
PATH: ./Model/bert_sparse_model_1.pt
Accuracy for fold 1: 46.465
F1 Score for fold 1: 0.313
Loss for fold 1: 4.352
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 2097.032470703125, std: 93901.1171875
Train Size: 5282, Test Size: 1143
total step: 8275
PATH: ./Model/bert_sparse_model_2.pt
Accuracy for fold 2: 45.669
F1 Score for fold 2: 0.307
Loss for fold 2: 2.359
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 1956.8017578125, std: 118163.984375
Train Size: 5956, Test Size: 469
total step: 9325
PATH: ./Model/bert_sparse_model_3.pt
Accuracy for fold 3: 51.812
F1 Score for fold 3: 0.339
Loss for fold 3: 3.079
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 1929.4678955078125, std: 132453.96875
Train Size: 5535, Test Size: 890
total step: 8650
PATH: ./Model/bert_sparse_model_4.pt
Accuracy for fold 4: 53.708
F1 Score for fold 4: 0.323
Loss for fold 4: 30.214
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 997.2289428710938, std: 27703.28125
Train Size: 5204, Test Size: 1221
total step: 8150
PATH: ./Model/bert_sparse_model_5.pt
Accuracy for fold 5: 44.881
F1 Score for fold 5: 0.290
Loss for fold 5: 6.663
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 4463.4423828125, std: 258645.296875
Train Size: 6411, Test Size: 14
total step: 10025
PATH: ./Model/bert_sparse_model_6.pt
Accuracy for fold 6: 78.571
F1 Score for fold 6: 0.440
Loss for fold 6: 0.540
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 807.1517333984375, std: 39961.62109375
Train Size: 6192, Test Size: 233
total step: 9675
PATH: ./Model/bert_sparse_model_7.pt
Accuracy for fold 7: 61.373
F1 Score for fold 7: 0.382
Loss for fold 7: 0.712
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 2539.30029296875, std: 202374.5625
Train Size: 6187, Test Size: 238
total step: 9675
PATH: ./Model/bert_sparse_model_8.pt
Accuracy for fold 8: 50.000
F1 Score for fold 8: 0.328
Loss for fold 8: 1.686
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 5718.9541015625, std: 248859.078125
Train Size: 6287, Test Size: 138
total step: 9825
PATH: ./Model/bert_sparse_model_9.pt
Accuracy for fold 9: 55.797
F1 Score for fold 9: 0.329
Loss for fold 9: 0.771

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 46.464646464646464, F1 31.332196421029916
Fold 1: Acc 45.66929133858268, F1 30.70765565871639
Fold 2: Acc 51.812366737739865, F1 33.90150848090963
Fold 3: Acc 53.70786516853933, F1 32.33706486282848
Fold 4: Acc 44.88124488124488, F1 28.969019831679127
Fold 5: Acc 78.57142857142857, F1 44.0
Fold 6: Acc 61.37339055793991, F1 38.248447891587695
Fold 7: Acc 50.0, F1 32.755471973594005
Fold 8: Acc 55.79710144927537, F1 32.8750222218279
Average: 54.253%
F1: 33.903%
Loss: 5.597%


STARTING TEST of 50 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 990.4443969726562, std: 47837.56640625
Train Size: 4346, Test Size: 2079
total step: 13600
PATH: ./Model/bert_sparse_model_1.pt
Accuracy for fold 1: 59.452
F1 Score for fold 1: 0.367
Loss for fold 1: 1.428
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 2622.715087890625, std: 201796.796875
Train Size: 5282, Test Size: 1143
total step: 16550
PATH: ./Model/bert_sparse_model_2.pt
Accuracy for fold 2: 57.480
F1 Score for fold 2: 0.362
Loss for fold 2: 0.770
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 711.4775390625, std: 35154.703125
Train Size: 5956, Test Size: 469
total step: 18650
PATH: ./Model/bert_sparse_model_3.pt
Accuracy for fold 3: 52.026
F1 Score for fold 3: 0.340
Loss for fold 3: 1.112
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 2258.5078125, std: 187283.734375
Train Size: 5535, Test Size: 890
total step: 17300
PATH: ./Model/bert_sparse_model_4.pt
Accuracy for fold 4: 46.742
F1 Score for fold 4: 0.314
Loss for fold 4: 0.841
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 1854.427490234375, std: 117238.796875
Train Size: 5204, Test Size: 1221
total step: 16300
PATH: ./Model/bert_sparse_model_5.pt
Accuracy for fold 5: 52.989
F1 Score for fold 5: 0.343
Loss for fold 5: 1.015
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 1459.31103515625, std: 69368.0625
Train Size: 6411, Test Size: 14
total step: 20050
PATH: ./Model/bert_sparse_model_6.pt
Accuracy for fold 6: 21.429
F1 Score for fold 6: 0.176
Loss for fold 6: 1.184
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 2410.6220703125, std: 128676.15625
Train Size: 6192, Test Size: 233
total step: 19350
PATH: ./Model/bert_sparse_model_7.pt
Accuracy for fold 7: 56.223
F1 Score for fold 7: 0.357
Loss for fold 7: 0.691
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 2086.321044921875, std: 120737.6484375
Train Size: 6187, Test Size: 238
total step: 19350
PATH: ./Model/bert_sparse_model_8.pt
Accuracy for fold 8: 54.202
F1 Score for fold 8: 0.360
Loss for fold 8: 0.762
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 617.0831909179688, std: 25587.43359375
Train Size: 6287, Test Size: 138
total step: 19650
PATH: ./Model/bert_sparse_model_9.pt
Accuracy for fold 9: 44.928
F1 Score for fold 9: 0.309
Loss for fold 9: 0.709

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 59.45165945165945, F1 36.69921563703778
Fold 1: Acc 57.48031496062992, F1 36.24794286691667
Fold 2: Acc 52.02558635394456, F1 33.961921701755415
Fold 3: Acc 46.741573033707866, F1 31.408544032409523
Fold 4: Acc 52.98935298935299, F1 34.326799172183954
Fold 5: Acc 21.428571428571427, F1 17.647058823529413
Fold 6: Acc 56.22317596566524, F1 35.723320603428824
Fold 7: Acc 54.20168067226891, F1 35.99181152941646
Fold 8: Acc 44.927536231884055, F1 30.895845968309736
Average: 49.497%
F1: 32.545%
Loss: 0.946%


STARTING TEST of 100 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 860.64111328125, std: 60212.88671875
Train Size: 4346, Test Size: 2079
total step: 27200
PATH: ./Model/bert_sparse_model_1.pt
Accuracy for fold 1: 55.411
F1 Score for fold 1: 0.352
Loss for fold 1: 4.799
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 3069.585693359375, std: 170546.890625
Train Size: 5282, Test Size: 1143
total step: 33100
PATH: ./Model/bert_sparse_model_2.pt
Accuracy for fold 2: 52.668
F1 Score for fold 2: 0.344
Loss for fold 2: 1.125
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 815.0093383789062, std: 25600.96484375
Train Size: 5956, Test Size: 469
total step: 37300
PATH: ./Model/bert_sparse_model_3.pt
Accuracy for fold 3: 50.533
F1 Score for fold 3: 0.334
Loss for fold 3: 4.408
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 2276.55859375, std: 121659.9375
Train Size: 5535, Test Size: 890
total step: 34600
PATH: ./Model/bert_sparse_model_4.pt
Accuracy for fold 4: 48.427
F1 Score for fold 4: 0.321
Loss for fold 4: 0.748
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 5101.29296875, std: 279411.1875
Train Size: 5204, Test Size: 1221
total step: 32600
PATH: ./Model/bert_sparse_model_5.pt
Accuracy for fold 5: 52.826
F1 Score for fold 5: 0.342
Loss for fold 5: 0.863
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 759.4830932617188, std: 34707.65234375
Train Size: 6411, Test Size: 14
total step: 40100
PATH: ./Model/bert_sparse_model_6.pt
Accuracy for fold 6: 35.714
F1 Score for fold 6: 0.263
Loss for fold 6: 0.917
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 1023.0189208984375, std: 49957.91015625
Train Size: 6192, Test Size: 233
total step: 38700
PATH: ./Model/bert_sparse_model_7.pt
Accuracy for fold 7: 44.206
F1 Score for fold 7: 0.312
Loss for fold 7: 0.723
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 5211.5869140625, std: 296759.5
Train Size: 6187, Test Size: 238
total step: 38700
PATH: ./Model/bert_sparse_model_8.pt
Accuracy for fold 8: 55.882
F1 Score for fold 8: 0.361
Loss for fold 8: 0.698
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 1154.796630859375, std: 65418.1015625
Train Size: 6287, Test Size: 138
total step: 39300
PATH: ./Model/bert_sparse_model_9.pt
Accuracy for fold 9: 56.522
F1 Score for fold 9: 0.359
Loss for fold 9: 0.758

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 55.41125541125541, F1 35.18538389009141
Fold 1: Acc 52.66841644794401, F1 34.43179769822746
Fold 2: Acc 50.53304904051173, F1 33.421290915643944
Fold 3: Acc 48.426966292134836, F1 32.12985596378982
Fold 4: Acc 52.825552825552826, F1 34.2208762634913
Fold 5: Acc 35.714285714285715, F1 26.315789473684212
Fold 6: Acc 44.20600858369099, F1 31.176555732629627
Fold 7: Acc 55.88235294117647, F1 36.09216194163216
Fold 8: Acc 56.52173913043478, F1 35.88763173185204
Average: 50.243%
F1: 33.207%
Loss: 1.671%



************************************************************
STARTING A CROSS-VALIDATION ... [100] epochs
************************************************************

STARTING TEST of 100 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 1230.2943115234375, std: 54639.578125
Train Size: 4346, Test Size: 2079
total step: 27200
PATH: ./Model/bert_sparse_model_1.pt
Accuracy for fold 1: 44.925
F1 Score for fold 1: 0.306
Loss for fold 1: 1.229
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 1072.9932861328125, std: 63172.83203125
Train Size: 5282, Test Size: 1143
total step: 33100
PATH: ./Model/bert_sparse_model_2.pt
Accuracy for fold 2: 46.194
F1 Score for fold 2: 0.310
Loss for fold 2: 0.878
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 1652.5223388671875, std: 116205.75
Train Size: 5956, Test Size: 469
total step: 37300
PATH: ./Model/bert_sparse_model_3.pt
Accuracy for fold 3: 52.878
F1 Score for fold 3: 0.343
Loss for fold 3: 0.723
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 1247.4442138671875, std: 56795.94140625
Train Size: 5535, Test Size: 890
total step: 34600
PATH: ./Model/bert_sparse_model_4.pt
Accuracy for fold 4: 49.775
F1 Score for fold 4: 0.333
Loss for fold 4: 0.719
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 2819.813232421875, std: 187448.75
Train Size: 5204, Test Size: 1221
total step: 32600
PATH: ./Model/bert_sparse_model_5.pt
Accuracy for fold 5: 51.269
F1 Score for fold 5: 0.334
Loss for fold 5: 0.812
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 1516.8785400390625, std: 70959.8359375
Train Size: 6411, Test Size: 14
total step: 40100
PATH: ./Model/bert_sparse_model_6.pt
Accuracy for fold 6: 57.143
F1 Score for fold 6: 0.364
Loss for fold 6: 0.682
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 2277.959228515625, std: 123295.65625
Train Size: 6192, Test Size: 233
total step: 38700
PATH: ./Model/bert_sparse_model_7.pt
Accuracy for fold 7: 63.090
F1 Score for fold 7: 0.389
Loss for fold 7: 0.660
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 1295.5135498046875, std: 59699.57421875
Train Size: 6187, Test Size: 238
total step: 38700
PATH: ./Model/bert_sparse_model_8.pt
Accuracy for fold 8: 52.521
F1 Score for fold 8: 0.343
Loss for fold 8: 0.711
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 2523.224365234375, std: 197500.0
Train Size: 6287, Test Size: 138
total step: 39300
PATH: ./Model/bert_sparse_model_9.pt
Accuracy for fold 9: 42.754
F1 Score for fold 9: 0.305
Loss for fold 9: 0.737

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 44.92544492544492, F1 30.636149132847628
Fold 1: Acc 46.194225721784775, F1 31.03292102524149
Fold 2: Acc 52.87846481876333, F1 34.268621849609396
Fold 3: Acc 49.7752808988764, F1 33.32320234957667
Fold 4: Acc 51.269451269451274, F1 33.44300387466843
Fold 5: Acc 57.14285714285714, F1 36.36363636363636
Fold 6: Acc 63.0901287553648, F1 38.86763632652277
Fold 7: Acc 52.52100840336135, F1 34.325917117294544
Fold 8: Acc 42.7536231884058, F1 30.54952998489589
Average: 51.172%
F1: 33.646%
Loss: 0.794



************************************************************
STARTING A CROSS-VALIDATION ... [100] epochs
************************************************************

STARTING TEST of 100 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 1823.7586669921875, std: 120064.0
Train Size: 4346, Test Size: 2079
total step: 27200
PATH: ./Model/bert_sparse_model_1.pt
Accuracy for fold 1: 61.472
F1 Score for fold 1: 0.372
Loss for fold 1: 0.896
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 2178.69287109375, std: 119982.1328125
Train Size: 5282, Test Size: 1143
total step: 33100
PATH: ./Model/bert_sparse_model_2.pt
Accuracy for fold 2: 44.969
F1 Score for fold 2: 0.301
Loss for fold 2: 0.849
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 2220.570068359375, std: 134211.953125
Train Size: 5956, Test Size: 469
total step: 37300
PATH: ./Model/bert_sparse_model_3.pt
Accuracy for fold 3: 52.665
F1 Score for fold 3: 0.346
Loss for fold 3: 0.713
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 1962.6929931640625, std: 184689.421875
Train Size: 5535, Test Size: 890
total step: 34600
PATH: ./Model/bert_sparse_model_4.pt
Accuracy for fold 4: 51.798
F1 Score for fold 4: 0.337
Loss for fold 4: 0.708
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 3081.037353515625, std: 172112.359375
Train Size: 5204, Test Size: 1221
total step: 32600
PATH: ./Model/bert_sparse_model_5.pt
Accuracy for fold 5: 50.369
F1 Score for fold 5: 0.331
Loss for fold 5: 0.713
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 977.1697387695312, std: 42464.68359375
Train Size: 6411, Test Size: 14
total step: 40100
PATH: ./Model/bert_sparse_model_6.pt
Accuracy for fold 6: 35.714
F1 Score for fold 6: 0.263
Loss for fold 6: 14.025
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 1648.259765625, std: 85802.4375
Train Size: 6192, Test Size: 233
total step: 38700
PATH: ./Model/bert_sparse_model_7.pt
Accuracy for fold 7: 45.494
F1 Score for fold 7: 0.313
Loss for fold 7: 0.728
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 504.07916259765625, std: 18483.638671875
Train Size: 6187, Test Size: 238
total step: 38700
PATH: ./Model/bert_sparse_model_8.pt
Accuracy for fold 8: 55.462
F1 Score for fold 8: 0.366
Loss for fold 8: 0.683
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 2185.830810546875, std: 125212.1171875
Train Size: 6287, Test Size: 138
total step: 39300
PATH: ./Model/bert_sparse_model_9.pt
Accuracy for fold 9: 49.275
F1 Score for fold 9: 0.340
Loss for fold 9: 0.710

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 61.471861471861466, F1 37.23190908601494
Fold 1: Acc 44.969378827646544, F1 30.119637531498498
Fold 2: Acc 52.66524520255863, F1 34.55982205736541
Fold 3: Acc 51.79775280898876, F1 33.6577501628594
Fold 4: Acc 50.368550368550366, F1 33.10389995717187
Fold 5: Acc 35.714285714285715, F1 26.315789473684212
Fold 6: Acc 45.493562231759654, F1 31.282058148357823
Fold 7: Acc 55.46218487394958, F1 36.610107541938405
Fold 8: Acc 49.275362318840585, F1 33.95756838014656
Average: 49.691%
F1: 32.982%
Loss: 2.225



************************************************************
STARTING A CROSS-VALIDATION ... [100] epochs
************************************************************

STARTING TEST of 100 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 1760.52587890625, std: 66331.3828125
Train Size: 4346, Test Size: 2079
total step: 27200
PATH: ./Model/bert_sparse_model_1.pt
Accuracy for fold 1: 52.092
F1 Score for fold 1: 0.338
Loss for fold 1: 1.044
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 544.1055908203125, std: 33961.95703125
Train Size: 5282, Test Size: 1143
total step: 33100
PATH: ./Model/bert_sparse_model_2.pt
Accuracy for fold 2: 35.521
F1 Score for fold 2: 0.241
Loss for fold 2: 0.945
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 364.9725646972656, std: 11458.50390625
Train Size: 5956, Test Size: 469
total step: 37300
PATH: ./Model/bert_sparse_model_3.pt
Accuracy for fold 3: 49.893
F1 Score for fold 3: 0.326
Loss for fold 3: 2.162
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 1267.148681640625, std: 60377.16796875
Train Size: 5535, Test Size: 890
total step: 34600
PATH: ./Model/bert_sparse_model_4.pt

************************************************************
STARTING A CROSS-VALIDATION ... [100] epochs
************************************************************

STARTING TEST of 100 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 901.2869873046875, std: 48669.98828125
Train Size: 4346, Test Size: 2079
total step: 27200
PATH: ./Model/bert_sparse_model_1.pt
Accuracy for fold 1: 24.579
F1 Score for fold 1: 0.177
Loss for fold 1: 1.046
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 2156.501708984375, std: 101491.5625
Train Size: 5282, Test Size: 1143
total step: 33100
PATH: ./Model/bert_sparse_model_2.pt
Accuracy for fold 2: 51.269
F1 Score for fold 2: 0.337
Loss for fold 2: 0.885
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 3056.909912109375, std: 182828.609375
Train Size: 5956, Test Size: 469
total step: 37300
PATH: ./Model/bert_sparse_model_3.pt
Accuracy for fold 3: 51.599
F1 Score for fold 3: 0.334
Loss for fold 3: 0.727
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 3282.198486328125, std: 209877.125
Train Size: 5535, Test Size: 890
total step: 34600
PATH: ./Model/bert_sparse_model_4.pt
Accuracy for fold 4: 49.775
F1 Score for fold 4: 0.327
Loss for fold 4: 0.772
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 296.36956787109375, std: 10219.2412109375
Train Size: 5204, Test Size: 1221
total step: 32600
PATH: ./Model/bert_sparse_model_5.pt
Accuracy for fold 5: 47.093
F1 Score for fold 5: 0.308
Loss for fold 5: 0.804
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 1428.9312744140625, std: 61736.07421875
Train Size: 6411, Test Size: 14
total step: 40100
PATH: ./Model/bert_sparse_model_6.pt
Accuracy for fold 6: 35.714
F1 Score for fold 6: 0.263
Loss for fold 6: 0.743
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 712.0791015625, std: 38023.91796875
Train Size: 6192, Test Size: 233
total step: 38700
PATH: ./Model/bert_sparse_model_7.pt
Accuracy for fold 7: 58.798
F1 Score for fold 7: 0.372
Loss for fold 7: 0.688
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 197.04432678222656, std: 4161.3984375
Train Size: 6187, Test Size: 238
total step: 38700
PATH: ./Model/bert_sparse_model_8.pt
Accuracy for fold 8: 52.101
F1 Score for fold 8: 0.342
Loss for fold 8: 0.694
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 297.39105224609375, std: 7031.68603515625
Train Size: 6287, Test Size: 138
total step: 39300
PATH: ./Model/bert_sparse_model_9.pt
Accuracy for fold 9: 46.377
F1 Score for fold 9: 0.315
Loss for fold 9: 0.715

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 24.579124579124578, F1 17.728125873746524
Fold 1: Acc 51.268591426071744, F1 33.72649401485877
Fold 2: Acc 51.59914712153518, F1 33.36983270532914
Fold 3: Acc 49.7752808988764, F1 32.65267733026269
Fold 4: Acc 47.09254709254709, F1 30.818334273489885
Fold 5: Acc 35.714285714285715, F1 26.315789473684212
Fold 6: Acc 58.798283261802574, F1 37.212529310308746
Fold 7: Acc 52.10084033613446, F1 34.22409064796042
Fold 8: Acc 46.3768115942029, F1 31.5291396274383
Average: 46.367%
F1: 30.842%
Loss: 0.786



************************************************************
STARTING A CROSS-VALIDATION ... [100] epochs
************************************************************
TIME: 31/03/2021 18:37:56
LAYER: [Sequential(
  (0): Linear(in_features=869, out_features=96, bias=True)
  (1): ELU(alpha=1.0)
  (2): Dropout(p=0.5, inplace=False)
  (3): Linear(in_features=96, out_features=24, bias=True)
  (4): ELU(alpha=1.0)
  (5): Dropout(p=0.5, inplace=False)
  (6): Linear(in_features=24, out_features=1, bias=True)
)]

STARTING TEST of 100 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 999.7426147460938, std: 41757.4921875
Train Size: 4346, Test Size: 2079
total step: 27200
PATH: ./Model/bert_sparse_model_1.pt
Accuracy for fold 1: 30.014
F1 Score for fold 1: 0.203
Loss for fold 1: 0.973
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 4860.73681640625, std: 258833.5625
Train Size: 5282, Test Size: 1143
total step: 33100
PATH: ./Model/bert_sparse_model_2.pt
Accuracy for fold 2: 52.318
F1 Score for fold 2: 0.341
Loss for fold 2: 0.771
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 836.9896850585938, std: 38420.671875
Train Size: 5956, Test Size: 469
total step: 37300
PATH: ./Model/bert_sparse_model_3.pt
Accuracy for fold 3: 52.239
F1 Score for fold 3: 0.338
Loss for fold 3: 1.516
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 586.8114013671875, std: 22897.923828125
Train Size: 5535, Test Size: 890
total step: 34600
PATH: ./Model/bert_sparse_model_4.pt
Accuracy for fold 4: 51.348
F1 Score for fold 4: 0.337
Loss for fold 4: 0.760
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 636.055908203125, std: 30816.380859375
Train Size: 5204, Test Size: 1221
total step: 32600
PATH: ./Model/bert_sparse_model_5.pt
Accuracy for fold 5: 47.338
F1 Score for fold 5: 0.317
Loss for fold 5: 5.581
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 2396.647216796875, std: 186782.96875
Train Size: 6411, Test Size: 14
total step: 40100
PATH: ./Model/bert_sparse_model_6.pt
Accuracy for fold 6: 50.000
F1 Score for fold 6: 0.333
Loss for fold 6: 0.694
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 6567.70703125, std: 279270.46875
Train Size: 6192, Test Size: 233
total step: 38700
PATH: ./Model/bert_sparse_model_7.pt
Accuracy for fold 7: 42.489
F1 Score for fold 7: 0.299
Loss for fold 7: 0.737
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 1243.0960693359375, std: 69061.4140625
Train Size: 6187, Test Size: 238
total step: 38700
PATH: ./Model/bert_sparse_model_8.pt
Accuracy for fold 8: 50.840
F1 Score for fold 8: 0.337
Loss for fold 8: 0.730
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 1034.05908203125, std: 63513.9296875
Train Size: 6287, Test Size: 138
total step: 39300
PATH: ./Model/bert_sparse_model_9.pt
Accuracy for fold 9: 52.174
F1 Score for fold 9: 0.352
Loss for fold 9: 0.700

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 30.014430014430015, F1 20.329881502230815
Fold 1: Acc 52.31846019247593, F1 34.094144605369294
Fold 2: Acc 52.23880597014925, F1 33.81135426518758
Fold 3: Acc 51.348314606741575, F1 33.655633914142015
Fold 4: Acc 47.338247338247335, F1 31.74001647471132
Fold 5: Acc 50.0, F1 33.33333333333333
Fold 6: Acc 42.48927038626609, F1 29.919186399219985
Fold 7: Acc 50.84033613445378, F1 33.669406786111594
Fold 8: Acc 52.17391304347826, F1 35.17515949242477
Average: 47.640%
F1: 31.748%
Loss: 1.385



************************************************************
STARTING A CROSS-VALIDATION ... [100] epochs
************************************************************
TIME: 31/03/2021 18:58:07
LAYER: [Sequential(
  (0): Linear(in_features=869, out_features=80, bias=True)
  (1): ELU(alpha=1.0)
  (2): Dropout(p=0.5, inplace=False)
  (3): Linear(in_features=80, out_features=16, bias=True)
  (4): ELU(alpha=1.0)
  (5): Dropout(p=0.5, inplace=False)
  (6): Linear(in_features=16, out_features=1, bias=True)
)]

STARTING TEST of 100 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 924.3533935546875, std: 57768.5625
Train Size: 4346, Test Size: 2079
total step: 27200
PATH: ./Model/bert_sparse_model_1.pt
Accuracy for fold 1: 40.404
F1 Score for fold 1: 0.278
Loss for fold 1: 0.811
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 1042.9210205078125, std: 47780.92578125
Train Size: 5282, Test Size: 1143
total step: 33100
PATH: ./Model/bert_sparse_model_2.pt
Accuracy for fold 2: 43.045
F1 Score for fold 2: 0.294
Loss for fold 2: 0.761
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 294.7773132324219, std: 7061.037109375
Train Size: 5956, Test Size: 469
total step: 37300
PATH: ./Model/bert_sparse_model_3.pt
Accuracy for fold 3: 49.680
F1 Score for fold 3: 0.326
Loss for fold 3: 0.709
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 2181.853515625, std: 193829.625
Train Size: 5535, Test Size: 890
total step: 34600
PATH: ./Model/bert_sparse_model_4.pt
Accuracy for fold 4: 48.315
F1 Score for fold 4: 0.322
Loss for fold 4: 0.742
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 3515.058349609375, std: 197538.875
Train Size: 5204, Test Size: 1221
total step: 32600
PATH: ./Model/bert_sparse_model_5.pt
Accuracy for fold 5: 48.403
F1 Score for fold 5: 0.323
Loss for fold 5: 2.546
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 900.7053833007812, std: 49565.44140625
Train Size: 6411, Test Size: 14
total step: 40100
PATH: ./Model/bert_sparse_model_6.pt
Accuracy for fold 6: 57.143
F1 Score for fold 6: 0.364
Loss for fold 6: 0.639
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 892.6735229492188, std: 30542.60546875
Train Size: 6192, Test Size: 233
total step: 38700
PATH: ./Model/bert_sparse_model_7.pt
Accuracy for fold 7: 46.781
F1 Score for fold 7: 0.324
Loss for fold 7: 0.745
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 526.3793334960938, std: 17874.205078125
Train Size: 6187, Test Size: 238
total step: 38700
PATH: ./Model/bert_sparse_model_8.pt
Accuracy for fold 8: 51.261
F1 Score for fold 8: 0.334
Loss for fold 8: 0.788
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 1107.4892578125, std: 51523.578125
Train Size: 6287, Test Size: 138
total step: 39300
PATH: ./Model/bert_sparse_model_9.pt
Accuracy for fold 9: 48.551
F1 Score for fold 9: 0.334
Loss for fold 9: 0.717

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 40.4040404040404, F1 27.75096943944642
Fold 1: Acc 43.044619422572175, F1 29.38590298049285
Fold 2: Acc 49.68017057569296, F1 32.60157023464709
Fold 3: Acc 48.31460674157304, F1 32.24092691919141
Fold 4: Acc 48.402948402948404, F1 32.291218934414054
Fold 5: Acc 57.14285714285714, F1 36.36363636363636
Fold 6: Acc 46.78111587982833, F1 32.44367121340438
Fold 7: Acc 51.26050420168067, F1 33.36748001453883
Fold 8: Acc 48.55072463768116, F1 33.4166252427122
Average: 48.176%
F1: 32.207%
Loss: 0.940



************************************************************
STARTING A CROSS-VALIDATION ... [100, 200] epochs
************************************************************
TIME: 31/03/2021 21:43:35
LAYER: [Sequential(
  (0): Linear(in_features=869, out_features=72, bias=True)
  (1): ELU(alpha=1.0)
  (2): Dropout(p=0.5, inplace=False)
  (3): Linear(in_features=72, out_features=10, bias=True)
  (4): ELU(alpha=1.0)
  (5): Dropout(p=0.5, inplace=False)
  (6): Linear(in_features=10, out_features=1, bias=True)
)]

STARTING TEST of 100 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 2274.3701171875, std: 121728.5234375
Train Size: 4346, Test Size: 2079
total step: 27200
PATH: ./Model/bert_sparse_model_1.pt
Accuracy for fold 1: 50.553
F1 Score for fold 1: 0.333
Loss for fold 1: 2.134
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 1362.786376953125, std: 62564.1328125
Train Size: 5282, Test Size: 1143
total step: 33100
PATH: ./Model/bert_sparse_model_2.pt
Accuracy for fold 2: 49.869
F1 Score for fold 2: 0.329
Loss for fold 2: 0.732
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 1339.6241455078125, std: 57870.82421875
Train Size: 5956, Test Size: 469
total step: 37300
PATH: ./Model/bert_sparse_model_3.pt
Accuracy for fold 3: 48.827
F1 Score for fold 3: 0.323
Loss for fold 3: 0.711
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 2269.68212890625, std: 119983.4453125
Train Size: 5535, Test Size: 890
total step: 34600
PATH: ./Model/bert_sparse_model_4.pt
Accuracy for fold 4: 51.011
F1 Score for fold 4: 0.336
Loss for fold 4: 0.740
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 680.0275268554688, std: 25650.09375
Train Size: 5204, Test Size: 1221
total step: 32600
PATH: ./Model/bert_sparse_model_5.pt
Accuracy for fold 5: 49.386
F1 Score for fold 5: 0.329
Loss for fold 5: 1.413
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 676.9535522460938, std: 33450.8671875
Train Size: 6411, Test Size: 14
total step: 40100
PATH: ./Model/bert_sparse_model_6.pt
Accuracy for fold 6: 50.000
F1 Score for fold 6: 0.333
Loss for fold 6: 0.709
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 2926.489013671875, std: 111253.5234375
Train Size: 6192, Test Size: 233
total step: 38700
PATH: ./Model/bert_sparse_model_7.pt
Accuracy for fold 7: 52.361
F1 Score for fold 7: 0.345
Loss for fold 7: 0.695
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 2232.550537109375, std: 129070.484375
Train Size: 6187, Test Size: 238
total step: 38700
PATH: ./Model/bert_sparse_model_8.pt
Accuracy for fold 8: 52.521
F1 Score for fold 8: 0.349
Loss for fold 8: 0.697
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 2327.53076171875, std: 120843.734375
Train Size: 6287, Test Size: 138
total step: 39300
PATH: ./Model/bert_sparse_model_9.pt
Accuracy for fold 9: 58.696
F1 Score for fold 9: 0.374
Loss for fold 9: 0.717

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 50.55315055315055, F1 33.257280404346574
Fold 1: Acc 49.86876640419948, F1 32.94471483295705
Fold 2: Acc 48.8272921108742, F1 32.30743150493777
Fold 3: Acc 51.01123595505618, F1 33.588206113064516
Fold 4: Acc 49.385749385749385, F1 32.88896584482881
Fold 5: Acc 50.0, F1 33.33333333333333
Fold 6: Acc 52.36051502145923, F1 34.461065214564
Fold 7: Acc 52.52100840336135, F1 34.92412003482518
Fold 8: Acc 58.69565217391305, F1 37.4393139294167
Average: 51.469%
F1: 33.905%
Loss: 0.950


STARTING TEST of 200 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 1915.46240234375, std: 127743.609375
Train Size: 4346, Test Size: 2079
total step: 54400
PATH: ./Model/bert_sparse_model_1.pt
Accuracy for fold 1: 49.254
F1 Score for fold 1: 0.327
Loss for fold 1: 0.720
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 658.7125854492188, std: 27034.8046875
Train Size: 5282, Test Size: 1143
total step: 66200
PATH: ./Model/bert_sparse_model_2.pt
Accuracy for fold 2: 49.956
F1 Score for fold 2: 0.329
Loss for fold 2: 0.707
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 2231.858154296875, std: 89789.46875
Train Size: 5956, Test Size: 469
total step: 74600
PATH: ./Model/bert_sparse_model_3.pt
Accuracy for fold 3: 48.401
F1 Score for fold 3: 0.325
Loss for fold 3: 0.712
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 1345.50390625, std: 62875.01953125
Train Size: 5535, Test Size: 890
total step: 69200
PATH: ./Model/bert_sparse_model_4.pt
Accuracy for fold 4: 51.798
F1 Score for fold 4: 0.341
Loss for fold 4: 0.705
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 900.7730102539062, std: 50437.296875
Train Size: 5204, Test Size: 1221
total step: 65200
PATH: ./Model/bert_sparse_model_5.pt
Accuracy for fold 5: 48.731
F1 Score for fold 5: 0.324
Loss for fold 5: 0.717
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 2350.380126953125, std: 194875.921875
Train Size: 6411, Test Size: 14
total step: 80200
PATH: ./Model/bert_sparse_model_6.pt
Accuracy for fold 6: 42.857
F1 Score for fold 6: 0.300
Loss for fold 6: 0.721
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 1406.387939453125, std: 47628.4296875
Train Size: 6192, Test Size: 233
total step: 77400
PATH: ./Model/bert_sparse_model_7.pt
Accuracy for fold 7: 54.506
F1 Score for fold 7: 0.356
Loss for fold 7: 0.689
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 1599.7918701171875, std: 122792.8828125
Train Size: 6187, Test Size: 238
total step: 77400
PATH: ./Model/bert_sparse_model_8.pt
Accuracy for fold 8: 52.941
F1 Score for fold 8: 0.354
Loss for fold 8: 0.697
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 2806.188232421875, std: 191270.59375
Train Size: 6287, Test Size: 138
total step: 78600
PATH: ./Model/bert_sparse_model_9.pt
Accuracy for fold 9: 50.725
F1 Score for fold 9: 0.343
Loss for fold 9: 0.713

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 49.254449254449256, F1 32.71179264550313
Fold 1: Acc 49.95625546806649, F1 32.886820729136524
Fold 2: Acc 48.40085287846482, F1 32.482880315603616
Fold 3: Acc 51.79775280898876, F1 34.14379168751419
Fold 4: Acc 48.730548730548726, F1 32.41808221022559
Fold 5: Acc 42.857142857142854, F1 30.0
Fold 6: Acc 54.506437768240346, F1 35.60881207904906
Fold 7: Acc 52.94117647058824, F1 35.35089557595952
Fold 8: Acc 50.72463768115942, F1 34.29147039377218
Average: 49.908%
F1: 33.322%
Loss: 0.709

