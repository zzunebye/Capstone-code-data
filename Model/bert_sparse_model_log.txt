

************************************************************
STARTING A CROSS-VALIDATION ... [5] epochs
************************************************************
TIME: 01/04/2021 13:24:27
LAYER: [Sequential(
  (0): Linear(in_features=869, out_features=80, bias=True)
  (1): ELU(alpha=1.0)
  (2): Dropout(p=0.5, inplace=False)
  (3): Linear(in_features=80, out_features=16, bias=True)
  (4): ELU(alpha=1.0)
  (5): Dropout(p=0.5, inplace=False)
  (6): Linear(in_features=16, out_features=1, bias=True)
)]

STARTING TEST of 5 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 236.33355712890625, std: 4946.08349609375
Train Size: 4346, Test Size: 2079
total step: 2720
PATH: ./Model/bert_sparse_model_1.pt

************************************************************
STARTING A CROSS-VALIDATION ... [5] epochs
************************************************************
TIME: 03/04/2021 14:28:34
LAYER: [Sequential(
  (0): Linear(in_features=869, out_features=80, bias=True)
  (1): ELU(alpha=1.0)
  (2): Dropout(p=0.5, inplace=False)
  (3): Linear(in_features=80, out_features=16, bias=True)
  (4): ELU(alpha=1.0)
  (5): Dropout(p=0.5, inplace=False)
  (6): Linear(in_features=16, out_features=1, bias=True)
)]

STARTING TEST of 5 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 1699.229736328125, std: 74561.375
Train Size: 4346, Test Size: 2079
total step: 2720
PATH: ./Model/bert_sparse_model_1.pt
Accuracy for fold 1: 53.199
F1 Score for fold 1: 0.344
Loss for fold 1: 2895.978
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 1185.041259765625, std: 67327.2890625
Train Size: 5282, Test Size: 1143
total step: 3305
PATH: ./Model/bert_sparse_model_2.pt
Accuracy for fold 2: 57.655
F1 Score for fold 2: 0.364
Loss for fold 2: 506.718
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 4652.244140625, std: 190997.78125
Train Size: 5956, Test Size: 469
total step: 3725
PATH: ./Model/bert_sparse_model_3.pt
Accuracy for fold 3: 51.386
F1 Score for fold 3: 0.329
Loss for fold 3: 2565.259
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 4646.09423828125, std: 280710.1875
Train Size: 5535, Test Size: 890
total step: 3460
PATH: ./Model/bert_sparse_model_4.pt
Accuracy for fold 4: 52.697
F1 Score for fold 4: 0.337
Loss for fold 4: 3203.956
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 1974.0767822265625, std: 76641.7890625
Train Size: 5204, Test Size: 1221
total step: 3255
PATH: ./Model/bert_sparse_model_5.pt
Accuracy for fold 5: 52.007
F1 Score for fold 5: 0.333
Loss for fold 5: 1474.390
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 1992.8902587890625, std: 68556.6875
Train Size: 6411, Test Size: 14
total step: 4010
PATH: ./Model/bert_sparse_model_6.pt
Accuracy for fold 6: 57.143
F1 Score for fold 6: 0.362
Loss for fold 6: 471.756
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 1212.457763671875, std: 54755.55078125
Train Size: 6192, Test Size: 233
total step: 3870
PATH: ./Model/bert_sparse_model_7.pt
Accuracy for fold 7: 48.498
F1 Score for fold 7: 0.319
Loss for fold 7: 172.686
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 446.40386962890625, std: 20253.517578125
Train Size: 6187, Test Size: 238
total step: 3870
PATH: ./Model/bert_sparse_model_8.pt
Accuracy for fold 8: 47.479
F1 Score for fold 8: 0.309
Loss for fold 8: 98.842
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 1060.9610595703125, std: 55229.890625
Train Size: 6287, Test Size: 138
total step: 3930
PATH: ./Model/bert_sparse_model_9.pt
Accuracy for fold 9: 50.725
F1 Score for fold 9: 0.324
Loss for fold 9: 947.375

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 53.198653198653204, F1 34.38431965127493
Fold 1: Acc 57.655293088363955, F1 36.403727020524954
Fold 2: Acc 51.385927505330486, F1 32.94904337548262
Fold 3: Acc 52.69662921348315, F1 33.70756085362827
Fold 4: Acc 52.006552006552006, F1 33.271446680537636
Fold 5: Acc 57.14285714285714, F1 36.19047619047619
Fold 6: Acc 48.497854077253216, F1 31.89970735035113
Fold 7: Acc 47.47899159663865, F1 30.935432448037492
Fold 8: Acc 50.72463768115942, F1 32.40752805970198
Average: 52.310%
F1: 33.572%
Loss: 1370.773

