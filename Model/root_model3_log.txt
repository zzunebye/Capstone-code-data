

************************************************************
STARTING A CROSS-VALIDATION ... [100] epochs
************************************************************
TIME: 01/04/2021 09:22:27
LAYER: [Sequential(
  (0): Linear(in_features=49, out_features=8, bias=True)
  (1): ELU(alpha=1.0)
  (2): Dropout(p=0.5, inplace=False)
  (3): Linear(in_features=8, out_features=3, bias=True)
  (4): ELU(alpha=1.0)
  (5): Dropout(p=0.5, inplace=False)
  (6): Linear(in_features=3, out_features=1, bias=True)
)]

STARTING TEST of 100 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 11228.1416015625, std: 260122.265625
Train Size: 4346, Test Size: 2079
total step: 27200
PATH: ./Model/root_model3_1.pt
Accuracy for fold 1: 63.444
F1 Score for fold 1: 0.377
Loss for fold 1: 0.678
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 10446.947265625, std: 146136.046875
Train Size: 5282, Test Size: 1143
total step: 33100
PATH: ./Model/root_model3_2.pt
Accuracy for fold 2: 43.132
F1 Score for fold 2: 0.295
Loss for fold 2: 1.835
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 33864.05078125, std: 783676.4375
Train Size: 5956, Test Size: 469
total step: 37300
PATH: ./Model/root_model3_3.pt
Accuracy for fold 3: 52.239
F1 Score for fold 3: 0.343
Loss for fold 3: 0.691
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 41853.2578125, std: 832006.8125
Train Size: 5535, Test Size: 890
total step: 34600
PATH: ./Model/root_model3_4.pt
Accuracy for fold 4: 54.045
F1 Score for fold 4: 0.343
Loss for fold 4: 0.724
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 34891.828125, std: 515853.8125
Train Size: 5204, Test Size: 1221
total step: 32600
PATH: ./Model/root_model3_5.pt
Accuracy for fold 5: 47.993
F1 Score for fold 5: 0.321
Loss for fold 5: 0.727
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 11056.4619140625, std: 121966.3515625
Train Size: 6411, Test Size: 14
total step: 40100
PATH: ./Model/root_model3_6.pt
Accuracy for fold 6: 35.714
F1 Score for fold 6: 0.263
Loss for fold 6: 0.816
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 48952.546875, std: 859401.5625
Train Size: 6192, Test Size: 233
total step: 38700
PATH: ./Model/root_model3_7.pt
Accuracy for fold 7: 41.631
F1 Score for fold 7: 0.301
Loss for fold 7: 0.736
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 44938.85546875, std: 928818.625
Train Size: 6187, Test Size: 238
total step: 38700
PATH: ./Model/root_model3_8.pt
Accuracy for fold 8: 48.319
F1 Score for fold 8: 0.326
Loss for fold 8: 0.711
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 46430.21484375, std: 641599.3125
Train Size: 6287, Test Size: 138
total step: 39300
PATH: ./Model/root_model3_9.pt
Accuracy for fold 9: 49.275
F1 Score for fold 9: 0.324
Loss for fold 9: 0.722

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 63.44396344396345, F1 37.7267621087601
Fold 1: Acc 43.13210848643919, F1 29.455308182828787
Fold 2: Acc 52.23880597014925, F1 34.31813452346033
Fold 3: Acc 54.044943820224724, F1 34.2876490220143
Fold 4: Acc 47.993447993447994, F1 32.10608358188274
Fold 5: Acc 35.714285714285715, F1 26.315789473684212
Fold 6: Acc 41.63090128755365, F1 30.10144200515538
Fold 7: Acc 48.319327731092436, F1 32.59060044907015
Fold 8: Acc 49.275362318840585, F1 32.381605239629316
Average: 48.421%
F1: 32.143%
Loss: 0.849

RESULT:
Average: 48.42%
F1: 32.14%
Loss: 0.85
