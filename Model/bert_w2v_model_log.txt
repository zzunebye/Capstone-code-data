

************************************************************
STARTING A CROSS-VALIDATION ... [50] epochs
************************************************************
TIME: 01/04/2021 11:12:35


************************************************************
STARTING A CROSS-VALIDATION ... [50] epochs
************************************************************
TIME: 01/04/2021 11:38:09
LAYER: [Sequential(
  (0): Linear(in_features=968, out_features=70, bias=True)
  (1): ELU(alpha=1.0)
  (2): Dropout(p=0.5, inplace=False)
  (3): Linear(in_features=70, out_features=10, bias=True)
  (4): ELU(alpha=1.0)
  (5): Dropout(p=0.5, inplace=False)
  (6): Linear(in_features=10, out_features=1, bias=True)
)]

STARTING TEST of 50 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 0.030418967828154564, std: 0.3176175653934479
Train Size: 4346, Test Size: 2079
total step: 27200
PATH: ./Model/bert_w2v_model_1.pt
Accuracy for fold 1: 76.816
F1 Score for fold 1: 0.502
Loss for fold 1: 0.524
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 0.030526604503393173, std: 0.31462883949279785
Train Size: 5282, Test Size: 1143
total step: 33050
PATH: ./Model/bert_w2v_model_2.pt
Accuracy for fold 2: 74.366
F1 Score for fold 2: 0.517
Loss for fold 2: 0.586
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 0.031102379783988, std: 0.3174213767051697
Train Size: 5956, Test Size: 469
total step: 37250
PATH: ./Model/bert_w2v_model_3.pt
Accuracy for fold 3: 66.525
F1 Score for fold 3: 0.413
Loss for fold 3: 0.674
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 0.030489489436149597, std: 0.3150375485420227
Train Size: 5535, Test Size: 890
total step: 34600
PATH: ./Model/bert_w2v_model_4.pt
Accuracy for fold 4: 70.112
F1 Score for fold 4: 0.446
Loss for fold 4: 0.646
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 0.030141467228531837, std: 0.3168102204799652
Train Size: 5204, Test Size: 1221
total step: 32550
PATH: ./Model/bert_w2v_model_5.pt
Accuracy for fold 5: 71.744
F1 Score for fold 5: 0.444
Loss for fold 5: 0.644
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 0.03032052330672741, std: 0.31546342372894287
Train Size: 6411, Test Size: 14
total step: 40100
PATH: ./Model/bert_w2v_model_6.pt
Accuracy for fold 6: 78.571
F1 Score for fold 6: 0.648
Loss for fold 6: 0.346
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 0.031116560101509094, std: 0.31956860423088074
Train Size: 6192, Test Size: 233
total step: 38700
PATH: ./Model/bert_w2v_model_7.pt
Accuracy for fold 7: 39.056
F1 Score for fold 7: 0.284
Loss for fold 7: 1.048
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 0.029521752148866653, std: 0.3177598714828491
Train Size: 6187, Test Size: 238
total step: 38700
PATH: ./Model/bert_w2v_model_8.pt
Accuracy for fold 8: 62.185
F1 Score for fold 8: 0.492
Loss for fold 8: 0.860
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 0.03024839051067829, std: 0.31826162338256836
Train Size: 6287, Test Size: 138
total step: 39300
PATH: ./Model/bert_w2v_model_9.pt
Accuracy for fold 9: 57.971
F1 Score for fold 9: 0.384
Loss for fold 9: 0.860

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 76.81577681577681, F1 50.191514433938764
Fold 1: Acc 74.36570428696413, F1 51.71366593938776
Fold 2: Acc 66.52452025586354, F1 41.32855062492585
Fold 3: Acc 70.11235955056179, F1 44.555998308807354
Fold 4: Acc 71.74447174447175, F1 44.4029607665972
Fold 5: Acc 78.57142857142857, F1 64.83516483516483
Fold 6: Acc 39.05579399141631, F1 28.39486693563946
Fold 7: Acc 62.18487394957983, F1 49.20642382827258
Fold 8: Acc 57.971014492753625, F1 38.394938394938386
Average: 66.372%
F1: 45.892%
Loss: 0.687

RESULT:
Average: 66.37%
F1: 45.89%
Loss: 0.69


************************************************************
STARTING A CROSS-VALIDATION ... [50] epochs
************************************************************
TIME: 01/04/2021 11:56:00
LAYER: [Sequential(
  (0): Linear(in_features=968, out_features=80, bias=True)
  (1): ELU(alpha=1.0)
  (2): Dropout(p=0.5, inplace=False)
  (3): Linear(in_features=80, out_features=12, bias=True)
  (4): ELU(alpha=1.0)
  (5): Dropout(p=0.5, inplace=False)
  (6): Linear(in_features=12, out_features=1, bias=True)
)]

STARTING TEST of 50 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 0.03017139621078968, std: 0.3186417520046234
Train Size: 4346, Test Size: 2079
total step: 27200
PATH: ./Model/bert_w2v_model_1.pt
Accuracy for fold 1: 76.335
F1 Score for fold 1: 0.496
Loss for fold 1: 0.532
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 0.029505962505936623, std: 0.31566962599754333
Train Size: 5282, Test Size: 1143
total step: 33050
PATH: ./Model/bert_w2v_model_2.pt
Accuracy for fold 2: 73.403
F1 Score for fold 2: 0.500
Loss for fold 2: 0.575
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 0.030967772006988525, std: 0.313530296087265
Train Size: 5956, Test Size: 469
total step: 37250
PATH: ./Model/bert_w2v_model_3.pt
Accuracy for fold 3: 68.230
F1 Score for fold 3: 0.437
Loss for fold 3: 0.678
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 0.029877549037337303, std: 0.31630149483680725
Train Size: 5535, Test Size: 890
total step: 34600
PATH: ./Model/bert_w2v_model_4.pt
Accuracy for fold 4: 70.787
F1 Score for fold 4: 0.465
Loss for fold 4: 0.650
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 0.03131826967000961, std: 0.31359025835990906
Train Size: 5204, Test Size: 1221
total step: 32550
PATH: ./Model/bert_w2v_model_5.pt
Accuracy for fold 5: 71.744
F1 Score for fold 5: 0.461
Loss for fold 5: 0.630
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 0.029258185997605324, std: 0.3195198178291321
Train Size: 6411, Test Size: 14
total step: 40100
PATH: ./Model/bert_w2v_model_6.pt
Accuracy for fold 6: 78.571
F1 Score for fold 6: 0.648
Loss for fold 6: 0.382
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 0.03145851567387581, std: 0.3156641721725464
Train Size: 6192, Test Size: 233
total step: 38700
PATH: ./Model/bert_w2v_model_7.pt
Accuracy for fold 7: 39.914
F1 Score for fold 7: 0.284
Loss for fold 7: 1.067
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 0.030023617669939995, std: 0.32102105021476746
Train Size: 6187, Test Size: 238
total step: 38700
PATH: ./Model/bert_w2v_model_8.pt
Accuracy for fold 8: 61.765
F1 Score for fold 8: 0.479
Loss for fold 8: 0.863
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 0.03088313899934292, std: 0.31547650694847107
Train Size: 6287, Test Size: 138
total step: 39300
PATH: ./Model/bert_w2v_model_9.pt
Accuracy for fold 9: 58.696
F1 Score for fold 9: 0.386
Loss for fold 9: 0.831

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 76.33477633477634, F1 49.600846483963466
Fold 1: Acc 73.40332458442694, F1 49.97986557041679
Fold 2: Acc 68.23027718550107, F1 43.68446052881016
Fold 3: Acc 70.78651685393258, F1 46.46917127816012
Fold 4: Acc 71.74447174447175, F1 46.086889723253435
Fold 5: Acc 78.57142857142857, F1 64.83516483516483
Fold 6: Acc 39.91416309012876, F1 28.382928468765375
Fold 7: Acc 61.76470588235294, F1 47.93857869488122
Fold 8: Acc 58.69565217391305, F1 38.64975604106038
Average: 66.605%
F1: 46.181%
Loss: 0.690

RESULT:
Average: 66.61%
F1: 46.18%
Loss: 0.69


************************************************************
STARTING A CROSS-VALIDATION ... [50] epochs
************************************************************
TIME: 01/04/2021 12:12:01
LAYER: [Sequential(
  (0): Linear(in_features=968, out_features=80, bias=True)
  (1): ELU(alpha=1.0)
  (2): Dropout(p=0.5, inplace=False)
  (3): Linear(in_features=80, out_features=12, bias=True)
  (4): ELU(alpha=1.0)
  (5): Dropout(p=0.5, inplace=False)
  (6): Linear(in_features=12, out_features=1, bias=True)
)]

STARTING TEST of 50 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 0.030263420194387436, std: 0.31726905703544617
Train Size: 4346, Test Size: 2079
total step: 27200
PATH: ./Model/bert_w2v_model_1.pt
Accuracy for fold 1: 76.479
F1 Score for fold 1: 0.487
Loss for fold 1: 0.541
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 0.02951112948358059, std: 0.31365782022476196
Train Size: 5282, Test Size: 1143
total step: 33050
PATH: ./Model/bert_w2v_model_2.pt
Accuracy for fold 2: 72.878
F1 Score for fold 2: 0.472
Loss for fold 2: 0.619
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 0.03000754490494728, std: 0.3183509111404419
Train Size: 5956, Test Size: 469
total step: 37250
PATH: ./Model/bert_w2v_model_3.pt
Accuracy for fold 3: 66.098
F1 Score for fold 3: 0.435
Loss for fold 3: 0.688
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 0.02868668921291828, std: 0.31841981410980225
Train Size: 5535, Test Size: 890
total step: 34600
PATH: ./Model/bert_w2v_model_4.pt
Accuracy for fold 4: 70.000
F1 Score for fold 4: 0.440
Loss for fold 4: 0.645
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 0.030998069792985916, std: 0.31444117426872253
Train Size: 5204, Test Size: 1221
total step: 32550
PATH: ./Model/bert_w2v_model_5.pt
Accuracy for fold 5: 71.908
F1 Score for fold 5: 0.458
Loss for fold 5: 0.652
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 0.03061872348189354, std: 0.31411901116371155
Train Size: 6411, Test Size: 14
total step: 40100
PATH: ./Model/bert_w2v_model_6.pt
Accuracy for fold 6: 78.571
F1 Score for fold 6: 0.648
Loss for fold 6: 0.304
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 0.030009379610419273, std: 0.3118496239185333
Train Size: 6192, Test Size: 233
total step: 38700
PATH: ./Model/bert_w2v_model_7.pt
Accuracy for fold 7: 39.485
F1 Score for fold 7: 0.282
Loss for fold 7: 1.030
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 0.03014661744236946, std: 0.3142450153827667
Train Size: 6187, Test Size: 238
total step: 38700
PATH: ./Model/bert_w2v_model_8.pt
Accuracy for fold 8: 61.765
F1 Score for fold 8: 0.477
Loss for fold 8: 0.859
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 0.030278822407126427, std: 0.3174956440925598
Train Size: 6287, Test Size: 138
total step: 39300
PATH: ./Model/bert_w2v_model_9.pt
Accuracy for fold 9: 60.145
F1 Score for fold 9: 0.393
Loss for fold 9: 0.935

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 76.47907647907648, F1 48.72576197251531
Fold 1: Acc 72.87839020122485, F1 47.2164813897098
Fold 2: Acc 66.09808102345416, F1 43.54601569953379
Fold 3: Acc 70.0, F1 44.027029150624706
Fold 4: Acc 71.9082719082719, F1 45.76528940165312
Fold 5: Acc 78.57142857142857, F1 64.83516483516483
Fold 6: Acc 39.48497854077253, F1 28.234721882790552
Fold 7: Acc 61.76470588235294, F1 47.73461832285363
Fold 8: Acc 60.14492753623188, F1 39.29220537916189
Average: 66.370%
F1: 45.486%
Loss: 0.697

RESULT:
Average: 66.37%
F1: 45.49%
Loss: 0.70


************************************************************
STARTING A CROSS-VALIDATION ... [50] epochs
************************************************************
TIME: 01/04/2021 12:25:07
LAYER: [Sequential(
  (0): Linear(in_features=968, out_features=80, bias=True)
  (1): ELU(alpha=1.0)
  (2): Dropout(p=0.5, inplace=False)
  (3): Linear(in_features=80, out_features=12, bias=True)
  (4): ELU(alpha=1.0)
  (5): Dropout(p=0.5, inplace=False)
  (6): Linear(in_features=12, out_features=4, bias=True)
  (7): ELU(alpha=1.0)
  (8): Dropout(p=0.5, inplace=False)
  (9): Linear(in_features=4, out_features=1, bias=True)
)]

STARTING TEST of 50 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 0.03125843405723572, std: 0.31723761558532715
Train Size: 4346, Test Size: 2079
total step: 27200
PATH: ./Model/bert_w2v_model_1.pt
Accuracy for fold 1: 76.720
F1 Score for fold 1: 0.494
Loss for fold 1: 0.550
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 0.029679667204618454, std: 0.31474730372428894
Train Size: 5282, Test Size: 1143
total step: 33050
PATH: ./Model/bert_w2v_model_2.pt
Accuracy for fold 2: 63.167
F1 Score for fold 2: 0.390
Loss for fold 2: 0.684
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 0.0301760733127594, std: 0.31643328070640564
Train Size: 5956, Test Size: 469
total step: 37250
PATH: ./Model/bert_w2v_model_3.pt
Accuracy for fold 3: 67.591
F1 Score for fold 3: 0.415
Loss for fold 3: 0.646
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 0.03054899163544178, std: 0.3146883547306061
Train Size: 5535, Test Size: 890
total step: 34600
PATH: ./Model/bert_w2v_model_4.pt
Accuracy for fold 4: 71.124
F1 Score for fold 4: 0.449
Loss for fold 4: 0.616
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 0.03026524931192398, std: 0.3170831501483917
Train Size: 5204, Test Size: 1221
total step: 32550
PATH: ./Model/bert_w2v_model_5.pt
Accuracy for fold 5: 70.598
F1 Score for fold 5: 0.451
Loss for fold 5: 0.643
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 0.030167365446686745, std: 0.31772151589393616
Train Size: 6411, Test Size: 14
total step: 40100
PATH: ./Model/bert_w2v_model_6.pt
Accuracy for fold 6: 78.571
F1 Score for fold 6: 0.648
Loss for fold 6: 0.366
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 0.03186606243252754, std: 0.31318578124046326
Train Size: 6192, Test Size: 233
total step: 38700
PATH: ./Model/bert_w2v_model_7.pt
Accuracy for fold 7: 40.343
F1 Score for fold 7: 0.290
Loss for fold 7: 0.921
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 0.029640192165970802, std: 0.319414883852005
Train Size: 6187, Test Size: 238
total step: 38700
PATH: ./Model/bert_w2v_model_8.pt
Accuracy for fold 8: 58.824
F1 Score for fold 8: 0.406
Loss for fold 8: 0.926
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 0.029406586661934853, std: 0.3156890273094177
Train Size: 6287, Test Size: 138
total step: 39300
PATH: ./Model/bert_w2v_model_9.pt
Accuracy for fold 9: 56.522
F1 Score for fold 9: 0.374
Loss for fold 9: 0.824

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 76.71957671957672, F1 49.42078604416276
Fold 1: Acc 63.167104111986006, F1 39.011801846447575
Fold 2: Acc 67.590618336887, F1 41.532014538411104
Fold 3: Acc 71.12359550561797, F1 44.91052019141912
Fold 4: Acc 70.5978705978706, F1 45.099921463557884
Fold 5: Acc 78.57142857142857, F1 64.83516483516483
Fold 6: Acc 40.343347639484975, F1 28.955107839228003
Fold 7: Acc 58.82352941176471, F1 40.568376534763104
Fold 8: Acc 56.52173913043478, F1 37.44902440554613
Average: 64.829%
F1: 43.531%
Loss: 0.686

RESULT:
Average: 64.83%
F1: 43.53%
Loss: 0.69


************************************************************
STARTING A CROSS-VALIDATION ... [50] epochs
************************************************************
TIME: 01/04/2021 12:38:57
LAYER: [Sequential(
  (0): Linear(in_features=968, out_features=64, bias=True)
  (1): ELU(alpha=1.0)
  (2): Dropout(p=0.5, inplace=False)
  (3): Linear(in_features=64, out_features=12, bias=True)
  (4): ELU(alpha=1.0)
  (5): Dropout(p=0.5, inplace=False)
  (6): Linear(in_features=12, out_features=1, bias=True)
)]

STARTING TEST of 50 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 0.030645912513136864, std: 0.313277006149292
Train Size: 4346, Test Size: 2079
total step: 27200
PATH: ./Model/bert_w2v_model_1.pt
Accuracy for fold 1: 76.575
F1 Score for fold 1: 0.501
Loss for fold 1: 0.522
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 0.03018464334309101, std: 0.3164657652378082
Train Size: 5282, Test Size: 1143
total step: 33050
PATH: ./Model/bert_w2v_model_2.pt
Accuracy for fold 2: 71.304
F1 Score for fold 2: 0.467
Loss for fold 2: 0.621
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 0.029073521494865417, std: 0.3214377462863922
Train Size: 5956, Test Size: 469
total step: 37250
PATH: ./Model/bert_w2v_model_3.pt
Accuracy for fold 3: 67.164
F1 Score for fold 3: 0.415
Loss for fold 3: 0.656
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 0.029871920123696327, std: 0.31710952520370483
Train Size: 5535, Test Size: 890
total step: 34600
PATH: ./Model/bert_w2v_model_4.pt
Accuracy for fold 4: 70.449
F1 Score for fold 4: 0.447
Loss for fold 4: 0.620
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 0.0318492092192173, std: 0.3162848651409149
Train Size: 5204, Test Size: 1221
total step: 32550
PATH: ./Model/bert_w2v_model_5.pt
Accuracy for fold 5: 71.990
F1 Score for fold 5: 0.449
Loss for fold 5: 0.637
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 0.03032473661005497, std: 0.31768798828125
Train Size: 6411, Test Size: 14
total step: 40100
PATH: ./Model/bert_w2v_model_6.pt
Accuracy for fold 6: 78.571
F1 Score for fold 6: 0.648
Loss for fold 6: 0.443
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 0.030371537432074547, std: 0.31932753324508667
Train Size: 6192, Test Size: 233
total step: 38700
PATH: ./Model/bert_w2v_model_7.pt
Accuracy for fold 7: 34.764
F1 Score for fold 7: 0.254
Loss for fold 7: 1.290
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 0.030779551714658737, std: 0.3202141523361206
Train Size: 6187, Test Size: 238
total step: 38700
PATH: ./Model/bert_w2v_model_8.pt
Accuracy for fold 8: 61.765
F1 Score for fold 8: 0.506
Loss for fold 8: 0.862
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 0.030090456828475, std: 0.3180072605609894
Train Size: 6287, Test Size: 138
total step: 39300
PATH: ./Model/bert_w2v_model_9.pt
Accuracy for fold 9: 58.696
F1 Score for fold 9: 0.385
Loss for fold 9: 0.888

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 76.57527657527658, F1 50.07521578950159
Fold 1: Acc 71.30358705161855, F1 46.6596318039888
Fold 2: Acc 67.16417910447761, F1 41.538262732292544
Fold 3: Acc 70.4494382022472, F1 44.65465620521806
Fold 4: Acc 71.99017199017199, F1 44.872401236037675
Fold 5: Acc 78.57142857142857, F1 64.83516483516483
Fold 6: Acc 34.763948497854074, F1 25.44210200862561
Fold 7: Acc 61.76470588235294, F1 50.55096164339862
Fold 8: Acc 58.69565217391305, F1 38.519258519258514
Average: 65.698%
F1: 45.239%
Loss: 0.727

RESULT:
Average: 65.70%
F1: 45.24%
Loss: 0.73
