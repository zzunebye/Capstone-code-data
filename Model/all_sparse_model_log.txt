

************************************************************
STARTING A CROSS-VALIDATION ... [100] epochs
************************************************************

STARTING TEST of 100 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 9033.7177734375, std: 142579.796875
Train Size: 4346, Test Size: 2079
total step: 27200
PATH: ./Model/all_sparse_model_1.pt
Accuracy for fold 1: 70.611
F1 Score for fold 1: 0.420
Loss for fold 1: 21.168
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 17645.1328125, std: 250179.8125
Train Size: 5282, Test Size: 1143
total step: 33100
PATH: ./Model/all_sparse_model_2.pt
Accuracy for fold 2: 35.083
F1 Score for fold 2: 0.239
Loss for fold 2: 1.126
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 14770.572265625, std: 253293.671875
Train Size: 5956, Test Size: 469
total step: 37300
PATH: ./Model/all_sparse_model_3.pt
Accuracy for fold 3: 45.842
F1 Score for fold 3: 0.314
Loss for fold 3: 1.311
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 19592.08984375, std: 553984.4375
Train Size: 5535, Test Size: 890
total step: 34600
PATH: ./Model/all_sparse_model_4.pt
Accuracy for fold 4: 49.101
F1 Score for fold 4: 0.324
Loss for fold 4: 0.913
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 25421.28515625, std: 352387.375
Train Size: 5204, Test Size: 1221
total step: 32600
PATH: ./Model/all_sparse_model_5.pt
Accuracy for fold 5: 54.382
F1 Score for fold 5: 0.346
Loss for fold 5: 1.105
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 8891.556640625, std: 151719.34375
Train Size: 6411, Test Size: 14
total step: 40100
PATH: ./Model/all_sparse_model_6.pt
Accuracy for fold 6: 35.714
F1 Score for fold 6: 0.263
Loss for fold 6: 0.851
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 16188.8134765625, std: 360756.375
Train Size: 6192, Test Size: 233
total step: 38700
PATH: ./Model/all_sparse_model_7.pt
Accuracy for fold 7: 47.210
F1 Score for fold 7: 0.323
Loss for fold 7: 0.966
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 7984.4375, std: 172181.375
Train Size: 6187, Test Size: 238
total step: 38700
PATH: ./Model/all_sparse_model_8.pt
Accuracy for fold 8: 49.580
F1 Score for fold 8: 0.335
Loss for fold 8: 2.386
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 11286.82421875, std: 206233.15625
Train Size: 6287, Test Size: 138
total step: 39300
PATH: ./Model/all_sparse_model_9.pt
Accuracy for fold 9: 49.275
F1 Score for fold 9: 0.337
Loss for fold 9: 3.052

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 70.61087061087062, F1 42.02518843384677
Fold 1: Acc 35.08311461067367, F1 23.899202510581645
Fold 2: Acc 45.84221748400853, F1 31.38861123146367
Fold 3: Acc 49.10112359550562, F1 32.425965259671266
Fold 4: Acc 54.38165438165438, F1 34.57965433665096
Fold 5: Acc 35.714285714285715, F1 26.315789473684212
Fold 6: Acc 47.21030042918455, F1 32.33874476126075
Fold 7: Acc 49.57983193277311, F1 33.46467002732987
Fold 8: Acc 49.275362318840585, F1 33.74558984388853
Average: 48.533%
F1: 32.243%
Loss: 3.653



************************************************************
STARTING A CROSS-VALIDATION ... [100] epochs
************************************************************

STARTING TEST of 100 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 16343.1162109375, std: 374510.09375
Train Size: 4346, Test Size: 2079
total step: 27200
PATH: ./Model/all_sparse_model_1.pt

************************************************************
STARTING A CROSS-VALIDATION ... [100] epochs
************************************************************

STARTING TEST of 100 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 3586.9814453125, std: 48379.33984375
Train Size: 4346, Test Size: 2079
total step: 27200
PATH: ./Model/all_sparse_model_1.pt

************************************************************
STARTING A CROSS-VALIDATION ... [100] epochs
************************************************************

STARTING TEST of 100 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 17212.80078125, std: 335131.34375
Train Size: 4346, Test Size: 2079
total step: 27200
PATH: ./Model/all_sparse_model_1.pt

************************************************************
STARTING A CROSS-VALIDATION ... [100] epochs
************************************************************

STARTING TEST of 100 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 5922.80810546875, std: 99281.40625
Train Size: 4346, Test Size: 2079
total step: 27200
PATH: ./Model/all_sparse_model_1.pt
Accuracy for fold 1: 47.282
F1 Score for fold 1: 0.316
Loss for fold 1: 17.500
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 11552.6904296875, std: 169672.40625
Train Size: 5282, Test Size: 1143
total step: 33100
PATH: ./Model/all_sparse_model_2.pt
Accuracy for fold 2: 52.318
F1 Score for fold 2: 0.339
Loss for fold 2: 1.687
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 8632.11328125, std: 118195.0
Train Size: 5956, Test Size: 469
total step: 37300
PATH: ./Model/all_sparse_model_3.pt
Accuracy for fold 3: 47.548
F1 Score for fold 3: 0.290
Loss for fold 3: 0.762
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 34406.6640625, std: 773558.5625
Train Size: 5535, Test Size: 890
total step: 34600
PATH: ./Model/all_sparse_model_4.pt
Accuracy for fold 4: 51.461
F1 Score for fold 4: 0.318
Loss for fold 4: 3.469
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 26913.62890625, std: 595335.0
Train Size: 5204, Test Size: 1221
total step: 32600
PATH: ./Model/all_sparse_model_5.pt
Accuracy for fold 5: 49.058
F1 Score for fold 5: 0.322
Loss for fold 5: 3.170
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 2852.235107421875, std: 36151.4609375
Train Size: 6411, Test Size: 14
total step: 40100
PATH: ./Model/all_sparse_model_6.pt
Accuracy for fold 6: 85.714
F1 Score for fold 6: 0.462
Loss for fold 6: 0.572
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 24525.4921875, std: 568824.75
Train Size: 6192, Test Size: 233
total step: 38700
PATH: ./Model/all_sparse_model_7.pt
Accuracy for fold 7: 65.665
F1 Score for fold 7: 0.394
Loss for fold 7: 0.862
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 12868.3095703125, std: 216119.890625
Train Size: 6187, Test Size: 238
total step: 38700
PATH: ./Model/all_sparse_model_8.pt
Accuracy for fold 8: 55.462
F1 Score for fold 8: 0.367
Loss for fold 8: 2.305
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 11739.5419921875, std: 234698.703125
Train Size: 6287, Test Size: 138
total step: 39300
PATH: ./Model/all_sparse_model_9.pt
Accuracy for fold 9: 52.899
F1 Score for fold 9: 0.353
Loss for fold 9: 0.773

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 47.28234728234728, F1 31.574171501482255
Fold 1: Acc 52.31846019247593, F1 33.88539170797336
Fold 2: Acc 47.54797441364605, F1 29.044230257043697
Fold 3: Acc 51.460674157303366, F1 31.79519882818132
Fold 4: Acc 49.058149058149056, F1 32.187915375960515
Fold 5: Acc 85.71428571428571, F1 46.153846153846146
Fold 6: Acc 65.66523605150213, F1 39.44158508136605
Fold 7: Acc 55.46218487394958, F1 36.71014225586077
Fold 8: Acc 52.89855072463768, F1 35.25981304623562
Average: 56.379%
F1: 35.117%
Loss: 3.456



************************************************************
STARTING A CROSS-VALIDATION ... [100] epochs
************************************************************
TIME: 31/03/2021 17:41:34
LAYER: [Sequential(
  (0): Linear(in_features=101, out_features=32, bias=True)
  (1): ELU(alpha=1.0)
  (2): Dropout(p=0.5, inplace=False)
  (3): Linear(in_features=32, out_features=10, bias=True)
  (4): ELU(alpha=1.0)
  (5): Dropout(p=0.5, inplace=False)
  (6): Linear(in_features=10, out_features=1, bias=True)
)]

STARTING TEST of 100 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 22680.18359375, std: 558684.375
Train Size: 4346, Test Size: 2079
total step: 27200
PATH: ./Model/all_sparse_model_1.pt
Accuracy for fold 1: 62.626
F1 Score for fold 1: 0.377
Loss for fold 1: 21.134
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 3537.511962890625, std: 37890.78515625
Train Size: 5282, Test Size: 1143
total step: 33100
PATH: ./Model/all_sparse_model_2.pt
Accuracy for fold 2: 53.543
F1 Score for fold 2: 0.343
Loss for fold 2: 1.656
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 5570.20458984375, std: 98388.875
Train Size: 5956, Test Size: 469
total step: 37300
PATH: ./Model/all_sparse_model_3.pt
Accuracy for fold 3: 48.614
F1 Score for fold 3: 0.318
Loss for fold 3: 0.903
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 3548.816162109375, std: 38426.33203125
Train Size: 5535, Test Size: 890
total step: 34600
PATH: ./Model/all_sparse_model_4.pt
Accuracy for fold 4: 54.494
F1 Score for fold 4: 0.341
Loss for fold 4: 2.703
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 2746.553955078125, std: 27551.212890625
Train Size: 5204, Test Size: 1221
total step: 32600
PATH: ./Model/all_sparse_model_5.pt
Accuracy for fold 5: 53.153
F1 Score for fold 5: 0.335
Loss for fold 5: 10.166
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 6015.6513671875, std: 88154.859375
Train Size: 6411, Test Size: 14
total step: 40100
PATH: ./Model/all_sparse_model_6.pt
Accuracy for fold 6: 21.429
F1 Score for fold 6: 0.176
Loss for fold 6: 0.819
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 13356.3564453125, std: 329324.34375
Train Size: 6192, Test Size: 233
total step: 38700
PATH: ./Model/all_sparse_model_7.pt
Accuracy for fold 7: 48.069
F1 Score for fold 7: 0.324
Loss for fold 7: 0.822
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 21620.154296875, std: 520253.0
Train Size: 6187, Test Size: 238
total step: 38700
PATH: ./Model/all_sparse_model_8.pt
Accuracy for fold 8: 50.000
F1 Score for fold 8: 0.324
Loss for fold 8: 0.743
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 14502.9599609375, std: 339718.5
Train Size: 6287, Test Size: 138
total step: 39300
PATH: ./Model/all_sparse_model_9.pt
Accuracy for fold 9: 50.725
F1 Score for fold 9: 0.330
Loss for fold 9: 19.313

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 62.62626262626263, F1 37.748401339667396
Fold 1: Acc 53.54330708661418, F1 34.28047087829401
Fold 2: Acc 48.61407249466951, F1 31.817493868306176
Fold 3: Acc 54.49438202247191, F1 34.085605714122394
Fold 4: Acc 53.153153153153156, F1 33.46108319565635
Fold 5: Acc 21.428571428571427, F1 17.647058823529413
Fold 6: Acc 48.06866952789699, F1 32.36099762028107
Fold 7: Acc 50.0, F1 32.43503872010052
Fold 8: Acc 50.72463768115942, F1 32.98943708026635
Average: 49.184%
F1: 31.870%
Loss: 6.473

RESULT:
Average: 49.18%
F1: 31.87%
Loss: 6.47


************************************************************
STARTING A CROSS-VALIDATION ... [100] epochs
************************************************************

STARTING TEST of 100 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 16623.244140625, std: 541429.625
Train Size: 4346, Test Size: 2079
total step: 27200
PATH: ./Model/all_sparse_model_1.pt

************************************************************
STARTING A CROSS-VALIDATION ... [100] epochs
************************************************************
TIME: 31/03/2021 19:51:33
LAYER: [Sequential(
  (0): Linear(in_features=101, out_features=24, bias=True)
  (1): ELU(alpha=1.0)
  (2): Dropout(p=0.5, inplace=False)
  (3): Linear(in_features=24, out_features=1, bias=True)
)]

STARTING TEST of 100 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 9497.3642578125, std: 162454.4375
Train Size: 4346, Test Size: 2079
total step: 27200
PATH: ./Model/all_sparse_model_1.pt
Accuracy for fold 1: 54.497
F1 Score for fold 1: 0.349
Loss for fold 1: 3.843
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 6643.03466796875, std: 125934.9765625
Train Size: 5282, Test Size: 1143
total step: 33100
PATH: ./Model/all_sparse_model_2.pt
Accuracy for fold 2: 58.093
F1 Score for fold 2: 0.358
Loss for fold 2: 4.329
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 4816.9462890625, std: 67263.765625
Train Size: 5956, Test Size: 469
total step: 37300
PATH: ./Model/all_sparse_model_3.pt
Accuracy for fold 3: 48.401
F1 Score for fold 3: 0.325
Loss for fold 3: 0.734
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 20845.65625, std: 431987.25
Train Size: 5535, Test Size: 890
total step: 34600
PATH: ./Model/all_sparse_model_4.pt
Accuracy for fold 4: 49.101
F1 Score for fold 4: 0.328
Loss for fold 4: 0.829
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 14184.033203125, std: 251212.0625
Train Size: 5204, Test Size: 1221
total step: 32600
PATH: ./Model/all_sparse_model_5.pt
Accuracy for fold 5: 50.778
F1 Score for fold 5: 0.334
Loss for fold 5: 11.396
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 7966.87646484375, std: 141975.609375
Train Size: 6411, Test Size: 14
total step: 40100
PATH: ./Model/all_sparse_model_6.pt
Accuracy for fold 6: 50.000
F1 Score for fold 6: 0.333
Loss for fold 6: 0.714
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 7641.06787109375, std: 166728.0
Train Size: 6192, Test Size: 233
total step: 38700
PATH: ./Model/all_sparse_model_7.pt
Accuracy for fold 7: 54.506
F1 Score for fold 7: 0.355
Loss for fold 7: 0.697
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 20117.4609375, std: 391212.4375
Train Size: 6187, Test Size: 238
total step: 38700
PATH: ./Model/all_sparse_model_8.pt
Accuracy for fold 8: 49.160
F1 Score for fold 8: 0.334
Loss for fold 8: 2.350
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 31431.44140625, std: 506496.78125
Train Size: 6287, Test Size: 138
total step: 39300
PATH: ./Model/all_sparse_model_9.pt
Accuracy for fold 9: 57.246
F1 Score for fold 9: 0.362
Loss for fold 9: 1.846

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 54.4973544973545, F1 34.87203582406348
Fold 1: Acc 58.09273840769904, F1 35.77605876875561
Fold 2: Acc 48.40085287846482, F1 32.45966936112482
Fold 3: Acc 49.10112359550562, F1 32.81824385505803
Fold 4: Acc 50.778050778050776, F1 33.442752873582904
Fold 5: Acc 50.0, F1 33.33333333333333
Fold 6: Acc 54.506437768240346, F1 35.50481943950875
Fold 7: Acc 49.159663865546214, F1 33.36236683112825
Fold 8: Acc 57.2463768115942, F1 36.179125444090786
Average: 52.420%
F1: 34.194%
Loss: 2.971



************************************************************
STARTING A CROSS-VALIDATION ... [100] epochs
************************************************************
TIME: 31/03/2021 19:54:21
LAYER: [Sequential(
  (0): Linear(in_features=101, out_features=24, bias=True)
  (1): ELU(alpha=1.0)
  (2): Dropout(p=0.5, inplace=False)
  (3): Linear(in_features=24, out_features=6, bias=True)
  (4): ELU(alpha=1.0)
  (5): Dropout(p=0.5, inplace=False)
  (6): Linear(in_features=6, out_features=1, bias=True)
)]

STARTING TEST of 100 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 9530.779296875, std: 160476.28125
Train Size: 4346, Test Size: 2079
total step: 27200
PATH: ./Model/all_sparse_model_1.pt
Accuracy for fold 1: 48.725
F1 Score for fold 1: 0.323
Loss for fold 1: 2.845
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 17278.0625, std: 249050.71875
Train Size: 5282, Test Size: 1143
total step: 33100
PATH: ./Model/all_sparse_model_2.pt
Accuracy for fold 2: 52.056
F1 Score for fold 2: 0.337
Loss for fold 2: 0.934
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 9682.7626953125, std: 186474.875
Train Size: 5956, Test Size: 469
total step: 37300
PATH: ./Model/all_sparse_model_3.pt
Accuracy for fold 3: 48.188
F1 Score for fold 3: 0.324
Loss for fold 3: 0.816
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 14642.419921875, std: 220896.28125
Train Size: 5535, Test Size: 890
total step: 34600
PATH: ./Model/all_sparse_model_4.pt
Accuracy for fold 4: 52.809
F1 Score for fold 4: 0.345
Loss for fold 4: 0.710
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 3893.86083984375, std: 49062.3984375
Train Size: 5204, Test Size: 1221
total step: 32600
PATH: ./Model/all_sparse_model_5.pt
Accuracy for fold 5: 48.239
F1 Score for fold 5: 0.324
Loss for fold 5: 0.785
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 17283.375, std: 358015.96875
Train Size: 6411, Test Size: 14
total step: 40100
PATH: ./Model/all_sparse_model_6.pt
Accuracy for fold 6: 57.143
F1 Score for fold 6: 0.364
Loss for fold 6: 0.759
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 22334.771484375, std: 378742.84375
Train Size: 6192, Test Size: 233
total step: 38700
PATH: ./Model/all_sparse_model_7.pt
Accuracy for fold 7: 53.648
F1 Score for fold 7: 0.354
Loss for fold 7: 0.707
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 13277.6435546875, std: 276192.71875
Train Size: 6187, Test Size: 238
total step: 38700
PATH: ./Model/all_sparse_model_8.pt
Accuracy for fold 8: 50.000
F1 Score for fold 8: 0.327
Loss for fold 8: 1.451
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 6002.78173828125, std: 54643.65234375
Train Size: 6287, Test Size: 138
total step: 39300
PATH: ./Model/all_sparse_model_9.pt
Accuracy for fold 9: 58.696
F1 Score for fold 9: 0.396
Loss for fold 9: 0.685

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 48.725348725348724, F1 32.31030330278243
Fold 1: Acc 52.05599300087489, F1 33.74884038737496
Fold 2: Acc 48.18763326226013, F1 32.35146953838556
Fold 3: Acc 52.80898876404494, F1 34.47184343212391
Fold 4: Acc 48.239148239148236, F1 32.36508504512272
Fold 5: Acc 57.14285714285714, F1 36.36363636363636
Fold 6: Acc 53.648068669527895, F1 35.36680244554848
Fold 7: Acc 50.0, F1 32.68010885986773
Fold 8: Acc 58.69565217391305, F1 39.609373986185574
Average: 52.167%
F1: 34.363%
Loss: 1.077



************************************************************
STARTING A CROSS-VALIDATION ... [100] epochs
************************************************************
TIME: 31/03/2021 22:16:47
LAYER: [Sequential(
  (0): Linear(in_features=101, out_features=24, bias=True)
  (1): ELU(alpha=1.0)
  (2): Dropout(p=0.5, inplace=False)
  (3): Linear(in_features=24, out_features=1, bias=True)
)]

STARTING TEST of 100 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 8932.974609375, std: 197833.1875
Train Size: 4346, Test Size: 2079
total step: 27200
PATH: ./Model/all_sparse_model_1.pt
Accuracy for fold 1: 45.455
F1 Score for fold 1: 0.308
Loss for fold 1: 2.254
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 10920.7529296875, std: 246943.90625
Train Size: 5282, Test Size: 1143
total step: 33100
PATH: ./Model/all_sparse_model_2.pt
Accuracy for fold 2: 53.456
F1 Score for fold 2: 0.346
Loss for fold 2: 9.024
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 29783.244140625, std: 494510.6875
Train Size: 5956, Test Size: 469
total step: 37300
PATH: ./Model/all_sparse_model_3.pt
Accuracy for fold 3: 50.320
F1 Score for fold 3: 0.332
Loss for fold 3: 0.804
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 10209.849609375, std: 171279.265625
Train Size: 5535, Test Size: 890
total step: 34600
PATH: ./Model/all_sparse_model_4.pt
Accuracy for fold 4: 52.697
F1 Score for fold 4: 0.346
Loss for fold 4: 0.712
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 6599.0302734375, std: 90755.0625
Train Size: 5204, Test Size: 1221
total step: 32600
PATH: ./Model/all_sparse_model_5.pt
Accuracy for fold 5: 48.894
F1 Score for fold 5: 0.325
Loss for fold 5: 1.926
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 18267.751953125, std: 368059.21875
Train Size: 6411, Test Size: 14
total step: 40100
PATH: ./Model/all_sparse_model_6.pt
Accuracy for fold 6: 50.000
F1 Score for fold 6: 0.333
Loss for fold 6: 0.691
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 13049.5283203125, std: 193638.265625
Train Size: 6192, Test Size: 233
total step: 38700
PATH: ./Model/all_sparse_model_7.pt
Accuracy for fold 7: 49.356
F1 Score for fold 7: 0.332
Loss for fold 7: 0.723
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 16544.677734375, std: 382418.28125
Train Size: 6187, Test Size: 238
total step: 38700
PATH: ./Model/all_sparse_model_8.pt
Accuracy for fold 8: 53.782
F1 Score for fold 8: 0.354
Loss for fold 8: 0.792
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 25241.28125, std: 584981.1875
Train Size: 6287, Test Size: 138
total step: 39300
PATH: ./Model/all_sparse_model_9.pt
Accuracy for fold 9: 51.449
F1 Score for fold 9: 0.335
Loss for fold 9: 0.710

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 45.45454545454545, F1 30.762033315577174
Fold 1: Acc 53.45581802274716, F1 34.62371830384147
Fold 2: Acc 50.31982942430704, F1 33.19359002919625
Fold 3: Acc 52.69662921348315, F1 34.56202306484212
Fold 4: Acc 48.894348894348894, F1 32.50237767476755
Fold 5: Acc 50.0, F1 33.33333333333333
Fold 6: Acc 49.35622317596567, F1 33.207934290972176
Fold 7: Acc 53.78151260504202, F1 35.42876633779081
Fold 8: Acc 51.449275362318836, F1 33.517644436358985
Average: 50.601%
F1: 33.459%
Loss: 1.960



************************************************************
STARTING A CROSS-VALIDATION ... [100] epochs
************************************************************
TIME: 31/03/2021 22:21:29
LAYER: [Sequential(
  (0): Linear(in_features=101, out_features=24, bias=True)
  (1): ELU(alpha=1.0)
  (2): Dropout(p=0.5, inplace=False)
  (3): Linear(in_features=24, out_features=1, bias=True)
)]

STARTING TEST of 100 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 6187.76416015625, std: 87369.8671875
Train Size: 4346, Test Size: 2079
total step: 27200
PATH: ./Model/all_sparse_model_1.pt