

************************************************************
STARTING A CROSS-VALIDATION ... [100] epochs
************************************************************

STARTING TEST of 100 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 0.03992735221982002, std: 0.3297499418258667
Train Size: 4346, Test Size: 2079
total step: 27200
PATH: ./Model/bert_model_1.pt
Accuracy for fold 1: 78.740
F1 Score for fold 1: 0.456
Loss for fold 1: 0.494
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 0.04004747420549393, std: 0.3307754099369049
Train Size: 5282, Test Size: 1143
total step: 33100
PATH: ./Model/bert_model_2.pt
Accuracy for fold 2: 72.441
F1 Score for fold 2: 0.435
Loss for fold 2: 0.580
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 0.03992227464914322, std: 0.33094850182533264
Train Size: 5956, Test Size: 469
total step: 37300
PATH: ./Model/bert_model_3.pt
Accuracy for fold 3: 68.657
F1 Score for fold 3: 0.415
Loss for fold 3: 0.633
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 0.039967846125364304, std: 0.3296012580394745
Train Size: 5535, Test Size: 890
total step: 34600
PATH: ./Model/bert_model_4.pt
Accuracy for fold 4: 74.607
F1 Score for fold 4: 0.444
Loss for fold 4: 0.542
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 0.03966675326228142, std: 0.3295711874961853
Train Size: 5204, Test Size: 1221
total step: 32600
PATH: ./Model/bert_model_5.pt
Accuracy for fold 5: 72.482
F1 Score for fold 5: 0.429
Loss for fold 5: 0.601
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 0.03988838568329811, std: 0.32977908849716187
Train Size: 6411, Test Size: 14
total step: 40100
PATH: ./Model/bert_model_6.pt
Accuracy for fold 6: 85.714
F1 Score for fold 6: 0.462
Loss for fold 6: 0.349
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 0.04005471244454384, std: 0.3302648663520813
Train Size: 6192, Test Size: 233
total step: 38700
PATH: ./Model/bert_model_7.pt
Accuracy for fold 7: 57.082
F1 Score for fold 7: 0.376
Loss for fold 7: 0.733
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 0.03999065235257149, std: 0.3283098638057709
Train Size: 6187, Test Size: 238
total step: 38700
PATH: ./Model/bert_model_8.pt
Accuracy for fold 8: 60.084
F1 Score for fold 8: 0.360
Loss for fold 8: 0.798
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 0.039641011506319046, std: 0.3308781385421753
Train Size: 6287, Test Size: 138
total step: 39300
PATH: ./Model/bert_model_9.pt
Accuracy for fold 9: 55.797
F1 Score for fold 9: 0.353
Loss for fold 9: 0.904

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 78.73977873977874, F1 45.625470023800524
Fold 1: Acc 72.44094488188976, F1 43.50742731422256
Fold 2: Acc 68.65671641791045, F1 41.51088821098379
Fold 3: Acc 74.6067415730337, F1 44.43060995288757
Fold 4: Acc 72.48157248157248, F1 42.85610780556853
Fold 5: Acc 85.71428571428571, F1 46.153846153846146
Fold 6: Acc 57.08154506437768, F1 37.5900551246698
Fold 7: Acc 60.08403361344538, F1 35.96407494406936
Fold 8: Acc 55.79710144927537, F1 35.321918530488155
Average: 69.511%
F1: 41.440%
Loss: 0.626

