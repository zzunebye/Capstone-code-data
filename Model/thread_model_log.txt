

************************************************************
STARTING A CROSS-VALIDATION ... [100] epochs
************************************************************

STARTING TEST of 100 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: -0.04096132889389992, std: 0.8903726935386658
Train Size: 4346, Test Size: 2079
total step: 27200
PATH: ./Model/thread_model_1.pt

************************************************************
STARTING A CROSS-VALIDATION ... [100] epochs
************************************************************

STARTING TEST of 100 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 5252.51318359375, std: 58722.1171875
Train Size: 4346, Test Size: 2079
total step: 27200
PATH: ./Model/thread_model_1.pt
Accuracy for fold 1: 50.216
F1 Score for fold 1: 0.329
Loss for fold 1: 1.841
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 2169.268310546875, std: 15569.9794921875
Train Size: 5282, Test Size: 1143
total step: 33100
PATH: ./Model/thread_model_2.pt
Accuracy for fold 2: 62.817
F1 Score for fold 2: 0.384
Loss for fold 2: 4.630
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 3700.199462890625, std: 33325.33984375
Train Size: 5956, Test Size: 469
total step: 37300
PATH: ./Model/thread_model_3.pt
Accuracy for fold 3: 54.371
F1 Score for fold 3: 0.352
Loss for fold 3: 0.703
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 5871.48876953125, std: 66131.734375
Train Size: 5535, Test Size: 890
total step: 34600
PATH: ./Model/thread_model_4.pt
Accuracy for fold 4: 53.933
F1 Score for fold 4: 0.346
Loss for fold 4: 1.272
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 8413.00390625, std: 111157.2109375
Train Size: 5204, Test Size: 1221
total step: 32600
PATH: ./Model/thread_model_5.pt
Accuracy for fold 5: 50.287
F1 Score for fold 5: 0.331
Loss for fold 5: 1.523
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 5348.88720703125, std: 51999.0703125
Train Size: 6411, Test Size: 14
total step: 40100
PATH: ./Model/thread_model_6.pt
Accuracy for fold 6: 42.857
F1 Score for fold 6: 0.300
Loss for fold 6: 0.668
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 3649.062255859375, std: 32766.166015625
Train Size: 6192, Test Size: 233
total step: 38700
PATH: ./Model/thread_model_7.pt
Accuracy for fold 7: 52.361
F1 Score for fold 7: 0.350
Loss for fold 7: 0.685
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 4467.9306640625, std: 52606.93359375
Train Size: 6187, Test Size: 238
total step: 38700
PATH: ./Model/thread_model_8.pt
Accuracy for fold 8: 52.101
F1 Score for fold 8: 0.343
Loss for fold 8: 0.705
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 3606.45654296875, std: 33703.24609375
Train Size: 6287, Test Size: 138
total step: 39300
PATH: ./Model/thread_model_9.pt
Accuracy for fold 9: 45.652
F1 Score for fold 9: 0.320
Loss for fold 9: 0.706

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 50.21645021645021, F1 32.85937042007104
Fold 1: Acc 62.81714785651793, F1 38.38212908520217
Fold 2: Acc 54.37100213219617, F1 35.23819065111948
Fold 3: Acc 53.93258426966292, F1 34.59183329756838
Fold 4: Acc 50.28665028665029, F1 33.0809428090835
Fold 5: Acc 42.857142857142854, F1 30.0
Fold 6: Acc 52.36051502145923, F1 35.000285453651045
Fold 7: Acc 52.10084033613446, F1 34.252884640900724
Fold 8: Acc 45.65217391304348, F1 31.958550991085065
Average: 51.622%
F1: 33.929%
Loss: 1.415



************************************************************
STARTING A CROSS-VALIDATION ... [100] epochs
************************************************************

STARTING TEST of 100 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 9416.568359375, std: 151986.8125
Train Size: 4346, Test Size: 2079
total step: 27200
PATH: ./Model/thread_model_1.pt
Accuracy for fold 1: 59.548
F1 Score for fold 1: 0.369
Loss for fold 1: 21.665
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 2020.333251953125, std: 17211.255859375
Train Size: 5282, Test Size: 1143
total step: 33100
PATH: ./Model/thread_model_2.pt
Accuracy for fold 2: 45.057
F1 Score for fold 2: 0.305
Loss for fold 2: 0.903
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 2119.792236328125, std: 16210.62109375
Train Size: 5956, Test Size: 469
total step: 37300
PATH: ./Model/thread_model_3.pt
Accuracy for fold 3: 51.812
F1 Score for fold 3: 0.335
Loss for fold 3: 0.784
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 4711.14599609375, std: 35888.67578125
Train Size: 5535, Test Size: 890
total step: 34600
PATH: ./Model/thread_model_4.pt
Accuracy for fold 4: 49.551
F1 Score for fold 4: 0.327
Loss for fold 4: 0.753
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 2381.95458984375, std: 17284.845703125
Train Size: 5204, Test Size: 1221
total step: 32600
PATH: ./Model/thread_model_5.pt
Accuracy for fold 5: 49.386
F1 Score for fold 5: 0.320
Loss for fold 5: 2.775
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 3404.647216796875, std: 34907.62890625
Train Size: 6411, Test Size: 14
total step: 40100
PATH: ./Model/thread_model_6.pt
Accuracy for fold 6: 28.571
F1 Score for fold 6: 0.222
Loss for fold 6: 0.777
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 4691.6650390625, std: 42294.83984375
Train Size: 6192, Test Size: 233
total step: 38700
PATH: ./Model/thread_model_7.pt
Accuracy for fold 7: 47.210
F1 Score for fold 7: 0.316
Loss for fold 7: 0.719
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 1986.712158203125, std: 19518.048828125
Train Size: 6187, Test Size: 238
total step: 38700
PATH: ./Model/thread_model_8.pt
Accuracy for fold 8: 53.782
F1 Score for fold 8: 0.346
Loss for fold 8: 1.106
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 7090.25341796875, std: 69226.0
Train Size: 6287, Test Size: 138
total step: 39300
PATH: ./Model/thread_model_9.pt
Accuracy for fold 9: 49.275
F1 Score for fold 9: 0.323
Loss for fold 9: 0.730

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 59.54785954785955, F1 36.87105865028383
Fold 1: Acc 45.05686789151356, F1 30.541001524879384
Fold 2: Acc 51.812366737739865, F1 33.537042873030714
Fold 3: Acc 49.550561797752806, F1 32.74463014794694
Fold 4: Acc 49.385749385749385, F1 32.025633464306
Fold 5: Acc 28.57142857142857, F1 22.222222222222225
Fold 6: Acc 47.21030042918455, F1 31.605923455988766
Fold 7: Acc 53.78151260504202, F1 34.58108832533385
Fold 8: Acc 49.275362318840585, F1 32.31862761077102
Average: 48.244%
F1: 31.827%
Loss: 3.357



************************************************************
STARTING A CROSS-VALIDATION ... [100] epochs
************************************************************

STARTING TEST of 100 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 2233.407958984375, std: 14519.87890625
Train Size: 4346, Test Size: 2079
total step: 27200
PATH: ./Model/thread_model_1.pt
Accuracy for fold 1: 67.581
F1 Score for fold 1: 0.398
Loss for fold 1: 0.707
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 3285.93603515625, std: 26265.107421875
Train Size: 5282, Test Size: 1143
total step: 33100
PATH: ./Model/thread_model_2.pt
Accuracy for fold 2: 46.982
F1 Score for fold 2: 0.316
Loss for fold 2: 4.515
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 2243.55029296875, std: 18500.79296875
Train Size: 5956, Test Size: 469
total step: 37300
PATH: ./Model/thread_model_3.pt
Accuracy for fold 3: 47.122
F1 Score for fold 3: 0.320
Loss for fold 3: 0.734
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 2002.2689208984375, std: 13732.0478515625
Train Size: 5535, Test Size: 890
total step: 34600
PATH: ./Model/thread_model_4.pt
Accuracy for fold 4: 47.640
F1 Score for fold 4: 0.317
Loss for fold 4: 0.736
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 2789.60009765625, std: 23484.24609375
Train Size: 5204, Test Size: 1221
total step: 32600
PATH: ./Model/thread_model_5.pt
Accuracy for fold 5: 49.058
F1 Score for fold 5: 0.327
Loss for fold 5: 0.718
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 3426.75537109375, std: 27412.267578125
Train Size: 6411, Test Size: 14
total step: 40100
PATH: ./Model/thread_model_6.pt
Accuracy for fold 6: 64.286
F1 Score for fold 6: 0.391
Loss for fold 6: 0.700
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 4262.46923828125, std: 74537.421875
Train Size: 6192, Test Size: 233
total step: 38700
PATH: ./Model/thread_model_7.pt
Accuracy for fold 7: 27.468
F1 Score for fold 7: 0.210
Loss for fold 7: 0.831
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 3402.080810546875, std: 32714.830078125
Train Size: 6187, Test Size: 238
total step: 38700
PATH: ./Model/thread_model_8.pt
Accuracy for fold 8: 48.739
F1 Score for fold 8: 0.329
Loss for fold 8: 0.697
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 3325.291259765625, std: 30482.400390625
Train Size: 6287, Test Size: 138
total step: 39300
PATH: ./Model/thread_model_9.pt
Accuracy for fold 9: 50.725
F1 Score for fold 9: 0.341
Loss for fold 9: 0.722

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 67.58056758056759, F1 39.78249548880382
Fold 1: Acc 46.981627296587924, F1 31.569407462624575
Fold 2: Acc 47.12153518123667, F1 31.982298435575522
Fold 3: Acc 47.640449438202246, F1 31.651890059007773
Fold 4: Acc 49.058149058149056, F1 32.65980834557908
Fold 5: Acc 64.28571428571429, F1 39.130434782608695
Fold 6: Acc 27.467811158798284, F1 21.032759985235412
Fold 7: Acc 48.739495798319325, F1 32.88815710737523
Fold 8: Acc 50.72463768115942, F1 34.09663173998398
Average: 49.956%
F1: 32.755%
Loss: 1.151



************************************************************
STARTING A CROSS-VALIDATION ... [100] epochs
************************************************************

STARTING TEST of 100 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 1652.353271484375, std: 10731.3203125
Train Size: 4346, Test Size: 2079
total step: 27200
PATH: ./Model/thread_model_1.pt
Accuracy for fold 1: 47.282
F1 Score for fold 1: 0.316
Loss for fold 1: 6.250
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 8198.57421875, std: 107628.6640625
Train Size: 5282, Test Size: 1143
total step: 33100
PATH: ./Model/thread_model_2.pt
Accuracy for fold 2: 48.294
F1 Score for fold 2: 0.324
Loss for fold 2: 0.859
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 5660.1689453125, std: 61845.77734375
Train Size: 5956, Test Size: 469
total step: 37300
PATH: ./Model/thread_model_3.pt
Accuracy for fold 3: 51.386
F1 Score for fold 3: 0.320
Loss for fold 3: 0.692
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 6880.8017578125, std: 79488.6640625
Train Size: 5535, Test Size: 890
total step: 34600
PATH: ./Model/thread_model_4.pt
Accuracy for fold 4: 48.090
F1 Score for fold 4: 0.321
Loss for fold 4: 0.929
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 4513.76123046875, std: 54193.4140625
Train Size: 5204, Test Size: 1221
total step: 32600
PATH: ./Model/thread_model_5.pt
Accuracy for fold 5: 47.502
F1 Score for fold 5: 0.315
Loss for fold 5: 0.713
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 3830.815185546875, std: 30881.380859375
Train Size: 6411, Test Size: 14
total step: 40100
PATH: ./Model/thread_model_6.pt
Accuracy for fold 6: 71.429
F1 Score for fold 6: 0.417
Loss for fold 6: 0.663
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 6445.51025390625, std: 117366.2734375
Train Size: 6192, Test Size: 233
total step: 38700
PATH: ./Model/thread_model_7.pt
Accuracy for fold 7: 25.322
F1 Score for fold 7: 0.201
Loss for fold 7: 0.800
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 4403.1630859375, std: 43682.5
Train Size: 6187, Test Size: 238
total step: 38700
PATH: ./Model/thread_model_8.pt
Accuracy for fold 8: 50.420
F1 Score for fold 8: 0.341
Loss for fold 8: 2.300
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 4213.6865234375, std: 41518.80078125
Train Size: 6287, Test Size: 138
total step: 39300
PATH: ./Model/thread_model_9.pt
Accuracy for fold 9: 52.899
F1 Score for fold 9: 0.350
Loss for fold 9: 0.726

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 47.28234728234728, F1 31.62013639696868
Fold 1: Acc 48.29396325459317, F1 32.42254730770839
Fold 2: Acc 51.385927505330486, F1 31.969071745014045
Fold 3: Acc 48.08988764044943, F1 32.145549513960276
Fold 4: Acc 47.5020475020475, F1 31.516886768328035
Fold 5: Acc 71.42857142857143, F1 41.666666666666664
Fold 6: Acc 25.321888412017167, F1 20.122961232463084
Fold 7: Acc 50.42016806722689, F1 34.062791239261834
Fold 8: Acc 52.89855072463768, F1 35.038260719420144
Average: 49.180%
F1: 32.285%
Loss: 1.548



************************************************************
STARTING A CROSS-VALIDATION ... [100] epochs
************************************************************
TIME: 31/03/2021 17:35:34
LAYER: [Sequential(
  (0): Linear(in_features=52, out_features=12, bias=True)
  (1): ELU(alpha=1.0)
  (2): Dropout(p=0.5, inplace=False)
  (3): Linear(in_features=12, out_features=8, bias=True)
  (4): ELU(alpha=1.0)
  (5): Dropout(p=0.5, inplace=False)
  (6): Linear(in_features=8, out_features=1, bias=True)
)]

STARTING TEST of 100 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 6276.50341796875, std: 73412.59375
Train Size: 4346, Test Size: 2079
total step: 27200
PATH: ./Model/thread_model_1.pt
Accuracy for fold 1: 47.138
F1 Score for fold 1: 0.315
Loss for fold 1: 41.377
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 3382.296875, std: 35671.8046875
Train Size: 5282, Test Size: 1143
total step: 33100
PATH: ./Model/thread_model_2.pt
Accuracy for fold 2: 50.831
F1 Score for fold 2: 0.334
Loss for fold 2: 3.596
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 3273.20166015625, std: 22619.671875
Train Size: 5956, Test Size: 469
total step: 37300
PATH: ./Model/thread_model_3.pt
Accuracy for fold 3: 49.893
F1 Score for fold 3: 0.334
Loss for fold 3: 1.118
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 3725.86767578125, std: 29656.4296875
Train Size: 5535, Test Size: 890
total step: 34600
PATH: ./Model/thread_model_4.pt
Accuracy for fold 4: 54.831
F1 Score for fold 4: 0.350
Loss for fold 4: 0.701
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 5077.9658203125, std: 58702.8046875
Train Size: 5204, Test Size: 1221
total step: 32600
PATH: ./Model/thread_model_5.pt
Accuracy for fold 5: 50.860
F1 Score for fold 5: 0.323
Loss for fold 5: 0.756
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 2779.0673828125, std: 38529.80859375
Train Size: 6411, Test Size: 14
total step: 40100
PATH: ./Model/thread_model_6.pt
Accuracy for fold 6: 35.714
F1 Score for fold 6: 0.263
Loss for fold 6: 0.762
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 5883.55908203125, std: 69633.7109375
Train Size: 6192, Test Size: 233
total step: 38700
PATH: ./Model/thread_model_7.pt
Accuracy for fold 7: 61.803
F1 Score for fold 7: 0.384
Loss for fold 7: 0.682
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 4875.990234375, std: 49363.1484375
Train Size: 6187, Test Size: 238
total step: 38700
PATH: ./Model/thread_model_8.pt
Accuracy for fold 8: 53.782
F1 Score for fold 8: 0.344
Loss for fold 8: 0.690
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 4047.944091796875, std: 36099.7265625
Train Size: 6287, Test Size: 138
total step: 39300
PATH: ./Model/thread_model_9.pt
Accuracy for fold 9: 41.304
F1 Score for fold 9: 0.277
Loss for fold 9: 0.790

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 47.13804713804714, F1 31.492301793395505
Fold 1: Acc 50.83114610673666, F1 33.395593256393816
Fold 2: Acc 49.89339019189765, F1 33.432143102604144
Fold 3: Acc 54.831460674157306, F1 35.03986478118473
Fold 4: Acc 50.859950859950864, F1 32.33310015087067
Fold 5: Acc 35.714285714285715, F1 26.315789473684212
Fold 6: Acc 61.80257510729614, F1 38.38371599404602
Fold 7: Acc 53.78151260504202, F1 34.36717411499769
Fold 8: Acc 41.30434782608695, F1 27.720312525873137
Average: 49.573%
F1: 32.498%
Loss: 5.608

RESULT:
Average: 49.57%
F1: 32.50%
Loss: 5.61


************************************************************
STARTING A CROSS-VALIDATION ... [100] epochs
************************************************************
TIME: 31/03/2021 17:38:58
LAYER: [Sequential(
  (0): Linear(in_features=52, out_features=8, bias=True)
  (1): ELU(alpha=1.0)
  (2): Dropout(p=0.5, inplace=False)
  (3): Linear(in_features=8, out_features=1, bias=True)
)]

STARTING TEST of 100 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 2218.407958984375, std: 27374.849609375
Train Size: 4346, Test Size: 2079
total step: 27200
PATH: ./Model/thread_model_1.pt
Accuracy for fold 1: 26.407
F1 Score for fold 1: 0.192
Loss for fold 1: 4.071
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 2988.001708984375, std: 25369.9296875
Train Size: 5282, Test Size: 1143
total step: 33100
PATH: ./Model/thread_model_2.pt
Accuracy for fold 2: 50.044
F1 Score for fold 2: 0.329
Loss for fold 2: 38.897
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 2779.08154296875, std: 25266.849609375
Train Size: 5956, Test Size: 469
total step: 37300
PATH: ./Model/thread_model_3.pt
Accuracy for fold 3: 50.320
F1 Score for fold 3: 0.326
Loss for fold 3: 0.715
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 4095.23388671875, std: 45379.8046875
Train Size: 5535, Test Size: 890
total step: 34600
PATH: ./Model/thread_model_4.pt
Accuracy for fold 4: 52.584
F1 Score for fold 4: 0.340
Loss for fold 4: 0.701
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 2340.610595703125, std: 16358.943359375
Train Size: 5204, Test Size: 1221
total step: 32600
PATH: ./Model/thread_model_5.pt
Accuracy for fold 5: 50.123
F1 Score for fold 5: 0.329
Loss for fold 5: 1.297
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 2168.1513671875, std: 14720.2724609375
Train Size: 6411, Test Size: 14
total step: 40100
PATH: ./Model/thread_model_6.pt
Accuracy for fold 6: 50.000
F1 Score for fold 6: 0.333
Loss for fold 6: 0.682
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 2994.467041015625, std: 25774.3984375
Train Size: 6192, Test Size: 233
total step: 38700
PATH: ./Model/thread_model_7.pt
Accuracy for fold 7: 58.369
F1 Score for fold 7: 0.371
Loss for fold 7: 0.688
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 7652.109375, std: 105651.640625
Train Size: 6187, Test Size: 238
total step: 38700
PATH: ./Model/thread_model_8.pt
Accuracy for fold 8: 52.941
F1 Score for fold 8: 0.342
Loss for fold 8: 0.704
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 3234.190185546875, std: 32006.470703125
Train Size: 6287, Test Size: 138
total step: 39300
PATH: ./Model/thread_model_9.pt
Accuracy for fold 9: 46.377
F1 Score for fold 9: 0.313
Loss for fold 9: 0.741

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 26.406926406926406, F1 19.23877325870914
Fold 1: Acc 50.04374453193351, F1 32.93130391109333
Fold 2: Acc 50.31982942430704, F1 32.582826883490945
Fold 3: Acc 52.58426966292134, F1 34.01825033518281
Fold 4: Acc 50.122850122850124, F1 32.90094797365563
Fold 5: Acc 50.0, F1 33.33333333333333
Fold 6: Acc 58.36909871244635, F1 37.08128303313973
Fold 7: Acc 52.94117647058824, F1 34.20872489326497
Fold 8: Acc 46.3768115942029, F1 31.313884183449403
Average: 48.574%
F1: 31.957%
Loss: 5.389

RESULT:
Average: 48.57%
F1: 31.96%
Loss: 5.39


************************************************************
STARTING A CROSS-VALIDATION ... [100] epochs
************************************************************
TIME: 31/03/2021 19:43:59
LAYER: [Sequential(
  (0): Linear(in_features=52, out_features=12, bias=True)
  (1): ELU(alpha=1.0)
  (2): Dropout(p=0.5, inplace=False)
  (3): Linear(in_features=12, out_features=1, bias=True)
)]

STARTING TEST of 100 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 2309.717041015625, std: 16357.2470703125
Train Size: 4346, Test Size: 2079
total step: 27200
PATH: ./Model/thread_model_1.pt
Accuracy for fold 1: 71.573
F1 Score for fold 1: 0.449
Loss for fold 1: 1.179
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 3065.073974609375, std: 41932.11328125
Train Size: 5282, Test Size: 1143
total step: 33100
PATH: ./Model/thread_model_2.pt
Accuracy for fold 2: 51.706
F1 Score for fold 2: 0.339
Loss for fold 2: 9.416
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 4082.15234375, std: 34203.9375
Train Size: 5956, Test Size: 469
total step: 37300
PATH: ./Model/thread_model_3.pt
Accuracy for fold 3: 48.401
F1 Score for fold 3: 0.325
Loss for fold 3: 0.939
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 6079.896484375, std: 72986.421875
Train Size: 5535, Test Size: 890
total step: 34600
PATH: ./Model/thread_model_4.pt
Accuracy for fold 4: 49.326
F1 Score for fold 4: 0.326
Loss for fold 4: 0.810
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 4489.58251953125, std: 45543.953125
Train Size: 5204, Test Size: 1221
total step: 32600
PATH: ./Model/thread_model_5.pt
Accuracy for fold 5: 47.584
F1 Score for fold 5: 0.317
Loss for fold 5: 3.898
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 3317.09619140625, std: 23526.96484375
Train Size: 6411, Test Size: 14
total step: 40100
PATH: ./Model/thread_model_6.pt
Accuracy for fold 6: 35.714
F1 Score for fold 6: 0.263
Loss for fold 6: 0.769
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 3409.818603515625, std: 24966.7890625
Train Size: 6192, Test Size: 233
total step: 38700
PATH: ./Model/thread_model_7.pt
Accuracy for fold 7: 48.498
F1 Score for fold 7: 0.321
Loss for fold 7: 0.942
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 5270.9443359375, std: 54121.23828125
Train Size: 6187, Test Size: 238
total step: 38700
PATH: ./Model/thread_model_8.pt
Accuracy for fold 8: 52.101
F1 Score for fold 8: 0.339
Loss for fold 8: 1.422
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 4257.63037109375, std: 43257.109375
Train Size: 6287, Test Size: 138
total step: 39300
PATH: ./Model/thread_model_9.pt
Accuracy for fold 9: 45.652
F1 Score for fold 9: 0.309
Loss for fold 9: 0.746

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 71.57287157287158, F1 44.937620342028154
Fold 1: Acc 51.70603674540683, F1 33.93975225587634
Fold 2: Acc 48.40085287846482, F1 32.49723346946856
Fold 3: Acc 49.325842696629216, F1 32.63985663411781
Fold 4: Acc 47.583947583947584, F1 31.74337249047859
Fold 5: Acc 35.714285714285715, F1 26.315789473684212
Fold 6: Acc 48.497854077253216, F1 32.114030592851265
Fold 7: Acc 52.10084033613446, F1 33.949018869734985
Fold 8: Acc 45.65217391304348, F1 30.851795547447722
Average: 50.062%
F1: 33.221%
Loss: 2.236

RESULT:
Average: 50.06%
F1: 33.22%
Loss: 2.24


************************************************************
STARTING A CROSS-VALIDATION ... [100] epochs
************************************************************
TIME: 31/03/2021 22:21:44
LAYER: [Sequential(
  (0): Linear(in_features=52, out_features=12, bias=True)
  (1): ELU(alpha=1.0)
  (2): Dropout(p=0.5, inplace=False)
  (3): Linear(in_features=12, out_features=1, bias=True)
)]

STARTING TEST of 100 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 1513.3990478515625, std: 9209.28125
Train Size: 4346, Test Size: 2079
total step: 27200
PATH: ./Model/thread_model_1.pt
Accuracy for fold 1: 53.776
F1 Score for fold 1: 0.344
Loss for fold 1: 0.842
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 3458.050537109375, std: 31953.384765625
Train Size: 5282, Test Size: 1143
total step: 33100
PATH: ./Model/thread_model_2.pt
Accuracy for fold 2: 48.906
F1 Score for fold 2: 0.328
Loss for fold 2: 4.360
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 2396.5078125, std: 27343.39453125
Train Size: 5956, Test Size: 469
total step: 37300
PATH: ./Model/thread_model_3.pt
Accuracy for fold 3: 50.533
F1 Score for fold 3: 0.335
Loss for fold 3: 0.712
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 3576.190185546875, std: 32742.845703125
Train Size: 5535, Test Size: 890
total step: 34600
PATH: ./Model/thread_model_4.pt
Accuracy for fold 4: 50.899
F1 Score for fold 4: 0.336
Loss for fold 4: 0.708
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 8217.3974609375, std: 165216.734375
Train Size: 5204, Test Size: 1221
total step: 32600
PATH: ./Model/thread_model_5.pt
Accuracy for fold 5: 50.696
F1 Score for fold 5: 0.334
Loss for fold 5: 0.732
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 3772.12744140625, std: 37585.75
Train Size: 6411, Test Size: 14
total step: 40100
PATH: ./Model/thread_model_6.pt
Accuracy for fold 6: 35.714
F1 Score for fold 6: 0.263
Loss for fold 6: 0.751
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 3529.4970703125, std: 28442.146484375
Train Size: 6192, Test Size: 233
total step: 38700
PATH: ./Model/thread_model_7.pt
Accuracy for fold 7: 66.953
F1 Score for fold 7: 0.412
Loss for fold 7: 1.375
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 4592.0126953125, std: 50946.26171875
Train Size: 6187, Test Size: 238
total step: 38700
PATH: ./Model/thread_model_8.pt
Accuracy for fold 8: 47.479
F1 Score for fold 8: 0.318
Loss for fold 8: 0.821
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 2664.506103515625, std: 19139.0390625
Train Size: 6287, Test Size: 138
total step: 39300
PATH: ./Model/thread_model_9.pt
Accuracy for fold 9: 55.072
F1 Score for fold 9: 0.357
Loss for fold 9: 0.783

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 53.775853775853776, F1 34.449838549715246
Fold 1: Acc 48.90638670166229, F1 32.82115447360467
Fold 2: Acc 50.53304904051173, F1 33.530573241707
Fold 3: Acc 50.89887640449439, F1 33.58396452639668
Fold 4: Acc 50.696150696150696, F1 33.384228294568565
Fold 5: Acc 35.714285714285715, F1 26.315789473684212
Fold 6: Acc 66.95278969957081, F1 41.24797778260853
Fold 7: Acc 47.47899159663865, F1 31.764306705407577
Fold 8: Acc 55.072463768115945, F1 35.74230385824589
Average: 51.114%
F1: 33.649%
Loss: 1.232

RESULT:
Average: 51.11%
F1: 33.65%
Loss: 1.23
