

************************************************************
STARTING A CROSS-VALIDATION ... [150] epochs
************************************************************
TIME: 03/04/2021 14:43:26
LAYER: [Sequential(
  (0): Linear(in_features=52, out_features=10, bias=True)
  (1): ELU(alpha=1.0)
  (2): Dropout(p=0.5, inplace=False)
  (3): Linear(in_features=10, out_features=4, bias=True)
  (4): ELU(alpha=1.0)
  (5): Dropout(p=0.5, inplace=False)
  (6): Linear(in_features=4, out_features=1, bias=True)
)]

STARTING TEST of 150 EPOCH


----------------------------------------------------------------------------
> FOLD 1
----------------------------------------------------------------------------
mean: 5618.32861328125, std: 37102.53515625
Train Size: 4346, Test Size: 2079
total step: 81600
PATH: ./Model/thread_model_1.pt
Accuracy for fold 1: 48.581
F1 Score for fold 1: 0.318
Loss for fold 1: 220.112
----------------------------------------------------------------------------
> FOLD 2
----------------------------------------------------------------------------
mean: 4924.4052734375, std: 42548.64453125
Train Size: 5282, Test Size: 1143
total step: 99150
PATH: ./Model/thread_model_2.pt
Accuracy for fold 2: 50.481
F1 Score for fold 2: 0.331
Loss for fold 2: 12.150
----------------------------------------------------------------------------
> FOLD 3
----------------------------------------------------------------------------
mean: 6316.24169921875, std: 54435.52734375
Train Size: 5956, Test Size: 469
total step: 111750
PATH: ./Model/thread_model_3.pt
Accuracy for fold 3: 48.614
F1 Score for fold 3: 0.319
Loss for fold 3: 35.765
----------------------------------------------------------------------------
> FOLD 4
----------------------------------------------------------------------------
mean: 3660.19775390625, std: 50473.77734375
Train Size: 5535, Test Size: 890
total step: 103800
PATH: ./Model/thread_model_4.pt
Accuracy for fold 4: 50.000
F1 Score for fold 4: 0.345
Loss for fold 4: 9.925
----------------------------------------------------------------------------
> FOLD 5
----------------------------------------------------------------------------
mean: 4382.771484375, std: 32723.47265625
Train Size: 5204, Test Size: 1221
total step: 97650
PATH: ./Model/thread_model_5.pt
Accuracy for fold 5: 49.713
F1 Score for fold 5: 0.326
Loss for fold 5: 3.590
----------------------------------------------------------------------------
> FOLD 6
----------------------------------------------------------------------------
mean: 4817.048828125, std: 45221.3359375
Train Size: 6411, Test Size: 14
total step: 120300
PATH: ./Model/thread_model_6.pt
Accuracy for fold 6: 85.714
F1 Score for fold 6: 0.461
Loss for fold 6: 0.582
----------------------------------------------------------------------------
> FOLD 7
----------------------------------------------------------------------------
mean: 1475.84326171875, std: 6637.95849609375
Train Size: 6192, Test Size: 233
total step: 116100
PATH: ./Model/thread_model_7.pt
Accuracy for fold 7: 13.734
F1 Score for fold 7: 0.112
Loss for fold 7: 1.071
----------------------------------------------------------------------------
> FOLD 8
----------------------------------------------------------------------------
mean: 4526.6923828125, std: 39593.875
Train Size: 6187, Test Size: 238
total step: 116100
PATH: ./Model/thread_model_8.pt
Accuracy for fold 8: 46.218
F1 Score for fold 8: 0.310
Loss for fold 8: 2.650
----------------------------------------------------------------------------
> FOLD 9
----------------------------------------------------------------------------
mean: 2144.964111328125, std: 14002.3173828125
Train Size: 6287, Test Size: 138
total step: 117900
PATH: ./Model/thread_model_9.pt
Accuracy for fold 9: 56.522
F1 Score for fold 9: 0.366
Loss for fold 9: 0.683

----------------------------------------------------------------------------
>>>K-FOLD CROSS VALIDATION RESULTS FOR 9 FOLDS
----------------------------------------------------------------------------
Fold 0: Acc 48.58104858104858, F1 31.756163242454747
Fold 1: Acc 50.481189851268596, F1 33.09178135949793
Fold 2: Acc 48.61407249466951, F1 31.91470457994979
Fold 3: Acc 50.0, F1 34.45572654561416
Fold 4: Acc 49.713349713349714, F1 32.62727262727269
Fold 5: Acc 85.71428571428571, F1 46.147186147186154
Fold 6: Acc 13.733905579399142, F1 11.229028482247369
Fold 7: Acc 46.21848739495798, F1 31.035145993129195
Fold 8: Acc 56.52173913043478, F1 36.55291568335046
Average: 49.953%
F1: 32.090%
Loss: 31.837

RESULT:
Average: 49.95%
F1: 32.09%
Loss: 31.84
