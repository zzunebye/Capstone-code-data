{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "venv",
   "display_name": "x86VenvTest",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Implementing BERTweet\n",
    "    이 노트북은 Huggingface의 BERTweet 모델을 이용해 기존 raw data를 BERTweet 벡터 결과물로 변환하는 코드이다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Import Libraries and Pretrained model "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer \n",
    "import logging"
   ]
  },
  {
   "source": [
    "# text:{BREAKING: Armed man takes hostage in ...} text_token: {['breaking', 'armed',...]}\n",
    "raw_text = pd.read_csv('./data/raw_text_tokens.csv')"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "### 밑의 코드는 아래와 같은 결과를 출력한다.\n",
    "\n",
    "    'BREAKING: Armed man takes hostage in kosher grocery east of Paris http://t.co/PBs3sMwhLt'\n",
    "    \n",
    "=> *BaseModelOutputWithPoolingAndCrossAttentions*\n",
    "- 이 객체는 last_hidden_state와 pooler_output 텐서를 보유한다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'BREAKING: Armed man takes hostage in kosher grocery east of Paris http://t.co/PBs3sMwhLt'"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "raw_text.text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n",
      "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.0480,  0.3487,  0.1595,  ..., -0.0423, -0.3147, -0.0868],\n",
      "         [ 0.1590, -0.0998,  0.3287,  ..., -0.3114, -0.2305, -0.0202],\n",
      "         [ 0.2081,  0.0818,  0.4836,  ..., -0.0545, -0.0031, -0.1902],\n",
      "         ...,\n",
      "         [-0.3463,  0.2122,  0.0758,  ...,  0.2262, -0.4408, -0.0811],\n",
      "         [-0.0756, -0.1232, -0.0746,  ...,  0.0938,  0.0649, -0.0071],\n",
      "         [-0.0688,  0.3809,  0.1822,  ..., -0.0761, -0.2949, -0.0837]]]), pooler_output=tensor([[ 2.8395e-01, -1.5147e-01,  2.4038e-02, -2.1575e-01,  2.1765e-02,\n",
      "         -1.5563e-01,  1.0030e-01, -9.7862e-02,  2.0039e-01, -1.8787e-01,\n",
      "          1.9666e-02, -4.1347e-02, -1.3147e-01,  3.1222e-02,  2.9899e-01,\n",
      "         -1.3644e-01, -2.3771e-01, -4.6295e-02,  6.6188e-02,  2.8947e-03,\n",
      "         -1.7158e-01, -9.1481e-02,  2.9454e-01,  7.3388e-02,  2.1981e-04,\n",
      "          3.0350e-02, -2.5320e-01, -3.4750e-02,  1.7135e-01, -7.9902e-02,\n",
      "         -1.5119e-03, -1.7464e-01,  1.0034e-01,  1.8144e-01,  1.5433e-01,\n",
      "         -8.8051e-02,  2.0611e-01,  4.3127e-02, -1.2707e-02,  6.6236e-02,\n",
      "         -1.5027e-01, -6.6082e-02,  7.9277e-02, -1.1644e-01,  9.8845e-04,\n",
      "         -4.9513e-03, -1.6267e-01,  3.8820e-02,  4.4528e-01, -8.2403e-02,\n",
      "         -2.9459e-02,  1.3415e-01, -3.7619e-02, -6.9443e-02, -6.8385e-03,\n",
      "          9.6964e-02, -8.8030e-03, -4.7601e-02, -2.3799e-01,  1.8214e-01,\n",
      "         -4.3444e-02,  3.6343e-01, -2.2037e-01, -4.0540e-01, -1.5871e-01,\n",
      "         -2.7480e-01, -1.2169e-02,  8.9949e-02,  4.3174e-01,  2.4880e-01,\n",
      "          2.5374e-01,  8.7878e-02, -1.9735e-01, -2.7122e-02, -2.0267e-01,\n",
      "         -1.6815e-01, -5.0042e-03, -8.4998e-02,  1.3522e-01,  4.2522e-02,\n",
      "          7.8119e-02, -3.6897e-01,  2.3451e-01, -1.5933e-01, -2.6342e-01,\n",
      "          2.7039e-01,  1.7785e-01,  1.5066e-01, -1.7975e-02,  2.4644e-01,\n",
      "         -2.5951e-02, -1.2625e-02, -1.0192e-01, -1.0941e-01, -2.0698e-01,\n",
      "         -1.0087e-01,  4.0336e-02,  2.0282e-01, -8.0349e-02, -9.2250e-02,\n",
      "         -1.7426e-01,  5.6315e-02, -3.8727e-02,  6.2713e-02, -1.9911e-02,\n",
      "         -1.2705e-01,  1.1257e-02,  2.1053e-01,  5.1661e-02, -1.6080e-01,\n",
      "         -6.3943e-02, -8.5894e-02, -2.3986e-01, -9.9872e-02,  2.9288e-01,\n",
      "          1.4143e-02, -2.1093e-01,  1.8583e-01,  2.6866e-01, -6.1501e-03,\n",
      "         -2.1864e-02,  3.2791e-01,  2.1102e-01,  2.1576e-01,  1.1626e-01,\n",
      "         -1.0148e-01, -8.0364e-02,  5.1362e-02,  8.7376e-02, -2.9187e-01,\n",
      "          7.2969e-02, -1.1547e-01,  7.3518e-02, -2.1221e-01,  1.0846e-01,\n",
      "         -2.5473e-02,  1.4527e-01,  1.1647e-02,  1.4246e-01,  1.6319e-01,\n",
      "         -1.2192e-02, -1.9795e-01, -2.2932e-02,  4.1528e-01,  6.0398e-02,\n",
      "          2.5241e-01, -7.1646e-02,  1.7291e-01, -1.3608e-01,  1.1868e-01,\n",
      "          1.0628e-01, -7.3167e-02, -1.0881e-01,  1.0680e-01, -7.2692e-02,\n",
      "         -8.7255e-02,  1.3981e-02,  7.0927e-02,  8.6266e-02, -6.9877e-02,\n",
      "          2.0978e-01, -2.1859e-01,  5.7888e-02, -5.0730e-02,  1.5676e-01,\n",
      "         -8.0934e-03, -1.9406e-01, -9.1567e-02, -8.1348e-02, -3.9332e-02,\n",
      "         -1.5751e-01, -8.1736e-02, -6.0732e-01, -3.2790e-01,  1.2912e-01,\n",
      "          1.7100e-01, -9.9248e-02,  1.1852e-01,  2.3223e-01,  1.9500e-02,\n",
      "         -8.6336e-03,  2.0510e-01, -2.1640e-01,  5.0056e-02, -3.0031e-01,\n",
      "          2.1386e-01, -5.1490e-02, -1.0305e-01, -4.7870e-02,  1.2727e-01,\n",
      "          2.5325e-02, -5.3219e-02,  2.3186e-01,  1.4677e-01, -4.3417e-01,\n",
      "         -1.2675e-01,  5.3024e-02, -3.5288e-01,  3.4656e-02,  3.3902e-02,\n",
      "          1.7017e-01,  7.3511e-02, -2.1776e-01,  7.3416e-02,  1.3911e-01,\n",
      "         -1.0054e-01, -1.6887e-03, -6.8535e-02,  2.6447e-02, -1.5319e-01,\n",
      "         -1.8373e-01, -2.2591e-01, -7.5448e-02, -2.3122e-01, -1.9402e-01,\n",
      "          2.3094e-01, -3.1214e-01, -4.4589e-03, -4.4619e-01,  3.6092e-01,\n",
      "          2.1396e-01, -1.3536e-01,  2.2376e-01,  5.2887e-02, -1.4125e-01,\n",
      "         -6.4780e-02,  4.6834e-01,  1.3461e-01, -2.6534e-01, -2.4041e-01,\n",
      "         -1.2256e-01, -1.8411e-01,  1.9177e-01, -4.3667e-02,  1.8202e-01,\n",
      "          5.2985e-01,  2.1434e-01,  1.0231e-01, -1.4455e-01,  5.8915e-02,\n",
      "         -1.3106e-01, -3.3969e-02,  1.2298e-01, -1.9661e-01,  9.4885e-02,\n",
      "          7.3445e-03,  3.7372e-01,  5.0661e-02, -8.8187e-02,  4.9603e-02,\n",
      "         -1.5518e-01, -3.1834e-01, -2.0903e-01,  1.0608e-01, -6.6194e-02,\n",
      "          4.6667e-02,  8.8467e-02, -3.4847e-03,  4.1374e-01,  1.6893e-01,\n",
      "          1.0701e-01,  2.7653e-01, -2.8538e-01, -8.7279e-02, -2.4708e-01,\n",
      "          5.1297e-02, -2.1318e-02, -2.4254e-01,  6.9607e-02, -8.9231e-02,\n",
      "         -1.7389e-01, -1.8610e-01,  6.4962e-02, -1.2000e-01, -1.7040e-01,\n",
      "         -1.6282e-01,  9.3660e-02,  1.5531e-01,  6.5633e-02, -2.8870e-01,\n",
      "          5.7279e-02,  2.3628e-01, -1.8834e-01, -3.8196e-02, -1.0290e-01,\n",
      "         -1.3624e-01,  6.3912e-02,  2.1120e-01,  1.8050e-01, -1.2612e-01,\n",
      "         -1.5538e-01, -1.8804e-01,  4.1572e-02,  3.4610e-01,  6.3898e-02,\n",
      "         -2.0909e-01,  7.5565e-02, -2.8918e-02,  1.7746e-01, -2.8167e-02,\n",
      "         -3.3081e-02, -1.4224e-01,  4.4999e-02, -1.8226e-01, -1.4907e-01,\n",
      "         -2.2059e-01, -1.3102e-01,  3.8721e-02,  1.3308e-01,  8.4252e-02,\n",
      "          2.7245e-01, -8.8711e-02,  1.2524e-01,  2.2220e-01, -1.6608e-02,\n",
      "          1.0248e-01,  1.8056e-01,  1.2476e-01, -2.6994e-02, -7.8177e-02,\n",
      "         -1.9345e-01, -2.5703e-01, -9.5562e-02, -6.9119e-03,  1.0051e-01,\n",
      "          2.2689e-02, -1.7188e-01,  4.7390e-02, -5.6376e-02,  2.7040e-01,\n",
      "          2.5758e-01, -1.0707e-01,  9.3139e-02, -8.5705e-02, -1.6832e-01,\n",
      "         -1.5678e-01,  1.3854e-01, -8.7709e-03,  1.0817e-01,  6.7005e-02,\n",
      "         -1.9746e-01, -9.8642e-02,  3.0429e-01,  6.7486e-02,  1.6228e-01,\n",
      "          4.7976e-01, -1.1060e-01,  1.4474e-01, -1.2229e-01,  1.9626e-03,\n",
      "         -9.2067e-02, -1.7188e-01,  9.5359e-02,  1.8483e-02,  2.0681e-01,\n",
      "         -3.4572e-01,  1.1354e-01,  1.2296e-01, -1.8997e-01,  1.0330e-01,\n",
      "         -2.0136e-01,  6.5250e-02,  1.0394e-01, -1.7098e-01, -2.8462e-01,\n",
      "          3.1258e-02, -1.0653e-01, -1.6774e-01,  2.5348e-01, -3.1650e-02,\n",
      "         -2.8402e-02,  7.3557e-02,  3.8556e-01, -1.3268e-01, -9.3267e-02,\n",
      "          3.4821e-02, -1.5816e-02, -3.4495e-01, -1.2592e-01,  7.6596e-02,\n",
      "          6.5637e-02, -1.3884e-01, -3.1309e-01,  7.7619e-02, -7.1433e-02,\n",
      "          7.7215e-02, -3.8666e-01,  1.6634e-01,  1.6405e-01, -4.0085e-02,\n",
      "          2.3025e-01, -3.0634e-02, -1.5593e-01, -4.7827e-01,  7.3236e-03,\n",
      "         -5.3154e-03,  8.3913e-02,  8.5799e-02,  2.9620e-01, -8.0136e-02,\n",
      "         -4.9883e-02, -1.5019e-01,  1.6501e-01, -6.5616e-02, -6.6704e-02,\n",
      "         -1.7041e-01, -4.2490e-02,  1.2309e-01,  1.4547e-01,  9.9729e-02,\n",
      "         -2.3040e-01,  2.0993e-01, -3.9689e-01, -7.8158e-02,  3.7124e-02,\n",
      "          2.9365e-02,  8.2348e-02,  9.7009e-02,  8.7674e-02, -1.6916e-01,\n",
      "          7.3385e-02, -1.0896e-01,  1.5164e-01, -3.7889e-02,  2.3037e-02,\n",
      "         -1.5353e-02, -1.5030e-01, -2.0853e-01, -1.8108e-01, -1.7813e-01,\n",
      "          2.1299e-02, -2.0849e-01, -1.1161e-01, -2.3260e-02, -1.1595e-01,\n",
      "          2.6304e-02,  1.1257e-01,  7.8219e-02,  1.1029e-01, -1.6990e-01,\n",
      "         -2.6577e-01, -1.4202e-01,  3.1409e-01, -2.5747e-01, -1.9777e-01,\n",
      "         -6.5721e-02, -1.6053e-01, -2.7040e-01, -2.1090e-01, -2.4392e-01,\n",
      "          1.9262e-01, -2.8231e-02, -1.4774e-01,  8.2244e-02,  1.2111e-01,\n",
      "          1.4560e-02,  9.4518e-02, -3.3580e-02,  1.9584e-01,  1.2023e-02,\n",
      "          1.6856e-01, -6.0214e-02,  6.5578e-02,  2.7858e-01, -5.7506e-02,\n",
      "         -1.1367e-01,  8.5595e-02, -3.7010e-02, -1.1048e-01,  1.9192e-01,\n",
      "          1.5151e-01, -1.9771e-01, -1.4255e-01,  1.3178e-01, -3.0111e-01,\n",
      "         -1.4241e-02,  6.9638e-02,  2.8635e-01,  4.2783e-02, -6.2587e-03,\n",
      "         -1.0634e-01,  4.3039e-02, -9.8091e-02,  2.5359e-01, -2.2795e-01,\n",
      "          4.2149e-02, -2.0446e-01, -1.5147e-01,  3.1298e-01, -2.9232e-01,\n",
      "          1.7280e-01, -7.4065e-02, -2.6899e-01,  3.1445e-01,  1.0402e-01,\n",
      "         -3.3157e-01,  2.3241e-01,  5.2224e-02, -6.1744e-02, -6.5831e-02,\n",
      "         -1.9841e-01, -2.0259e-02,  4.1226e-02, -1.4522e-01, -1.7562e-01,\n",
      "         -2.2351e-01, -3.1517e-01,  1.5985e-01, -2.1289e-01,  3.3370e-01,\n",
      "          9.8924e-02, -7.2988e-02, -6.8950e-02,  1.1281e-01, -1.4077e-01,\n",
      "          1.5173e-01, -1.1748e-01, -2.6358e-01,  1.3881e-01,  1.1491e-01,\n",
      "         -1.4709e-01, -1.0288e-01, -1.9709e-01,  2.1068e-01,  2.0605e-01,\n",
      "          2.2213e-01, -3.0014e-01, -2.8459e-02, -1.8822e-01, -1.7132e-01,\n",
      "          2.0974e-01,  9.5646e-02,  1.1194e-01,  1.4144e-01,  1.2821e-01,\n",
      "         -2.3807e-01, -1.4283e-01, -2.0079e-02, -1.1257e-01, -1.0487e-01,\n",
      "         -1.9984e-01,  3.4155e-01, -7.4028e-02,  5.1600e-02,  3.8084e-02,\n",
      "          1.6337e-01,  1.4999e-02, -2.0001e-02,  2.2905e-01, -4.0232e-02,\n",
      "          2.0042e-01, -6.6782e-02, -2.1427e-02, -2.4240e-01, -1.5395e-01,\n",
      "         -1.9376e-01,  5.1871e-01, -1.3683e-01,  3.1478e-02, -1.3006e-03,\n",
      "         -2.1298e-01,  1.9364e-01,  7.8122e-02,  8.9922e-02, -6.1826e-02,\n",
      "         -5.8171e-02,  1.9483e-01, -2.8751e-01, -9.1498e-02,  9.3818e-02,\n",
      "          2.0088e-01,  5.2616e-02, -1.0723e-01, -2.0169e-01, -1.8595e-01,\n",
      "         -3.3925e-01,  3.1662e-01,  5.8276e-02, -2.2336e-01, -3.4447e-01,\n",
      "          1.0319e-01,  1.2210e-03, -3.4119e-02, -2.5810e-01, -1.0172e-01,\n",
      "          1.6819e-01,  8.2849e-02, -2.6992e-01,  6.0844e-02, -4.4331e-02,\n",
      "         -5.2659e-02, -2.9891e-01,  2.2430e-01,  2.0284e-01,  1.5600e-01,\n",
      "          4.7764e-02, -1.0598e-01, -1.9735e-01, -5.0565e-02, -3.9756e-03,\n",
      "          4.5400e-01, -2.6543e-02,  2.6013e-01, -2.3565e-01, -1.7372e-01,\n",
      "         -3.6209e-02,  1.8780e-01,  1.6089e-01,  6.7131e-02, -1.9276e-01,\n",
      "          4.5484e-02, -3.6563e-02,  8.6246e-02, -1.4784e-01,  1.1559e-01,\n",
      "          2.5016e-01, -6.0874e-02,  1.9563e-01, -1.1872e-01, -3.7275e-02,\n",
      "         -1.4389e-01, -9.8746e-03,  2.4774e-01, -2.2082e-01,  1.3445e-01,\n",
      "          1.4572e-01,  2.6515e-03, -3.8951e-02,  1.4300e-01, -5.9685e-02,\n",
      "          2.0810e-01,  1.0518e-01,  1.6073e-01, -1.3284e-01,  7.7868e-02,\n",
      "          1.3269e-01, -2.3092e-01, -3.0184e-01,  1.0855e-01, -4.5128e-02,\n",
      "         -1.3949e-01,  7.9634e-02, -3.5480e-01, -3.2326e-01, -2.0989e-01,\n",
      "         -3.1261e-02, -2.2711e-01,  1.1222e-01, -4.7374e-03,  7.7661e-02,\n",
      "         -3.4322e-01,  7.5447e-02, -3.7793e-03, -6.8501e-03, -1.1408e-02,\n",
      "          6.2828e-02, -3.1856e-03,  1.2982e-01,  1.5675e-01,  3.0070e-01,\n",
      "         -2.6661e-01, -1.0090e-01, -2.4026e-01, -3.0497e-02, -2.8638e-01,\n",
      "         -6.7124e-02,  1.6012e-01,  1.8212e-02,  2.6951e-01,  2.6900e-01,\n",
      "          1.5876e-01,  7.9906e-02,  1.5865e-01, -6.8572e-02, -1.3185e-01,\n",
      "          4.0262e-02, -3.0369e-01,  1.6195e-01, -1.1735e-01, -2.7283e-01,\n",
      "          2.5075e-01, -2.6888e-01, -1.9144e-02,  2.2387e-01,  3.4657e-03,\n",
      "         -1.2852e-01,  3.3911e-03, -2.0377e-01,  2.1522e-01,  2.4539e-01,\n",
      "          2.0739e-01, -1.2184e-01, -1.0788e-02, -1.8650e-02, -2.7413e-01,\n",
      "          9.5353e-02, -2.7969e-02, -4.3768e-02,  1.6691e-02, -1.6968e-01,\n",
      "         -9.8752e-02, -2.1054e-01,  2.2371e-01,  2.2537e-01, -2.2435e-02,\n",
      "         -2.3221e-01, -5.4466e-02,  1.6106e-01,  7.0837e-02,  2.7239e-01,\n",
      "          8.7752e-02,  1.1697e-01, -1.0782e-01, -2.3860e-01, -3.6469e-02,\n",
      "          2.6591e-01, -6.6756e-02, -3.2848e-01, -1.1523e-01, -1.5390e-01,\n",
      "          2.4838e-01,  9.8568e-02,  4.0440e-01, -7.0133e-02,  1.9195e-01,\n",
      "         -1.0857e-01, -1.3916e-01, -1.3901e-01,  4.7549e-02, -1.7884e-01,\n",
      "         -1.9925e-01,  2.0170e-01,  4.0620e-01, -8.1125e-03,  9.3677e-02,\n",
      "         -3.6540e-02, -2.6956e-01,  2.5153e-02, -1.5447e-01, -1.1398e-01,\n",
      "         -1.0093e-01, -5.6190e-02, -1.2826e-01, -8.2434e-03, -3.7177e-02,\n",
      "          8.0992e-03, -5.1484e-02,  2.0843e-01, -3.2339e-01,  3.5447e-01,\n",
      "         -1.0841e-01, -2.2332e-01,  2.3125e-01,  2.6770e-01, -1.2733e-01,\n",
      "         -2.6503e-02, -7.6957e-03,  9.5470e-02, -1.6447e-01, -2.7946e-01,\n",
      "         -1.7459e-01,  1.3692e-01,  4.8909e-02,  1.7275e-01, -3.3390e-01,\n",
      "         -8.0434e-03, -1.9335e-01, -7.9218e-02]]), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n"
     ]
    }
   ],
   "source": [
    "# For transformers v3.x: # tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\")\n",
    "## With TensorFlow 2.0+: # from transformers import TFAutoModel # bertweet = TFAutoModel.from_pretrained(\"vinai/bertweet-base\")\n",
    "\n",
    "bertweet = AutoModel.from_pretrained(\"vinai/bertweet-base\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=False) # For transformers v4.x+\n",
    "\n",
    "input_ids = torch.tensor([tokenizer.encode(raw_text.text[0])])\n",
    "\n",
    "with torch.no_grad():\n",
    "    features = bertweet(input_ids)  # Models outputs are now tuples\n",
    "\n",
    "# print(features)"
   ]
  },
  {
   "source": [
    "## Processing the entire raw_test corpus"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [tokenizer.tokenize(tweet) for tweet in raw_text.text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 25, 768])\ntorch.Size([25, 768])\ntorch.Size([25, 768])\ntorch.Size([768])\nOur final sentence embedding vector of shape: torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "input_ids = torch.tensor([tokenizer.encode(raw_text.text[0])])\n",
    "\n",
    "with torch.no_grad():\n",
    "    features = bertweet(input_ids)  # Models outputs are now tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[    0, 19481, 31440,    22, 19959,   171,   956, 20778,    16,  3322,\n",
       "         10794,  8923,  3420,    15,  3177, 45565, 11412, 46442,   423,   698,\n",
       "           423,   455,  2938, 31429,     2]])"
      ]
     },
     "metadata": {},
     "execution_count": 140
    }
   ],
   "source": [
    "input_ids # input sentence's word indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_hidden = features.last_hidden_state\n",
    "print(last_hidden.shape)\n",
    "sentence_embedding = torch.mean(last_hidden, dim=0)\n",
    "print(sentence_embedding.shape)\n",
    "token_vecs = last_hidden[-1]\n",
    "print(token_vecs.shape)\n",
    "sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "print(sentence_embedding.shape)\n",
    "\n",
    "print (\"Our final sentence embedding vector of shape:\", sentence_embedding.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([-5.0837e-02,  9.2732e-02,  1.1474e-01,  7.5394e-02,  1.0709e-01,\n",
       "         1.3905e-01,  7.3160e-02,  1.3031e-01,  2.2848e-01, -1.0013e-01,\n",
       "        -1.4994e-02,  1.1385e-01, -1.5093e-01,  1.2282e-01,  1.0534e-01,\n",
       "         2.8266e-01, -9.2135e-03,  2.6026e-02,  3.8447e-01,  5.2748e-03,\n",
       "        -2.9484e-02,  8.4773e-03,  1.3608e-01,  8.6456e-02,  1.8791e-01,\n",
       "        -9.6116e-03,  6.7772e-02,  1.6709e-02,  2.5986e-01,  3.6181e-02,\n",
       "        -3.3826e-02, -3.3800e-02,  1.2717e-01, -3.4795e-02,  1.8405e-01,\n",
       "        -2.0551e-01,  3.6112e-02,  3.1310e-01,  2.8765e-02,  6.6649e-02,\n",
       "        -2.6885e-02, -3.0104e-01,  2.5878e-02,  2.2134e-01,  4.1341e-01,\n",
       "        -4.6079e-02, -8.6279e-03, -8.9164e-02,  1.8050e-01, -3.8341e-02,\n",
       "         6.2557e-02,  1.9168e-02,  2.9405e-01, -1.2726e-01, -7.2294e-02,\n",
       "        -1.6538e-01,  1.6099e-01,  3.1980e-01,  2.2167e-01, -4.7767e-02,\n",
       "         4.3942e-02, -9.4910e-02,  1.6816e-01, -9.8562e-02,  2.3590e-01,\n",
       "         8.3192e-03,  1.7944e-01, -4.2238e-02,  2.3585e-01,  8.5420e-02,\n",
       "         1.2240e-01,  2.4702e-02,  4.9678e-02, -4.3627e-03,  2.2773e-02,\n",
       "         7.3948e-02,  9.3372e-02, -8.7660e-02,  1.6639e-02, -4.7036e-04,\n",
       "         1.8962e-02,  3.0085e-02, -4.2204e-02, -4.8046e-02,  1.5718e-01,\n",
       "        -5.6926e-02,  9.0154e-02, -4.3578e-01,  4.9993e-02,  1.1859e-01,\n",
       "         1.2175e-01,  1.8842e-01, -9.0434e-03, -1.0635e-01,  2.0515e-02,\n",
       "         5.1942e-02,  9.7716e-02, -1.7143e-01, -1.4616e-01,  1.1817e-01,\n",
       "         1.7412e-01,  1.8744e-01,  1.2416e-01,  1.7795e-02,  1.8841e-01,\n",
       "         3.7865e-03,  1.3625e-01,  9.1680e-03, -4.3809e-02, -5.8206e-02,\n",
       "        -5.3651e-02, -7.1363e-02, -2.7494e-02,  5.9122e-02, -5.6397e-02,\n",
       "         7.6876e-02,  2.3384e-02, -1.0122e-01, -3.5729e-02, -3.5874e-02,\n",
       "        -1.1355e-01,  3.2688e-01,  1.1283e+00, -1.6252e-01,  2.4455e-01,\n",
       "         1.3415e-01, -3.4133e-01, -2.3636e-02, -2.3074e-01,  2.3435e-01,\n",
       "         1.7640e-02,  1.3977e-01,  1.2609e-02,  9.9411e-02,  1.2015e-01,\n",
       "         8.2593e-02, -2.9837e-02,  7.5398e-02,  7.3279e-02,  1.9299e-01,\n",
       "        -1.0465e-02,  3.7354e-02,  1.5242e-01,  1.3083e-01,  1.8574e-01,\n",
       "        -1.7404e-02, -6.2685e-02, -1.5518e-01,  1.0387e-01,  6.9338e-02,\n",
       "         1.9215e-01,  2.3552e-01, -3.4443e-02,  2.4692e-01, -5.6299e-02,\n",
       "         2.8346e-01,  1.5655e-01, -6.4347e-02,  9.3145e-02, -1.0082e-01,\n",
       "         4.9034e-01,  8.5057e-02,  7.0042e-02, -1.5875e-01,  3.6534e-02,\n",
       "        -2.4924e-02,  1.7134e-01,  1.8444e-01,  8.5795e-02, -3.8079e-01,\n",
       "        -1.4753e-01,  9.7836e-02,  1.3298e-01, -1.1972e-01, -5.3787e-02,\n",
       "        -1.9190e-01, -4.6694e-03,  5.5565e-02,  1.0500e-01,  2.1799e-01,\n",
       "         1.1888e-01, -1.3437e-02,  4.9413e-02, -1.8465e-01,  1.4252e-01,\n",
       "         9.3046e-02,  7.3345e-01, -2.6955e-02,  7.6216e-02,  1.0262e-01,\n",
       "         7.5032e-02,  1.5983e-01,  1.7600e-01,  3.4533e-02,  2.1697e-01,\n",
       "        -4.0822e-02, -6.2011e-01,  1.5153e-02, -1.9123e-01, -2.7980e-02,\n",
       "         1.4497e-01,  8.2474e-02,  4.0928e-03,  1.3780e-01,  1.4259e-02,\n",
       "        -2.6320e-02,  1.2979e-01,  3.7035e-02,  1.0347e-01,  1.3058e-01,\n",
       "         5.9276e-02, -7.0080e-03,  5.1470e-02,  1.7787e-01,  1.5472e-01,\n",
       "         1.4597e+00, -1.9871e-02, -1.7711e-01,  8.7100e-03,  2.0217e-01,\n",
       "         2.3483e-02, -7.0018e-04,  2.4965e-01,  1.3207e-02,  1.4274e-02,\n",
       "         3.5296e-02,  1.8386e-01,  1.6801e-01, -1.9373e-01, -3.3217e-02,\n",
       "         1.1260e-01, -6.6201e-01,  2.3631e-01,  2.2692e-02,  7.6554e-02,\n",
       "        -7.6364e-02,  1.3151e-03,  3.4090e-03,  1.4321e-01, -8.5346e-02,\n",
       "        -1.1333e-01,  4.1998e-02, -3.1089e-01,  3.6343e-02,  7.8607e-02,\n",
       "         7.6445e-03, -3.1925e-03,  2.4589e-01, -5.9802e-03,  3.6605e-01,\n",
       "         1.1316e-01, -9.0079e-02,  1.8500e-01,  1.0817e-02,  4.4746e-02,\n",
       "         6.5226e-02,  2.2737e-02,  4.7623e-02,  1.5578e-02,  1.9983e-01,\n",
       "         1.1903e-01, -1.7745e-01,  2.4336e-01,  2.6125e-02, -1.3475e-01,\n",
       "         6.2516e-02, -3.4227e-03, -8.6743e-02,  3.7737e-02,  9.2975e-02,\n",
       "         1.3743e-02,  1.9833e-02,  1.7909e-02,  6.1941e-02, -1.2511e-01,\n",
       "         2.6385e-02,  1.7766e-01,  2.0973e-01,  1.3869e-01,  1.9386e-01,\n",
       "         3.2021e-01,  1.7049e-01,  9.8713e-02,  9.4638e-02,  1.6746e-01,\n",
       "         5.2898e-02,  5.5709e-02, -1.9147e-01,  2.9039e-02,  2.3186e-02,\n",
       "         1.6540e-01, -1.9926e-02,  9.3978e-02,  7.1466e-02, -1.0697e-01,\n",
       "        -2.8393e-01,  9.3820e-02, -1.3530e-01, -8.0348e-02, -7.9342e-02,\n",
       "         1.3895e-01, -5.7813e-02, -3.5777e-02,  2.6291e-02,  1.5904e-01,\n",
       "         2.1355e-02,  2.3304e-02,  1.1873e-01, -5.2093e-02, -4.4166e-02,\n",
       "         6.9713e-02, -1.4371e-01,  2.4674e-01, -2.4893e-01,  1.6762e-01,\n",
       "         2.7105e-01, -1.3233e-02,  9.9574e-02,  5.3031e-02,  7.9658e-02,\n",
       "         2.0334e-02, -7.4295e-02,  1.9707e-01, -9.8494e-02, -5.0227e-02,\n",
       "         1.4823e-01,  1.0921e-01,  1.0681e-01,  1.0765e-01, -2.7090e-02,\n",
       "         1.1277e-01, -1.5164e-01, -3.3031e-02,  8.2240e-02,  1.0810e-02,\n",
       "         1.4583e-01,  1.2710e-01,  4.9430e-02, -5.0675e-02,  1.7730e-01,\n",
       "         3.8675e-02, -3.3512e-02, -8.6339e-03, -3.7838e-01,  3.2945e-01,\n",
       "         5.2087e-02, -1.9405e-01,  2.0345e-01, -8.6647e-03, -3.6847e-02,\n",
       "         4.8802e-02,  3.0757e-02,  1.7082e-01,  5.8219e-02,  1.6642e-01,\n",
       "         1.5484e-01, -2.6366e-02,  7.7685e-02, -8.8685e-02, -8.0075e-02,\n",
       "        -8.5859e-02,  6.8221e-02,  1.3909e-01,  3.1414e-02, -1.3288e-02,\n",
       "        -4.6386e-02,  5.7323e-02,  2.0031e-02, -9.7825e-02,  6.6423e-02,\n",
       "         4.2751e-02,  1.4121e-01,  2.8556e-02,  8.1620e-02, -4.4420e-02,\n",
       "        -2.3792e-01,  2.1506e-02,  1.3607e+00, -8.6635e-02,  6.8215e-02,\n",
       "         8.7148e-02,  1.7850e-01, -3.2101e-02,  9.6385e-02, -2.9826e-02,\n",
       "        -5.1449e-02, -7.4922e-02,  3.9719e-02,  4.7692e-02,  5.9988e-02,\n",
       "         2.7319e-02,  7.1627e-02, -3.3938e-02, -9.0796e-02,  3.3027e-02,\n",
       "         6.7911e-02,  9.4762e-02,  7.8694e-02, -7.2326e-03, -1.3146e-02,\n",
       "         1.8629e-01, -2.1997e-02,  4.9522e-02, -3.6549e-01,  1.5774e-01,\n",
       "         2.2086e-01,  1.0500e-03,  4.7939e-01,  1.5371e-01,  1.7278e-01,\n",
       "         4.4130e-02,  8.0743e-02,  1.3916e-01,  2.8630e-02, -1.0059e-01,\n",
       "         5.7783e-02,  2.5898e-01, -1.6781e-02,  2.1237e-01,  2.5909e-01,\n",
       "         1.9299e-01,  8.7324e-02, -1.7723e-01,  1.6585e-01, -1.3197e-02,\n",
       "        -2.3591e-01,  1.1858e-01,  7.6536e-02, -1.9959e-01,  6.5384e-02,\n",
       "         8.1454e-02,  1.2155e-02,  8.0003e-02,  8.7354e-02,  2.0402e-01,\n",
       "         2.4035e-02,  6.3078e-02,  3.9728e-01,  1.6337e-01,  1.3807e-01,\n",
       "        -1.5153e-01,  1.1616e-01, -2.4617e-02, -5.7374e-02, -1.8934e-02,\n",
       "         1.2608e+00, -1.2109e-01, -6.8355e-02,  5.2829e-03,  2.3374e-01,\n",
       "         1.2668e-01,  1.6650e-01,  1.5511e-01,  5.0933e-02,  9.9754e-02,\n",
       "         1.5740e-01,  1.4706e-02,  6.6160e-02, -1.7415e-02,  3.3976e-02,\n",
       "         1.4418e-01, -7.4391e-02,  2.1804e-01,  1.0832e-01,  6.9208e-02,\n",
       "         2.1019e-02,  9.6360e-02,  2.3787e-02,  9.9954e-02,  2.1042e-02,\n",
       "        -1.9663e-01,  9.1346e-02, -2.3672e-01,  1.9975e-01, -7.6617e-02,\n",
       "         2.1211e-01, -1.1981e-01,  5.5534e-02, -5.0219e-02, -1.2184e-02,\n",
       "         2.7356e-02,  4.0284e-02, -1.2552e-01,  1.0628e-01,  9.4535e-02,\n",
       "        -4.0326e-02,  2.2018e-01,  2.9439e-01, -7.0671e-03,  1.5102e-02,\n",
       "         2.0965e-01, -7.1828e-02,  4.0391e-01,  9.5651e-02, -1.2581e-02,\n",
       "        -1.7435e-01, -1.8406e-03,  1.6571e-02, -2.2704e-01, -4.2659e-02,\n",
       "        -5.2829e-02,  1.4349e-02, -3.3431e-01, -5.8526e-02,  1.4640e-02,\n",
       "         6.5510e-02, -2.3657e-01,  2.3562e-01, -1.4104e-01, -4.5091e-02,\n",
       "         9.1257e-02,  3.3083e-04, -8.5923e-02, -1.1395e-01,  1.6588e-01,\n",
       "         1.1526e-01,  1.5169e-01, -1.9073e-02,  3.5888e-01,  1.8764e-01,\n",
       "         1.6105e-01,  1.5560e-03, -1.3340e-01, -2.9830e-02,  7.2631e-02,\n",
       "        -1.0632e-01,  1.0788e-02,  7.7473e-02,  2.7454e-01,  6.4489e-02,\n",
       "        -6.6754e-02, -1.0169e-02,  1.4799e-01,  6.8978e-01,  5.1599e-02,\n",
       "         6.0270e-02,  1.2269e-01,  9.5201e-02,  3.4943e-01,  1.3713e-01,\n",
       "         1.3771e-02, -1.8656e-01, -1.1290e-01,  1.1464e-01,  2.1767e-02,\n",
       "         1.1698e-01,  2.6966e-01,  2.5507e-02, -4.9283e-02,  1.4599e-02,\n",
       "        -1.9120e-01,  1.1708e-01, -1.3939e-01, -9.9676e-02, -1.5247e-02,\n",
       "         6.0215e-02,  1.4237e-01,  3.0017e-02, -1.5911e-02,  1.5122e-01,\n",
       "         6.5849e-02, -8.1206e-02,  7.0137e-02, -9.7330e-02, -9.3912e-02,\n",
       "        -1.2284e-03, -1.4399e-01,  9.7763e-02,  1.0737e-03,  1.2207e-01,\n",
       "        -1.2097e-01,  1.2406e-01,  1.3869e-01,  8.1858e-02, -1.9526e-01,\n",
       "        -2.3435e-02, -1.6751e-01,  2.0606e-01,  2.2723e-01, -1.5425e-01,\n",
       "         1.0897e-01, -1.2752e-01,  1.0033e-01,  7.2477e-03,  2.4320e-01,\n",
       "        -1.3354e-01, -7.6681e-02, -1.8970e-01,  8.7706e-02, -5.7754e-03,\n",
       "        -3.5790e-02,  8.4758e-02,  1.0164e-01,  2.1224e-01,  8.6524e-02,\n",
       "        -4.8381e-02, -5.1883e-02,  3.2049e-02, -5.0279e-02,  1.7213e-02,\n",
       "        -7.7121e-03, -3.9168e-01,  9.6847e-02,  2.7986e-02,  1.6868e-02,\n",
       "        -3.4939e-02,  6.7554e-02, -1.0633e-02, -5.1447e-02,  2.8215e-01,\n",
       "         9.1840e-02, -1.6462e-01,  8.6962e-02,  1.4070e-02,  4.5911e-01,\n",
       "         1.7774e-02,  2.0485e-02, -9.8100e-02,  1.2274e-01,  5.3456e-02,\n",
       "         4.0969e-02, -1.9563e-01, -1.4896e-01,  5.6046e-02,  1.2805e-01,\n",
       "        -1.4127e-01, -3.9320e-02,  1.8649e-01,  1.5805e-01,  4.7916e-02,\n",
       "        -1.2573e-01,  7.1971e-02, -2.6531e-02,  1.4632e-01,  1.2133e-01,\n",
       "         2.3354e-02, -1.1862e-01, -2.6744e-02, -1.4840e-01,  9.1453e-02,\n",
       "         1.2672e-01,  1.1461e-01,  1.2071e-01, -3.5757e-02,  3.1627e-02,\n",
       "        -3.3960e-02, -1.4522e-01,  1.5119e-02, -4.1766e-01, -1.1531e-01,\n",
       "         3.2223e-01,  8.2257e-02,  5.6434e-02, -3.8664e-01, -1.2488e-01,\n",
       "         2.0085e-01,  1.3792e-01, -9.0170e-02,  2.5741e-01, -2.5595e-01,\n",
       "         1.1731e-01,  1.6514e-01,  5.0803e-01, -1.4933e-02, -1.6436e-01,\n",
       "         2.2041e-01, -6.2270e-02,  1.2603e-01, -1.5052e-02,  5.2886e-02,\n",
       "        -5.3562e-01,  3.5637e-02,  4.4476e-01, -5.9953e-02,  3.7359e-02,\n",
       "         2.3975e-01,  1.5730e-01, -1.0893e-01,  3.5680e-01,  1.7034e-02,\n",
       "         1.7362e-01,  2.1861e-01,  7.8150e-02, -1.4954e-01,  4.1637e-02,\n",
       "         2.5998e-01,  5.0585e-02, -1.3644e-01,  5.4819e-02,  1.6658e-01,\n",
       "         1.4876e-01,  2.1871e-01, -1.6653e-01,  6.9710e-02, -2.2982e-02,\n",
       "        -7.0087e-02, -6.6930e-03, -6.4969e-02,  1.3001e-01,  5.4172e-02,\n",
       "        -1.2430e-01, -7.8061e-02, -1.6416e-01,  3.0940e-02,  2.0683e-01,\n",
       "         1.3486e-01, -1.9087e-01,  2.9455e-02, -4.7716e-02,  5.8307e-01,\n",
       "        -1.1322e-01,  2.2272e-01,  2.4497e-02,  2.6618e-01,  2.2932e-02,\n",
       "        -6.1573e-02,  4.1119e-02,  4.0224e-02, -1.3157e-01, -1.6524e-01,\n",
       "         1.4671e-01,  7.5032e-02,  1.2044e-01, -8.5065e-02,  1.8167e-01,\n",
       "         4.1622e-02, -1.3794e-01,  1.1175e-01,  3.3204e-02,  1.5224e-01,\n",
       "         3.0201e-02,  3.5101e-02, -7.1860e-02,  4.7905e-02, -1.5814e-01,\n",
       "        -8.8049e-02,  1.7642e-01, -4.3394e-02, -1.0993e-01, -6.8155e-04,\n",
       "        -5.2071e-03, -1.1089e-01,  3.9530e-01,  1.0418e-01, -1.2605e-01,\n",
       "         3.1001e-01,  2.4269e-01,  1.8128e-01,  9.3428e-02,  3.9698e-02,\n",
       "        -1.1851e-02,  1.3923e-01,  5.9400e-02, -1.5553e-01, -5.8981e-02,\n",
       "         2.3868e-01,  1.6313e-01,  9.5772e-02,  8.0576e-02, -4.9174e-02,\n",
       "         1.4364e-02,  1.3576e-01,  1.2084e-01, -1.9499e-02, -9.2559e-02,\n",
       "         3.7895e-02, -2.6119e-02, -3.7888e-02])"
      ]
     },
     "metadata": {},
     "execution_count": 143
    }
   ],
   "source": [
    "sentence_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 BREA@@\n1 KING@@\n2 :\n3 Armed\n4 man\n5 takes\n6 hostage\n7 in\n8 ko@@\n9 sher\n10 grocery\n11 east\n12 of\n13 Paris\n14 http://@@\n15 t.co/@@\n16 PB@@\n17 s@@\n18 3@@\n19 s@@\n20 M@@\n21 wh@@\n22 Lt\n"
     ]
    }
   ],
   "source": [
    "for i, token_str in enumerate(tokens[0]):\n",
    "  print (i, token_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Calculate the cosine similarity between the word bank \n",
    "# in \"bank robber\" vs \"river bank\" (different meanings).\n",
    "diff_bank = 1 - cosine(token_vecs_sum[10], token_vecs_sum[19])\n",
    "\n",
    "# Calculate the cosine similarity between the word bank\n",
    "# in \"bank robber\" vs \"bank vault\" (same meaning).\n",
    "same_bank = 1 - cosine(token_vecs_sum[10], token_vecs_sum[6])\n",
    "\n",
    "print('Vector similarity for  *similar*  meanings:  %.2f' % same_bank)\n",
    "print('Vector similarity for *different* meanings:  %.2f' % diff_bank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'BREAKING: Armed man takes hostage in kosher grocery east of Paris http://t.co/PBs3sMwhLt'"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "raw_text.text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [tokenizer.tokenize(tweet) for tweet in raw_text.text]\n",
    "# tokens[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokens[1])\n",
    "texts_inverse = [tokenizer.convert_tokens_to_ids(token) for token in tokens]\n",
    "# texts_inverse[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "BREA@@ 19481\nKING@@ 31440\n: 22\nArmed 19959\nman 171\ntakes 956\nhostage 20778\nin 16\nko@@ 3322\nsher 10794\ngrocery 8923\neast 3420\nof 15\nParis 3177\nhttp://@@ 45565\nt.co/@@ 11412\nPB@@ 46442\ns@@ 423\n3@@ 698\ns@@ 423\nM@@ 455\nwh@@ 2938\nLt 31429\n"
     ]
    }
   ],
   "source": [
    "# Display the words with their indeces.\n",
    "for tup in zip(tokens[0], texts_inverse[0]):\n",
    "    print('{} {}'.format(tup[0], tup[1]))"
   ]
  },
  {
   "source": [
    "## Bulk Embedding"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = raw_text.text\n",
    "text.dropna(inplace=True)\n",
    "# text = text.sample(frac=0.4, random_state=999)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=False)\n",
    "bertweet = AutoModel.from_pretrained(\"vinai/bertweet-base\")\n",
    "\n",
    "sents = [tokenizer.tokenize(tweet) for tweet in text]\n",
    "len(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertweet.eval()\n",
    "\n",
    "embeddings = []\n",
    "\n",
    "for sent in sents:\n",
    "    input_ids = torch.tensor([tokenizer.encode(sent)])\n",
    "    with torch.no_grad():\n",
    "        features = bertweet(input_ids)  # Models outputs are now tuples\n",
    "    embeddings.append(features)\n",
    "    \n",
    "result = [torch.mean(features.last_hidden_state[-1], dim=0).tolist() for features in embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(5802, 768)"
      ]
     },
     "metadata": {},
     "execution_count": 308
    }
   ],
   "source": [
    "df_bertweet = pd.DataFrame(result)\n",
    "print(df_bertweet.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'df_bertweet' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-430273c1de93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_bertweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./bertweet.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_bertweet' is not defined"
     ]
    }
   ],
   "source": [
    "df_bertweet.to_csv('./bertweet.csv', index = False)"
   ]
  },
  {
   "source": [
    "### Save the file"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(5802, 35)\n(5802, 768)\n(5802, 803)\n"
     ]
    }
   ],
   "source": [
    "bertweet = pd.read_csv('./bertweet.csv')\n",
    "df_data = pd.read_csv('./data_notembeded.csv')\n",
    "print(df_data.shape)\n",
    "print(bertweet.shape)\n",
    "df_bertweet = pd.concat([df_data,bertweet],axis=1)\n",
    "print(df_bertweet.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bertweet.to_csv('./df_bertweet.csv', index = False)"
   ]
  },
  {
   "source": [
    "## Bulk Embedding (Validation File)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_valid_notembeded.csv')\n",
    "\n",
    "text = data.text\n",
    "text.dropna(inplace=True)\n",
    "# text = text.sample(frac=0.4, random_state=999)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=False)\n",
    "bertweet = AutoModel.from_pretrained(\"vinai/bertweet-base\")\n",
    "\n",
    "sents = [tokenizer.tokenize(tweet) for tweet in text]\n",
    "len(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertweet.eval()\n",
    "embeddings = []\n",
    "\n",
    "for sent in sents:\n",
    "    input_ids = torch.tensor([tokenizer.encode(sent)])\n",
    "    with torch.no_grad():\n",
    "        features = bertweet(input_ids)  # Models outputs are now tuples\n",
    "    embeddings.append(features)\n",
    "    \n",
    "result = [torch.mean(features.last_hidden_state[-1], dim=0).tolist() for features in embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(390, 768)\n"
     ]
    }
   ],
   "source": [
    "bertweet = pd.DataFrame(result)\n",
    "print(bertweet.shape)\n",
    "print(data.shape)\n",
    "print(bertweet.shape)\n",
    "df_valid_bertweet = pd.concat([data,bertweet],axis=1)\n",
    "print(df_valid_bertweet.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'bertweet' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-7a599ed16ab5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbertweet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'bertweet' is not defined"
     ]
    }
   ],
   "source": [
    "bertweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_bertweet.to_csv('./df_valid_bertweet.csv', index = False)"
   ]
  },
  {
   "source": [
    "## Bulk Embedding (Train and Test File)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "text = data.text\n",
    "text.dropna(inplace=True)\n",
    "# text = text.sample(frac=0.4, random_state=999)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=False)\n",
    "bertweet = AutoModel.from_pretrained(\"vinai/bertweet-base\")\n",
    "\n",
    "sents = [tokenizer.tokenize(tweet) for tweet in text]\n",
    "print(len(sents))\n",
    "\n",
    "bertweet.eval()\n",
    "embeddings = []\n",
    "\n",
    "for sent in sents:\n",
    "    input_ids = torch.tensor([tokenizer.encode(sent)])\n",
    "    with torch.no_grad():\n",
    "        features = bertweet(input_ids)  # Models outputs are now tuples\n",
    "    embeddings.append(features)\n",
    "    \n",
    "result = [torch.mean(features.last_hidden_state[-1], dim=0).tolist() for features in embeddings]\n",
    "\n",
    "bertweet = pd.DataFrame(result)\n",
    "print(bertweet.shape)\n",
    "print(data.shape)\n",
    "print(bertweet.shape)\n",
    "df_valid_bertweet = pd.concat([data,bertweet],axis=1)\n",
    "print(df_valid_bertweet.shape)"
   ]
  }
 ]
}