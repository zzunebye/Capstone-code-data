{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions / Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fetchData import fetchdata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(X_train, X_test, y_train, y_test, clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    result = clf.predict(X_test)\n",
    "    print(\"Accuracy:\\t\\t\",accuracy_score(y_test,result))\n",
    "    print('Precision Score:\\t', str(precision_score(y_test,result)))\n",
    "    print('Recall Score:\\t\\t' + str(recall_score(y_test,result)))\n",
    "    print(\"F1 Score:\\t\\t\",f1_score(y_test, result, average='macro', zero_division=True))\n",
    "    print(classification_report(y_test, result))\n",
    "    \n",
    "\n",
    "def valid(X_valid, y_valid, clf):\n",
    "    clf.fit\n",
    "    result = clf.predict(X_valid)\n",
    "    print(\"Accuracy:\",accuracy_score(result,y_valid))\n",
    "    print(classification_report(y_valid, result))\n",
    "\n",
    "def cv_events(data):\n",
    "    NUM_EVENT = data.Event.unique().shape[0]\n",
    "    EVENTS = data.Event.unique()\n",
    "\n",
    "    cv_pd_list = []\n",
    "    for i, d in enumerate(EVENTS):\n",
    "        df1, df2 = [x for _, x in data.groupby(data['Event'] != d)]\n",
    "        df1.reset_index(inplace=True, drop=True)\n",
    "        df2.reset_index(inplace=True, drop=True)\n",
    "        cv_pd_list.append([df1, df2])\n",
    "    return cv_pd_list\n",
    "\n",
    "def algorithm_pipeline(X_train_data, X_test_data, y_train_data, y_test_data, \n",
    "                       model, param_grid, cv=10, scoring_fit='neg_mean_squared_error',\n",
    "                       do_probabilities = False):\n",
    "    gs = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid, \n",
    "        cv=cv, \n",
    "        n_jobs=-1, \n",
    "        scoring=scoring_fit,\n",
    "        verbose=2\n",
    "    )\n",
    "    fitted_model = gs.fit(X_train_data, y_train_data)\n",
    "    \n",
    "    if do_probabilities:\n",
    "      pred = fitted_model.predict_proba(X_test_data)\n",
    "    else:\n",
    "      pred = fitted_model.predict(X_test_data)\n",
    "    \n",
    "    return fitted_model, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_concat(data_list):\n",
    "    scaler = StandardScaler()\n",
    "    df = scaler.fit_transform(pd.concat(data_list, axis=1))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheme_AVGw2v = pd.read_csv('./data/_PHEME_text_AVGw2v.csv').drop(['token'],axis=1)\n",
    "pheme_sparse = pd.read_csv('./data/_PHEME_sparse.csv')\n",
    "pheme_y = pd.read_csv('./data/_PHEME_target.csv').target\n",
    "pheme_event = pd.read_csv('./data/_PHEME_text.csv')['Event']\n",
    "pheme_bert = fetchdata('pheme','bert')\n",
    "pheme_thread =  fetchdata('pheme','thread')\n",
    "\n",
    "ext_AVGw2v = pd.read_csv('./data/_PHEMEext_text_AVGw2v.csv').drop(['token'],axis=1)\n",
    "ext_sparse = pd.read_csv('./data/_PHEMEext_sparse.csv')\n",
    "ext_y = pd.read_csv('./data/_PHEMEext_text.csv').target\n",
    "ext_event = pd.read_csv('./data/_PHEMEext_text.csv').Event\n",
    "ext_bert = fetchdata('ext','bert')\n",
    "ext_thread = fetchdata('ext','thread')\n",
    "\n",
    "rhi = pd.read_csv('./data/_RHI_text_AVGw2v.csv').drop(['token'],axis=1)\n",
    "rhi_y = pd.read_csv('./data/_RHI_target.csv')\n",
    "rhi_bert = fetchdata('rhi','bert')\n",
    "\n",
    "# pheme_all = pd.read_csv(\"./data/all/_PHEMEall.csv\")\n",
    "# ext_all = pd.read_csv(\"./data/all/_PHEMEextall.csv\")\n",
    "\n",
    "# temp = pd.read_csv('./data/previous/data_notembeded.csv')\n",
    "# pd.concat([pheme_sparse, pheme_event])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheme_thread = pheme_thread.replace(-np.inf, 0)\n",
    "ext_thread = ext_thread.replace(-np.inf, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv = cv_events(pd.concat([pheme_sparse, pheme_event], axis=1))\n",
    "cv = cv_events(pd.concat([pheme_sparse, pheme_y, pheme_event],axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance on Sparse Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 21: capital_ratio (0.046487)\n",
      "2. feature 23: listed_count (0.045595)\n",
      "3. feature 22: tweet_count (0.044854)\n",
      "4. feature 25: follow_ratio (0.043432)\n",
      "5. feature 24: friends_count (0.038014)\n",
      "6. feature 17: word_count (0.037747)\n",
      "7. feature 2: Verb (0.037098)\n",
      "8. feature 1: Noun (0.036460)\n",
      "9. feature 16: char_count (0.035815)\n",
      "10. feature 9: Numeral (0.034910)\n",
      "11. feature 3: Adjective (0.034259)\n",
      "12. feature 29: AVG WordCount (0.033035)\n",
      "13. feature 15: HashTag (0.032760)\n",
      "14. feature 12: Determiner (0.032642)\n",
      "15. feature 10: Conjunction_inj (0.032559)\n",
      "16. feature 33: AVG Url (0.032452)\n",
      "17. feature 34: AVG Mention (0.032250)\n",
      "18. feature 27: SUM FriendsCount (0.032232)\n",
      "19. feature 28: AVG FriendsCount (0.031801)\n",
      "20. feature 32: Percent HashTag (0.030974)\n",
      "21. feature 31: SUM HashTag (0.030434)\n",
      "22. feature 30: AVG HashTag (0.029737)\n",
      "23. feature 0: URLcount (0.026713)\n",
      "24. feature 8: Adverb (0.025446)\n",
      "25. feature 4: Pronoun (0.022452)\n",
      "26. feature 5: FirstPersonPronoun (0.021319)\n",
      "27. feature 26: verified (0.019804)\n",
      "28. feature 14: Whs (0.015713)\n",
      "29. feature 35: Percent Mention (0.015694)\n",
      "30. feature 13: Modal (0.013865)\n",
      "31. feature 7: ThirdPersonPronoun (0.011743)\n",
      "32. feature 20: has_period (0.010568)\n",
      "33. feature 11: Particle (0.010023)\n",
      "34. feature 6: SecondPersonPronoun (0.007887)\n",
      "35. feature 18: has_question (0.007616)\n",
      "36. feature 19: has_exclaim (0.005607)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 432x288 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(pheme_sparse)\n",
    "X2 = scaler.fit_transform(pheme_thread)\n",
    "\n",
    "X = pd.concat([pheme_sparse, pheme_thread], axis=1)\n",
    "\n",
    "forest = ExtraTreesClassifier(n_estimators=250,\n",
    "                              random_state=3)\n",
    "\n",
    "forest.fit(X, pheme_y)\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d: %s (%f)\" % (f + 1, indices[f], X.columns[indices[f]], importances[indices[f]]))\n",
    "\n",
    "# Plot the impurity-based feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "        color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(pheme_thread.values)\n",
    "X_test = scaler.fit_transform(ext_thread.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.24123711340206186\n",
      "Precision Score:\t 1.0\n",
      "Recall Score:\t\t0.0027100271002710027\n",
      "F1 Score:\t\t 0.19603603603603603\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      1.00      0.39       116\n",
      "           1       1.00      0.00      0.01       369\n",
      "\n",
      "    accuracy                           0.24       485\n",
      "   macro avg       0.62      0.50      0.20       485\n",
      "weighted avg       0.82      0.24      0.10       485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = SVC()\n",
    "train_test(X_train, X_test, pheme_y, ext_y, clf)\n",
    "\n",
    "# Accuracy:\t\t 0.6268041237113402\n",
    "# Precision Score:\t 0.7596685082872928\n",
    "# Recall Score:\t\t0.7452574525745257\n",
    "# F1 Score:\t\t 0.49753590255796776"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "pheme_sparse_scaled = scaler.fit_transform(pheme_sparse.values)\n",
    "ext_sparse_scaled = scaler.fit_transform(ext_sparse.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.3463917525773196\n",
      "Precision Score:\t 0.9193548387096774\n",
      "Recall Score:\t\t0.15447154471544716\n",
      "F1 Score:\t\t 0.3381875002690382\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.96      0.41       116\n",
      "           1       0.92      0.15      0.26       369\n",
      "\n",
      "    accuracy                           0.35       485\n",
      "   macro avg       0.59      0.56      0.34       485\n",
      "weighted avg       0.76      0.35      0.30       485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(gamma='auto')\n",
    "train_test(pheme_sparse_scaled, ext_sparse_scaled, pheme_y, ext_y, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.5917525773195876\n",
      "Precision Score:\t 0.8577405857740585\n",
      "Recall Score:\t\t0.5555555555555556\n",
      "F1 Score:\t\t 0.5636903896481535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.71      0.45       116\n",
      "           1       0.86      0.56      0.67       369\n",
      "\n",
      "    accuracy                           0.59       485\n",
      "   macro avg       0.60      0.63      0.56       485\n",
      "weighted avg       0.73      0.59      0.62       485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "train_test(pheme_sparse_scaled, ext_sparse_scaled, pheme_y, ext_y, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPARSE - PHEME CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.47191011235955055\n",
      "Precision Score:\t 0.0\n",
      "Recall Score:\t\t0.0\n",
      "F1 Score:\t\t 0.32061068702290074\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      1.00      0.64       420\n",
      "           1       0.00      0.00      0.00       470\n",
      "\n",
      "    accuracy                           0.47       890\n",
      "   macro avg       0.24      0.50      0.32       890\n",
      "weighted avg       0.22      0.47      0.30       890\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/june/miniconda3/envs/rosetta/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/june/miniconda3/envs/rosetta/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/june/miniconda3/envs/rosetta/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/june/miniconda3/envs/rosetta/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "X = cv[3][1].drop(['target', 'Event'],axis=1)\n",
    "y = cv[3][1].target\n",
    "val_X = cv[3][0].drop(['target', 'Event'],axis=1)\n",
    "val_y = cv[3][0].target\n",
    "clf = SVC(gamma='auto')\n",
    "train_test(X, val_X, y, val_y, clf)\n",
    "# valid(rhi, rhi_y, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse + W2V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df = scaler.fit_transform(pheme_sparse.values)\n",
    "sparse_w2v = np.concatenate([df, pheme_AVGw2v.values],axis=1)\n",
    "df = scaler.fit_transform(ext_sparse.values)\n",
    "sparse_w2v_ext = np.concatenate([df, ext_AVGw2v.values],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.32989690721649484\n",
      "Precision Score:\t 0.9782608695652174\n",
      "Recall Score:\t\t0.12195121951219512\n",
      "F1 Score:\t\t 0.31564094214696625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.99      0.41       116\n",
      "           1       0.98      0.12      0.22       369\n",
      "\n",
      "    accuracy                           0.33       485\n",
      "   macro avg       0.62      0.56      0.32       485\n",
      "weighted avg       0.81      0.33      0.26       485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(gamma='auto')\n",
    "train_test(sparse_w2v, sparse_w2v_ext, pheme_y, ext_y, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.4\n",
      "Precision Score:\t 0.9148936170212766\n",
      "Recall Score:\t\t0.23306233062330622\n",
      "F1 Score:\t\t 0.3987628918680588\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.93      0.43       116\n",
      "           1       0.91      0.23      0.37       369\n",
      "\n",
      "    accuracy                           0.40       485\n",
      "   macro avg       0.60      0.58      0.40       485\n",
      "weighted avg       0.76      0.40      0.38       485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "train_test(sparse_w2v, sparse_w2v_ext, pheme_y, ext_y, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>BERTEmbed_0</th>\n      <th>BERTEmbed_1</th>\n      <th>BERTEmbed_2</th>\n      <th>BERTEmbed_3</th>\n      <th>BERTEmbed_4</th>\n      <th>BERTEmbed_5</th>\n      <th>BERTEmbed_6</th>\n      <th>BERTEmbed_7</th>\n      <th>BERTEmbed_8</th>\n      <th>BERTEmbed_9</th>\n      <th>...</th>\n      <th>BERTEmbed_758</th>\n      <th>BERTEmbed_759</th>\n      <th>BERTEmbed_760</th>\n      <th>BERTEmbed_761</th>\n      <th>BERTEmbed_762</th>\n      <th>BERTEmbed_763</th>\n      <th>BERTEmbed_764</th>\n      <th>BERTEmbed_765</th>\n      <th>BERTEmbed_766</th>\n      <th>BERTEmbed_767</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.299457</td>\n      <td>0.198897</td>\n      <td>-0.491295</td>\n      <td>0.211787</td>\n      <td>0.197080</td>\n      <td>0.234026</td>\n      <td>0.200608</td>\n      <td>-0.096086</td>\n      <td>0.250423</td>\n      <td>0.266876</td>\n      <td>...</td>\n      <td>0.209932</td>\n      <td>-0.166056</td>\n      <td>0.245046</td>\n      <td>-0.580443</td>\n      <td>-0.141690</td>\n      <td>0.222918</td>\n      <td>-0.144328</td>\n      <td>0.048243</td>\n      <td>-0.027414</td>\n      <td>-0.055394</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.299628</td>\n      <td>0.207495</td>\n      <td>-0.491100</td>\n      <td>0.207046</td>\n      <td>0.198606</td>\n      <td>0.223802</td>\n      <td>0.201070</td>\n      <td>-0.085390</td>\n      <td>0.272306</td>\n      <td>0.276768</td>\n      <td>...</td>\n      <td>0.227522</td>\n      <td>-0.168281</td>\n      <td>0.246145</td>\n      <td>-0.575933</td>\n      <td>-0.133583</td>\n      <td>0.210461</td>\n      <td>-0.141031</td>\n      <td>0.049042</td>\n      <td>-0.035745</td>\n      <td>-0.065774</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.300907</td>\n      <td>0.193260</td>\n      <td>-0.498778</td>\n      <td>0.215972</td>\n      <td>0.193097</td>\n      <td>0.223985</td>\n      <td>0.181815</td>\n      <td>-0.106533</td>\n      <td>0.247362</td>\n      <td>0.262557</td>\n      <td>...</td>\n      <td>0.210722</td>\n      <td>-0.168287</td>\n      <td>0.242233</td>\n      <td>-0.579043</td>\n      <td>-0.142183</td>\n      <td>0.223372</td>\n      <td>-0.142068</td>\n      <td>0.043969</td>\n      <td>-0.031963</td>\n      <td>-0.054336</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.294519</td>\n      <td>0.198307</td>\n      <td>-0.492020</td>\n      <td>0.211912</td>\n      <td>0.201571</td>\n      <td>0.225530</td>\n      <td>0.192947</td>\n      <td>-0.100199</td>\n      <td>0.261141</td>\n      <td>0.264648</td>\n      <td>...</td>\n      <td>0.216593</td>\n      <td>-0.163219</td>\n      <td>0.242032</td>\n      <td>-0.586569</td>\n      <td>-0.137623</td>\n      <td>0.219293</td>\n      <td>-0.139870</td>\n      <td>0.039641</td>\n      <td>-0.034909</td>\n      <td>-0.062468</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.296625</td>\n      <td>0.196416</td>\n      <td>-0.493361</td>\n      <td>0.214012</td>\n      <td>0.195244</td>\n      <td>0.231359</td>\n      <td>0.194209</td>\n      <td>-0.101270</td>\n      <td>0.252890</td>\n      <td>0.263173</td>\n      <td>...</td>\n      <td>0.211895</td>\n      <td>-0.166441</td>\n      <td>0.237079</td>\n      <td>-0.587006</td>\n      <td>-0.140724</td>\n      <td>0.224566</td>\n      <td>-0.142844</td>\n      <td>0.041942</td>\n      <td>-0.030708</td>\n      <td>-0.056173</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 768 columns</p>\n</div>",
      "text/plain": "   BERTEmbed_0  BERTEmbed_1  BERTEmbed_2  BERTEmbed_3  BERTEmbed_4  \\\n0     0.299457     0.198897    -0.491295     0.211787     0.197080   \n1     0.299628     0.207495    -0.491100     0.207046     0.198606   \n2     0.300907     0.193260    -0.498778     0.215972     0.193097   \n3     0.294519     0.198307    -0.492020     0.211912     0.201571   \n4     0.296625     0.196416    -0.493361     0.214012     0.195244   \n\n   BERTEmbed_5  BERTEmbed_6  BERTEmbed_7  BERTEmbed_8  BERTEmbed_9  ...  \\\n0     0.234026     0.200608    -0.096086     0.250423     0.266876  ...   \n1     0.223802     0.201070    -0.085390     0.272306     0.276768  ...   \n2     0.223985     0.181815    -0.106533     0.247362     0.262557  ...   \n3     0.225530     0.192947    -0.100199     0.261141     0.264648  ...   \n4     0.231359     0.194209    -0.101270     0.252890     0.263173  ...   \n\n   BERTEmbed_758  BERTEmbed_759  BERTEmbed_760  BERTEmbed_761  BERTEmbed_762  \\\n0       0.209932      -0.166056       0.245046      -0.580443      -0.141690   \n1       0.227522      -0.168281       0.246145      -0.575933      -0.133583   \n2       0.210722      -0.168287       0.242233      -0.579043      -0.142183   \n3       0.216593      -0.163219       0.242032      -0.586569      -0.137623   \n4       0.211895      -0.166441       0.237079      -0.587006      -0.140724   \n\n   BERTEmbed_763  BERTEmbed_764  BERTEmbed_765  BERTEmbed_766  BERTEmbed_767  \n0       0.222918      -0.144328       0.048243      -0.027414      -0.055394  \n1       0.210461      -0.141031       0.049042      -0.035745      -0.065774  \n2       0.223372      -0.142068       0.043969      -0.031963      -0.054336  \n3       0.219293      -0.139870       0.039641      -0.034909      -0.062468  \n4       0.224566      -0.142844       0.041942      -0.030708      -0.056173  \n\n[5 rows x 768 columns]"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pheme_y.head()\n",
    "pheme_bert.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.5917525773195876\n",
      "Precision Score:\t 0.7697160883280757\n",
      "Recall Score:\t\t0.6612466124661247\n",
      "F1 Score:\t\t 0.5070935818995606\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.37      0.30       116\n",
      "           1       0.77      0.66      0.71       369\n",
      "\n",
      "    accuracy                           0.59       485\n",
      "   macro avg       0.51      0.52      0.51       485\n",
      "weighted avg       0.65      0.59      0.61       485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(gamma='auto')\n",
    "train_test(pheme_bert, ext_bert, pheme_y, ext_y, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.6268041237113402\n",
      "Precision Score:\t 0.7596685082872928\n",
      "Recall Score:\t\t0.7452574525745257\n",
      "F1 Score:\t\t 0.49753590255796776\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.25      0.24       116\n",
      "           1       0.76      0.75      0.75       369\n",
      "\n",
      "    accuracy                           0.63       485\n",
      "   macro avg       0.50      0.50      0.50       485\n",
      "weighted avg       0.63      0.63      0.63       485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "train_test(pheme_bert, ext_bert, pheme_y, ext_y, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W2V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.32989690721649484\n",
      "Precision Score:\t 0.9782608695652174\n",
      "Recall Score:\t\t0.12195121951219512\n",
      "F1 Score:\t\t 0.31564094214696625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.99      0.41       116\n",
      "           1       0.98      0.12      0.22       369\n",
      "\n",
      "    accuracy                           0.33       485\n",
      "   macro avg       0.62      0.56      0.32       485\n",
      "weighted avg       0.81      0.33      0.26       485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(gamma='auto')\n",
    "train_test(sparse_w2v, sparse_w2v_ext, pheme_y, ext_y, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.4\n",
      "Precision Score:\t 0.9148936170212766\n",
      "Recall Score:\t\t0.23306233062330622\n",
      "F1 Score:\t\t 0.3987628918680588\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.93      0.43       116\n",
      "           1       0.91      0.23      0.37       369\n",
      "\n",
      "    accuracy                           0.40       485\n",
      "   macro avg       0.60      0.58      0.40       485\n",
      "weighted avg       0.76      0.40      0.38       485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "train_test(sparse_w2v, sparse_w2v_ext, pheme_y, ext_y, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT + SPARSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df = scaler.fit_transform(pheme_sparse.values)\n",
    "df2 = scaler.fit_transform(pheme_thread.values)\n",
    "sparse_bert = np.concatenate([df, df2, pheme_bert.values],axis=1)\n",
    "df = scaler.fit_transform(ext_sparse.values)\n",
    "df2 = scaler.fit_transform(ext_thread.values)\n",
    "sparse_bert_ext = np.concatenate([df, df2, ext_bert.values],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.4350515463917526\n",
      "Precision Score:\t 0.8925619834710744\n",
      "Recall Score:\t\t0.2926829268292683\n",
      "F1 Score:\t\t 0.43499149659863945\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.89      0.43       116\n",
      "           1       0.89      0.29      0.44       369\n",
      "\n",
      "    accuracy                           0.44       485\n",
      "   macro avg       0.59      0.59      0.43       485\n",
      "weighted avg       0.75      0.44      0.44       485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(gamma='auto')\n",
    "train_test(sparse_bert, sparse_bert_ext, pheme_y, ext_y, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.6268041237113402\n",
      "Precision Score:\t 0.7596685082872928\n",
      "Recall Score:\t\t0.7452574525745257\n",
      "F1 Score:\t\t 0.49753590255796776\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.25      0.24       116\n",
      "           1       0.76      0.75      0.75       369\n",
      "\n",
      "    accuracy                           0.63       485\n",
      "   macro avg       0.50      0.50      0.50       485\n",
      "weighted avg       0.63      0.63      0.63       485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "train_test(sparse_bert, sparse_bert_ext, pheme_y, ext_y, clf)\n",
    "\n",
    "# Accuracy:\t\t 0.6268041237113402\n",
    "# Precision Score:\t 0.7596685082872928\n",
    "# Recall Score:\t\t0.7452574525745257\n",
    "# F1 Score:\t\t 0.49753590255796776"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.6536082474226804\n",
      "Precision Score:\t 0.7570332480818415\n",
      "Recall Score:\t\t0.8021680216802168\n",
      "F1 Score:\t\t 0.48947368421052634\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.18      0.20       116\n",
      "           1       0.76      0.80      0.78       369\n",
      "\n",
      "    accuracy                           0.65       485\n",
      "   macro avg       0.49      0.49      0.49       485\n",
      "weighted avg       0.63      0.65      0.64       485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = scale_concat([pheme_sparse, pheme_bert])\n",
    "X2 = scale_concat([ext_sparse, ext_bert])\n",
    "clf = GaussianNB()\n",
    "train_test(X, sparse_bert_ext, pheme_y, ext_y, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.5051546391752577\n",
      "Precision Score:\t 0.8028169014084507\n",
      "Recall Score:\t\t0.4634146341463415\n",
      "F1 Score:\t\t 0.4845360824742268\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.64      0.38       116\n",
      "           1       0.80      0.46      0.59       369\n",
      "\n",
      "    accuracy                           0.51       485\n",
      "   macro avg       0.54      0.55      0.48       485\n",
      "weighted avg       0.68      0.51      0.54       485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = scale_concat([pheme_sparse, pheme_bert, pheme_thread])\n",
    "X2 = scale_concat([ext_sparse, ext_bert, ext_thread])\n",
    "clf = SVC()\n",
    "train_test(X, X2, pheme_y, ext_y, clf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rosetta",
   "language": "python",
   "name": "rosetta"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}