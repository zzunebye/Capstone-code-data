{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions / Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fetchData import fetchdata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(X_train, X_test, y_train, y_test, clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    result = clf.predict(X_test)\n",
    "    print(\"Accuracy:\\t\\t\",accuracy_score(y_test,result))\n",
    "    print('Precision Score:\\t', str(precision_score(y_test,result)))\n",
    "    print('Recall Score:\\t\\t' + str(recall_score(y_test,result)))\n",
    "    print(\"F1 Score:\\t\\t\",f1_score(y_test, result, average='macro', zero_division=True))\n",
    "    print(classification_report(y_test, result))\n",
    "    \n",
    "\n",
    "def valid(X_valid, y_valid, clf):\n",
    "    clf.fit\n",
    "    result = clf.predict(X_valid)\n",
    "    print(\"Accuracy:\",accuracy_score(result,y_valid))\n",
    "    print(classification_report(y_valid, result))\n",
    "\n",
    "def cv_events(data):\n",
    "    NUM_EVENT = data.Event.unique().shape[0]\n",
    "    EVENTS = data.Event.unique()\n",
    "\n",
    "    cv_pd_list = []\n",
    "    for i, d in enumerate(EVENTS):\n",
    "        df1, df2 = [x for _, x in data.groupby(data['Event'] != d)]\n",
    "        df1.reset_index(inplace=True, drop=True)\n",
    "        df2.reset_index(inplace=True, drop=True)\n",
    "        cv_pd_list.append([df1, df2])\n",
    "    return cv_pd_list\n",
    "\n",
    "def algorithm_pipeline(X_train_data, X_test_data, y_train_data, y_test_data, \n",
    "                       model, param_grid, cv=10, scoring_fit='neg_mean_squared_error',\n",
    "                       do_probabilities = False):\n",
    "    gs = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid, \n",
    "        cv=cv, \n",
    "        n_jobs=-1, \n",
    "        scoring=scoring_fit,\n",
    "        verbose=2\n",
    "    )\n",
    "    fitted_model = gs.fit(X_train_data, y_train_data)\n",
    "    \n",
    "    if do_probabilities:\n",
    "      pred = fitted_model.predict_proba(X_test_data)\n",
    "    else:\n",
    "      pred = fitted_model.predict(X_test_data)\n",
    "    \n",
    "    return fitted_model, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_concat(data_list):\n",
    "    scaler = StandardScaler()\n",
    "    df = scaler.fit_transform(pd.concat(data_list, axis=1))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final\n",
    "pheme_sparse_final = pd.read_csv('./data/_PHEME_sparse.csv')\n",
    "pheme_y = pd.read_csv('./data/_PHEME_target.csv').target\n",
    "pheme_pos_final = pd.read_csv('./data/_PHEME_postags.csv')\n",
    "pheme_thread_final_avg = pd.read_csv('./data/_PHEME_thread_avg.csv')\n",
    "pheme_thread_final_std = pd.read_csv('./data/_PHEME_thread_std.csv')\n",
    "\n",
    "ext_pos_final = pd.read_csv('./data/_PHEMEext_postags.csv')\n",
    "ext_sparse_final = pd.read_csv('./data/_PHEMEext_sparse.csv')\n",
    "ext_y = pd.read_csv('./data/_PHEMEext_text.csv').target\n",
    "ext_thread_final_avg = pd.read_csv('./data/_PHEMEext_thread_avg.csv')\n",
    "ext_thread_final_std = pd.read_csv('./data/_PHEMEext_thread_std.csv')\n",
    "\n",
    "pheme_bert_simple_normal = pd.read_csv('./data/_PHEME_Bert_final_simple_nrmzd.csv')\n",
    "ext_bert_simple_normal = pd.read_csv('./data/_PHEMEext_Bert_final_simple_nrmzd.csv')\n",
    "\n",
    "pheme_bert_brackets_normal = pd.read_csv('./data/_PHEME_Bert_final_brackets_nrmzd.csv')\n",
    "ext_bert_brackets_normal = pd.read_csv('./data/_PHEMEext_Bert_final_brackets_nrmzd.csv')\n",
    "\n",
    "pheme_event = pd.read_csv('./data/_PHEME_text.csv')['Event']\n",
    "ext_event = pd.read_csv('./data/_PHEMEext_text.csv').Event\n",
    "pheme_AVGw2v = pd.read_csv('./data/_PHEME_text_AVGw2v_final.csv')\n",
    "ext_AVGw2v = pd.read_csv('./data/_PHEMEext_text_AVGw2v_final.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheme_root = pd.concat([pheme_sparse_final, pheme_pos_final],axis=1)\n",
    "ext_root = pd.concat([ext_sparse_final, ext_pos_final],axis=1)\n",
    "\n",
    "pheme_root_thread = pd.concat([pheme_root, pheme_thread_final_avg],axis=1)\n",
    "ext_root_thread = pd.concat([ext_root, ext_thread_final_avg],axis=1)\n",
    "\n",
    "pheme_total_bert= pd.concat([pheme_root_thread, pheme_bert_simple_normal],axis=1)\n",
    "ext_total_bert = pd.concat([ext_root_thread, ext_bert_simple_normal],axis=1)\n",
    "pheme_total_w2v= pd.concat([pheme_root_thread, pheme_AVGw2v],axis=1)\n",
    "ext_total_w2v = pd.concat([ext_root_thread, ext_AVGw2v],axis=1)\n",
    "\n",
    "\n",
    "\n",
    "pheme_w2v_bert = pd.concat([pheme_AVGw2v, pheme_bert_simple_normal],axis=1)\n",
    "ext_w2v_bert = pd.concat([ext_AVGw2v, ext_bert_simple_normal],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_event = pd.concat([pheme_event,ext_event],axis=0, ignore_index=True)\n",
    "all_y = pd.concat([pheme_y,ext_y],axis=0, ignore_index=True)\n",
    "\n",
    "all_root = pd.concat([pheme_root, ext_root],axis=0, ignore_index=True)\n",
    "all_thread = pd.concat([pheme_thread_final_avg, ext_thread_final_avg],axis=0, ignore_index=True)\n",
    "all_bert_simple = pd.concat([pheme_bert_simple_normal,ext_bert_simple_normal],axis=0,ignore_index=True)\n",
    "all_AVGw2v = pd.concat([pheme_AVGw2v,ext_AVGw2v],axis=0,ignore_index=True)\n",
    "all_w2v_bert = pd.concat([pheme_w2v_bert,ext_w2v_bert],axis=0,ignore_index=True)\n",
    "all_root_thread = pd.concat([pheme_root_thread,ext_root_thread],axis=0,ignore_index=True)\n",
    "all_total_bert = pd.concat([pheme_total_bert,ext_total_bert],axis=0,ignore_index=True)\n",
    "all_total_w2v = pd.concat([pheme_total_w2v,ext_total_w2v],axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(6425, 301)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_total_w2v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv = cv_events(pd.concat([pheme_sparse, pheme_event], axis=1))\n",
    "# cv = cv_events(pd.concat([pheme_sparse, pheme_y, pheme_event],axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed_value=42):\n",
    "    \"\"\"Set seed for reproducibility.\n",
    "    \"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_cv(dataset, events=pheme_event, target=pheme_y, verbose=True):\n",
    "    cv_pd_list = []\n",
    "    data = pd.concat([dataset, pheme_event, pheme_y], axis=1)\n",
    "    NUM_EVENT = data.Event.unique().shape[0]\n",
    "    EVENTS = data.Event.unique()\n",
    "    results = {}\n",
    "\n",
    "    for i, d in enumerate(EVENTS):\n",
    "        df1, df2 = [x for _, x in data.groupby(data['Event'] != d)]\n",
    "        df1.reset_index(inplace=True, drop=True)\n",
    "        df2.reset_index(inplace=True, drop=True)\n",
    "        cv_pd_list.append([df2, df1])\n",
    "    for index, fold in enumerate(cv_pd_list):\n",
    "        train, test = fold\n",
    "        print(\"FOLD %d\\n----------------------------------------------------------------------------\" % (int(index)+1))\n",
    "        train_target = train.pop('target')\n",
    "        train.pop('Event')\n",
    "        test_target = test.pop('target')\n",
    "        test.pop('Event')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(623, 301)"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ext_total_w2v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_process(dataset, clfClass, target, events, verbose=True, scaling=False):\n",
    "\n",
    "    # cv_pd_list[?][0]은 Training cv_pd_list[?][1] Testing\n",
    "    cv_pd_list = []\n",
    "    data = pd.concat([dataset, events, target], axis=1)\n",
    "    NUM_EVENT = data.Event.unique().shape[0]\n",
    "    EVENTS = data.Event.unique()\n",
    "    results = {}\n",
    "    # modelClass.__class__\n",
    "\n",
    "    for i, d in enumerate(EVENTS):\n",
    "        df1, df2 = [x for _, x in data.groupby(data['Event'] != d)]\n",
    "        df1.reset_index(inplace=True, drop=True)\n",
    "        df2.reset_index(inplace=True, drop=True)\n",
    "        cv_pd_list.append([df2, df1])\n",
    "    \n",
    "    # for train, test in cv_pd_list:\n",
    "    #     print(\"Train: %s \\ Test: %s\" % (train.shape, test.shape))\n",
    "\n",
    "    # log = writeLog()\n",
    "    modelname = clfClass.__name__\n",
    "    PREFIX = \"./Model/\"+modelname+\"_\"\n",
    "    # log.write(PREFIX+\"log.txt\",f\"\\nSTARTING TEST of {epochs} EPOCH\\n\")\n",
    "\n",
    "    for index, fold in enumerate(cv_pd_list):\n",
    "\n",
    "        # DATA PREPARATION\n",
    "        train, test = fold\n",
    "        # log.writeWithoutCR(PREFIX+\"log.txt\",f\"\\n----------------------------------------------------------------------------\\n> FOLD {int(index)+1}\\n----------------------------------------------------------------------------\")\n",
    "        print(f'> FOLD {int(index)+1}')\n",
    "        train_target = train.pop('target')\n",
    "        train.pop('Event').values\n",
    "        test_target = test.pop('target')\n",
    "        test.pop('Event')\n",
    "\n",
    "        if scaling==True:\n",
    "            scaler = StandardScaler()\n",
    "            train = pd.DataFrame(scaler.fit_transform(train))\n",
    "            test = pd.DataFrame(scaler.transform(test))\n",
    "\n",
    "        train_size = int(train.shape[0])\n",
    "        test_size = int(test.shape[0])\n",
    "\n",
    "        model = clfClass()\n",
    "\n",
    "        if verbose==True:\n",
    "                # print(\"mean: %s, std: %s\" % (data[0].mean(), data[0].std()))\n",
    "                print(\"Train Size\",train_size,\"Test Size\",test_size)\n",
    "\n",
    "        model.fit(train, train_target)\n",
    "        result = model.predict(test)\n",
    "\n",
    "        acc = accuracy_score(test_target,result)\n",
    "        f1 = f1_score(test_target,result, average='macro')\n",
    "        if verbose==True:\n",
    "            print(\"Accuracy:\\t\\t\",acc)\n",
    "            print('Precision Score:\\t', str(precision_score(test_target,result)))\n",
    "            print('Recall Score:\\t\\t' + str(recall_score(test_target,result)))\n",
    "            print(\"F1 Score:\\t\\t\",f1)\n",
    "        # print(classification_report(test_target,result)\n",
    "\n",
    "        results[index] = [acc*100, f1*100,train_size, test_size]\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = []\n",
    "result_mean_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> FOLD 1\n",
      "Train Size 4346 Test Size 2079\n",
      "Accuracy:\t\t 0.7229437229437229\n",
      "Precision Score:\t 0.4206989247311828\n",
      "Recall Score:\t\t0.6834061135371179\n",
      "F1 Score:\t\t 0.6629703763911748\n",
      "> FOLD 2\n",
      "Train Size 5282 Test Size 1143\n",
      "Accuracy:\t\t 0.710411198600175\n",
      "Precision Score:\t 0.3769633507853403\n",
      "Recall Score:\t\t0.2535211267605634\n",
      "F1 Score:\t\t 0.5601929727687522\n",
      "> FOLD 3\n",
      "Train Size 5956 Test Size 469\n",
      "Accuracy:\t\t 0.6460554371002132\n",
      "Precision Score:\t 0.7068965517241379\n",
      "Recall Score:\t\t0.5168067226890757\n",
      "F1 Score:\t\t 0.6407490125143047\n",
      "> FOLD 4\n",
      "Train Size 5535 Test Size 890\n",
      "Accuracy:\t\t 0.6348314606741573\n",
      "Precision Score:\t 0.7821011673151751\n",
      "Recall Score:\t\t0.4276595744680851\n",
      "F1 Score:\t\t 0.6221576918504934\n",
      "> FOLD 5\n",
      "Train Size 5204 Test Size 1221\n",
      "Accuracy:\t\t 0.6764946764946765\n",
      "Precision Score:\t 0.673972602739726\n",
      "Recall Score:\t\t0.47126436781609193\n",
      "F1 Score:\t\t 0.650329699808234\n",
      "> FOLD 6\n",
      "Train Size 6411 Test Size 14\n",
      "Accuracy:\t\t 0.35714285714285715\n",
      "Precision Score:\t 1.0\n",
      "Recall Score:\t\t0.35714285714285715\n",
      "F1 Score:\t\t 0.2631578947368421\n",
      "> FOLD 7\n",
      "Train Size 6192 Test Size 233\n",
      "Accuracy:\t\t 0.23605150214592274\n",
      "Precision Score:\t 0.9636363636363636\n",
      "Recall Score:\t\t0.2314410480349345\n",
      "F1 Score:\t\t 0.19760872929887013\n",
      "> FOLD 8\n",
      "Train Size 6187 Test Size 238\n",
      "Accuracy:\t\t 0.5756302521008403\n",
      "Precision Score:\t 0.6712328767123288\n",
      "Recall Score:\t\t0.3888888888888889\n",
      "F1 Score:\t\t 0.5639206864648151\n",
      "> FOLD 9\n",
      "Train Size 6287 Test Size 138\n",
      "Accuracy:\t\t 0.5289855072463768\n",
      "Precision Score:\t 0.4696969696969697\n",
      "Recall Score:\t\t0.5081967213114754\n",
      "F1 Score:\t\t 0.5259736828198489\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------- #\n",
    "#                                  ROOT + POS                                  #\n",
    "# ---------------------------------------------------------------------------- #\n",
    "\n",
    "dataset = all_root\n",
    "model = SVC\n",
    "\n",
    "testing_results = []\n",
    "\n",
    "result = cv_process(dataset, clfClass=model, events=all_event, target=all_y, verbose=True, scaling=True)\n",
    "testing_results.append(result)\n",
    "\n",
    "# writeLog().writeWithoutCR(\"./Model/\"+root_model.__name__+\"_\"+\"log.txt\",f\"RESULT:\\n{epochs_diff(testing_results)}\")\n",
    "result_df = pd.DataFrame.from_dict(testing_results[0], orient='index', columns=['Acc', 'F1', 'Train_size','Test_size'])\n",
    "result_df['Features'] = 'RP'\n",
    "result_df['CV'] = 9\n",
    "result_df['CLF'] = model.__name__\n",
    "\n",
    "result_list.append(result_df)\n",
    "CV_result_df = pd.DataFrame(result_df[['Acc','F1', 'CV']].mean(), columns=[result_df.Features[0]]).T\n",
    "CV_result_df['CLF'] = result_df['CLF'][0]\n",
    "result_mean_list.append(CV_result_df)\n",
    "\n",
    "testing_results = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> FOLD 1\n",
      "> FOLD 2\n",
      "> FOLD 3\n",
      "> FOLD 4\n",
      "> FOLD 5\n",
      "> FOLD 6\n",
      "> FOLD 7\n",
      "> FOLD 8\n",
      "> FOLD 9\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------- #\n",
    "#                                  Thread                                  #\n",
    "# ---------------------------------------------------------------------------- #\n",
    "\n",
    "dataset = all_thread\n",
    "model = SVC\n",
    "\n",
    "testing_results = []\n",
    "\n",
    "result = cv_process(dataset, clfClass=model, events=all_event, target=all_y, verbose=False, scaling=True)\n",
    "testing_results.append(result)\n",
    "\n",
    "# writeLog().writeWithoutCR(\"./Model/\"+root_model.__name__+\"_\"+\"log.txt\",f\"RESULT:\\n{epochs_diff(testing_results)}\")\n",
    "result_df = pd.DataFrame.from_dict(testing_results[0], orient='index', columns=['Acc', 'F1', 'Train_size','Test_size'])\n",
    "result_df['Features'] = 'Thread'\n",
    "result_df['CV'] = 9\n",
    "result_df['CLF'] = model.__name__\n",
    "\n",
    "result_list.append(result_df)\n",
    "CV_result_df = pd.DataFrame(result_df[['Acc','F1', 'CV']].mean(), columns=[result_df.Features[0]]).T\n",
    "CV_result_df['CLF'] = result_df['CLF'][0]\n",
    "result_mean_list.append(CV_result_df)\n",
    "\n",
    "testing_results = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> FOLD 1\n",
      "Train Size 4346 Test Size 2079\n",
      "Accuracy:\t\t 0.8258778258778259\n",
      "Precision Score:\t 0.5845070422535211\n",
      "Recall Score:\t\t0.7248908296943232\n",
      "F1 Score:\t\t 0.7657961954695167\n",
      "> FOLD 2\n",
      "Train Size 5282 Test Size 1143\n",
      "Accuracy:\t\t 0.7725284339457568\n",
      "Precision Score:\t 0.58\n",
      "Recall Score:\t\t0.30633802816901406\n",
      "F1 Score:\t\t 0.6302664450438434\n",
      "> FOLD 3\n",
      "Train Size 5956 Test Size 469\n",
      "Accuracy:\t\t 0.6886993603411514\n",
      "Precision Score:\t 0.7446808510638298\n",
      "Recall Score:\t\t0.5882352941176471\n",
      "F1 Score:\t\t 0.6860603726525822\n",
      "> FOLD 4\n",
      "Train Size 5535 Test Size 890\n",
      "Accuracy:\t\t 0.648314606741573\n",
      "Precision Score:\t 0.8284518828451883\n",
      "Recall Score:\t\t0.42127659574468085\n",
      "F1 Score:\t\t 0.6331414559241655\n",
      "> FOLD 5\n",
      "Train Size 5204 Test Size 1221\n",
      "Accuracy:\t\t 0.6764946764946765\n",
      "Precision Score:\t 0.7797356828193832\n",
      "Recall Score:\t\t0.3390804597701149\n",
      "F1 Score:\t\t 0.6196582645732802\n",
      "> FOLD 6\n",
      "Train Size 6411 Test Size 14\n",
      "Accuracy:\t\t 0.5714285714285714\n",
      "Precision Score:\t 1.0\n",
      "Recall Score:\t\t0.5714285714285714\n",
      "F1 Score:\t\t 0.36363636363636365\n",
      "> FOLD 7\n",
      "Train Size 6192 Test Size 233\n",
      "Accuracy:\t\t 0.06437768240343347\n",
      "Precision Score:\t 1.0\n",
      "Recall Score:\t\t0.048034934497816595\n",
      "F1 Score:\t\t 0.06353244837758112\n",
      "> FOLD 8\n",
      "Train Size 6187 Test Size 238\n",
      "Accuracy:\t\t 0.5336134453781513\n",
      "Precision Score:\t 0.8\n",
      "Recall Score:\t\t0.15873015873015872\n",
      "F1 Score:\t\t 0.46168110035659704\n",
      "> FOLD 9\n",
      "Train Size 6287 Test Size 138\n",
      "Accuracy:\t\t 0.572463768115942\n",
      "Precision Score:\t 0.5555555555555556\n",
      "Recall Score:\t\t0.16393442622950818\n",
      "F1 Score:\t\t 0.47683608558761165\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------- #\n",
    "#                                  w2v                                  #\n",
    "# ---------------------------------------------------------------------------- #\n",
    "\n",
    "dataset = all_AVGw2v\n",
    "model = SVC\n",
    "\n",
    "testing_results = []\n",
    "\n",
    "result = cv_process(dataset, clfClass=model, events=all_event, target=all_y, verbose=False, scaling=True)\n",
    "testing_results.append(result)\n",
    "\n",
    "# writeLog().writeWithoutCR(\"./Model/\"+root_model.__name__+\"_\"+\"log.txt\",f\"RESULT:\\n{epochs_diff(testing_results)}\")\n",
    "result_df = pd.DataFrame.from_dict(testing_results[0], orient='index', columns=['Acc', 'F1', 'Train_size','Test_size'])\n",
    "result_df['Features'] = 'W2V'\n",
    "result_df['CV'] = 9\n",
    "result_df['CLF'] = model.__name__\n",
    "\n",
    "result_list.append(result_df)\n",
    "CV_result_df = pd.DataFrame(result_df[['Acc','F1', 'CV']].mean(), columns=[result_df.Features[0]]).T\n",
    "CV_result_df['CLF'] = result_df['CLF'][0]\n",
    "result_mean_list.append(CV_result_df)\n",
    "\n",
    "testing_results = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> FOLD 1\n",
      "> FOLD 2\n",
      "> FOLD 3\n",
      "> FOLD 4\n",
      "> FOLD 5\n",
      "> FOLD 6\n",
      "> FOLD 7\n",
      "> FOLD 8\n",
      "> FOLD 9\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------- #\n",
    "#                                  BERT                                  #\n",
    "# ---------------------------------------------------------------------------- #\n",
    "\n",
    "dataset = all_bert_simple\n",
    "model = SVC\n",
    "testing_results = []\n",
    "\n",
    "result = cv_process(dataset, clfClass=model, events=all_event, target=all_y, verbose=False, scaling=True)\n",
    "testing_results.append(result)\n",
    "\n",
    "# writeLog().writeWithoutCR(\"./Model/\"+root_model.__name__+\"_\"+\"log.txt\",f\"RESULT:\\n{epochs_diff(testing_results)}\")\n",
    "result_df = pd.DataFrame.from_dict(testing_results[0], orient='index', columns=['Acc', 'F1', 'Train_size','Test_size'])\n",
    "result_df['Features'] = 'BERT'\n",
    "result_df['CV'] = 9\n",
    "result_df['CLF'] = model.__name__\n",
    "\n",
    "result_list.append(result_df)\n",
    "CV_result_df = pd.DataFrame(result_df[['Acc','F1', 'CV']].mean(), columns=[result_df.Features[0]]).T\n",
    "CV_result_df['CLF'] = result_df['CLF'][0]\n",
    "result_mean_list.append(CV_result_df)\n",
    "\n",
    "testing_results = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> FOLD 1\n",
      "Train Size 4346 Test Size 2079\n",
      "Accuracy:\t\t 0.5377585377585378\n",
      "Precision Score:\t 0.30579150579150577\n",
      "Recall Score:\t\t0.8646288209606987\n",
      "F1 Score:\t\t 0.526106359991129\n",
      "> FOLD 2\n",
      "Train Size 5282 Test Size 1143\n",
      "Accuracy:\t\t 0.5660542432195975\n",
      "Precision Score:\t 0.24519230769230768\n",
      "Recall Score:\t\t0.3591549295774648\n",
      "F1 Score:\t\t 0.4893460637722933\n",
      "> FOLD 3\n",
      "Train Size 5956 Test Size 469\n",
      "Accuracy:\t\t 0.5181236673773987\n",
      "Precision Score:\t 0.5165745856353591\n",
      "Recall Score:\t\t0.7857142857142857\n",
      "F1 Score:\t\t 0.47734714003944767\n",
      "> FOLD 4\n",
      "Train Size 5535 Test Size 890\n",
      "Accuracy:\t\t 0.6404494382022472\n",
      "Precision Score:\t 0.6306620209059234\n",
      "Recall Score:\t\t0.7702127659574468\n",
      "F1 Score:\t\t 0.629351990671331\n",
      "> FOLD 5\n",
      "Train Size 5204 Test Size 1221\n",
      "Accuracy:\t\t 0.5773955773955773\n",
      "Precision Score:\t 0.5033557046979866\n",
      "Recall Score:\t\t0.8620689655172413\n",
      "F1 Score:\t\t 0.566334621865398\n",
      "> FOLD 6\n",
      "Train Size 6411 Test Size 14\n",
      "Accuracy:\t\t 0.8571428571428571\n",
      "Precision Score:\t 1.0\n",
      "Recall Score:\t\t0.8571428571428571\n",
      "F1 Score:\t\t 0.4615384615384615\n",
      "> FOLD 7\n",
      "Train Size 6192 Test Size 233\n",
      "Accuracy:\t\t 0.6394849785407726\n",
      "Precision Score:\t 0.9801324503311258\n",
      "Recall Score:\t\t0.6462882096069869\n",
      "F1 Score:\t\t 0.40110159118727057\n",
      "> FOLD 8\n",
      "Train Size 6187 Test Size 238\n",
      "Accuracy:\t\t 0.5630252100840336\n",
      "Precision Score:\t 0.5567010309278351\n",
      "Recall Score:\t\t0.8571428571428571\n",
      "F1 Score:\t\t 0.5041666666666668\n",
      "> FOLD 9\n",
      "Train Size 6287 Test Size 138\n",
      "Accuracy:\t\t 0.427536231884058\n",
      "Precision Score:\t 0.4338235294117647\n",
      "Recall Score:\t\t0.9672131147540983\n",
      "F1 Score:\t\t 0.29949238578680204\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------- #\n",
    "#                                  ROOT + POS + Thread                                  #\n",
    "# ---------------------------------------------------------------------------- #\n",
    "\n",
    "dataset = all_root_thread\n",
    "model = GaussianNB\n",
    "\n",
    "\n",
    "testing_results = []\n",
    "\n",
    "result = cv_process(dataset, clfClass=model, events=all_event, target=all_y, verbose=False, scaling=True)\n",
    "testing_results.append(result)\n",
    "\n",
    "# writeLog().writeWithoutCR(\"./Model/\"+root_model.__name__+\"_\"+\"log.txt\",f\"RESULT:\\n{epochs_diff(testing_results)}\")\n",
    "result_df = pd.DataFrame.from_dict(testing_results[0], orient='index', columns=['Acc', 'F1', 'Train_size','Test_size'])\n",
    "result_df['Features'] = 'RPT'\n",
    "result_df['CV'] = 9\n",
    "result_df['CLF'] = model.__name__\n",
    "\n",
    "result_list.append(result_df)\n",
    "CV_result_df = pd.DataFrame(result_df[['Acc','F1', 'CV']].mean(), columns=[result_df.Features[0]]).T\n",
    "CV_result_df['CLF'] = result_df['CLF'][0]\n",
    "result_mean_list.append(CV_result_df)\n",
    "\n",
    "testing_results = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> FOLD 1\n",
      "> FOLD 2\n",
      "> FOLD 3\n",
      "> FOLD 4\n",
      "> FOLD 5\n",
      "> FOLD 6\n",
      "> FOLD 7\n",
      "> FOLD 8\n",
      "> FOLD 9\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------- #\n",
    "#                                 W2V + RPT                                 #\n",
    "# ---------------------------------------------------------------------------- #\n",
    "\n",
    "dataset = all_total_w2v\n",
    "model = SVC\n",
    "\n",
    "testing_results = []\n",
    "\n",
    "result = cv_process(dataset, clfClass=model, events=all_event, target=all_y, verbose=False, scaling=True)\n",
    "testing_results.append(result)\n",
    "\n",
    "# writeLog().writeWithoutCR(\"./Model/\"+root_model.__name__+\"_\"+\"log.txt\",f\"RESULT:\\n{epochs_diff(testing_results)}\")\n",
    "result_df = pd.DataFrame.from_dict(testing_results[0], orient='index', columns=['Acc', 'F1', 'Train_size','Test_size'])\n",
    "result_df['Features'] = 'RPT + W2V'\n",
    "result_df['CV'] = 9\n",
    "result_df['CLF'] = model.__name__\n",
    "\n",
    "result_list.append(result_df)\n",
    "CV_result_df = pd.DataFrame(result_df[['Acc','F1', 'CV']].mean(), columns=[result_df.Features[0]]).T\n",
    "CV_result_df['CLF'] = result_df['CLF'][0]\n",
    "result_mean_list.append(CV_result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> FOLD 1\n",
      "Train Size 4346 Test Size 2079\n",
      "Accuracy:\t\t 0.8335738335738335\n",
      "Precision Score:\t 0.6007194244604317\n",
      "Recall Score:\t\t0.7292576419213974\n",
      "F1 Score:\t\t 0.7743631148651702\n",
      "> FOLD 2\n",
      "Train Size 5282 Test Size 1143\n",
      "Accuracy:\t\t 0.7585301837270341\n",
      "Precision Score:\t 0.5714285714285714\n",
      "Recall Score:\t\t0.11267605633802817\n",
      "F1 Score:\t\t 0.5232029502448461\n",
      "> FOLD 3\n",
      "Train Size 5956 Test Size 469\n",
      "Accuracy:\t\t 0.652452025586354\n",
      "Precision Score:\t 0.7551020408163265\n",
      "Recall Score:\t\t0.46638655462184875\n",
      "F1 Score:\t\t 0.6409337497945091\n",
      "> FOLD 4\n",
      "Train Size 5535 Test Size 890\n",
      "Accuracy:\t\t 0.7573033707865169\n",
      "Precision Score:\t 0.8207070707070707\n",
      "Recall Score:\t\t0.6914893617021277\n",
      "F1 Score:\t\t 0.7571267580010208\n",
      "> FOLD 5\n",
      "Train Size 5204 Test Size 1221\n",
      "Accuracy:\t\t 0.7264537264537264\n",
      "Precision Score:\t 0.7385786802030457\n",
      "Recall Score:\t\t0.5574712643678161\n",
      "F1 Score:\t\t 0.7082491543951421\n",
      "> FOLD 6\n",
      "Train Size 6411 Test Size 14\n",
      "Accuracy:\t\t 0.6428571428571429\n",
      "Precision Score:\t 1.0\n",
      "Recall Score:\t\t0.6428571428571429\n",
      "F1 Score:\t\t 0.391304347826087\n",
      "> FOLD 7\n",
      "Train Size 6192 Test Size 233\n",
      "Accuracy:\t\t 0.20600858369098712\n",
      "Precision Score:\t 0.9782608695652174\n",
      "Recall Score:\t\t0.1965065502183406\n",
      "F1 Score:\t\t 0.1793431699190861\n",
      "> FOLD 8\n",
      "Train Size 6187 Test Size 238\n",
      "Accuracy:\t\t 0.542016806722689\n",
      "Precision Score:\t 0.7931034482758621\n",
      "Recall Score:\t\t0.18253968253968253\n",
      "F1 Score:\t\t 0.47860516531001907\n",
      "> FOLD 9\n",
      "Train Size 6287 Test Size 138\n",
      "Accuracy:\t\t 0.5652173913043478\n",
      "Precision Score:\t 0.5081967213114754\n",
      "Recall Score:\t\t0.5081967213114754\n",
      "F1 Score:\t\t 0.5592931658505429\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------- #\n",
    "#                                 ALL Features                                 #\n",
    "# ---------------------------------------------------------------------------- #\n",
    "\n",
    "dataset = all_total_bert\n",
    "model = SVC\n",
    "\n",
    "testing_results = []\n",
    "\n",
    "result = cv_process(dataset, clfClass=model, events=all_event, target=all_y, verbose=False, scaling=True)\n",
    "testing_results.append(result)\n",
    "\n",
    "# writeLog().writeWithoutCR(\"./Model/\"+root_model.__name__+\"_\"+\"log.txt\",f\"RESULT:\\n{epochs_diff(testing_results)}\")\n",
    "result_df = pd.DataFrame.from_dict(testing_results[0], orient='index', columns=['Acc', 'F1', 'Train_size','Test_size'])\n",
    "result_df['Features'] = 'RPT + BERT'\n",
    "result_df['CV'] = 9\n",
    "result_df['CLF'] = model.__name__\n",
    "\n",
    "result_list.append(result_df)\n",
    "CV_result_df = pd.DataFrame(result_df[['Acc','F1', 'CV']].mean(), columns=[result_df.Features[0]]).T\n",
    "CV_result_df['CLF'] = result_df['CLF'][0]\n",
    "result_mean_list.append(CV_result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Acc</th>\n      <th>F1</th>\n      <th>Train_size</th>\n      <th>Test_size</th>\n      <th>Features</th>\n      <th>CV</th>\n      <th>CLF</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>74.170274</td>\n      <td>66.476049</td>\n      <td>4346</td>\n      <td>2079</td>\n      <td>RP</td>\n      <td>9</td>\n      <td>RandomForestClassifier</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>73.928259</td>\n      <td>50.874870</td>\n      <td>5282</td>\n      <td>1143</td>\n      <td>RP</td>\n      <td>9</td>\n      <td>RandomForestClassifier</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>67.590618</td>\n      <td>67.590471</td>\n      <td>5956</td>\n      <td>469</td>\n      <td>RP</td>\n      <td>9</td>\n      <td>RandomForestClassifier</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>58.314607</td>\n      <td>54.586528</td>\n      <td>5535</td>\n      <td>890</td>\n      <td>RP</td>\n      <td>9</td>\n      <td>RandomForestClassifier</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>65.356265</td>\n      <td>59.023627</td>\n      <td>5204</td>\n      <td>1221</td>\n      <td>RP</td>\n      <td>9</td>\n      <td>RandomForestClassifier</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>61.588862</td>\n      <td>52.419810</td>\n      <td>5204</td>\n      <td>1221</td>\n      <td>Thread</td>\n      <td>9</td>\n      <td>SVC</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>71.428571</td>\n      <td>41.666667</td>\n      <td>6411</td>\n      <td>14</td>\n      <td>Thread</td>\n      <td>9</td>\n      <td>SVC</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>35.193133</td>\n      <td>26.532189</td>\n      <td>6192</td>\n      <td>233</td>\n      <td>Thread</td>\n      <td>9</td>\n      <td>SVC</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>57.142857</td>\n      <td>54.631083</td>\n      <td>6187</td>\n      <td>238</td>\n      <td>Thread</td>\n      <td>9</td>\n      <td>SVC</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>43.478261</td>\n      <td>32.335932</td>\n      <td>6287</td>\n      <td>138</td>\n      <td>Thread</td>\n      <td>9</td>\n      <td>SVC</td>\n    </tr>\n  </tbody>\n</table>\n<p>216 rows × 7 columns</p>\n</div>",
      "text/plain": "          Acc         F1  Train_size  Test_size Features  CV  \\\n0   74.170274  66.476049        4346       2079       RP   9   \n1   73.928259  50.874870        5282       1143       RP   9   \n2   67.590618  67.590471        5956        469       RP   9   \n3   58.314607  54.586528        5535        890       RP   9   \n4   65.356265  59.023627        5204       1221       RP   9   \n..        ...        ...         ...        ...      ...  ..   \n4   61.588862  52.419810        5204       1221   Thread   9   \n5   71.428571  41.666667        6411         14   Thread   9   \n6   35.193133  26.532189        6192        233   Thread   9   \n7   57.142857  54.631083        6187        238   Thread   9   \n8   43.478261  32.335932        6287        138   Thread   9   \n\n                       CLF  \n0   RandomForestClassifier  \n1   RandomForestClassifier  \n2   RandomForestClassifier  \n3   RandomForestClassifier  \n4   RandomForestClassifier  \n..                     ...  \n4                      SVC  \n5                      SVC  \n6                      SVC  \n7                      SVC  \n8                      SVC  \n\n[216 rows x 7 columns]"
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result = pd.concat(result_list)\n",
    "final_result.to_csv('./data/final_result_trad.csv')\n",
    "final_result = pd.read_csv('./data/final_result_trad.csv', index_col=['Unnamed: 0'])\n",
    "final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Acc</th>\n      <th>F1</th>\n      <th>CV</th>\n      <th>CLF</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>RP</th>\n      <td>59.585615</td>\n      <td>48.260343</td>\n      <td>9.0</td>\n      <td>RandomForestClassifier</td>\n    </tr>\n    <tr>\n      <th>RP</th>\n      <td>60.199755</td>\n      <td>48.327515</td>\n      <td>9.0</td>\n      <td>RandomForestClassifier</td>\n    </tr>\n    <tr>\n      <th>RP</th>\n      <td>60.199755</td>\n      <td>48.327515</td>\n      <td>9.0</td>\n      <td>RandomForestClassifier</td>\n    </tr>\n    <tr>\n      <th>RP</th>\n      <td>55.988184</td>\n      <td>51.986107</td>\n      <td>9.0</td>\n      <td>LogisticRegression</td>\n    </tr>\n    <tr>\n      <th>RP</th>\n      <td>56.539407</td>\n      <td>52.078453</td>\n      <td>9.0</td>\n      <td>SVC</td>\n    </tr>\n    <tr>\n      <th>RP</th>\n      <td>59.963892</td>\n      <td>52.372452</td>\n      <td>9.0</td>\n      <td>GaussianNB</td>\n    </tr>\n    <tr>\n      <th>thread</th>\n      <td>59.300732</td>\n      <td>45.718719</td>\n      <td>9.0</td>\n      <td>RandomForestClassifier</td>\n    </tr>\n    <tr>\n      <th>W2V</th>\n      <td>52.757742</td>\n      <td>47.164008</td>\n      <td>9.0</td>\n      <td>RandomForestClassifier</td>\n    </tr>\n    <tr>\n      <th>BERT</th>\n      <td>53.409970</td>\n      <td>47.769311</td>\n      <td>9.0</td>\n      <td>RandomForestClassifier</td>\n    </tr>\n    <tr>\n      <th>RPT</th>\n      <td>59.409867</td>\n      <td>46.771044</td>\n      <td>9.0</td>\n      <td>RandomForestClassifier</td>\n    </tr>\n    <tr>\n      <th>RPT + BERT</th>\n      <td>56.411103</td>\n      <td>51.820143</td>\n      <td>9.0</td>\n      <td>RandomForestClassifier</td>\n    </tr>\n    <tr>\n      <th>RP</th>\n      <td>59.963892</td>\n      <td>52.372452</td>\n      <td>9.0</td>\n      <td>GaussianNB</td>\n    </tr>\n    <tr>\n      <th>Thread</th>\n      <td>59.404906</td>\n      <td>46.335935</td>\n      <td>9.0</td>\n      <td>GaussianNB</td>\n    </tr>\n    <tr>\n      <th>W2V</th>\n      <td>59.440297</td>\n      <td>54.106923</td>\n      <td>9.0</td>\n      <td>GaussianNB</td>\n    </tr>\n    <tr>\n      <th>BERT</th>\n      <td>60.029846</td>\n      <td>56.775122</td>\n      <td>9.0</td>\n      <td>GaussianNB</td>\n    </tr>\n    <tr>\n      <th>RPT</th>\n      <td>59.188564</td>\n      <td>48.386503</td>\n      <td>9.0</td>\n      <td>GaussianNB</td>\n    </tr>\n    <tr>\n      <th>RPT + W2V</th>\n      <td>63.814826</td>\n      <td>55.708365</td>\n      <td>9.0</td>\n      <td>GaussianNB</td>\n    </tr>\n    <tr>\n      <th>RPT + BERT</th>\n      <td>61.619751</td>\n      <td>57.716726</td>\n      <td>9.0</td>\n      <td>GaussianNB</td>\n    </tr>\n    <tr>\n      <th>RPT + BERT</th>\n      <td>63.160145</td>\n      <td>55.693573</td>\n      <td>9.0</td>\n      <td>SVC</td>\n    </tr>\n    <tr>\n      <th>RP</th>\n      <td>56.539407</td>\n      <td>52.078453</td>\n      <td>9.0</td>\n      <td>SVC</td>\n    </tr>\n    <tr>\n      <th>BERT</th>\n      <td>60.753041</td>\n      <td>52.189512</td>\n      <td>9.0</td>\n      <td>SVC</td>\n    </tr>\n    <tr>\n      <th>RPT + W2V</th>\n      <td>62.337890</td>\n      <td>55.221933</td>\n      <td>9.0</td>\n      <td>SVC</td>\n    </tr>\n    <tr>\n      <th>W2V</th>\n      <td>59.486649</td>\n      <td>52.228986</td>\n      <td>9.0</td>\n      <td>SVC</td>\n    </tr>\n    <tr>\n      <th>Thread</th>\n      <td>57.417532</td>\n      <td>46.714669</td>\n      <td>9.0</td>\n      <td>SVC</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                  Acc         F1   CV                     CLF\nRP          59.585615  48.260343  9.0  RandomForestClassifier\nRP          60.199755  48.327515  9.0  RandomForestClassifier\nRP          60.199755  48.327515  9.0  RandomForestClassifier\nRP          55.988184  51.986107  9.0      LogisticRegression\nRP          56.539407  52.078453  9.0                     SVC\nRP          59.963892  52.372452  9.0              GaussianNB\nthread      59.300732  45.718719  9.0  RandomForestClassifier\nW2V         52.757742  47.164008  9.0  RandomForestClassifier\nBERT        53.409970  47.769311  9.0  RandomForestClassifier\nRPT         59.409867  46.771044  9.0  RandomForestClassifier\nRPT + BERT  56.411103  51.820143  9.0  RandomForestClassifier\nRP          59.963892  52.372452  9.0              GaussianNB\nThread      59.404906  46.335935  9.0              GaussianNB\nW2V         59.440297  54.106923  9.0              GaussianNB\nBERT        60.029846  56.775122  9.0              GaussianNB\nRPT         59.188564  48.386503  9.0              GaussianNB\nRPT + W2V   63.814826  55.708365  9.0              GaussianNB\nRPT + BERT  61.619751  57.716726  9.0              GaussianNB\nRPT + BERT  63.160145  55.693573  9.0                     SVC\nRP          56.539407  52.078453  9.0                     SVC\nBERT        60.753041  52.189512  9.0                     SVC\nRPT + W2V   62.337890  55.221933  9.0                     SVC\nW2V         59.486649  52.228986  9.0                     SVC\nThread      57.417532  46.714669  9.0                     SVC"
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_cv = pd.concat(result_mean_list)\n",
    "final_cv.to_csv('./data/final_cv_trad.csv')\n",
    "final_cv = pd.read_csv('./data/final_cv_trad.csv', index_col=['Unnamed: 0'])\n",
    "final_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Acc</th>\n      <th>F1</th>\n      <th>CV</th>\n      <th>CLF</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>RP</th>\n      <td>59.585615</td>\n      <td>48.260343</td>\n      <td>9.0</td>\n      <td>RandomForestClassifier</td>\n    </tr>\n    <tr>\n      <th>RP</th>\n      <td>60.199755</td>\n      <td>48.327515</td>\n      <td>9.0</td>\n      <td>RandomForestClassifier</td>\n    </tr>\n    <tr>\n      <th>RP</th>\n      <td>60.199755</td>\n      <td>48.327515</td>\n      <td>9.0</td>\n      <td>RandomForestClassifier</td>\n    </tr>\n    <tr>\n      <th>thread</th>\n      <td>59.300732</td>\n      <td>45.718719</td>\n      <td>9.0</td>\n      <td>RandomForestClassifier</td>\n    </tr>\n    <tr>\n      <th>W2V</th>\n      <td>52.757742</td>\n      <td>47.164008</td>\n      <td>9.0</td>\n      <td>RandomForestClassifier</td>\n    </tr>\n    <tr>\n      <th>BERT</th>\n      <td>53.409970</td>\n      <td>47.769311</td>\n      <td>9.0</td>\n      <td>RandomForestClassifier</td>\n    </tr>\n    <tr>\n      <th>RPT</th>\n      <td>59.409867</td>\n      <td>46.771044</td>\n      <td>9.0</td>\n      <td>RandomForestClassifier</td>\n    </tr>\n    <tr>\n      <th>RPT + BERT</th>\n      <td>56.411103</td>\n      <td>51.820143</td>\n      <td>9.0</td>\n      <td>RandomForestClassifier</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                  Acc         F1   CV                     CLF\nRP          59.585615  48.260343  9.0  RandomForestClassifier\nRP          60.199755  48.327515  9.0  RandomForestClassifier\nRP          60.199755  48.327515  9.0  RandomForestClassifier\nthread      59.300732  45.718719  9.0  RandomForestClassifier\nW2V         52.757742  47.164008  9.0  RandomForestClassifier\nBERT        53.409970  47.769311  9.0  RandomForestClassifier\nRPT         59.409867  46.771044  9.0  RandomForestClassifier\nRPT + BERT  56.411103  51.820143  9.0  RandomForestClassifier"
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_cv.loc[final_cv.CLF == 'RandomForestClassifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Acc</th>\n      <th>F1</th>\n      <th>CV</th>\n      <th>CLF</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>RP</th>\n      <td>59.963892</td>\n      <td>52.372452</td>\n      <td>9.0</td>\n      <td>GaussianNB</td>\n    </tr>\n    <tr>\n      <th>RP</th>\n      <td>59.963892</td>\n      <td>52.372452</td>\n      <td>9.0</td>\n      <td>GaussianNB</td>\n    </tr>\n    <tr>\n      <th>Thread</th>\n      <td>59.404906</td>\n      <td>46.335935</td>\n      <td>9.0</td>\n      <td>GaussianNB</td>\n    </tr>\n    <tr>\n      <th>W2V</th>\n      <td>59.440297</td>\n      <td>54.106923</td>\n      <td>9.0</td>\n      <td>GaussianNB</td>\n    </tr>\n    <tr>\n      <th>BERT</th>\n      <td>60.029846</td>\n      <td>56.775122</td>\n      <td>9.0</td>\n      <td>GaussianNB</td>\n    </tr>\n    <tr>\n      <th>RPT</th>\n      <td>59.188564</td>\n      <td>48.386503</td>\n      <td>9.0</td>\n      <td>GaussianNB</td>\n    </tr>\n    <tr>\n      <th>RPT + W2V</th>\n      <td>63.814826</td>\n      <td>55.708365</td>\n      <td>9.0</td>\n      <td>GaussianNB</td>\n    </tr>\n    <tr>\n      <th>RPT + BERT</th>\n      <td>61.619751</td>\n      <td>57.716726</td>\n      <td>9.0</td>\n      <td>GaussianNB</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                  Acc         F1   CV         CLF\nRP          59.963892  52.372452  9.0  GaussianNB\nRP          59.963892  52.372452  9.0  GaussianNB\nThread      59.404906  46.335935  9.0  GaussianNB\nW2V         59.440297  54.106923  9.0  GaussianNB\nBERT        60.029846  56.775122  9.0  GaussianNB\nRPT         59.188564  48.386503  9.0  GaussianNB\nRPT + W2V   63.814826  55.708365  9.0  GaussianNB\nRPT + BERT  61.619751  57.716726  9.0  GaussianNB"
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_cv.loc[final_cv.CLF == 'GaussianNB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Acc</th>\n      <th>F1</th>\n      <th>CV</th>\n      <th>CLF</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>RP</th>\n      <td>56.539407</td>\n      <td>52.078453</td>\n      <td>9.0</td>\n      <td>SVC</td>\n    </tr>\n    <tr>\n      <th>RPT + BERT</th>\n      <td>63.160145</td>\n      <td>55.693573</td>\n      <td>9.0</td>\n      <td>SVC</td>\n    </tr>\n    <tr>\n      <th>RP</th>\n      <td>56.539407</td>\n      <td>52.078453</td>\n      <td>9.0</td>\n      <td>SVC</td>\n    </tr>\n    <tr>\n      <th>BERT</th>\n      <td>60.753041</td>\n      <td>52.189512</td>\n      <td>9.0</td>\n      <td>SVC</td>\n    </tr>\n    <tr>\n      <th>RPT + W2V</th>\n      <td>62.337890</td>\n      <td>55.221933</td>\n      <td>9.0</td>\n      <td>SVC</td>\n    </tr>\n    <tr>\n      <th>W2V</th>\n      <td>59.486649</td>\n      <td>52.228986</td>\n      <td>9.0</td>\n      <td>SVC</td>\n    </tr>\n    <tr>\n      <th>Thread</th>\n      <td>57.417532</td>\n      <td>46.714669</td>\n      <td>9.0</td>\n      <td>SVC</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                  Acc         F1   CV  CLF\nRP          56.539407  52.078453  9.0  SVC\nRPT + BERT  63.160145  55.693573  9.0  SVC\nRP          56.539407  52.078453  9.0  SVC\nBERT        60.753041  52.189512  9.0  SVC\nRPT + W2V   62.337890  55.221933  9.0  SVC\nW2V         59.486649  52.228986  9.0  SVC\nThread      57.417532  46.714669  9.0  SVC"
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_cv.loc[final_cv.CLF == 'SVC']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance on Sparse Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 25: capital_ratio (0.022929)\n",
      "2. feature 28: tweet_count (0.022486)\n",
      "3. feature 13: Numeral (0.021493)\n",
      "4. feature 31: follower_count (0.020663)\n",
      "5. feature 5: Noun (0.020122)\n",
      "6. feature 29: listed_count (0.019489)\n",
      "7. feature 6: Verb (0.018645)\n",
      "8. feature 65: AVG FPP (0.017962)\n",
      "9. feature 32: followers/friend (0.017806)\n",
      "10. feature 33: favourites_count (0.017505)\n",
      "11. feature 20: word_count (0.017440)\n",
      "12. feature 3: Skepticism (0.017433)\n",
      "13. feature 16: Determiner (0.017349)\n",
      "14. feature 7: Adjective (0.017347)\n",
      "15. feature 34: account_age_days (0.017262)\n",
      "16. feature 19: char_count (0.017011)\n",
      "17. feature 71: AVG Skepticism (0.016744)\n",
      "18. feature 66: STD FPP (0.016599)\n",
      "19. feature 21: HashTag (0.016599)\n",
      "20. feature 68: STD SPP (0.016549)\n",
      "21. feature 69: AVG TPP (0.016370)\n",
      "22. feature 8: Pronoun (0.016242)\n",
      "23. feature 30: friends_count (0.016239)\n",
      "24. feature 35: verified (0.016109)\n",
      "25. feature 67: AVG SPP (0.016017)\n",
      "26. feature 14: Conjunction_inj (0.015892)\n",
      "27. feature 70: STD TPP (0.015641)\n",
      "28. feature 58: thread_time (0.015584)\n",
      "29. feature 43: Ratio HashTag (0.015365)\n",
      "30. feature 40: AVG CharCount (0.015332)\n",
      "31. feature 56: AVG AccAge (0.014981)\n",
      "32. feature 42: SUM HashTag (0.014903)\n",
      "33. feature 39: AVG WordCount (0.014641)\n",
      "34. feature 61: Ratio Media (0.014641)\n",
      "35. feature 38: AVG FriendsCount (0.014580)\n",
      "36. feature 64: RATIO Period (0.014563)\n",
      "37. feature 41: AVG HashTag (0.014531)\n",
      "38. feature 57: STD AccAge (0.014445)\n",
      "39. feature 62: RATIO Question (0.014375)\n",
      "40. feature 26: retweet_count (0.014099)\n",
      "41. feature 9: FirstPersonPronoun (0.013946)\n",
      "42. feature 2: has_media (0.013903)\n",
      "43. feature 54: AVG RT (0.013776)\n",
      "44. feature 63: RATIO Exclaim (0.013766)\n",
      "45. feature 48: AVG Mention (0.013723)\n",
      "46. feature 53: SUM RT (0.013463)\n",
      "47. feature 37: SUM FriendsCount (0.013344)\n",
      "48. feature 12: Adverb (0.013295)\n",
      "49. feature 49: Ratio Mention (0.013066)\n",
      "50. feature 36: depth (0.012995)\n",
      "51. feature 46: RATIO Url (0.012822)\n",
      "52. feature 47: SUM Mention (0.012702)\n",
      "53. feature 50: Tweets Count (0.012663)\n",
      "54. feature 45: STD Url (0.012413)\n",
      "55. feature 55: STD RT (0.012302)\n",
      "56. feature 44: AVG Url (0.012253)\n",
      "57. feature 1: URLcount (0.011909)\n",
      "58. feature 51: Ratio Verified (0.011506)\n",
      "59. feature 17: Modal (0.010629)\n",
      "60. feature 52: SUM Verified (0.009691)\n",
      "61. feature 59: STD Emoji (0.009532)\n",
      "62. feature 18: Whs (0.009385)\n",
      "63. feature 60: AVG Emoji (0.009360)\n",
      "64. feature 4: MentionCount (0.007886)\n",
      "65. feature 11: ThirdPersonPronoun (0.007481)\n",
      "66. feature 24: has_period (0.006557)\n",
      "67. feature 15: Particle (0.006539)\n",
      "68. feature 10: SecondPersonPronoun (0.005420)\n",
      "69. feature 22: has_question (0.004551)\n",
      "70. feature 23: has_exclaim (0.004076)\n",
      "71. feature 0: emoji_count (0.001062)\n",
      "72. feature 27: isRT (0.000000)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 432x288 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(pheme_sparse)\n",
    "X2 = scaler.fit_transform(pheme_thread)\n",
    "\n",
    "X = pd.concat([pheme_sparse, pheme_thread], axis=1)\n",
    "\n",
    "forest = ExtraTreesClassifier(n_estimators=250,\n",
    "                              random_state=3)\n",
    "\n",
    "forest.fit(X, pheme_y)\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d: %s (%f)\" % (f + 1, indices[f], X.columns[indices[f]], importances[indices[f]]))\n",
    "\n",
    "# Plot the impurity-based feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "        color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature ranking:\n",
    "1. feature 25: capital_ratio (0.023554)\n",
    "2. feature 29: listed_count (0.023047)\n",
    "3. feature 28: tweet_count (0.022576)\n",
    "4. feature 13: Numeral (0.022373)\n",
    "5. feature 31: follow_ratio (0.021648)\n",
    "6. feature 5: Noun (0.020772)\n",
    "7. feature 6: Verb (0.018965)\n",
    "8. feature 30: friends_count (0.018720)\n",
    "9. feature 7: Adjective (0.018711)\n",
    "10. feature 32: account_age_days (0.018371)\n",
    "11. feature 3: Skepticism (0.018333)\n",
    "12. feature 63: AVG FPP (0.018230)\n",
    "13. feature 16: Determiner (0.018211)\n",
    "14. feature 20: word_count (0.017997)\n",
    "15. feature 19: char_count (0.017476)\n",
    "16. feature 64: STD FPP (0.017206)\n",
    "17. feature 67: AVG TPP (0.017082)\n",
    "18. feature 69: AVG Skepticism (0.017057)\n",
    "19. feature 21: HashTag (0.016944)\n",
    "20. feature 65: AVG SPP (0.016567)\n",
    "21. feature 56: thread_time (0.016411)\n",
    "22. feature 66: STD SPP (0.016360)\n",
    "23. feature 14: Conjunction_inj (0.016151)\n",
    "24. feature 68: STD TPP (0.016145)\n",
    "25. feature 41: Ratio HashTag (0.016090)\n",
    "26. feature 38: AVG CharCount (0.015695)\n",
    "27. feature 8: Pronoun (0.015674)\n",
    "28. feature 54: AVG AccAge (0.015432)\n",
    "29. feature 37: AVG WordCount (0.015418)\n",
    "30. feature 40: SUM HashTag (0.015303)\n",
    "31. feature 33: verified (0.015233)\n",
    "32. feature 36: AVG FriendsCount (0.015208)\n",
    "33. feature 9: FirstPersonPronoun (0.015171)\n",
    "34. feature 62: RATIO Period (0.015147)\n",
    "35. feature 59: Ratio Media (0.015048)\n",
    "36. feature 39: AVG HashTag (0.014982)\n",
    "37. feature 60: RATIO Question (0.014928)\n",
    "38. feature 55: STD AccAge (0.014914)\n",
    "39. feature 26: retweet_count (0.014715)\n",
    "40. feature 51: SUM RT (0.014321)\n",
    "41. feature 52: AVG RT (0.014225)\n",
    "42. feature 46: AVG Mention (0.014223)\n",
    "43. feature 61: RATIO Exclaim (0.014075)\n",
    "44. feature 2: has_media (0.013751)\n",
    "45. feature 35: SUM FriendsCount (0.013744)\n",
    "46. feature 47: Ratio Mention (0.013624)\n",
    "47. feature 12: Adverb (0.013606)\n",
    "48. feature 34: depth (0.013599)\n",
    "49. feature 53: STD RT (0.013502)\n",
    "50. feature 44: RATIO Url (0.013118)\n",
    "51. feature 48: Tweets Count (0.013090)\n",
    "52. feature 45: SUM Mention (0.013022)\n",
    "53. feature 43: STD Url (0.012792)\n",
    "54. feature 42: AVG Url (0.012651)\n",
    "55. feature 1: URLcount (0.012328)\n",
    "56. feature 49: Ratio Verified (0.011846)\n",
    "57. feature 17: Modal (0.010733)\n",
    "58. feature 50: SUM Verified (0.010200)\n",
    "59. feature 18: Whs (0.009731)\n",
    "60. feature 57: STD Emoji (0.009702)\n",
    "61. feature 58: AVG Emoji (0.009570)\n",
    "62. feature 4: MentionCount (0.008058)\n",
    "63. feature 11: ThirdPersonPronoun (0.007592)\n",
    "64. feature 24: has_period (0.006844)\n",
    "65. feature 15: Particle (0.006585)\n",
    "66. feature 10: SecondPersonPronoun (0.005497)\n",
    "67. feature 22: has_question (0.004690)\n",
    "68. feature 23: has_exclaim (0.004280)\n",
    "69. feature 0: emoji_count (0.001138)\n",
    "70. feature 27: isRT (0.000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 25: capital_ratio (0.023554)\n",
      "2. feature 29: listed_count (0.023047)\n",
      "3. feature 28: tweet_count (0.022576)\n",
      "4. feature 13: Numeral (0.022373)\n",
      "5. feature 31: follow_ratio (0.021648)\n",
      "6. feature 5: Noun (0.020772)\n",
      "7. feature 6: Verb (0.018965)\n",
      "8. feature 30: friends_count (0.018720)\n",
      "9. feature 7: Adjective (0.018711)\n",
      "10. feature 32: account_age_days (0.018371)\n",
      "11. feature 3: Skepticism (0.018333)\n",
      "12. feature 63: AVG FPP (0.018230)\n",
      "13. feature 16: Determiner (0.018211)\n",
      "14. feature 20: word_count (0.017997)\n",
      "15. feature 19: char_count (0.017476)\n",
      "16. feature 64: STD FPP (0.017206)\n",
      "17. feature 67: AVG TPP (0.017082)\n",
      "18. feature 69: AVG Skepticism (0.017057)\n",
      "19. feature 21: HashTag (0.016944)\n",
      "20. feature 65: AVG SPP (0.016567)\n",
      "21. feature 56: thread_time (0.016411)\n",
      "22. feature 66: STD SPP (0.016360)\n",
      "23. feature 14: Conjunction_inj (0.016151)\n",
      "24. feature 68: STD TPP (0.016145)\n",
      "25. feature 41: Ratio HashTag (0.016090)\n",
      "26. feature 38: AVG CharCount (0.015695)\n",
      "27. feature 8: Pronoun (0.015674)\n",
      "28. feature 54: AVG AccAge (0.015432)\n",
      "29. feature 37: AVG WordCount (0.015418)\n",
      "30. feature 40: SUM HashTag (0.015303)\n",
      "31. feature 33: verified (0.015233)\n",
      "32. feature 36: AVG FriendsCount (0.015208)\n",
      "33. feature 9: FirstPersonPronoun (0.015171)\n",
      "34. feature 62: RATIO Period (0.015147)\n",
      "35. feature 59: Ratio Media (0.015048)\n",
      "36. feature 39: AVG HashTag (0.014982)\n",
      "37. feature 60: RATIO Question (0.014928)\n",
      "38. feature 55: STD AccAge (0.014914)\n",
      "39. feature 26: retweet_count (0.014715)\n",
      "40. feature 51: SUM RT (0.014321)\n",
      "41. feature 52: AVG RT (0.014225)\n",
      "42. feature 46: AVG Mention (0.014223)\n",
      "43. feature 61: RATIO Exclaim (0.014075)\n",
      "44. feature 2: has_media (0.013751)\n",
      "45. feature 35: SUM FriendsCount (0.013744)\n",
      "46. feature 47: Ratio Mention (0.013624)\n",
      "47. feature 12: Adverb (0.013606)\n",
      "48. feature 34: depth (0.013599)\n",
      "49. feature 53: STD RT (0.013502)\n",
      "50. feature 44: RATIO Url (0.013118)\n",
      "51. feature 48: Tweets Count (0.013090)\n",
      "52. feature 45: SUM Mention (0.013022)\n",
      "53. feature 43: STD Url (0.012792)\n",
      "54. feature 42: AVG Url (0.012651)\n",
      "55. feature 1: URLcount (0.012328)\n",
      "56. feature 49: Ratio Verified (0.011846)\n",
      "57. feature 17: Modal (0.010733)\n",
      "58. feature 50: SUM Verified (0.010200)\n",
      "59. feature 18: Whs (0.009731)\n",
      "60. feature 57: STD Emoji (0.009702)\n",
      "61. feature 58: AVG Emoji (0.009570)\n",
      "62. feature 4: MentionCount (0.008058)\n",
      "63. feature 11: ThirdPersonPronoun (0.007592)\n",
      "64. feature 24: has_period (0.006844)\n",
      "65. feature 15: Particle (0.006585)\n",
      "66. feature 10: SecondPersonPronoun (0.005497)\n",
      "67. feature 22: has_question (0.004690)\n",
      "68. feature 23: has_exclaim (0.004280)\n",
      "69. feature 0: emoji_count (0.001138)\n",
      "70. feature 27: isRT (0.000000)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 432x288 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(pheme_sparse)\n",
    "X2 = scaler.fit_transform(pheme_thread)\n",
    "\n",
    "X = pd.concat([pheme_sparse, pheme_thread], axis=1)\n",
    "\n",
    "forest = ExtraTreesClassifier(n_estimators=250,\n",
    "                              random_state=3)\n",
    "\n",
    "forest.fit(X, pheme_y)\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d: %s (%f)\" % (f + 1, indices[f], X.columns[indices[f]], importances[indices[f]]))\n",
    "\n",
    "# Plot the impurity-based feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "        color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 2\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 3\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 4\n",
      "----------------------------------------------------------------------------\n",
      "FOLD 5\n",
      "----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "process_cv(pheme_thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(pheme_thread.values)\n",
    "X_test = scaler.fit_transform(ext_thread.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.24123711340206186\n",
      "Precision Score:\t 1.0\n",
      "Recall Score:\t\t0.0027100271002710027\n",
      "F1 Score:\t\t 0.19603603603603603\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      1.00      0.39       116\n",
      "           1       1.00      0.00      0.01       369\n",
      "\n",
      "    accuracy                           0.24       485\n",
      "   macro avg       0.62      0.50      0.20       485\n",
      "weighted avg       0.82      0.24      0.10       485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = SVC()\n",
    "train_test(X_train, X_test, pheme_y, ext_y, clf)\n",
    "\n",
    "# Accuracy:\t\t 0.6268041237113402\n",
    "# Precision Score:\t 0.7596685082872928\n",
    "# Recall Score:\t\t0.7452574525745257\n",
    "# F1 Score:\t\t 0.49753590255796776"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "pheme_sparse_scaled = scaler.fit_transform(pheme_sparse.values)\n",
    "ext_sparse_scaled = scaler.fit_transform(ext_sparse.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.354639175257732\n",
      "Precision Score:\t 0.9242424242424242\n",
      "Recall Score:\t\t0.16531165311653118\n",
      "F1 Score:\t\t 0.34770652057149\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.96      0.41       116\n",
      "           1       0.92      0.17      0.28       369\n",
      "\n",
      "    accuracy                           0.35       485\n",
      "   macro avg       0.59      0.56      0.35       485\n",
      "weighted avg       0.77      0.35      0.31       485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(gamma='auto')\n",
    "train_test(pheme_sparse_scaled, ext_sparse_scaled, pheme_y, ext_y, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.6371134020618556\n",
      "Precision Score:\t 0.8205980066445183\n",
      "Recall Score:\t\t0.6693766937669376\n",
      "F1 Score:\t\t 0.5753233830845771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.53      0.41       116\n",
      "           1       0.82      0.67      0.74       369\n",
      "\n",
      "    accuracy                           0.64       485\n",
      "   macro avg       0.58      0.60      0.58       485\n",
      "weighted avg       0.70      0.64      0.66       485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "train_test(pheme_sparse_scaled, ext_sparse_scaled, pheme_y, ext_y, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPARSE - PHEME CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.47191011235955055\n",
      "Precision Score:\t 0.0\n",
      "Recall Score:\t\t0.0\n",
      "F1 Score:\t\t 0.32061068702290074\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      1.00      0.64       420\n",
      "           1       0.00      0.00      0.00       470\n",
      "\n",
      "    accuracy                           0.47       890\n",
      "   macro avg       0.24      0.50      0.32       890\n",
      "weighted avg       0.22      0.47      0.30       890\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/june/miniconda3/envs/rosetta/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/june/miniconda3/envs/rosetta/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/june/miniconda3/envs/rosetta/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/june/miniconda3/envs/rosetta/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "X = cv[3][1].drop(['target', 'Event'],axis=1)\n",
    "y = cv[3][1].target\n",
    "val_X = cv[3][0].drop(['target', 'Event'],axis=1)\n",
    "val_y = cv[3][0].target\n",
    "clf = SVC(gamma='auto')\n",
    "train_test(X, val_X, y, val_y, clf)\n",
    "# valid(rhi, rhi_y, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse + W2V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df = scaler.fit_transform(pheme_sparse.values)\n",
    "sparse_w2v = np.concatenate([df, pheme_AVGw2v.values],axis=1)\n",
    "df = scaler.fit_transform(ext_sparse.values)\n",
    "sparse_w2v_ext = np.concatenate([df, ext_AVGw2v.values],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sparse_w2v' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-442f5acd8e74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse_w2v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_w2v_ext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpheme_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mext_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sparse_w2v' is not defined"
     ]
    }
   ],
   "source": [
    "clf = SVC(gamma='auto')\n",
    "train_test(sparse_w2v, sparse_w2v_ext, pheme_y, ext_y, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.4\n",
      "Precision Score:\t 0.9148936170212766\n",
      "Recall Score:\t\t0.23306233062330622\n",
      "F1 Score:\t\t 0.3987628918680588\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.93      0.43       116\n",
      "           1       0.91      0.23      0.37       369\n",
      "\n",
      "    accuracy                           0.40       485\n",
      "   macro avg       0.60      0.58      0.40       485\n",
      "weighted avg       0.76      0.40      0.38       485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "train_test(sparse_w2v, sparse_w2v_ext, pheme_y, ext_y, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>BERTEmbed_0</th>\n      <th>BERTEmbed_1</th>\n      <th>BERTEmbed_2</th>\n      <th>BERTEmbed_3</th>\n      <th>BERTEmbed_4</th>\n      <th>BERTEmbed_5</th>\n      <th>BERTEmbed_6</th>\n      <th>BERTEmbed_7</th>\n      <th>BERTEmbed_8</th>\n      <th>BERTEmbed_9</th>\n      <th>...</th>\n      <th>BERTEmbed_758</th>\n      <th>BERTEmbed_759</th>\n      <th>BERTEmbed_760</th>\n      <th>BERTEmbed_761</th>\n      <th>BERTEmbed_762</th>\n      <th>BERTEmbed_763</th>\n      <th>BERTEmbed_764</th>\n      <th>BERTEmbed_765</th>\n      <th>BERTEmbed_766</th>\n      <th>BERTEmbed_767</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.299457</td>\n      <td>0.198897</td>\n      <td>-0.491295</td>\n      <td>0.211787</td>\n      <td>0.197080</td>\n      <td>0.234026</td>\n      <td>0.200608</td>\n      <td>-0.096086</td>\n      <td>0.250423</td>\n      <td>0.266876</td>\n      <td>...</td>\n      <td>0.209932</td>\n      <td>-0.166056</td>\n      <td>0.245046</td>\n      <td>-0.580443</td>\n      <td>-0.141690</td>\n      <td>0.222918</td>\n      <td>-0.144328</td>\n      <td>0.048243</td>\n      <td>-0.027414</td>\n      <td>-0.055394</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.299628</td>\n      <td>0.207495</td>\n      <td>-0.491100</td>\n      <td>0.207046</td>\n      <td>0.198606</td>\n      <td>0.223802</td>\n      <td>0.201070</td>\n      <td>-0.085390</td>\n      <td>0.272306</td>\n      <td>0.276768</td>\n      <td>...</td>\n      <td>0.227522</td>\n      <td>-0.168281</td>\n      <td>0.246145</td>\n      <td>-0.575933</td>\n      <td>-0.133583</td>\n      <td>0.210461</td>\n      <td>-0.141031</td>\n      <td>0.049042</td>\n      <td>-0.035745</td>\n      <td>-0.065774</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.300907</td>\n      <td>0.193260</td>\n      <td>-0.498778</td>\n      <td>0.215972</td>\n      <td>0.193097</td>\n      <td>0.223985</td>\n      <td>0.181815</td>\n      <td>-0.106533</td>\n      <td>0.247362</td>\n      <td>0.262557</td>\n      <td>...</td>\n      <td>0.210722</td>\n      <td>-0.168287</td>\n      <td>0.242233</td>\n      <td>-0.579043</td>\n      <td>-0.142183</td>\n      <td>0.223372</td>\n      <td>-0.142068</td>\n      <td>0.043969</td>\n      <td>-0.031963</td>\n      <td>-0.054336</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.294519</td>\n      <td>0.198307</td>\n      <td>-0.492020</td>\n      <td>0.211912</td>\n      <td>0.201571</td>\n      <td>0.225530</td>\n      <td>0.192947</td>\n      <td>-0.100199</td>\n      <td>0.261141</td>\n      <td>0.264648</td>\n      <td>...</td>\n      <td>0.216593</td>\n      <td>-0.163219</td>\n      <td>0.242032</td>\n      <td>-0.586569</td>\n      <td>-0.137623</td>\n      <td>0.219293</td>\n      <td>-0.139870</td>\n      <td>0.039641</td>\n      <td>-0.034909</td>\n      <td>-0.062468</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.296625</td>\n      <td>0.196416</td>\n      <td>-0.493361</td>\n      <td>0.214012</td>\n      <td>0.195244</td>\n      <td>0.231359</td>\n      <td>0.194209</td>\n      <td>-0.101270</td>\n      <td>0.252890</td>\n      <td>0.263173</td>\n      <td>...</td>\n      <td>0.211895</td>\n      <td>-0.166441</td>\n      <td>0.237079</td>\n      <td>-0.587006</td>\n      <td>-0.140724</td>\n      <td>0.224566</td>\n      <td>-0.142844</td>\n      <td>0.041942</td>\n      <td>-0.030708</td>\n      <td>-0.056173</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 768 columns</p>\n</div>",
      "text/plain": "   BERTEmbed_0  BERTEmbed_1  BERTEmbed_2  BERTEmbed_3  BERTEmbed_4  \\\n0     0.299457     0.198897    -0.491295     0.211787     0.197080   \n1     0.299628     0.207495    -0.491100     0.207046     0.198606   \n2     0.300907     0.193260    -0.498778     0.215972     0.193097   \n3     0.294519     0.198307    -0.492020     0.211912     0.201571   \n4     0.296625     0.196416    -0.493361     0.214012     0.195244   \n\n   BERTEmbed_5  BERTEmbed_6  BERTEmbed_7  BERTEmbed_8  BERTEmbed_9  ...  \\\n0     0.234026     0.200608    -0.096086     0.250423     0.266876  ...   \n1     0.223802     0.201070    -0.085390     0.272306     0.276768  ...   \n2     0.223985     0.181815    -0.106533     0.247362     0.262557  ...   \n3     0.225530     0.192947    -0.100199     0.261141     0.264648  ...   \n4     0.231359     0.194209    -0.101270     0.252890     0.263173  ...   \n\n   BERTEmbed_758  BERTEmbed_759  BERTEmbed_760  BERTEmbed_761  BERTEmbed_762  \\\n0       0.209932      -0.166056       0.245046      -0.580443      -0.141690   \n1       0.227522      -0.168281       0.246145      -0.575933      -0.133583   \n2       0.210722      -0.168287       0.242233      -0.579043      -0.142183   \n3       0.216593      -0.163219       0.242032      -0.586569      -0.137623   \n4       0.211895      -0.166441       0.237079      -0.587006      -0.140724   \n\n   BERTEmbed_763  BERTEmbed_764  BERTEmbed_765  BERTEmbed_766  BERTEmbed_767  \n0       0.222918      -0.144328       0.048243      -0.027414      -0.055394  \n1       0.210461      -0.141031       0.049042      -0.035745      -0.065774  \n2       0.223372      -0.142068       0.043969      -0.031963      -0.054336  \n3       0.219293      -0.139870       0.039641      -0.034909      -0.062468  \n4       0.224566      -0.142844       0.041942      -0.030708      -0.056173  \n\n[5 rows x 768 columns]"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pheme_y.head()\n",
    "pheme_bert.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.5917525773195876\n",
      "Precision Score:\t 0.7697160883280757\n",
      "Recall Score:\t\t0.6612466124661247\n",
      "F1 Score:\t\t 0.5070935818995606\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.37      0.30       116\n",
      "           1       0.77      0.66      0.71       369\n",
      "\n",
      "    accuracy                           0.59       485\n",
      "   macro avg       0.51      0.52      0.51       485\n",
      "weighted avg       0.65      0.59      0.61       485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(gamma='auto')\n",
    "train_test(pheme_bert, ext_bert, pheme_y, ext_y, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.6268041237113402\n",
      "Precision Score:\t 0.7596685082872928\n",
      "Recall Score:\t\t0.7452574525745257\n",
      "F1 Score:\t\t 0.49753590255796776\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.25      0.24       116\n",
      "           1       0.76      0.75      0.75       369\n",
      "\n",
      "    accuracy                           0.63       485\n",
      "   macro avg       0.50      0.50      0.50       485\n",
      "weighted avg       0.63      0.63      0.63       485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "train_test(pheme_bert, ext_bert, pheme_y, ext_y, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W2V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.32989690721649484\n",
      "Precision Score:\t 0.9782608695652174\n",
      "Recall Score:\t\t0.12195121951219512\n",
      "F1 Score:\t\t 0.31564094214696625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.99      0.41       116\n",
      "           1       0.98      0.12      0.22       369\n",
      "\n",
      "    accuracy                           0.33       485\n",
      "   macro avg       0.62      0.56      0.32       485\n",
      "weighted avg       0.81      0.33      0.26       485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(gamma='auto')\n",
    "train_test(sparse_w2v, sparse_w2v_ext, pheme_y, ext_y, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.4\n",
      "Precision Score:\t 0.9148936170212766\n",
      "Recall Score:\t\t0.23306233062330622\n",
      "F1 Score:\t\t 0.3987628918680588\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.93      0.43       116\n",
      "           1       0.91      0.23      0.37       369\n",
      "\n",
      "    accuracy                           0.40       485\n",
      "   macro avg       0.60      0.58      0.40       485\n",
      "weighted avg       0.76      0.40      0.38       485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "train_test(sparse_w2v, sparse_w2v_ext, pheme_y, ext_y, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT + SPARSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df = scaler.fit_transform(pheme_sparse.values)\n",
    "df2 = scaler.fit_transform(pheme_thread.values)\n",
    "sparse_bert = np.concatenate([df, df2, pheme_bert.values],axis=1)\n",
    "df = scaler.fit_transform(ext_sparse.values)\n",
    "df2 = scaler.fit_transform(ext_thread.values)\n",
    "sparse_bert_ext = np.concatenate([df, df2, ext_bert.values],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.4350515463917526\n",
      "Precision Score:\t 0.8925619834710744\n",
      "Recall Score:\t\t0.2926829268292683\n",
      "F1 Score:\t\t 0.43499149659863945\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.89      0.43       116\n",
      "           1       0.89      0.29      0.44       369\n",
      "\n",
      "    accuracy                           0.44       485\n",
      "   macro avg       0.59      0.59      0.43       485\n",
      "weighted avg       0.75      0.44      0.44       485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(gamma='auto')\n",
    "train_test(sparse_bert, sparse_bert_ext, pheme_y, ext_y, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.6268041237113402\n",
      "Precision Score:\t 0.7596685082872928\n",
      "Recall Score:\t\t0.7452574525745257\n",
      "F1 Score:\t\t 0.49753590255796776\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.25      0.24       116\n",
      "           1       0.76      0.75      0.75       369\n",
      "\n",
      "    accuracy                           0.63       485\n",
      "   macro avg       0.50      0.50      0.50       485\n",
      "weighted avg       0.63      0.63      0.63       485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "train_test(sparse_bert, sparse_bert_ext, pheme_y, ext_y, clf)\n",
    "\n",
    "# Accuracy:\t\t 0.6268041237113402\n",
    "# Precision Score:\t 0.7596685082872928\n",
    "# Recall Score:\t\t0.7452574525745257\n",
    "# F1 Score:\t\t 0.49753590255796776"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.6536082474226804\n",
      "Precision Score:\t 0.7570332480818415\n",
      "Recall Score:\t\t0.8021680216802168\n",
      "F1 Score:\t\t 0.48947368421052634\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.18      0.20       116\n",
      "           1       0.76      0.80      0.78       369\n",
      "\n",
      "    accuracy                           0.65       485\n",
      "   macro avg       0.49      0.49      0.49       485\n",
      "weighted avg       0.63      0.65      0.64       485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = scale_concat([pheme_sparse, pheme_bert])\n",
    "X2 = scale_concat([ext_sparse, ext_bert])\n",
    "clf = GaussianNB()\n",
    "train_test(X, sparse_bert_ext, pheme_y, ext_y, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.5051546391752577\n",
      "Precision Score:\t 0.8028169014084507\n",
      "Recall Score:\t\t0.4634146341463415\n",
      "F1 Score:\t\t 0.4845360824742268\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.64      0.38       116\n",
      "           1       0.80      0.46      0.59       369\n",
      "\n",
      "    accuracy                           0.51       485\n",
      "   macro avg       0.54      0.55      0.48       485\n",
      "weighted avg       0.68      0.51      0.54       485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = scale_concat([pheme_sparse, pheme_bert, pheme_thread])\n",
    "X2 = scale_concat([ext_sparse, ext_bert, ext_thread])\n",
    "clf = SVC()\n",
    "train_test(X, X2, pheme_y, ext_y, clf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rosetta",
   "language": "python",
   "name": "rosetta"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}