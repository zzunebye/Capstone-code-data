{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fetchData import fetchdata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(X_train, X_test, y_train, y_test, clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    result = clf.predict(X_test)\n",
    "    print(\"Accuracy:\\t\\t\",accuracy_score(y_test,result))\n",
    "    print('Precision Score:\\t', str(precision_score(y_test,result)))\n",
    "    print('Recall Score:\\t\\t' + str(recall_score(y_test,result)))\n",
    "    print(\"F1 Score:\\t\\t\",f1_score(y_test, result, average='macro', zero_division=True))\n",
    "    print(classification_report(y_test, result))\n",
    "    \n",
    "\n",
    "def valid(X_valid, y_valid, clf):\n",
    "    clf.fit\n",
    "    result = clf.predict(X_valid)\n",
    "    print(\"Accuracy:\",accuracy_score(result,y_valid))\n",
    "    print(classification_report(y_valid, result))\n",
    "\n",
    "def cv_events(data):\n",
    "    NUM_EVENT = data.Event.unique().shape[0]\n",
    "    EVENTS = data.Event.unique()\n",
    "\n",
    "    cv_pd_list = []\n",
    "    for i, d in enumerate(EVENTS):\n",
    "        df1, df2 = [x for _, x in data.groupby(data['Event'] != d)]\n",
    "        df1.reset_index(inplace=True, drop=True)\n",
    "        df2.reset_index(inplace=True, drop=True)\n",
    "        cv_pd_list.append([df1, df2])\n",
    "    return cv_pd_list\n",
    "\n",
    "def algorithm_pipeline(X_train_data, X_test_data, y_train_data, y_test_data, \n",
    "                       model, param_grid, cv=10, scoring_fit='neg_mean_squared_error',\n",
    "                       do_probabilities = False):\n",
    "    gs = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid, \n",
    "        cv=cv, \n",
    "        n_jobs=-1, \n",
    "        scoring=scoring_fit,\n",
    "        verbose=2\n",
    "    )\n",
    "    fitted_model = gs.fit(X_train_data, y_train_data)\n",
    "    \n",
    "    if do_probabilities:\n",
    "      pred = fitted_model.predict_proba(X_test_data)\n",
    "    else:\n",
    "      pred = fitted_model.predict(X_test_data)\n",
    "    \n",
    "    return fitted_model, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheme_AVGw2v = pd.read_csv('./data/_PHEME_text_AVGw2v.csv').drop(['token'],axis=1)\n",
    "pheme_sparse = pd.read_csv('./data/_PHEME_sparse.csv')\n",
    "pheme_y = pd.read_csv('./data/_PHEME_target.csv').target\n",
    "pheme_event = pd.read_csv('./data/_PHEME_text.csv')['Event']\n",
    "pheme_bert = fetchdata('pheme','bert')\n",
    "# pd.read_csv('./data/_PHEME_text_AVGw2v.csv')\n",
    "\n",
    "ext_AVGw2v = pd.read_csv('./data/_PHEMEext_text_AVGw2v.csv').drop(['token'],axis=1)\n",
    "ext_sparse = pd.read_csv('./data/_PHEMEext_sparse.csv')\n",
    "ext_y = pd.read_csv('./data/_PHEMEext_text.csv').target\n",
    "ext_event = pd.read_csv('./data/_PHEMEext_text.csv').Event\n",
    "ext_bert = fetchdata('ext','bert')\n",
    "\n",
    "rhi = pd.read_csv('./data/_RHI_text_AVGw2v.csv').drop(['token'],axis=1)\n",
    "rhi_y = pd.read_csv('./data/_RHI_target.csv')\n",
    "rhi_bert = fetchdata('rhi','bert')\n",
    "\n",
    "# temp = pd.read_csv('./data/previous/data_notembeded.csv')\n",
    "\n",
    "# pd.concat([pheme_sparse, pheme_event])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nothing():\n",
    "    # pheme_sparse.verified = pheme_sparse.verified.replace({True: 1, False: 0}) \n",
    "    # ext_sparse.verified = ext_sparse.verified.replace({True: 1, False: 0}) \n",
    "    # pheme_sparse.has_question = pheme_sparse.has_question.replace({True: 1, False: 0}) \n",
    "    # ext_sparse.has_question = ext_sparse.has_question.replace({True: 1, False: 0}) \n",
    "    # pheme_sparse.has_exclaim = pheme_sparse.has_exclaim.replace({True: 1, False: 0}) \n",
    "    # ext_sparse.has_exclaim = ext_sparse.has_exclaim.replace({True: 1, False: 0}) \n",
    "    # pheme_sparse.has_period = pheme_sparse.has_period.replace({True: 1, False: 0}) \n",
    "    # ext_sparse.has_period = ext_sparse.has_period.replace({True: 1, False: 0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv = cv_events(pd.concat([pheme_sparse, pheme_event], axis=1))\n",
    "cv = cv_events(pd.concat([pheme_sparse, pheme_y, pheme_event],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance on Sparse Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 21: capital_ratio (0.070348)\n",
      "2. feature 22: tweet_count (0.067731)\n",
      "3. feature 25: follow_ratio (0.065416)\n",
      "4. feature 23: listed_count (0.061458)\n",
      "5. feature 16: char_count (0.057502)\n",
      "6. feature 17: word_count (0.056836)\n",
      "7. feature 24: friends_count (0.053489)\n",
      "8. feature 1: Noun (0.052405)\n",
      "9. feature 2: Verb (0.051640)\n",
      "10. feature 3: Adjective (0.047992)\n",
      "11. feature 10: Conjunction_inj (0.047734)\n",
      "12. feature 15: HashTag (0.045334)\n",
      "13. feature 12: Determiner (0.043449)\n",
      "14. feature 9: Numeral (0.040898)\n",
      "15. feature 8: Adverb (0.035493)\n",
      "16. feature 0: URLcount (0.033127)\n",
      "17. feature 4: Pronoun (0.025715)\n",
      "18. feature 5: FirstPersonPronoun (0.024285)\n",
      "19. feature 26: verified (0.021909)\n",
      "20. feature 14: Whs (0.019576)\n",
      "21. feature 13: Modal (0.015865)\n",
      "22. feature 7: ThirdPersonPronoun (0.013858)\n",
      "23. feature 11: Particle (0.012361)\n",
      "24. feature 20: has_period (0.011424)\n",
      "25. feature 6: SecondPersonPronoun (0.009101)\n",
      "26. feature 18: has_question (0.008733)\n",
      "27. feature 19: has_exclaim (0.006321)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 432x288 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(pheme_sparse)\n",
    "\n",
    "forest = ExtraTreesClassifier(n_estimators=250,\n",
    "                              random_state=3)\n",
    "\n",
    "forest.fit(X, pheme_y)\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(pheme_sparse.shape[1]):\n",
    "    print(\"%d. feature %d: %s (%f)\" % (f + 1, indices[f], pheme_sparse.columns[indices[f]], importances[indices[f]]))\n",
    "\n",
    "# Plot the impurity-based feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(pheme_sparse.shape[1]), importances[indices],\n",
    "        color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(pheme_sparse.shape[1]), indices)\n",
    "plt.xlim([-1, pheme_sparse.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>URLcount</th>\n      <th>Noun</th>\n      <th>Verb</th>\n      <th>Adjective</th>\n      <th>Pronoun</th>\n      <th>FirstPersonPronoun</th>\n      <th>SecondPersonPronoun</th>\n      <th>ThirdPersonPronoun</th>\n      <th>Adverb</th>\n      <th>Numeral</th>\n      <th>...</th>\n      <th>word_count</th>\n      <th>has_question</th>\n      <th>has_exclaim</th>\n      <th>has_period</th>\n      <th>capital_ratio</th>\n      <th>tweet_count</th>\n      <th>listed_count</th>\n      <th>friends_count</th>\n      <th>follow_ratio</th>\n      <th>verified</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>7</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>12</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.159091</td>\n      <td>15.956172</td>\n      <td>7177</td>\n      <td>614</td>\n      <td>17.564194</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.037736</td>\n      <td>10.071462</td>\n      <td>140</td>\n      <td>375</td>\n      <td>12.201205</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>4</td>\n      <td>4</td>\n      <td>7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>18</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.073529</td>\n      <td>12.810170</td>\n      <td>758</td>\n      <td>592</td>\n      <td>14.316352</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>4</td>\n      <td>5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>16</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.101449</td>\n      <td>15.732035</td>\n      <td>102287</td>\n      <td>1038</td>\n      <td>23.876904</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>7</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>13</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.145299</td>\n      <td>16.680002</td>\n      <td>13583</td>\n      <td>460</td>\n      <td>19.683865</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 27 columns</p>\n</div>",
      "text/plain": "   URLcount  Noun  Verb  Adjective  Pronoun  FirstPersonPronoun  \\\n0         1     7     2          0        0                   0   \n1         0     3     2          0        0                   0   \n2         0     4     4          7        0                   0   \n3         2     4     5          1        0                   0   \n4         2     7     2          0        0                   0   \n\n   SecondPersonPronoun  ThirdPersonPronoun  Adverb  Numeral  ...  word_count  \\\n0                    0                   0       0        0  ...          12   \n1                    0                   0       0        0  ...           6   \n2                    0                   0       1        0  ...          18   \n3                    0                   0       0        0  ...          16   \n4                    0                   0       0        0  ...          13   \n\n   has_question  has_exclaim  has_period  capital_ratio  tweet_count  \\\n0             0            0           1       0.159091    15.956172   \n1             0            0           1       0.037736    10.071462   \n2             0            0           1       0.073529    12.810170   \n3             0            0           1       0.101449    15.732035   \n4             0            0           1       0.145299    16.680002   \n\n   listed_count  friends_count  follow_ratio  verified  \n0          7177            614     17.564194         1  \n1           140            375     12.201205         0  \n2           758            592     14.316352         0  \n3        102287           1038     23.876904         1  \n4         13583            460     19.683865         1  \n\n[5 rows x 27 columns]"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pheme_sparse.head()\n",
    "# pheme_sparse.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.2865979381443299\n",
      "Precision Score:\t 0.9259259259259259\n",
      "Recall Score:\t\t0.06775067750677506\n",
      "F1 Score:\t\t 0.2617375849083166\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.98      0.40       116\n",
      "           1       0.93      0.07      0.13       369\n",
      "\n",
      "    accuracy                           0.29       485\n",
      "   macro avg       0.59      0.53      0.26       485\n",
      "weighted avg       0.76      0.29      0.19       485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = make_pipeline((StandardScaler()), SVC(gamma='auto'))\n",
    "train_test(pheme_sparse, ext_sparse, pheme_y, ext_y, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.23917525773195877\n",
      "Precision Score:\t 0.5\n",
      "Recall Score:\t\t0.0027100271002710027\n",
      "F1 Score:\t\t 0.19468206219710296\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.99      0.38       116\n",
      "           1       0.50      0.00      0.01       369\n",
      "\n",
      "    accuracy                           0.24       485\n",
      "   macro avg       0.37      0.50      0.19       485\n",
      "weighted avg       0.44      0.24      0.10       485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "train_test(pheme_sparse, ext_sparse, pheme_y, ext_y, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.31958762886597936\n",
      "Precision Score:\t 0.975609756097561\n",
      "Recall Score:\t\t0.10840108401084012\n",
      "F1 Score:\t\t 0.302918118466899\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.99      0.41       116\n",
      "           1       0.98      0.11      0.20       369\n",
      "\n",
      "    accuracy                           0.32       485\n",
      "   macro avg       0.62      0.55      0.30       485\n",
      "weighted avg       0.80      0.32      0.25       485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = make_pipeline((StandardScaler()), GradientBoostingClassifier())\n",
    "train_test(pheme_sparse, ext_sparse, pheme_y, ext_y, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.32989690721649484\n",
      "Precision Score:\t 0.9074074074074074\n",
      "Recall Score:\t\t0.13279132791327913\n",
      "F1 Score:\t\t 0.3187642892026571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.96      0.41       116\n",
      "           1       0.91      0.13      0.23       369\n",
      "\n",
      "    accuracy                           0.33       485\n",
      "   macro avg       0.58      0.54      0.32       485\n",
      "weighted avg       0.75      0.33      0.27       485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clf = make_pipeline((StandardScaler()), model.best_estimator_)\n",
    "clf = make_pipeline((StandardScaler()), AdaBoostClassifier())\n",
    "train_test(pheme_sparse, ext_sparse, pheme_y, ext_y, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPARSE - PHEME CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.47191011235955055\n",
      "Precision Score:\t 0.0\n",
      "Recall Score:\t\t0.0\n",
      "F1 Score:\t\t 0.32061068702290074\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      1.00      0.64       420\n",
      "           1       0.00      0.00      0.00       470\n",
      "\n",
      "    accuracy                           0.47       890\n",
      "   macro avg       0.24      0.50      0.32       890\n",
      "weighted avg       0.22      0.47      0.30       890\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/june/miniconda3/envs/rosetta/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/june/miniconda3/envs/rosetta/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/june/miniconda3/envs/rosetta/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/june/miniconda3/envs/rosetta/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "X = cv[3][1].drop(['target', 'Event'],axis=1)\n",
    "y = cv[3][1].target\n",
    "val_X = cv[3][0].drop(['target', 'Event'],axis=1)\n",
    "val_y = cv[3][0].target\n",
    "clf = SVC(gamma='auto')\n",
    "train_test(X, val_X, y, val_y, clf)\n",
    "# valid(rhi, rhi_y, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparse + W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_w2v = pd.concat([pheme_sparse, pheme_AVGw2v],axis=1)\n",
    "sparse_w2v_ext = pd.concat([ext_sparse, ext_AVGw2v],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Columns: 227 entries, URLcount to vec_avg199\n",
      "dtypes: bool(4), float64(203), int64(20)\n",
      "memory usage: 5.4 KB\n"
     ]
    }
   ],
   "source": [
    "sparse_w2v.head(3).info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.29690721649484536\n",
      "Precision Score:\t 0.8888888888888888\n",
      "Recall Score:\t\t0.08672086720867209\n",
      "F1 Score:\t\t 0.27724243417458755\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.97      0.40       116\n",
      "           1       0.89      0.09      0.16       369\n",
      "\n",
      "    accuracy                           0.30       485\n",
      "   macro avg       0.57      0.53      0.28       485\n",
      "weighted avg       0.74      0.30      0.22       485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = make_pipeline((StandardScaler()), SVC(gamma='auto'))\n",
    "train_test(sparse_w2v, sparse_w2v_ext, pheme_y, ext_y, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.3525773195876289\n",
      "Precision Score:\t 0.9365079365079365\n",
      "Recall Score:\t\t0.15989159891598917\n",
      "F1 Score:\t\t 0.3447525127357841\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.97      0.42       116\n",
      "           1       0.94      0.16      0.27       369\n",
      "\n",
      "    accuracy                           0.35       485\n",
      "   macro avg       0.60      0.56      0.34       485\n",
      "weighted avg       0.78      0.35      0.31       485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = make_pipeline((StandardScaler()), GaussianNB())\n",
    "train_test(sparse_w2v, sparse_w2v_ext, pheme_y, ext_y, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.44948453608247424\n",
      "Precision Score:\t 0.8923076923076924\n",
      "Recall Score:\t\t0.3143631436314363\n",
      "F1 Score:\t\t 0.4490254394138596\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.88      0.43       116\n",
      "           1       0.89      0.31      0.46       369\n",
      "\n",
      "    accuracy                           0.45       485\n",
      "   macro avg       0.59      0.60      0.45       485\n",
      "weighted avg       0.75      0.45      0.46       485\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/june/miniconda3/envs/rosetta/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "clf = make_pipeline((StandardScaler()), LogisticRegression())\n",
    "train_test(sparse_w2v, sparse_w2v_ext, pheme_y, ext_y, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.311340206185567\n",
      "Precision Score:\t 0.9069767441860465\n",
      "Recall Score:\t\t0.10569105691056911\n",
      "F1 Score:\t\t 0.29537704005289345\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.97      0.40       116\n",
      "           1       0.91      0.11      0.19       369\n",
      "\n",
      "    accuracy                           0.31       485\n",
      "   macro avg       0.58      0.54      0.30       485\n",
      "weighted avg       0.75      0.31      0.24       485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = make_pipeline((StandardScaler()), GradientBoostingClassifier())\n",
    "train_test(sparse_w2v, sparse_w2v_ext, pheme_y, ext_y, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.25773195876288657\n",
      "Precision Score:\t 1.0\n",
      "Recall Score:\t\t0.024390243902439025\n",
      "F1 Score:\t\t 0.21975546975546975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      1.00      0.39       116\n",
      "           1       1.00      0.02      0.05       369\n",
      "\n",
      "    accuracy                           0.26       485\n",
      "   macro avg       0.62      0.51      0.22       485\n",
      "weighted avg       0.82      0.26      0.13       485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # ------------------------------------ RF ------------------------------------ #\n",
    "\n",
    "# model = RandomForestClassifier()\n",
    "# param_grid = {\n",
    "#     'n_estimators': [400, 700, 1000],\n",
    "#     'max_depth': [15,20,25],\n",
    "#     'max_leaf_nodes': [50, 100, 200]\n",
    "# }\n",
    "\n",
    "# model, pred = algorithm_pipeline(pheme_sparse, ext_sparse, pheme_y, ext_y, model, \n",
    "#                                  param_grid, cv=5, scoring_fit='accuracy')\n",
    "\n",
    "# print(model.best_score_)\n",
    "# print(model.best_params_)\n",
    "\n",
    "clf = make_pipeline((StandardScaler()), model.best_estimator_)\n",
    "train_test(sparse_w2v, sparse_w2v_ext, pheme_y, ext_y, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>BERTEmbed_0</th>\n      <th>BERTEmbed_1</th>\n      <th>BERTEmbed_2</th>\n      <th>BERTEmbed_3</th>\n      <th>BERTEmbed_4</th>\n      <th>BERTEmbed_5</th>\n      <th>BERTEmbed_6</th>\n      <th>BERTEmbed_7</th>\n      <th>BERTEmbed_8</th>\n      <th>BERTEmbed_9</th>\n      <th>...</th>\n      <th>BERTEmbed_758</th>\n      <th>BERTEmbed_759</th>\n      <th>BERTEmbed_760</th>\n      <th>BERTEmbed_761</th>\n      <th>BERTEmbed_762</th>\n      <th>BERTEmbed_763</th>\n      <th>BERTEmbed_764</th>\n      <th>BERTEmbed_765</th>\n      <th>BERTEmbed_766</th>\n      <th>BERTEmbed_767</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.299457</td>\n      <td>0.198897</td>\n      <td>-0.491295</td>\n      <td>0.211787</td>\n      <td>0.197080</td>\n      <td>0.234026</td>\n      <td>0.200608</td>\n      <td>-0.096086</td>\n      <td>0.250423</td>\n      <td>0.266876</td>\n      <td>...</td>\n      <td>0.209932</td>\n      <td>-0.166056</td>\n      <td>0.245046</td>\n      <td>-0.580443</td>\n      <td>-0.141690</td>\n      <td>0.222918</td>\n      <td>-0.144328</td>\n      <td>0.048243</td>\n      <td>-0.027414</td>\n      <td>-0.055394</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.299628</td>\n      <td>0.207495</td>\n      <td>-0.491100</td>\n      <td>0.207046</td>\n      <td>0.198606</td>\n      <td>0.223802</td>\n      <td>0.201070</td>\n      <td>-0.085390</td>\n      <td>0.272306</td>\n      <td>0.276768</td>\n      <td>...</td>\n      <td>0.227522</td>\n      <td>-0.168281</td>\n      <td>0.246145</td>\n      <td>-0.575933</td>\n      <td>-0.133583</td>\n      <td>0.210461</td>\n      <td>-0.141031</td>\n      <td>0.049042</td>\n      <td>-0.035745</td>\n      <td>-0.065774</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.300907</td>\n      <td>0.193260</td>\n      <td>-0.498778</td>\n      <td>0.215972</td>\n      <td>0.193097</td>\n      <td>0.223985</td>\n      <td>0.181815</td>\n      <td>-0.106533</td>\n      <td>0.247362</td>\n      <td>0.262557</td>\n      <td>...</td>\n      <td>0.210722</td>\n      <td>-0.168287</td>\n      <td>0.242233</td>\n      <td>-0.579043</td>\n      <td>-0.142183</td>\n      <td>0.223372</td>\n      <td>-0.142068</td>\n      <td>0.043969</td>\n      <td>-0.031963</td>\n      <td>-0.054336</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.294519</td>\n      <td>0.198307</td>\n      <td>-0.492020</td>\n      <td>0.211912</td>\n      <td>0.201571</td>\n      <td>0.225530</td>\n      <td>0.192947</td>\n      <td>-0.100199</td>\n      <td>0.261141</td>\n      <td>0.264648</td>\n      <td>...</td>\n      <td>0.216593</td>\n      <td>-0.163219</td>\n      <td>0.242032</td>\n      <td>-0.586569</td>\n      <td>-0.137623</td>\n      <td>0.219293</td>\n      <td>-0.139870</td>\n      <td>0.039641</td>\n      <td>-0.034909</td>\n      <td>-0.062468</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.296625</td>\n      <td>0.196416</td>\n      <td>-0.493361</td>\n      <td>0.214012</td>\n      <td>0.195244</td>\n      <td>0.231359</td>\n      <td>0.194209</td>\n      <td>-0.101270</td>\n      <td>0.252890</td>\n      <td>0.263173</td>\n      <td>...</td>\n      <td>0.211895</td>\n      <td>-0.166441</td>\n      <td>0.237079</td>\n      <td>-0.587006</td>\n      <td>-0.140724</td>\n      <td>0.224566</td>\n      <td>-0.142844</td>\n      <td>0.041942</td>\n      <td>-0.030708</td>\n      <td>-0.056173</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 768 columns</p>\n</div>",
      "text/plain": "   BERTEmbed_0  BERTEmbed_1  BERTEmbed_2  BERTEmbed_3  BERTEmbed_4  \\\n0     0.299457     0.198897    -0.491295     0.211787     0.197080   \n1     0.299628     0.207495    -0.491100     0.207046     0.198606   \n2     0.300907     0.193260    -0.498778     0.215972     0.193097   \n3     0.294519     0.198307    -0.492020     0.211912     0.201571   \n4     0.296625     0.196416    -0.493361     0.214012     0.195244   \n\n   BERTEmbed_5  BERTEmbed_6  BERTEmbed_7  BERTEmbed_8  BERTEmbed_9  ...  \\\n0     0.234026     0.200608    -0.096086     0.250423     0.266876  ...   \n1     0.223802     0.201070    -0.085390     0.272306     0.276768  ...   \n2     0.223985     0.181815    -0.106533     0.247362     0.262557  ...   \n3     0.225530     0.192947    -0.100199     0.261141     0.264648  ...   \n4     0.231359     0.194209    -0.101270     0.252890     0.263173  ...   \n\n   BERTEmbed_758  BERTEmbed_759  BERTEmbed_760  BERTEmbed_761  BERTEmbed_762  \\\n0       0.209932      -0.166056       0.245046      -0.580443      -0.141690   \n1       0.227522      -0.168281       0.246145      -0.575933      -0.133583   \n2       0.210722      -0.168287       0.242233      -0.579043      -0.142183   \n3       0.216593      -0.163219       0.242032      -0.586569      -0.137623   \n4       0.211895      -0.166441       0.237079      -0.587006      -0.140724   \n\n   BERTEmbed_763  BERTEmbed_764  BERTEmbed_765  BERTEmbed_766  BERTEmbed_767  \n0       0.222918      -0.144328       0.048243      -0.027414      -0.055394  \n1       0.210461      -0.141031       0.049042      -0.035745      -0.065774  \n2       0.223372      -0.142068       0.043969      -0.031963      -0.054336  \n3       0.219293      -0.139870       0.039641      -0.034909      -0.062468  \n4       0.224566      -0.142844       0.041942      -0.030708      -0.056173  \n\n[5 rows x 768 columns]"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pheme_y.head()\n",
    "pheme_bert.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.3938144329896907\n",
      "Precision Score:\t 0.8205128205128205\n",
      "Recall Score:\t\t0.2601626016260163\n",
      "F1 Score:\t\t 0.393811855933068\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.82      0.39       116\n",
      "           1       0.82      0.26      0.40       369\n",
      "\n",
      "    accuracy                           0.39       485\n",
      "   macro avg       0.54      0.54      0.39       485\n",
      "weighted avg       0.69      0.39      0.39       485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "train_test(pheme_bert, ext_bert, pheme_y, ext_y, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.6268041237113402\n",
      "Precision Score:\t 0.7596685082872928\n",
      "Recall Score:\t\t0.7452574525745257\n",
      "F1 Score:\t\t 0.49753590255796776\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.25      0.24       116\n",
      "           1       0.76      0.75      0.75       369\n",
      "\n",
      "    accuracy                           0.63       485\n",
      "   macro avg       0.50      0.50      0.50       485\n",
      "weighted avg       0.63      0.63      0.63       485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = make_pipeline(StandardScaler(), GaussianNB())\n",
    "# clf = GaussianNB()\n",
    "train_test(pheme_bert, ext_bert, pheme_y, ext_y, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.30721649484536084\n",
      "Precision Score:\t 0.9230769230769231\n",
      "Recall Score:\t\t0.0975609756097561\n",
      "F1 Score:\t\t 0.2893029097760101\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.97      0.40       116\n",
      "           1       0.92      0.10      0.18       369\n",
      "\n",
      "    accuracy                           0.31       485\n",
      "   macro avg       0.59      0.54      0.29       485\n",
      "weighted avg       0.76      0.31      0.23       485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = make_pipeline(StandardScaler(), GradientBoostingClassifier())\n",
    "train_test(pheme_bert, ext_bert, pheme_y, ext_y, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t 0.3835051546391753\n",
      "Precision Score:\t 0.9375\n",
      "Recall Score:\t\t0.2032520325203252\n",
      "F1 Score:\t\t 0.3800896853318742\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.96      0.43       116\n",
      "           1       0.94      0.20      0.33       369\n",
      "\n",
      "    accuracy                           0.38       485\n",
      "   macro avg       0.61      0.58      0.38       485\n",
      "weighted avg       0.78      0.38      0.36       485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clf = make_pipeline((StandardScaler()), model.best_estimator_)\n",
    "# clf = make_pipeline(StandardScaler(), AdaBoostClassifier())\n",
    "clf = AdaBoostClassifier()\n",
    "train_test(pheme_bert, ext_bert, pheme_y, ext_y, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT + SPARSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rosetta",
   "language": "python",
   "name": "rosetta"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}